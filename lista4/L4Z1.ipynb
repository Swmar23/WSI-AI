{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3+m4uiYrdpT6b9RIrwp6B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swmar23/WSI-AI/blob/main/lista4/L4Z1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Marek Świergoń 261750\n",
        "\n",
        "# **Sprawozdanie z zadania 1 z listy 4 — laboratorium z Wprowadzenia do Sztucznej Inteligencji**\n",
        "\n",
        "Celem zadania było stworzenie i wytrenowania lasu decyzyjnego do rozpoznawania cyfr z obrazków rozmiaru 28 na 28 pikseli. Za zbiór danych do uczenia i testowania lasu przyjęty został [The MNIST Database of Handwritten Digits](http://yann.lecun.com/exdb/mnist/).\n",
        "\n",
        "Do utworzenia lasu decyzyjnego wykorzystałem bibliotekę `tensorflow_decision_forests`. Ponieważ nie jest ona domyślnie zainstalowana w środowisko Google Colab, to musiałem ją doinstalować poleceniem `!pip install tensorflow_decision_forests`.\n",
        "\n",
        "Drzewa decyzyjne przyjmują na wstępie dane obrazka w postaci tablic 28 * 28 = 784 zmiennych. Każda ze zmiennych przyjmuje wartości z zakresu 0.0 - 1.0 po odpowiednim przeskalowaniu pikseli, które pierwotnie mają zakres całkowitoliczbowy {0,1,...,255}.\n",
        "\n",
        "Konstruktorem `RandomForestModel(verbose=2, num_trees)` tworzę losowy las decyzyjny składający się z 50 drzew decyzyjnych.\n",
        "\n",
        "Do lasu decyzyjnego przekazuję treningowy zbiór obrazków (zapisanych jako jednowymiarowe tablice) i etykiet za pomocą `model_1.fit(data_train, labels_train)`.\n",
        "\n",
        "Po skończonym procesie tworzenia lasu decyzyjnego poleceniem `model_1.summary()` wyświetlam szczegółowe dane dotyczące np. znaczenia poszczególnych zmiennych (pikseli) przy podejmowaniu przez drzewa decyzji ostatecznie kwalifikującej do danej etykiety. W wynikach znajduje się również Confusion Table, czyli tabela, która pokazuje rozkład predykcji lasu względem faktycznych etykiet (wartości przesunięte o 1, czyli wiersz 1 dotyczy etykiety 0; analogicznie kolumna)\n",
        "\n",
        "Ostatecznie testuję las decyzyjny na zbiorze testowym metodą `model_1.evaluate(data_test, labels_test, return_dict=True)`. Otrzymuję współczynnik rozpoznawalności wynoszący około 96,5%. Jest to dobry wynik, choć gorszy od wyniku uzyskanego przez sieć neuronową z listy 3. Początkowo dodawanie kolejnych drzew do lasu daje wymiernie lepsze wyniki (przykładowo dla 1 drzewa skuteczność około 83% dla danych treningowych, dla 11 drzew 90,5%, dla 21 drzew 94%) jednak im więcej jest drzew w lesie, tym mniejszy wpływ na wynik mają kolejne dodane drzewa. Nawet 500 drzew decyzyjnych nie jest w stanie uzyskać wyniku otrzymanego z wykorzystaniem sieci neuronowej, tj. 97,7%.\n",
        "\n",
        "Proces tworzenia skutecznego lasu decyzyjnego jest bardziej czasochłonny niż wyszkolenie sieci neuronowej do zbliżonego poziomu współczynnika rozpoznawalności."
      ],
      "metadata": {
        "id": "E3rWV4Wb3gco"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtGfpVFba-ay",
        "outputId": "028ea923-1e27-4ff7-a59d-b635683bbfdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_decision_forests in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.5.3)\n",
            "Requirement already satisfied: tensorflow~=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.40.0)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (3.0.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (0.32.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2022.7.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tensorflow_decision_forests) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tensorflow_decision_forests) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (3.2.2)\n",
            "Use 2 thread(s) for training\n",
            "Use /tmp/tmptw28g65i as temporary training directory\n",
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: Tensor(\"data:0\", shape=(32, 784), dtype=float32)\n",
            "Label: Tensor(\"data_1:0\", shape=(32,), dtype=uint8)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(32,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(32,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(32,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(32,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(32,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(32,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(32,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(32,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(32,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(32,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(32,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(32,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(32,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(32,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(32,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(32,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(32,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(32,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(32,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(32,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(32,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(32,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(32,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(32,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(32,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(32,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(32,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(32,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(32,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(32,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(32,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(32,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(32,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(32,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(32,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(32,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(32,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(32,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(32,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(32,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(32,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(32,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(32,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(32,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(32,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(32,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(32,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(32,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(32,) dtype=float32>), 'data:0.49': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_49:0' shape=(32,) dtype=float32>), 'data:0.50': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_50:0' shape=(32,) dtype=float32>), 'data:0.51': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_51:0' shape=(32,) dtype=float32>), 'data:0.52': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_52:0' shape=(32,) dtype=float32>), 'data:0.53': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_53:0' shape=(32,) dtype=float32>), 'data:0.54': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_54:0' shape=(32,) dtype=float32>), 'data:0.55': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_55:0' shape=(32,) dtype=float32>), 'data:0.56': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_56:0' shape=(32,) dtype=float32>), 'data:0.57': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_57:0' shape=(32,) dtype=float32>), 'data:0.58': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_58:0' shape=(32,) dtype=float32>), 'data:0.59': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_59:0' shape=(32,) dtype=float32>), 'data:0.60': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_60:0' shape=(32,) dtype=float32>), 'data:0.61': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_61:0' shape=(32,) dtype=float32>), 'data:0.62': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_62:0' shape=(32,) dtype=float32>), 'data:0.63': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_63:0' shape=(32,) dtype=float32>), 'data:0.64': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_64:0' shape=(32,) dtype=float32>), 'data:0.65': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_65:0' shape=(32,) dtype=float32>), 'data:0.66': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_66:0' shape=(32,) dtype=float32>), 'data:0.67': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_67:0' shape=(32,) dtype=float32>), 'data:0.68': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_68:0' shape=(32,) dtype=float32>), 'data:0.69': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_69:0' shape=(32,) dtype=float32>), 'data:0.70': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_70:0' shape=(32,) dtype=float32>), 'data:0.71': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_71:0' shape=(32,) dtype=float32>), 'data:0.72': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_72:0' shape=(32,) dtype=float32>), 'data:0.73': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_73:0' shape=(32,) dtype=float32>), 'data:0.74': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_74:0' shape=(32,) dtype=float32>), 'data:0.75': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_75:0' shape=(32,) dtype=float32>), 'data:0.76': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_76:0' shape=(32,) dtype=float32>), 'data:0.77': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_77:0' shape=(32,) dtype=float32>), 'data:0.78': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_78:0' shape=(32,) dtype=float32>), 'data:0.79': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_79:0' shape=(32,) dtype=float32>), 'data:0.80': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_80:0' shape=(32,) dtype=float32>), 'data:0.81': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_81:0' shape=(32,) dtype=float32>), 'data:0.82': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_82:0' shape=(32,) dtype=float32>), 'data:0.83': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_83:0' shape=(32,) dtype=float32>), 'data:0.84': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_84:0' shape=(32,) dtype=float32>), 'data:0.85': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_85:0' shape=(32,) dtype=float32>), 'data:0.86': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_86:0' shape=(32,) dtype=float32>), 'data:0.87': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_87:0' shape=(32,) dtype=float32>), 'data:0.88': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_88:0' shape=(32,) dtype=float32>), 'data:0.89': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_89:0' shape=(32,) dtype=float32>), 'data:0.90': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_90:0' shape=(32,) dtype=float32>), 'data:0.91': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_91:0' shape=(32,) dtype=float32>), 'data:0.92': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_92:0' shape=(32,) dtype=float32>), 'data:0.93': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_93:0' shape=(32,) dtype=float32>), 'data:0.94': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_94:0' shape=(32,) dtype=float32>), 'data:0.95': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_95:0' shape=(32,) dtype=float32>), 'data:0.96': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_96:0' shape=(32,) dtype=float32>), 'data:0.97': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_97:0' shape=(32,) dtype=float32>), 'data:0.98': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_98:0' shape=(32,) dtype=float32>), 'data:0.99': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_99:0' shape=(32,) dtype=float32>), 'data:0.100': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_100:0' shape=(32,) dtype=float32>), 'data:0.101': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_101:0' shape=(32,) dtype=float32>), 'data:0.102': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_102:0' shape=(32,) dtype=float32>), 'data:0.103': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_103:0' shape=(32,) dtype=float32>), 'data:0.104': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_104:0' shape=(32,) dtype=float32>), 'data:0.105': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_105:0' shape=(32,) dtype=float32>), 'data:0.106': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_106:0' shape=(32,) dtype=float32>), 'data:0.107': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_107:0' shape=(32,) dtype=float32>), 'data:0.108': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_108:0' shape=(32,) dtype=float32>), 'data:0.109': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_109:0' shape=(32,) dtype=float32>), 'data:0.110': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_110:0' shape=(32,) dtype=float32>), 'data:0.111': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_111:0' shape=(32,) dtype=float32>), 'data:0.112': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_112:0' shape=(32,) dtype=float32>), 'data:0.113': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_113:0' shape=(32,) dtype=float32>), 'data:0.114': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_114:0' shape=(32,) dtype=float32>), 'data:0.115': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_115:0' shape=(32,) dtype=float32>), 'data:0.116': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_116:0' shape=(32,) dtype=float32>), 'data:0.117': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_117:0' shape=(32,) dtype=float32>), 'data:0.118': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_118:0' shape=(32,) dtype=float32>), 'data:0.119': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_119:0' shape=(32,) dtype=float32>), 'data:0.120': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_120:0' shape=(32,) dtype=float32>), 'data:0.121': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_121:0' shape=(32,) dtype=float32>), 'data:0.122': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_122:0' shape=(32,) dtype=float32>), 'data:0.123': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_123:0' shape=(32,) dtype=float32>), 'data:0.124': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_124:0' shape=(32,) dtype=float32>), 'data:0.125': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_125:0' shape=(32,) dtype=float32>), 'data:0.126': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_126:0' shape=(32,) dtype=float32>), 'data:0.127': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_127:0' shape=(32,) dtype=float32>), 'data:0.128': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_128:0' shape=(32,) dtype=float32>), 'data:0.129': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_129:0' shape=(32,) dtype=float32>), 'data:0.130': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_130:0' shape=(32,) dtype=float32>), 'data:0.131': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_131:0' shape=(32,) dtype=float32>), 'data:0.132': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_132:0' shape=(32,) dtype=float32>), 'data:0.133': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_133:0' shape=(32,) dtype=float32>), 'data:0.134': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_134:0' shape=(32,) dtype=float32>), 'data:0.135': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_135:0' shape=(32,) dtype=float32>), 'data:0.136': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_136:0' shape=(32,) dtype=float32>), 'data:0.137': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_137:0' shape=(32,) dtype=float32>), 'data:0.138': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_138:0' shape=(32,) dtype=float32>), 'data:0.139': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_139:0' shape=(32,) dtype=float32>), 'data:0.140': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_140:0' shape=(32,) dtype=float32>), 'data:0.141': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_141:0' shape=(32,) dtype=float32>), 'data:0.142': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_142:0' shape=(32,) dtype=float32>), 'data:0.143': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_143:0' shape=(32,) dtype=float32>), 'data:0.144': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_144:0' shape=(32,) dtype=float32>), 'data:0.145': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_145:0' shape=(32,) dtype=float32>), 'data:0.146': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_146:0' shape=(32,) dtype=float32>), 'data:0.147': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_147:0' shape=(32,) dtype=float32>), 'data:0.148': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_148:0' shape=(32,) dtype=float32>), 'data:0.149': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_149:0' shape=(32,) dtype=float32>), 'data:0.150': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_150:0' shape=(32,) dtype=float32>), 'data:0.151': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_151:0' shape=(32,) dtype=float32>), 'data:0.152': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_152:0' shape=(32,) dtype=float32>), 'data:0.153': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_153:0' shape=(32,) dtype=float32>), 'data:0.154': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_154:0' shape=(32,) dtype=float32>), 'data:0.155': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_155:0' shape=(32,) dtype=float32>), 'data:0.156': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_156:0' shape=(32,) dtype=float32>), 'data:0.157': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_157:0' shape=(32,) dtype=float32>), 'data:0.158': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_158:0' shape=(32,) dtype=float32>), 'data:0.159': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_159:0' shape=(32,) dtype=float32>), 'data:0.160': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_160:0' shape=(32,) dtype=float32>), 'data:0.161': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_161:0' shape=(32,) dtype=float32>), 'data:0.162': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_162:0' shape=(32,) dtype=float32>), 'data:0.163': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_163:0' shape=(32,) dtype=float32>), 'data:0.164': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_164:0' shape=(32,) dtype=float32>), 'data:0.165': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_165:0' shape=(32,) dtype=float32>), 'data:0.166': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_166:0' shape=(32,) dtype=float32>), 'data:0.167': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_167:0' shape=(32,) dtype=float32>), 'data:0.168': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_168:0' shape=(32,) dtype=float32>), 'data:0.169': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_169:0' shape=(32,) dtype=float32>), 'data:0.170': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_170:0' shape=(32,) dtype=float32>), 'data:0.171': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_171:0' shape=(32,) dtype=float32>), 'data:0.172': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_172:0' shape=(32,) dtype=float32>), 'data:0.173': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_173:0' shape=(32,) dtype=float32>), 'data:0.174': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_174:0' shape=(32,) dtype=float32>), 'data:0.175': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_175:0' shape=(32,) dtype=float32>), 'data:0.176': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_176:0' shape=(32,) dtype=float32>), 'data:0.177': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_177:0' shape=(32,) dtype=float32>), 'data:0.178': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_178:0' shape=(32,) dtype=float32>), 'data:0.179': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_179:0' shape=(32,) dtype=float32>), 'data:0.180': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_180:0' shape=(32,) dtype=float32>), 'data:0.181': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_181:0' shape=(32,) dtype=float32>), 'data:0.182': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_182:0' shape=(32,) dtype=float32>), 'data:0.183': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_183:0' shape=(32,) dtype=float32>), 'data:0.184': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_184:0' shape=(32,) dtype=float32>), 'data:0.185': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_185:0' shape=(32,) dtype=float32>), 'data:0.186': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_186:0' shape=(32,) dtype=float32>), 'data:0.187': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_187:0' shape=(32,) dtype=float32>), 'data:0.188': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_188:0' shape=(32,) dtype=float32>), 'data:0.189': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_189:0' shape=(32,) dtype=float32>), 'data:0.190': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_190:0' shape=(32,) dtype=float32>), 'data:0.191': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_191:0' shape=(32,) dtype=float32>), 'data:0.192': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_192:0' shape=(32,) dtype=float32>), 'data:0.193': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_193:0' shape=(32,) dtype=float32>), 'data:0.194': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_194:0' shape=(32,) dtype=float32>), 'data:0.195': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_195:0' shape=(32,) dtype=float32>), 'data:0.196': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_196:0' shape=(32,) dtype=float32>), 'data:0.197': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_197:0' shape=(32,) dtype=float32>), 'data:0.198': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_198:0' shape=(32,) dtype=float32>), 'data:0.199': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_199:0' shape=(32,) dtype=float32>), 'data:0.200': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_200:0' shape=(32,) dtype=float32>), 'data:0.201': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_201:0' shape=(32,) dtype=float32>), 'data:0.202': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_202:0' shape=(32,) dtype=float32>), 'data:0.203': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_203:0' shape=(32,) dtype=float32>), 'data:0.204': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_204:0' shape=(32,) dtype=float32>), 'data:0.205': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_205:0' shape=(32,) dtype=float32>), 'data:0.206': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_206:0' shape=(32,) dtype=float32>), 'data:0.207': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_207:0' shape=(32,) dtype=float32>), 'data:0.208': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_208:0' shape=(32,) dtype=float32>), 'data:0.209': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_209:0' shape=(32,) dtype=float32>), 'data:0.210': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_210:0' shape=(32,) dtype=float32>), 'data:0.211': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_211:0' shape=(32,) dtype=float32>), 'data:0.212': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_212:0' shape=(32,) dtype=float32>), 'data:0.213': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_213:0' shape=(32,) dtype=float32>), 'data:0.214': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_214:0' shape=(32,) dtype=float32>), 'data:0.215': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_215:0' shape=(32,) dtype=float32>), 'data:0.216': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_216:0' shape=(32,) dtype=float32>), 'data:0.217': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_217:0' shape=(32,) dtype=float32>), 'data:0.218': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_218:0' shape=(32,) dtype=float32>), 'data:0.219': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_219:0' shape=(32,) dtype=float32>), 'data:0.220': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_220:0' shape=(32,) dtype=float32>), 'data:0.221': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_221:0' shape=(32,) dtype=float32>), 'data:0.222': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_222:0' shape=(32,) dtype=float32>), 'data:0.223': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_223:0' shape=(32,) dtype=float32>), 'data:0.224': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_224:0' shape=(32,) dtype=float32>), 'data:0.225': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_225:0' shape=(32,) dtype=float32>), 'data:0.226': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_226:0' shape=(32,) dtype=float32>), 'data:0.227': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_227:0' shape=(32,) dtype=float32>), 'data:0.228': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_228:0' shape=(32,) dtype=float32>), 'data:0.229': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_229:0' shape=(32,) dtype=float32>), 'data:0.230': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_230:0' shape=(32,) dtype=float32>), 'data:0.231': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_231:0' shape=(32,) dtype=float32>), 'data:0.232': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_232:0' shape=(32,) dtype=float32>), 'data:0.233': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_233:0' shape=(32,) dtype=float32>), 'data:0.234': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_234:0' shape=(32,) dtype=float32>), 'data:0.235': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_235:0' shape=(32,) dtype=float32>), 'data:0.236': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_236:0' shape=(32,) dtype=float32>), 'data:0.237': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_237:0' shape=(32,) dtype=float32>), 'data:0.238': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_238:0' shape=(32,) dtype=float32>), 'data:0.239': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_239:0' shape=(32,) dtype=float32>), 'data:0.240': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_240:0' shape=(32,) dtype=float32>), 'data:0.241': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_241:0' shape=(32,) dtype=float32>), 'data:0.242': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_242:0' shape=(32,) dtype=float32>), 'data:0.243': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_243:0' shape=(32,) dtype=float32>), 'data:0.244': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_244:0' shape=(32,) dtype=float32>), 'data:0.245': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_245:0' shape=(32,) dtype=float32>), 'data:0.246': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_246:0' shape=(32,) dtype=float32>), 'data:0.247': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_247:0' shape=(32,) dtype=float32>), 'data:0.248': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_248:0' shape=(32,) dtype=float32>), 'data:0.249': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_249:0' shape=(32,) dtype=float32>), 'data:0.250': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_250:0' shape=(32,) dtype=float32>), 'data:0.251': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_251:0' shape=(32,) dtype=float32>), 'data:0.252': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_252:0' shape=(32,) dtype=float32>), 'data:0.253': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_253:0' shape=(32,) dtype=float32>), 'data:0.254': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_254:0' shape=(32,) dtype=float32>), 'data:0.255': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_255:0' shape=(32,) dtype=float32>), 'data:0.256': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_256:0' shape=(32,) dtype=float32>), 'data:0.257': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_257:0' shape=(32,) dtype=float32>), 'data:0.258': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_258:0' shape=(32,) dtype=float32>), 'data:0.259': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_259:0' shape=(32,) dtype=float32>), 'data:0.260': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_260:0' shape=(32,) dtype=float32>), 'data:0.261': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_261:0' shape=(32,) dtype=float32>), 'data:0.262': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_262:0' shape=(32,) dtype=float32>), 'data:0.263': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_263:0' shape=(32,) dtype=float32>), 'data:0.264': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_264:0' shape=(32,) dtype=float32>), 'data:0.265': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_265:0' shape=(32,) dtype=float32>), 'data:0.266': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_266:0' shape=(32,) dtype=float32>), 'data:0.267': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_267:0' shape=(32,) dtype=float32>), 'data:0.268': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_268:0' shape=(32,) dtype=float32>), 'data:0.269': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_269:0' shape=(32,) dtype=float32>), 'data:0.270': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_270:0' shape=(32,) dtype=float32>), 'data:0.271': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_271:0' shape=(32,) dtype=float32>), 'data:0.272': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_272:0' shape=(32,) dtype=float32>), 'data:0.273': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_273:0' shape=(32,) dtype=float32>), 'data:0.274': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_274:0' shape=(32,) dtype=float32>), 'data:0.275': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_275:0' shape=(32,) dtype=float32>), 'data:0.276': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_276:0' shape=(32,) dtype=float32>), 'data:0.277': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_277:0' shape=(32,) dtype=float32>), 'data:0.278': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_278:0' shape=(32,) dtype=float32>), 'data:0.279': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_279:0' shape=(32,) dtype=float32>), 'data:0.280': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_280:0' shape=(32,) dtype=float32>), 'data:0.281': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_281:0' shape=(32,) dtype=float32>), 'data:0.282': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_282:0' shape=(32,) dtype=float32>), 'data:0.283': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_283:0' shape=(32,) dtype=float32>), 'data:0.284': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_284:0' shape=(32,) dtype=float32>), 'data:0.285': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_285:0' shape=(32,) dtype=float32>), 'data:0.286': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_286:0' shape=(32,) dtype=float32>), 'data:0.287': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_287:0' shape=(32,) dtype=float32>), 'data:0.288': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_288:0' shape=(32,) dtype=float32>), 'data:0.289': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_289:0' shape=(32,) dtype=float32>), 'data:0.290': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_290:0' shape=(32,) dtype=float32>), 'data:0.291': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_291:0' shape=(32,) dtype=float32>), 'data:0.292': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_292:0' shape=(32,) dtype=float32>), 'data:0.293': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_293:0' shape=(32,) dtype=float32>), 'data:0.294': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_294:0' shape=(32,) dtype=float32>), 'data:0.295': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_295:0' shape=(32,) dtype=float32>), 'data:0.296': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_296:0' shape=(32,) dtype=float32>), 'data:0.297': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_297:0' shape=(32,) dtype=float32>), 'data:0.298': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_298:0' shape=(32,) dtype=float32>), 'data:0.299': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_299:0' shape=(32,) dtype=float32>), 'data:0.300': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_300:0' shape=(32,) dtype=float32>), 'data:0.301': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_301:0' shape=(32,) dtype=float32>), 'data:0.302': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_302:0' shape=(32,) dtype=float32>), 'data:0.303': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_303:0' shape=(32,) dtype=float32>), 'data:0.304': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_304:0' shape=(32,) dtype=float32>), 'data:0.305': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_305:0' shape=(32,) dtype=float32>), 'data:0.306': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_306:0' shape=(32,) dtype=float32>), 'data:0.307': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_307:0' shape=(32,) dtype=float32>), 'data:0.308': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_308:0' shape=(32,) dtype=float32>), 'data:0.309': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_309:0' shape=(32,) dtype=float32>), 'data:0.310': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_310:0' shape=(32,) dtype=float32>), 'data:0.311': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_311:0' shape=(32,) dtype=float32>), 'data:0.312': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_312:0' shape=(32,) dtype=float32>), 'data:0.313': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_313:0' shape=(32,) dtype=float32>), 'data:0.314': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_314:0' shape=(32,) dtype=float32>), 'data:0.315': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_315:0' shape=(32,) dtype=float32>), 'data:0.316': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_316:0' shape=(32,) dtype=float32>), 'data:0.317': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_317:0' shape=(32,) dtype=float32>), 'data:0.318': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_318:0' shape=(32,) dtype=float32>), 'data:0.319': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_319:0' shape=(32,) dtype=float32>), 'data:0.320': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_320:0' shape=(32,) dtype=float32>), 'data:0.321': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_321:0' shape=(32,) dtype=float32>), 'data:0.322': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_322:0' shape=(32,) dtype=float32>), 'data:0.323': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_323:0' shape=(32,) dtype=float32>), 'data:0.324': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_324:0' shape=(32,) dtype=float32>), 'data:0.325': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_325:0' shape=(32,) dtype=float32>), 'data:0.326': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_326:0' shape=(32,) dtype=float32>), 'data:0.327': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_327:0' shape=(32,) dtype=float32>), 'data:0.328': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_328:0' shape=(32,) dtype=float32>), 'data:0.329': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_329:0' shape=(32,) dtype=float32>), 'data:0.330': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_330:0' shape=(32,) dtype=float32>), 'data:0.331': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_331:0' shape=(32,) dtype=float32>), 'data:0.332': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_332:0' shape=(32,) dtype=float32>), 'data:0.333': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_333:0' shape=(32,) dtype=float32>), 'data:0.334': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_334:0' shape=(32,) dtype=float32>), 'data:0.335': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_335:0' shape=(32,) dtype=float32>), 'data:0.336': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_336:0' shape=(32,) dtype=float32>), 'data:0.337': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_337:0' shape=(32,) dtype=float32>), 'data:0.338': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_338:0' shape=(32,) dtype=float32>), 'data:0.339': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_339:0' shape=(32,) dtype=float32>), 'data:0.340': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_340:0' shape=(32,) dtype=float32>), 'data:0.341': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_341:0' shape=(32,) dtype=float32>), 'data:0.342': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_342:0' shape=(32,) dtype=float32>), 'data:0.343': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_343:0' shape=(32,) dtype=float32>), 'data:0.344': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_344:0' shape=(32,) dtype=float32>), 'data:0.345': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_345:0' shape=(32,) dtype=float32>), 'data:0.346': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_346:0' shape=(32,) dtype=float32>), 'data:0.347': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_347:0' shape=(32,) dtype=float32>), 'data:0.348': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_348:0' shape=(32,) dtype=float32>), 'data:0.349': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_349:0' shape=(32,) dtype=float32>), 'data:0.350': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_350:0' shape=(32,) dtype=float32>), 'data:0.351': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_351:0' shape=(32,) dtype=float32>), 'data:0.352': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_352:0' shape=(32,) dtype=float32>), 'data:0.353': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_353:0' shape=(32,) dtype=float32>), 'data:0.354': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_354:0' shape=(32,) dtype=float32>), 'data:0.355': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_355:0' shape=(32,) dtype=float32>), 'data:0.356': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_356:0' shape=(32,) dtype=float32>), 'data:0.357': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_357:0' shape=(32,) dtype=float32>), 'data:0.358': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_358:0' shape=(32,) dtype=float32>), 'data:0.359': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_359:0' shape=(32,) dtype=float32>), 'data:0.360': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_360:0' shape=(32,) dtype=float32>), 'data:0.361': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_361:0' shape=(32,) dtype=float32>), 'data:0.362': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_362:0' shape=(32,) dtype=float32>), 'data:0.363': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_363:0' shape=(32,) dtype=float32>), 'data:0.364': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_364:0' shape=(32,) dtype=float32>), 'data:0.365': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_365:0' shape=(32,) dtype=float32>), 'data:0.366': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_366:0' shape=(32,) dtype=float32>), 'data:0.367': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_367:0' shape=(32,) dtype=float32>), 'data:0.368': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_368:0' shape=(32,) dtype=float32>), 'data:0.369': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_369:0' shape=(32,) dtype=float32>), 'data:0.370': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_370:0' shape=(32,) dtype=float32>), 'data:0.371': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_371:0' shape=(32,) dtype=float32>), 'data:0.372': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_372:0' shape=(32,) dtype=float32>), 'data:0.373': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_373:0' shape=(32,) dtype=float32>), 'data:0.374': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_374:0' shape=(32,) dtype=float32>), 'data:0.375': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_375:0' shape=(32,) dtype=float32>), 'data:0.376': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_376:0' shape=(32,) dtype=float32>), 'data:0.377': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_377:0' shape=(32,) dtype=float32>), 'data:0.378': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_378:0' shape=(32,) dtype=float32>), 'data:0.379': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_379:0' shape=(32,) dtype=float32>), 'data:0.380': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_380:0' shape=(32,) dtype=float32>), 'data:0.381': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_381:0' shape=(32,) dtype=float32>), 'data:0.382': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_382:0' shape=(32,) dtype=float32>), 'data:0.383': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_383:0' shape=(32,) dtype=float32>), 'data:0.384': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_384:0' shape=(32,) dtype=float32>), 'data:0.385': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_385:0' shape=(32,) dtype=float32>), 'data:0.386': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_386:0' shape=(32,) dtype=float32>), 'data:0.387': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_387:0' shape=(32,) dtype=float32>), 'data:0.388': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_388:0' shape=(32,) dtype=float32>), 'data:0.389': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_389:0' shape=(32,) dtype=float32>), 'data:0.390': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_390:0' shape=(32,) dtype=float32>), 'data:0.391': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_391:0' shape=(32,) dtype=float32>), 'data:0.392': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_392:0' shape=(32,) dtype=float32>), 'data:0.393': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_393:0' shape=(32,) dtype=float32>), 'data:0.394': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_394:0' shape=(32,) dtype=float32>), 'data:0.395': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_395:0' shape=(32,) dtype=float32>), 'data:0.396': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_396:0' shape=(32,) dtype=float32>), 'data:0.397': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_397:0' shape=(32,) dtype=float32>), 'data:0.398': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_398:0' shape=(32,) dtype=float32>), 'data:0.399': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_399:0' shape=(32,) dtype=float32>), 'data:0.400': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_400:0' shape=(32,) dtype=float32>), 'data:0.401': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_401:0' shape=(32,) dtype=float32>), 'data:0.402': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_402:0' shape=(32,) dtype=float32>), 'data:0.403': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_403:0' shape=(32,) dtype=float32>), 'data:0.404': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_404:0' shape=(32,) dtype=float32>), 'data:0.405': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_405:0' shape=(32,) dtype=float32>), 'data:0.406': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_406:0' shape=(32,) dtype=float32>), 'data:0.407': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_407:0' shape=(32,) dtype=float32>), 'data:0.408': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_408:0' shape=(32,) dtype=float32>), 'data:0.409': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_409:0' shape=(32,) dtype=float32>), 'data:0.410': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_410:0' shape=(32,) dtype=float32>), 'data:0.411': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_411:0' shape=(32,) dtype=float32>), 'data:0.412': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_412:0' shape=(32,) dtype=float32>), 'data:0.413': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_413:0' shape=(32,) dtype=float32>), 'data:0.414': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_414:0' shape=(32,) dtype=float32>), 'data:0.415': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_415:0' shape=(32,) dtype=float32>), 'data:0.416': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_416:0' shape=(32,) dtype=float32>), 'data:0.417': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_417:0' shape=(32,) dtype=float32>), 'data:0.418': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_418:0' shape=(32,) dtype=float32>), 'data:0.419': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_419:0' shape=(32,) dtype=float32>), 'data:0.420': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_420:0' shape=(32,) dtype=float32>), 'data:0.421': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_421:0' shape=(32,) dtype=float32>), 'data:0.422': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_422:0' shape=(32,) dtype=float32>), 'data:0.423': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_423:0' shape=(32,) dtype=float32>), 'data:0.424': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_424:0' shape=(32,) dtype=float32>), 'data:0.425': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_425:0' shape=(32,) dtype=float32>), 'data:0.426': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_426:0' shape=(32,) dtype=float32>), 'data:0.427': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_427:0' shape=(32,) dtype=float32>), 'data:0.428': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_428:0' shape=(32,) dtype=float32>), 'data:0.429': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_429:0' shape=(32,) dtype=float32>), 'data:0.430': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_430:0' shape=(32,) dtype=float32>), 'data:0.431': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_431:0' shape=(32,) dtype=float32>), 'data:0.432': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_432:0' shape=(32,) dtype=float32>), 'data:0.433': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_433:0' shape=(32,) dtype=float32>), 'data:0.434': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_434:0' shape=(32,) dtype=float32>), 'data:0.435': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_435:0' shape=(32,) dtype=float32>), 'data:0.436': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_436:0' shape=(32,) dtype=float32>), 'data:0.437': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_437:0' shape=(32,) dtype=float32>), 'data:0.438': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_438:0' shape=(32,) dtype=float32>), 'data:0.439': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_439:0' shape=(32,) dtype=float32>), 'data:0.440': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_440:0' shape=(32,) dtype=float32>), 'data:0.441': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_441:0' shape=(32,) dtype=float32>), 'data:0.442': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_442:0' shape=(32,) dtype=float32>), 'data:0.443': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_443:0' shape=(32,) dtype=float32>), 'data:0.444': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_444:0' shape=(32,) dtype=float32>), 'data:0.445': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_445:0' shape=(32,) dtype=float32>), 'data:0.446': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_446:0' shape=(32,) dtype=float32>), 'data:0.447': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_447:0' shape=(32,) dtype=float32>), 'data:0.448': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_448:0' shape=(32,) dtype=float32>), 'data:0.449': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_449:0' shape=(32,) dtype=float32>), 'data:0.450': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_450:0' shape=(32,) dtype=float32>), 'data:0.451': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_451:0' shape=(32,) dtype=float32>), 'data:0.452': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_452:0' shape=(32,) dtype=float32>), 'data:0.453': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_453:0' shape=(32,) dtype=float32>), 'data:0.454': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_454:0' shape=(32,) dtype=float32>), 'data:0.455': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_455:0' shape=(32,) dtype=float32>), 'data:0.456': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_456:0' shape=(32,) dtype=float32>), 'data:0.457': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_457:0' shape=(32,) dtype=float32>), 'data:0.458': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_458:0' shape=(32,) dtype=float32>), 'data:0.459': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_459:0' shape=(32,) dtype=float32>), 'data:0.460': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_460:0' shape=(32,) dtype=float32>), 'data:0.461': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_461:0' shape=(32,) dtype=float32>), 'data:0.462': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_462:0' shape=(32,) dtype=float32>), 'data:0.463': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_463:0' shape=(32,) dtype=float32>), 'data:0.464': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_464:0' shape=(32,) dtype=float32>), 'data:0.465': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_465:0' shape=(32,) dtype=float32>), 'data:0.466': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_466:0' shape=(32,) dtype=float32>), 'data:0.467': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_467:0' shape=(32,) dtype=float32>), 'data:0.468': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_468:0' shape=(32,) dtype=float32>), 'data:0.469': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_469:0' shape=(32,) dtype=float32>), 'data:0.470': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_470:0' shape=(32,) dtype=float32>), 'data:0.471': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_471:0' shape=(32,) dtype=float32>), 'data:0.472': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_472:0' shape=(32,) dtype=float32>), 'data:0.473': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_473:0' shape=(32,) dtype=float32>), 'data:0.474': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_474:0' shape=(32,) dtype=float32>), 'data:0.475': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_475:0' shape=(32,) dtype=float32>), 'data:0.476': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_476:0' shape=(32,) dtype=float32>), 'data:0.477': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_477:0' shape=(32,) dtype=float32>), 'data:0.478': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_478:0' shape=(32,) dtype=float32>), 'data:0.479': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_479:0' shape=(32,) dtype=float32>), 'data:0.480': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_480:0' shape=(32,) dtype=float32>), 'data:0.481': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_481:0' shape=(32,) dtype=float32>), 'data:0.482': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_482:0' shape=(32,) dtype=float32>), 'data:0.483': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_483:0' shape=(32,) dtype=float32>), 'data:0.484': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_484:0' shape=(32,) dtype=float32>), 'data:0.485': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_485:0' shape=(32,) dtype=float32>), 'data:0.486': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_486:0' shape=(32,) dtype=float32>), 'data:0.487': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_487:0' shape=(32,) dtype=float32>), 'data:0.488': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_488:0' shape=(32,) dtype=float32>), 'data:0.489': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_489:0' shape=(32,) dtype=float32>), 'data:0.490': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_490:0' shape=(32,) dtype=float32>), 'data:0.491': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_491:0' shape=(32,) dtype=float32>), 'data:0.492': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_492:0' shape=(32,) dtype=float32>), 'data:0.493': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_493:0' shape=(32,) dtype=float32>), 'data:0.494': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_494:0' shape=(32,) dtype=float32>), 'data:0.495': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_495:0' shape=(32,) dtype=float32>), 'data:0.496': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_496:0' shape=(32,) dtype=float32>), 'data:0.497': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_497:0' shape=(32,) dtype=float32>), 'data:0.498': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_498:0' shape=(32,) dtype=float32>), 'data:0.499': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_499:0' shape=(32,) dtype=float32>), 'data:0.500': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_500:0' shape=(32,) dtype=float32>), 'data:0.501': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_501:0' shape=(32,) dtype=float32>), 'data:0.502': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_502:0' shape=(32,) dtype=float32>), 'data:0.503': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_503:0' shape=(32,) dtype=float32>), 'data:0.504': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_504:0' shape=(32,) dtype=float32>), 'data:0.505': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_505:0' shape=(32,) dtype=float32>), 'data:0.506': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_506:0' shape=(32,) dtype=float32>), 'data:0.507': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_507:0' shape=(32,) dtype=float32>), 'data:0.508': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_508:0' shape=(32,) dtype=float32>), 'data:0.509': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_509:0' shape=(32,) dtype=float32>), 'data:0.510': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_510:0' shape=(32,) dtype=float32>), 'data:0.511': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_511:0' shape=(32,) dtype=float32>), 'data:0.512': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_512:0' shape=(32,) dtype=float32>), 'data:0.513': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_513:0' shape=(32,) dtype=float32>), 'data:0.514': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_514:0' shape=(32,) dtype=float32>), 'data:0.515': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_515:0' shape=(32,) dtype=float32>), 'data:0.516': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_516:0' shape=(32,) dtype=float32>), 'data:0.517': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_517:0' shape=(32,) dtype=float32>), 'data:0.518': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_518:0' shape=(32,) dtype=float32>), 'data:0.519': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_519:0' shape=(32,) dtype=float32>), 'data:0.520': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_520:0' shape=(32,) dtype=float32>), 'data:0.521': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_521:0' shape=(32,) dtype=float32>), 'data:0.522': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_522:0' shape=(32,) dtype=float32>), 'data:0.523': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_523:0' shape=(32,) dtype=float32>), 'data:0.524': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_524:0' shape=(32,) dtype=float32>), 'data:0.525': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_525:0' shape=(32,) dtype=float32>), 'data:0.526': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_526:0' shape=(32,) dtype=float32>), 'data:0.527': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_527:0' shape=(32,) dtype=float32>), 'data:0.528': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_528:0' shape=(32,) dtype=float32>), 'data:0.529': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_529:0' shape=(32,) dtype=float32>), 'data:0.530': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_530:0' shape=(32,) dtype=float32>), 'data:0.531': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_531:0' shape=(32,) dtype=float32>), 'data:0.532': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_532:0' shape=(32,) dtype=float32>), 'data:0.533': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_533:0' shape=(32,) dtype=float32>), 'data:0.534': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_534:0' shape=(32,) dtype=float32>), 'data:0.535': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_535:0' shape=(32,) dtype=float32>), 'data:0.536': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_536:0' shape=(32,) dtype=float32>), 'data:0.537': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_537:0' shape=(32,) dtype=float32>), 'data:0.538': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_538:0' shape=(32,) dtype=float32>), 'data:0.539': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_539:0' shape=(32,) dtype=float32>), 'data:0.540': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_540:0' shape=(32,) dtype=float32>), 'data:0.541': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_541:0' shape=(32,) dtype=float32>), 'data:0.542': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_542:0' shape=(32,) dtype=float32>), 'data:0.543': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_543:0' shape=(32,) dtype=float32>), 'data:0.544': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_544:0' shape=(32,) dtype=float32>), 'data:0.545': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_545:0' shape=(32,) dtype=float32>), 'data:0.546': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_546:0' shape=(32,) dtype=float32>), 'data:0.547': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_547:0' shape=(32,) dtype=float32>), 'data:0.548': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_548:0' shape=(32,) dtype=float32>), 'data:0.549': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_549:0' shape=(32,) dtype=float32>), 'data:0.550': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_550:0' shape=(32,) dtype=float32>), 'data:0.551': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_551:0' shape=(32,) dtype=float32>), 'data:0.552': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_552:0' shape=(32,) dtype=float32>), 'data:0.553': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_553:0' shape=(32,) dtype=float32>), 'data:0.554': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_554:0' shape=(32,) dtype=float32>), 'data:0.555': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_555:0' shape=(32,) dtype=float32>), 'data:0.556': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_556:0' shape=(32,) dtype=float32>), 'data:0.557': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_557:0' shape=(32,) dtype=float32>), 'data:0.558': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_558:0' shape=(32,) dtype=float32>), 'data:0.559': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_559:0' shape=(32,) dtype=float32>), 'data:0.560': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_560:0' shape=(32,) dtype=float32>), 'data:0.561': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_561:0' shape=(32,) dtype=float32>), 'data:0.562': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_562:0' shape=(32,) dtype=float32>), 'data:0.563': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_563:0' shape=(32,) dtype=float32>), 'data:0.564': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_564:0' shape=(32,) dtype=float32>), 'data:0.565': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_565:0' shape=(32,) dtype=float32>), 'data:0.566': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_566:0' shape=(32,) dtype=float32>), 'data:0.567': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_567:0' shape=(32,) dtype=float32>), 'data:0.568': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_568:0' shape=(32,) dtype=float32>), 'data:0.569': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_569:0' shape=(32,) dtype=float32>), 'data:0.570': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_570:0' shape=(32,) dtype=float32>), 'data:0.571': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_571:0' shape=(32,) dtype=float32>), 'data:0.572': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_572:0' shape=(32,) dtype=float32>), 'data:0.573': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_573:0' shape=(32,) dtype=float32>), 'data:0.574': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_574:0' shape=(32,) dtype=float32>), 'data:0.575': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_575:0' shape=(32,) dtype=float32>), 'data:0.576': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_576:0' shape=(32,) dtype=float32>), 'data:0.577': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_577:0' shape=(32,) dtype=float32>), 'data:0.578': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_578:0' shape=(32,) dtype=float32>), 'data:0.579': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_579:0' shape=(32,) dtype=float32>), 'data:0.580': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_580:0' shape=(32,) dtype=float32>), 'data:0.581': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_581:0' shape=(32,) dtype=float32>), 'data:0.582': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_582:0' shape=(32,) dtype=float32>), 'data:0.583': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_583:0' shape=(32,) dtype=float32>), 'data:0.584': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_584:0' shape=(32,) dtype=float32>), 'data:0.585': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_585:0' shape=(32,) dtype=float32>), 'data:0.586': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_586:0' shape=(32,) dtype=float32>), 'data:0.587': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_587:0' shape=(32,) dtype=float32>), 'data:0.588': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_588:0' shape=(32,) dtype=float32>), 'data:0.589': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_589:0' shape=(32,) dtype=float32>), 'data:0.590': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_590:0' shape=(32,) dtype=float32>), 'data:0.591': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_591:0' shape=(32,) dtype=float32>), 'data:0.592': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_592:0' shape=(32,) dtype=float32>), 'data:0.593': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_593:0' shape=(32,) dtype=float32>), 'data:0.594': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_594:0' shape=(32,) dtype=float32>), 'data:0.595': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_595:0' shape=(32,) dtype=float32>), 'data:0.596': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_596:0' shape=(32,) dtype=float32>), 'data:0.597': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_597:0' shape=(32,) dtype=float32>), 'data:0.598': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_598:0' shape=(32,) dtype=float32>), 'data:0.599': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_599:0' shape=(32,) dtype=float32>), 'data:0.600': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_600:0' shape=(32,) dtype=float32>), 'data:0.601': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_601:0' shape=(32,) dtype=float32>), 'data:0.602': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_602:0' shape=(32,) dtype=float32>), 'data:0.603': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_603:0' shape=(32,) dtype=float32>), 'data:0.604': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_604:0' shape=(32,) dtype=float32>), 'data:0.605': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_605:0' shape=(32,) dtype=float32>), 'data:0.606': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_606:0' shape=(32,) dtype=float32>), 'data:0.607': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_607:0' shape=(32,) dtype=float32>), 'data:0.608': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_608:0' shape=(32,) dtype=float32>), 'data:0.609': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_609:0' shape=(32,) dtype=float32>), 'data:0.610': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_610:0' shape=(32,) dtype=float32>), 'data:0.611': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_611:0' shape=(32,) dtype=float32>), 'data:0.612': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_612:0' shape=(32,) dtype=float32>), 'data:0.613': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_613:0' shape=(32,) dtype=float32>), 'data:0.614': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_614:0' shape=(32,) dtype=float32>), 'data:0.615': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_615:0' shape=(32,) dtype=float32>), 'data:0.616': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_616:0' shape=(32,) dtype=float32>), 'data:0.617': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_617:0' shape=(32,) dtype=float32>), 'data:0.618': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_618:0' shape=(32,) dtype=float32>), 'data:0.619': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_619:0' shape=(32,) dtype=float32>), 'data:0.620': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_620:0' shape=(32,) dtype=float32>), 'data:0.621': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_621:0' shape=(32,) dtype=float32>), 'data:0.622': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_622:0' shape=(32,) dtype=float32>), 'data:0.623': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_623:0' shape=(32,) dtype=float32>), 'data:0.624': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_624:0' shape=(32,) dtype=float32>), 'data:0.625': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_625:0' shape=(32,) dtype=float32>), 'data:0.626': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_626:0' shape=(32,) dtype=float32>), 'data:0.627': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_627:0' shape=(32,) dtype=float32>), 'data:0.628': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_628:0' shape=(32,) dtype=float32>), 'data:0.629': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_629:0' shape=(32,) dtype=float32>), 'data:0.630': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_630:0' shape=(32,) dtype=float32>), 'data:0.631': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_631:0' shape=(32,) dtype=float32>), 'data:0.632': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_632:0' shape=(32,) dtype=float32>), 'data:0.633': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_633:0' shape=(32,) dtype=float32>), 'data:0.634': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_634:0' shape=(32,) dtype=float32>), 'data:0.635': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_635:0' shape=(32,) dtype=float32>), 'data:0.636': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_636:0' shape=(32,) dtype=float32>), 'data:0.637': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_637:0' shape=(32,) dtype=float32>), 'data:0.638': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_638:0' shape=(32,) dtype=float32>), 'data:0.639': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_639:0' shape=(32,) dtype=float32>), 'data:0.640': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_640:0' shape=(32,) dtype=float32>), 'data:0.641': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_641:0' shape=(32,) dtype=float32>), 'data:0.642': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_642:0' shape=(32,) dtype=float32>), 'data:0.643': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_643:0' shape=(32,) dtype=float32>), 'data:0.644': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_644:0' shape=(32,) dtype=float32>), 'data:0.645': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_645:0' shape=(32,) dtype=float32>), 'data:0.646': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_646:0' shape=(32,) dtype=float32>), 'data:0.647': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_647:0' shape=(32,) dtype=float32>), 'data:0.648': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_648:0' shape=(32,) dtype=float32>), 'data:0.649': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_649:0' shape=(32,) dtype=float32>), 'data:0.650': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_650:0' shape=(32,) dtype=float32>), 'data:0.651': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_651:0' shape=(32,) dtype=float32>), 'data:0.652': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_652:0' shape=(32,) dtype=float32>), 'data:0.653': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_653:0' shape=(32,) dtype=float32>), 'data:0.654': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_654:0' shape=(32,) dtype=float32>), 'data:0.655': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_655:0' shape=(32,) dtype=float32>), 'data:0.656': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_656:0' shape=(32,) dtype=float32>), 'data:0.657': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_657:0' shape=(32,) dtype=float32>), 'data:0.658': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_658:0' shape=(32,) dtype=float32>), 'data:0.659': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_659:0' shape=(32,) dtype=float32>), 'data:0.660': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_660:0' shape=(32,) dtype=float32>), 'data:0.661': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_661:0' shape=(32,) dtype=float32>), 'data:0.662': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_662:0' shape=(32,) dtype=float32>), 'data:0.663': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_663:0' shape=(32,) dtype=float32>), 'data:0.664': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_664:0' shape=(32,) dtype=float32>), 'data:0.665': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_665:0' shape=(32,) dtype=float32>), 'data:0.666': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_666:0' shape=(32,) dtype=float32>), 'data:0.667': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_667:0' shape=(32,) dtype=float32>), 'data:0.668': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_668:0' shape=(32,) dtype=float32>), 'data:0.669': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_669:0' shape=(32,) dtype=float32>), 'data:0.670': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_670:0' shape=(32,) dtype=float32>), 'data:0.671': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_671:0' shape=(32,) dtype=float32>), 'data:0.672': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_672:0' shape=(32,) dtype=float32>), 'data:0.673': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_673:0' shape=(32,) dtype=float32>), 'data:0.674': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_674:0' shape=(32,) dtype=float32>), 'data:0.675': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_675:0' shape=(32,) dtype=float32>), 'data:0.676': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_676:0' shape=(32,) dtype=float32>), 'data:0.677': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_677:0' shape=(32,) dtype=float32>), 'data:0.678': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_678:0' shape=(32,) dtype=float32>), 'data:0.679': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_679:0' shape=(32,) dtype=float32>), 'data:0.680': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_680:0' shape=(32,) dtype=float32>), 'data:0.681': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_681:0' shape=(32,) dtype=float32>), 'data:0.682': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_682:0' shape=(32,) dtype=float32>), 'data:0.683': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_683:0' shape=(32,) dtype=float32>), 'data:0.684': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_684:0' shape=(32,) dtype=float32>), 'data:0.685': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_685:0' shape=(32,) dtype=float32>), 'data:0.686': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_686:0' shape=(32,) dtype=float32>), 'data:0.687': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_687:0' shape=(32,) dtype=float32>), 'data:0.688': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_688:0' shape=(32,) dtype=float32>), 'data:0.689': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_689:0' shape=(32,) dtype=float32>), 'data:0.690': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_690:0' shape=(32,) dtype=float32>), 'data:0.691': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_691:0' shape=(32,) dtype=float32>), 'data:0.692': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_692:0' shape=(32,) dtype=float32>), 'data:0.693': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_693:0' shape=(32,) dtype=float32>), 'data:0.694': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_694:0' shape=(32,) dtype=float32>), 'data:0.695': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_695:0' shape=(32,) dtype=float32>), 'data:0.696': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_696:0' shape=(32,) dtype=float32>), 'data:0.697': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_697:0' shape=(32,) dtype=float32>), 'data:0.698': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_698:0' shape=(32,) dtype=float32>), 'data:0.699': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_699:0' shape=(32,) dtype=float32>), 'data:0.700': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_700:0' shape=(32,) dtype=float32>), 'data:0.701': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_701:0' shape=(32,) dtype=float32>), 'data:0.702': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_702:0' shape=(32,) dtype=float32>), 'data:0.703': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_703:0' shape=(32,) dtype=float32>), 'data:0.704': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_704:0' shape=(32,) dtype=float32>), 'data:0.705': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_705:0' shape=(32,) dtype=float32>), 'data:0.706': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_706:0' shape=(32,) dtype=float32>), 'data:0.707': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_707:0' shape=(32,) dtype=float32>), 'data:0.708': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_708:0' shape=(32,) dtype=float32>), 'data:0.709': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_709:0' shape=(32,) dtype=float32>), 'data:0.710': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_710:0' shape=(32,) dtype=float32>), 'data:0.711': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_711:0' shape=(32,) dtype=float32>), 'data:0.712': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_712:0' shape=(32,) dtype=float32>), 'data:0.713': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_713:0' shape=(32,) dtype=float32>), 'data:0.714': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_714:0' shape=(32,) dtype=float32>), 'data:0.715': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_715:0' shape=(32,) dtype=float32>), 'data:0.716': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_716:0' shape=(32,) dtype=float32>), 'data:0.717': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_717:0' shape=(32,) dtype=float32>), 'data:0.718': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_718:0' shape=(32,) dtype=float32>), 'data:0.719': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_719:0' shape=(32,) dtype=float32>), 'data:0.720': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_720:0' shape=(32,) dtype=float32>), 'data:0.721': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_721:0' shape=(32,) dtype=float32>), 'data:0.722': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_722:0' shape=(32,) dtype=float32>), 'data:0.723': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_723:0' shape=(32,) dtype=float32>), 'data:0.724': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_724:0' shape=(32,) dtype=float32>), 'data:0.725': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_725:0' shape=(32,) dtype=float32>), 'data:0.726': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_726:0' shape=(32,) dtype=float32>), 'data:0.727': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_727:0' shape=(32,) dtype=float32>), 'data:0.728': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_728:0' shape=(32,) dtype=float32>), 'data:0.729': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_729:0' shape=(32,) dtype=float32>), 'data:0.730': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_730:0' shape=(32,) dtype=float32>), 'data:0.731': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_731:0' shape=(32,) dtype=float32>), 'data:0.732': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_732:0' shape=(32,) dtype=float32>), 'data:0.733': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_733:0' shape=(32,) dtype=float32>), 'data:0.734': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_734:0' shape=(32,) dtype=float32>), 'data:0.735': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_735:0' shape=(32,) dtype=float32>), 'data:0.736': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_736:0' shape=(32,) dtype=float32>), 'data:0.737': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_737:0' shape=(32,) dtype=float32>), 'data:0.738': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_738:0' shape=(32,) dtype=float32>), 'data:0.739': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_739:0' shape=(32,) dtype=float32>), 'data:0.740': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_740:0' shape=(32,) dtype=float32>), 'data:0.741': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_741:0' shape=(32,) dtype=float32>), 'data:0.742': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_742:0' shape=(32,) dtype=float32>), 'data:0.743': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_743:0' shape=(32,) dtype=float32>), 'data:0.744': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_744:0' shape=(32,) dtype=float32>), 'data:0.745': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_745:0' shape=(32,) dtype=float32>), 'data:0.746': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_746:0' shape=(32,) dtype=float32>), 'data:0.747': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_747:0' shape=(32,) dtype=float32>), 'data:0.748': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_748:0' shape=(32,) dtype=float32>), 'data:0.749': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_749:0' shape=(32,) dtype=float32>), 'data:0.750': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_750:0' shape=(32,) dtype=float32>), 'data:0.751': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_751:0' shape=(32,) dtype=float32>), 'data:0.752': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_752:0' shape=(32,) dtype=float32>), 'data:0.753': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_753:0' shape=(32,) dtype=float32>), 'data:0.754': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_754:0' shape=(32,) dtype=float32>), 'data:0.755': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_755:0' shape=(32,) dtype=float32>), 'data:0.756': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_756:0' shape=(32,) dtype=float32>), 'data:0.757': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_757:0' shape=(32,) dtype=float32>), 'data:0.758': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_758:0' shape=(32,) dtype=float32>), 'data:0.759': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_759:0' shape=(32,) dtype=float32>), 'data:0.760': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_760:0' shape=(32,) dtype=float32>), 'data:0.761': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_761:0' shape=(32,) dtype=float32>), 'data:0.762': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_762:0' shape=(32,) dtype=float32>), 'data:0.763': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_763:0' shape=(32,) dtype=float32>), 'data:0.764': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_764:0' shape=(32,) dtype=float32>), 'data:0.765': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_765:0' shape=(32,) dtype=float32>), 'data:0.766': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_766:0' shape=(32,) dtype=float32>), 'data:0.767': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_767:0' shape=(32,) dtype=float32>), 'data:0.768': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_768:0' shape=(32,) dtype=float32>), 'data:0.769': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_769:0' shape=(32,) dtype=float32>), 'data:0.770': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_770:0' shape=(32,) dtype=float32>), 'data:0.771': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_771:0' shape=(32,) dtype=float32>), 'data:0.772': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_772:0' shape=(32,) dtype=float32>), 'data:0.773': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_773:0' shape=(32,) dtype=float32>), 'data:0.774': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_774:0' shape=(32,) dtype=float32>), 'data:0.775': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_775:0' shape=(32,) dtype=float32>), 'data:0.776': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_776:0' shape=(32,) dtype=float32>), 'data:0.777': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_777:0' shape=(32,) dtype=float32>), 'data:0.778': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_778:0' shape=(32,) dtype=float32>), 'data:0.779': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_779:0' shape=(32,) dtype=float32>), 'data:0.780': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_780:0' shape=(32,) dtype=float32>), 'data:0.781': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_781:0' shape=(32,) dtype=float32>), 'data:0.782': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_782:0' shape=(32,) dtype=float32>), 'data:0.783': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_783:0' shape=(32,) dtype=float32>)}\n",
            "Training dataset read in 0:00:12.319660. Found 60000 examples.\n",
            "Training model...\n",
            "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO 23-05-27 16:46:14.0453 UTC kernel.cc:773] Start Yggdrasil model training\n",
            "[INFO 23-05-27 16:46:14.0453 UTC kernel.cc:774] Collect training examples\n",
            "[INFO 23-05-27 16:46:14.0454 UTC kernel.cc:787] Dataspec guide:\n",
            "column_guides {\n",
            "  column_name_pattern: \"^__LABEL$\"\n",
            "  type: CATEGORICAL\n",
            "  categorial {\n",
            "    min_vocab_frequency: 0\n",
            "    max_vocab_count: -1\n",
            "  }\n",
            "}\n",
            "default_column_guide {\n",
            "  categorial {\n",
            "    max_vocab_count: 2000\n",
            "  }\n",
            "  discretized_numerical {\n",
            "    maximum_num_bins: 255\n",
            "  }\n",
            "}\n",
            "ignore_columns_without_guides: false\n",
            "detect_numerical_as_discretized_numerical: false\n",
            "\n",
            "[INFO 23-05-27 16:46:14.0517 UTC kernel.cc:393] Number of batches: 1875\n",
            "[INFO 23-05-27 16:46:14.0518 UTC kernel.cc:394] Number of examples: 60000\n",
            "[INFO 23-05-27 16:46:14.3790 UTC kernel.cc:794] Training dataset:\n",
            "Number of records: 60000\n",
            "Number of columns: 785\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 784 (99.8726%)\n",
            "\tCATEGORICAL: 1 (0.127389%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 784 (99.8726%)\n",
            "\t1: \"data:0.0\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t2: \"data:0.1\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t3: \"data:0.10\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t4: \"data:0.100\" NUMERICAL mean:0.0514691 min:0 max:1 sd:0.196\n",
            "\t5: \"data:0.101\" NUMERICAL mean:0.0463275 min:0 max:1 sd:0.186913\n",
            "\t6: \"data:0.102\" NUMERICAL mean:0.0374261 min:0 max:1 sd:0.168626\n",
            "\t7: \"data:0.103\" NUMERICAL mean:0.0269139 min:0 max:1 sd:0.143762\n",
            "\t8: \"data:0.104\" NUMERICAL mean:0.0164457 min:0 max:1 sd:0.11139\n",
            "\t9: \"data:0.105\" NUMERICAL mean:0.00892013 min:0 max:1 sd:0.0824683\n",
            "\t10: \"data:0.106\" NUMERICAL mean:0.00416092 min:0 max:1 sd:0.05417\n",
            "\t11: \"data:0.107\" NUMERICAL mean:0.00161987 min:0 max:1 sd:0.0344102\n",
            "\t12: \"data:0.108\" NUMERICAL mean:0.000635621 min:0 max:1 sd:0.0210457\n",
            "\t13: \"data:0.109\" NUMERICAL mean:0.000108889 min:0 max:0.752941 sd:0.00714436\n",
            "\t14: \"data:0.11\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t15: \"data:0.110\" NUMERICAL mean:1.09804e-05 min:0 max:0.47451 sd:0.00207816\n",
            "\t16: \"data:0.111\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t17: \"data:0.112\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t18: \"data:0.113\" NUMERICAL mean:2.48366e-06 min:0 max:0.14902 sd:0.000608365\n",
            "\t19: \"data:0.114\" NUMERICAL mean:2.04575e-05 min:0 max:0.564706 sd:0.00263512\n",
            "\t20: \"data:0.115\" NUMERICAL mean:5.62745e-05 min:0 max:0.396078 sd:0.00377852\n",
            "\t21: \"data:0.116\" NUMERICAL mean:0.00031719 min:0 max:0.996078 sd:0.0132368\n",
            "\t22: \"data:0.117\" NUMERICAL mean:0.00160869 min:0 max:1 sd:0.031956\n",
            "\t23: \"data:0.118\" NUMERICAL mean:0.00409111 min:0 max:1 sd:0.0519391\n",
            "\t24: \"data:0.119\" NUMERICAL mean:0.00948739 min:0 max:1 sd:0.08166\n",
            "\t25: \"data:0.12\" NUMERICAL mean:8.23529e-06 min:0 max:0.454902 sd:0.001864\n",
            "\t26: \"data:0.120\" NUMERICAL mean:0.0187284 min:0 max:1 sd:0.116147\n",
            "\t27: \"data:0.121\" NUMERICAL mean:0.0329193 min:0 max:1 sd:0.155308\n",
            "\t28: \"data:0.122\" NUMERICAL mean:0.0521971 min:0 max:1 sd:0.195569\n",
            "\t29: \"data:0.123\" NUMERICAL mean:0.0763816 min:0 max:1 sd:0.234531\n",
            "\t30: \"data:0.124\" NUMERICAL mean:0.106026 min:0 max:1 sd:0.271694\n",
            "\t31: \"data:0.125\" NUMERICAL mean:0.138087 min:0 max:1 sd:0.30545\n",
            "\t32: \"data:0.126\" NUMERICAL mean:0.164082 min:0 max:1 sd:0.328559\n",
            "\t33: \"data:0.127\" NUMERICAL mean:0.177461 min:0 max:1 sd:0.339036\n",
            "\t34: \"data:0.128\" NUMERICAL mean:0.173878 min:0 max:1 sd:0.335919\n",
            "\t35: \"data:0.129\" NUMERICAL mean:0.153496 min:0 max:1 sd:0.319183\n",
            "\t36: \"data:0.13\" NUMERICAL mean:3.0719e-05 min:0 max:0.996078 sd:0.00533795\n",
            "\t37: \"data:0.130\" NUMERICAL mean:0.122856 min:0 max:1 sd:0.290384\n",
            "\t38: \"data:0.131\" NUMERICAL mean:0.0898978 min:0 max:1 sd:0.251998\n",
            "\t39: \"data:0.132\" NUMERICAL mean:0.0581609 min:0 max:1 sd:0.20502\n",
            "\t40: \"data:0.133\" NUMERICAL mean:0.0339663 min:0 max:1 sd:0.156645\n",
            "\t41: \"data:0.134\" NUMERICAL mean:0.0178352 min:0 max:1 sd:0.112507\n",
            "\t42: \"data:0.135\" NUMERICAL mean:0.00838046 min:0 max:1 sd:0.0770372\n",
            "\t43: \"data:0.136\" NUMERICAL mean:0.00338392 min:0 max:1 sd:0.0477129\n",
            "\t44: \"data:0.137\" NUMERICAL mean:0.000814706 min:0 max:0.996078 sd:0.0209148\n",
            "\t45: \"data:0.138\" NUMERICAL mean:0.000116275 min:0 max:0.866667 sd:0.00815825\n",
            "\t46: \"data:0.139\" NUMERICAL mean:7.97386e-06 min:0 max:0.247059 sd:0.00138183\n",
            "\t47: \"data:0.14\" NUMERICAL mean:1.41176e-05 min:0 max:0.847059 sd:0.00345807\n",
            "\t48: \"data:0.140\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t49: \"data:0.141\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t50: \"data:0.142\" NUMERICAL mean:4.04575e-05 min:0 max:0.372549 sd:0.00339929\n",
            "\t51: \"data:0.143\" NUMERICAL mean:0.000248431 min:0 max:1 sd:0.0112666\n",
            "\t52: \"data:0.144\" NUMERICAL mean:0.00155085 min:0 max:1 sd:0.0299172\n",
            "\t53: \"data:0.145\" NUMERICAL mean:0.00573882 min:0 max:1 sd:0.0633007\n",
            "\t54: \"data:0.146\" NUMERICAL mean:0.0140697 min:0 max:1 sd:0.100738\n",
            "\t55: \"data:0.147\" NUMERICAL mean:0.0283444 min:0 max:1 sd:0.14382\n",
            "\t56: \"data:0.148\" NUMERICAL mean:0.0510475 min:0 max:1 sd:0.19308\n",
            "\t57: \"data:0.149\" NUMERICAL mean:0.0832075 min:0 max:1 sd:0.244203\n",
            "\t58: \"data:0.15\" NUMERICAL mean:5.88235e-07 min:0 max:0.0352941 sd:0.000144086\n",
            "\t59: \"data:0.150\" NUMERICAL mean:0.123531 min:0 max:1 sd:0.292356\n",
            "\t60: \"data:0.151\" NUMERICAL mean:0.173358 min:0 max:1 sd:0.336351\n",
            "\t61: \"data:0.152\" NUMERICAL mean:0.230995 min:0 max:1 sd:0.374971\n",
            "\t62: \"data:0.153\" NUMERICAL mean:0.289428 min:0 max:1 sd:0.404239\n",
            "\t63: \"data:0.154\" NUMERICAL mean:0.333736 min:0 max:1 sd:0.420259\n",
            "\t64: \"data:0.155\" NUMERICAL mean:0.355293 min:0 max:1 sd:0.425476\n",
            "\t65: \"data:0.156\" NUMERICAL mean:0.348721 min:0 max:1 sd:0.42311\n",
            "\t66: \"data:0.157\" NUMERICAL mean:0.314436 min:0 max:1 sd:0.412192\n",
            "\t67: \"data:0.158\" NUMERICAL mean:0.258599 min:0 max:1 sd:0.387961\n",
            "\t68: \"data:0.159\" NUMERICAL mean:0.19527 min:0 max:1 sd:0.351047\n",
            "\t69: \"data:0.16\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t70: \"data:0.160\" NUMERICAL mean:0.134705 min:0 max:1 sd:0.300919\n",
            "\t71: \"data:0.161\" NUMERICAL mean:0.0843529 min:0 max:1 sd:0.242655\n",
            "\t72: \"data:0.162\" NUMERICAL mean:0.0485895 min:0 max:1 sd:0.18628\n",
            "\t73: \"data:0.163\" NUMERICAL mean:0.0260358 min:0 max:1 sd:0.13681\n",
            "\t74: \"data:0.164\" NUMERICAL mean:0.0117361 min:0 max:1 sd:0.0895341\n",
            "\t75: \"data:0.165\" NUMERICAL mean:0.0033085 min:0 max:1 sd:0.044204\n",
            "\t76: \"data:0.166\" NUMERICAL mean:0.000555425 min:0 max:1 sd:0.017395\n",
            "\t77: \"data:0.167\" NUMERICAL mean:1.84314e-05 min:0 max:0.364706 sd:0.00224529\n",
            "\t78: \"data:0.168\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t79: \"data:0.169\" NUMERICAL mean:7.18954e-07 min:0 max:0.027451 sd:0.000129073\n",
            "\t80: \"data:0.17\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t81: \"data:0.170\" NUMERICAL mean:0.000107843 min:0 max:0.823529 sd:0.00688569\n",
            "\t82: \"data:0.171\" NUMERICAL mean:0.000868366 min:0 max:1 sd:0.0238787\n",
            "\t83: \"data:0.172\" NUMERICAL mean:0.00439026 min:0 max:1 sd:0.0555558\n",
            "\t84: \"data:0.173\" NUMERICAL mean:0.0129016 min:0 max:1 sd:0.0967939\n",
            "\t85: \"data:0.174\" NUMERICAL mean:0.0291626 min:0 max:1 sd:0.146432\n",
            "\t86: \"data:0.175\" NUMERICAL mean:0.0558997 min:0 max:1 sd:0.202955\n",
            "\t87: \"data:0.176\" NUMERICAL mean:0.0946578 min:0 max:1 sd:0.260524\n",
            "\t88: \"data:0.177\" NUMERICAL mean:0.146229 min:0 max:1 sd:0.315775\n",
            "\t89: \"data:0.178\" NUMERICAL mean:0.208296 min:0 max:1 sd:0.362351\n",
            "\t90: \"data:0.179\" NUMERICAL mean:0.278089 min:0 max:1 sd:0.397951\n",
            "\t91: \"data:0.18\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t92: \"data:0.180\" NUMERICAL mean:0.350112 min:0 max:1 sd:0.422445\n",
            "\t93: \"data:0.181\" NUMERICAL mean:0.4166 min:0 max:1 sd:0.435368\n",
            "\t94: \"data:0.182\" NUMERICAL mean:0.46473 min:0 max:1 sd:0.439888\n",
            "\t95: \"data:0.183\" NUMERICAL mean:0.486659 min:0 max:1 sd:0.440528\n",
            "\t96: \"data:0.184\" NUMERICAL mean:0.477299 min:0 max:1 sd:0.440513\n",
            "\t97: \"data:0.185\" NUMERICAL mean:0.439346 min:0 max:1 sd:0.439807\n",
            "\t98: \"data:0.186\" NUMERICAL mean:0.376895 min:0 max:1 sd:0.430861\n",
            "\t99: \"data:0.187\" NUMERICAL mean:0.294766 min:0 max:1 sd:0.406821\n",
            "\t100: \"data:0.188\" NUMERICAL mean:0.21191 min:0 max:1 sd:0.364981\n",
            "\t101: \"data:0.189\" NUMERICAL mean:0.13848 min:0 max:1 sd:0.306265\n",
            "\t102: \"data:0.19\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t103: \"data:0.190\" NUMERICAL mean:0.0823212 min:0 max:1 sd:0.242604\n",
            "\t104: \"data:0.191\" NUMERICAL mean:0.0448723 min:0 max:1 sd:0.18026\n",
            "\t105: \"data:0.192\" NUMERICAL mean:0.0211285 min:0 max:1 sd:0.122173\n",
            "\t106: \"data:0.193\" NUMERICAL mean:0.0072768 min:0 max:1 sd:0.0698991\n",
            "\t107: \"data:0.194\" NUMERICAL mean:0.00146157 min:0 max:0.996078 sd:0.0302492\n",
            "\t108: \"data:0.195\" NUMERICAL mean:0.000118824 min:0 max:0.992157 sd:0.00807883\n",
            "\t109: \"data:0.196\" NUMERICAL mean:3.0719e-06 min:0 max:0.184314 sd:0.000752451\n",
            "\t110: \"data:0.197\" NUMERICAL mean:7.73856e-05 min:0 max:0.74902 sd:0.00584881\n",
            "\t111: \"data:0.198\" NUMERICAL mean:0.000422222 min:0 max:1 sd:0.0160884\n",
            "\t112: \"data:0.199\" NUMERICAL mean:0.00233588 min:0 max:1 sd:0.0394851\n",
            "\t113: \"data:0.2\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t114: \"data:0.20\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t115: \"data:0.200\" NUMERICAL mean:0.00906824 min:0 max:1 sd:0.0802464\n",
            "\t116: \"data:0.201\" NUMERICAL mean:0.0232501 min:0 max:1 sd:0.130295\n",
            "\t117: \"data:0.202\" NUMERICAL mean:0.0487688 min:0 max:1 sd:0.189023\n",
            "\t118: \"data:0.203\" NUMERICAL mean:0.0880463 min:0 max:1 sd:0.250907\n",
            "\t119: \"data:0.204\" NUMERICAL mean:0.142332 min:0 max:1 sd:0.310026\n",
            "\t120: \"data:0.205\" NUMERICAL mean:0.211366 min:0 max:1 sd:0.361838\n",
            "\t121: \"data:0.206\" NUMERICAL mean:0.289273 min:0 max:1 sd:0.399023\n",
            "\t122: \"data:0.207\" NUMERICAL mean:0.369032 min:0 max:1 sd:0.421443\n",
            "\t123: \"data:0.208\" NUMERICAL mean:0.437567 min:0 max:1 sd:0.431184\n",
            "\t124: \"data:0.209\" NUMERICAL mean:0.490196 min:0 max:1 sd:0.432971\n",
            "\t125: \"data:0.21\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t126: \"data:0.210\" NUMERICAL mean:0.520624 min:0 max:1 sd:0.433064\n",
            "\t127: \"data:0.211\" NUMERICAL mean:0.530975 min:0 max:1 sd:0.43185\n",
            "\t128: \"data:0.212\" NUMERICAL mean:0.522897 min:0 max:1 sd:0.432254\n",
            "\t129: \"data:0.213\" NUMERICAL mean:0.496775 min:0 max:1 sd:0.434012\n",
            "\t130: \"data:0.214\" NUMERICAL mean:0.445281 min:0 max:1 sd:0.435216\n",
            "\t131: \"data:0.215\" NUMERICAL mean:0.367625 min:0 max:1 sd:0.426007\n",
            "\t132: \"data:0.216\" NUMERICAL mean:0.273639 min:0 max:1 sd:0.396302\n",
            "\t133: \"data:0.217\" NUMERICAL mean:0.183658 min:0 max:1 sd:0.344639\n",
            "\t134: \"data:0.218\" NUMERICAL mean:0.110368 min:0 max:1 sd:0.277623\n",
            "\t135: \"data:0.219\" NUMERICAL mean:0.059612 min:0 max:1 sd:0.207215\n",
            "\t136: \"data:0.22\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t137: \"data:0.220\" NUMERICAL mean:0.027583 min:0 max:1 sd:0.14001\n",
            "\t138: \"data:0.221\" NUMERICAL mean:0.0101295 min:0 max:1 sd:0.0835571\n",
            "\t139: \"data:0.222\" NUMERICAL mean:0.00201216 min:0 max:1 sd:0.0354199\n",
            "\t140: \"data:0.223\" NUMERICAL mean:0.000125033 min:0 max:0.992157 sd:0.00812393\n",
            "\t141: \"data:0.224\" NUMERICAL mean:1.59477e-05 min:0 max:0.74902 sd:0.00317336\n",
            "\t142: \"data:0.225\" NUMERICAL mean:0.000199281 min:0 max:0.988235 sd:0.0115055\n",
            "\t143: \"data:0.226\" NUMERICAL mean:0.00129163 min:0 max:1 sd:0.0299818\n",
            "\t144: \"data:0.227\" NUMERICAL mean:0.00516608 min:0 max:1 sd:0.0605999\n",
            "\t145: \"data:0.228\" NUMERICAL mean:0.0146986 min:0 max:1 sd:0.105397\n",
            "\t146: \"data:0.229\" NUMERICAL mean:0.0332685 min:0 max:1 sd:0.157758\n",
            "\t147: \"data:0.23\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t148: \"data:0.230\" NUMERICAL mean:0.0659537 min:0 max:1 sd:0.219832\n",
            "\t149: \"data:0.231\" NUMERICAL mean:0.116068 min:0 max:1 sd:0.284983\n",
            "\t150: \"data:0.232\" NUMERICAL mean:0.18404 min:0 max:1 sd:0.345363\n",
            "\t151: \"data:0.233\" NUMERICAL mean:0.267086 min:0 max:1 sd:0.392411\n",
            "\t152: \"data:0.234\" NUMERICAL mean:0.354084 min:0 max:1 sd:0.420533\n",
            "\t153: \"data:0.235\" NUMERICAL mean:0.425395 min:0 max:1 sd:0.432999\n",
            "\t154: \"data:0.236\" NUMERICAL mean:0.468374 min:0 max:1 sd:0.435721\n",
            "\t155: \"data:0.237\" NUMERICAL mean:0.483897 min:0 max:1 sd:0.436738\n",
            "\t156: \"data:0.238\" NUMERICAL mean:0.482502 min:0 max:1 sd:0.436026\n",
            "\t157: \"data:0.239\" NUMERICAL mean:0.479767 min:0 max:1 sd:0.434515\n",
            "\t158: \"data:0.24\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t159: \"data:0.240\" NUMERICAL mean:0.481294 min:0 max:1 sd:0.434371\n",
            "\t160: \"data:0.241\" NUMERICAL mean:0.478996 min:0 max:1 sd:0.43537\n",
            "\t161: \"data:0.242\" NUMERICAL mean:0.455925 min:0 max:1 sd:0.436799\n",
            "\t162: \"data:0.243\" NUMERICAL mean:0.394551 min:0 max:1 sd:0.432158\n",
            "\t163: \"data:0.244\" NUMERICAL mean:0.303208 min:0 max:1 sd:0.410189\n",
            "\t164: \"data:0.245\" NUMERICAL mean:0.207442 min:0 max:1 sd:0.363292\n",
            "\t165: \"data:0.246\" NUMERICAL mean:0.124748 min:0 max:1 sd:0.294444\n",
            "\t166: \"data:0.247\" NUMERICAL mean:0.0641477 min:0 max:1 sd:0.215119\n",
            "\t167: \"data:0.248\" NUMERICAL mean:0.0281791 min:0 max:1 sd:0.142545\n",
            "\t168: \"data:0.249\" NUMERICAL mean:0.010222 min:0 max:1 sd:0.0847009\n",
            "\t169: \"data:0.25\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t170: \"data:0.250\" NUMERICAL mean:0.00188856 min:0 max:0.996078 sd:0.0350151\n",
            "\t171: \"data:0.251\" NUMERICAL mean:0.000106601 min:0 max:0.866667 sd:0.00789315\n",
            "\t172: \"data:0.252\" NUMERICAL mean:1.9085e-05 min:0 max:0.721569 sd:0.00323161\n",
            "\t173: \"data:0.253\" NUMERICAL mean:0.000311634 min:0 max:0.996078 sd:0.0147626\n",
            "\t174: \"data:0.254\" NUMERICAL mean:0.00200791 min:0 max:1 sd:0.0378929\n",
            "\t175: \"data:0.255\" NUMERICAL mean:0.00674268 min:0 max:1 sd:0.0724408\n",
            "\t176: \"data:0.256\" NUMERICAL mean:0.0174346 min:0 max:1 sd:0.115922\n",
            "\t177: \"data:0.257\" NUMERICAL mean:0.0384574 min:0 max:1 sd:0.170022\n",
            "\t178: \"data:0.258\" NUMERICAL mean:0.0765744 min:0 max:1 sd:0.2366\n",
            "\t179: \"data:0.259\" NUMERICAL mean:0.135313 min:0 max:1 sd:0.306047\n",
            "\t180: \"data:0.26\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t181: \"data:0.260\" NUMERICAL mean:0.214513 min:0 max:1 sd:0.367162\n",
            "\t182: \"data:0.261\" NUMERICAL mean:0.306424 min:0 max:1 sd:0.409342\n",
            "\t183: \"data:0.262\" NUMERICAL mean:0.388387 min:0 max:1 sd:0.431326\n",
            "\t184: \"data:0.263\" NUMERICAL mean:0.433727 min:0 max:1 sd:0.437054\n",
            "\t185: \"data:0.264\" NUMERICAL mean:0.434461 min:0 max:1 sd:0.436605\n",
            "\t186: \"data:0.265\" NUMERICAL mean:0.410014 min:0 max:1 sd:0.431795\n",
            "\t187: \"data:0.266\" NUMERICAL mean:0.38842 min:0 max:1 sd:0.42735\n",
            "\t188: \"data:0.267\" NUMERICAL mean:0.389758 min:0 max:1 sd:0.426461\n",
            "\t189: \"data:0.268\" NUMERICAL mean:0.40915 min:0 max:1 sd:0.428741\n",
            "\t190: \"data:0.269\" NUMERICAL mean:0.434832 min:0 max:1 sd:0.433493\n",
            "\t191: \"data:0.27\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t192: \"data:0.270\" NUMERICAL mean:0.435601 min:0 max:1 sd:0.435825\n",
            "\t193: \"data:0.271\" NUMERICAL mean:0.388811 min:0 max:1 sd:0.43129\n",
            "\t194: \"data:0.272\" NUMERICAL mean:0.30212 min:0 max:1 sd:0.410109\n",
            "\t195: \"data:0.273\" NUMERICAL mean:0.206689 min:0 max:1 sd:0.364153\n",
            "\t196: \"data:0.274\" NUMERICAL mean:0.123327 min:0 max:1 sd:0.293516\n",
            "\t197: \"data:0.275\" NUMERICAL mean:0.0603636 min:0 max:1 sd:0.208025\n",
            "\t198: \"data:0.276\" NUMERICAL mean:0.023377 min:0 max:1 sd:0.128811\n",
            "\t199: \"data:0.277\" NUMERICAL mean:0.00744301 min:0 max:1 sd:0.0709265\n",
            "\t200: \"data:0.278\" NUMERICAL mean:0.00137974 min:0 max:1 sd:0.0292236\n",
            "\t201: \"data:0.279\" NUMERICAL mean:0.000110654 min:0 max:0.862745 sd:0.00783063\n",
            "\t202: \"data:0.28\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t203: \"data:0.280\" NUMERICAL mean:2.61438e-05 min:0 max:0.839216 sd:0.00452878\n",
            "\t204: \"data:0.281\" NUMERICAL mean:0.000386536 min:0 max:1 sd:0.017079\n",
            "\t205: \"data:0.282\" NUMERICAL mean:0.00205111 min:0 max:1 sd:0.0388445\n",
            "\t206: \"data:0.283\" NUMERICAL mean:0.00656699 min:0 max:1 sd:0.071221\n",
            "\t207: \"data:0.284\" NUMERICAL mean:0.0168199 min:0 max:1 sd:0.114071\n",
            "\t208: \"data:0.285\" NUMERICAL mean:0.0387311 min:0 max:1 sd:0.170408\n",
            "\t209: \"data:0.286\" NUMERICAL mean:0.0805463 min:0 max:1 sd:0.242297\n",
            "\t210: \"data:0.287\" NUMERICAL mean:0.145839 min:0 max:1 sd:0.315195\n",
            "\t211: \"data:0.288\" NUMERICAL mean:0.234177 min:0 max:1 sd:0.378294\n",
            "\t212: \"data:0.289\" NUMERICAL mean:0.327054 min:0 max:1 sd:0.41701\n",
            "\t213: \"data:0.29\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t214: \"data:0.290\" NUMERICAL mean:0.393043 min:0 max:1 sd:0.432766\n",
            "\t215: \"data:0.291\" NUMERICAL mean:0.404584 min:0 max:1 sd:0.434395\n",
            "\t216: \"data:0.292\" NUMERICAL mean:0.368204 min:0 max:1 sd:0.423429\n",
            "\t217: \"data:0.293\" NUMERICAL mean:0.325305 min:0 max:1 sd:0.408132\n",
            "\t218: \"data:0.294\" NUMERICAL mean:0.311462 min:0 max:1 sd:0.403756\n",
            "\t219: \"data:0.295\" NUMERICAL mean:0.331471 min:0 max:1 sd:0.412503\n",
            "\t220: \"data:0.296\" NUMERICAL mean:0.368112 min:0 max:1 sd:0.42121\n",
            "\t221: \"data:0.297\" NUMERICAL mean:0.40952 min:0 max:1 sd:0.43036\n",
            "\t222: \"data:0.298\" NUMERICAL mean:0.416789 min:0 max:1 sd:0.433194\n",
            "\t223: \"data:0.299\" NUMERICAL mean:0.369498 min:0 max:1 sd:0.42792\n",
            "\t224: \"data:0.3\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t225: \"data:0.30\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t226: \"data:0.300\" NUMERICAL mean:0.281761 min:0 max:1 sd:0.401756\n",
            "\t227: \"data:0.301\" NUMERICAL mean:0.189479 min:0 max:1 sd:0.352588\n",
            "\t228: \"data:0.302\" NUMERICAL mean:0.111679 min:0 max:1 sd:0.28147\n",
            "\t229: \"data:0.303\" NUMERICAL mean:0.052934 min:0 max:1 sd:0.195168\n",
            "\t230: \"data:0.304\" NUMERICAL mean:0.0180412 min:0 max:1 sd:0.113235\n",
            "\t231: \"data:0.305\" NUMERICAL mean:0.0045102 min:0 max:1 sd:0.0555044\n",
            "\t232: \"data:0.306\" NUMERICAL mean:0.000869935 min:0 max:0.996078 sd:0.023543\n",
            "\t233: \"data:0.307\" NUMERICAL mean:7.34641e-05 min:0 max:0.796078 sd:0.00618728\n",
            "\t234: \"data:0.308\" NUMERICAL mean:2.3268e-05 min:0 max:0.588235 sd:0.003298\n",
            "\t235: \"data:0.309\" NUMERICAL mean:0.000299608 min:0 max:1 sd:0.0144242\n",
            "\t236: \"data:0.31\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t237: \"data:0.310\" NUMERICAL mean:0.00165052 min:0 max:1 sd:0.0349661\n",
            "\t238: \"data:0.311\" NUMERICAL mean:0.00502105 min:0 max:1 sd:0.0612294\n",
            "\t239: \"data:0.312\" NUMERICAL mean:0.0142984 min:0 max:1 sd:0.10402\n",
            "\t240: \"data:0.313\" NUMERICAL mean:0.0374663 min:0 max:1 sd:0.166382\n",
            "\t241: \"data:0.314\" NUMERICAL mean:0.0828754 min:0 max:1 sd:0.244837\n",
            "\t242: \"data:0.315\" NUMERICAL mean:0.156292 min:0 max:1 sd:0.32363\n",
            "\t243: \"data:0.316\" NUMERICAL mean:0.25133 min:0 max:1 sd:0.387683\n",
            "\t244: \"data:0.317\" NUMERICAL mean:0.341999 min:0 max:1 sd:0.422322\n",
            "\t245: \"data:0.318\" NUMERICAL mean:0.387375 min:0 max:1 sd:0.432116\n",
            "\t246: \"data:0.319\" NUMERICAL mean:0.372027 min:0 max:1 sd:0.426741\n",
            "\t247: \"data:0.32\" NUMERICAL mean:1.04575e-06 min:0 max:0.0627451 sd:0.000256154\n",
            "\t248: \"data:0.320\" NUMERICAL mean:0.320328 min:0 max:1 sd:0.408073\n",
            "\t249: \"data:0.321\" NUMERICAL mean:0.287619 min:0 max:1 sd:0.392631\n",
            "\t250: \"data:0.322\" NUMERICAL mean:0.298608 min:0 max:1 sd:0.403007\n",
            "\t251: \"data:0.323\" NUMERICAL mean:0.335002 min:0 max:1 sd:0.417599\n",
            "\t252: \"data:0.324\" NUMERICAL mean:0.38154 min:0 max:1 sd:0.42334\n",
            "\t253: \"data:0.325\" NUMERICAL mean:0.4215 min:0 max:1 sd:0.431104\n",
            "\t254: \"data:0.326\" NUMERICAL mean:0.413762 min:0 max:1 sd:0.433011\n",
            "\t255: \"data:0.327\" NUMERICAL mean:0.349135 min:0 max:1 sd:0.423244\n",
            "\t256: \"data:0.328\" NUMERICAL mean:0.254684 min:0 max:1 sd:0.388245\n",
            "\t257: \"data:0.329\" NUMERICAL mean:0.166654 min:0 max:1 sd:0.333733\n",
            "\t258: \"data:0.33\" NUMERICAL mean:3.59477e-06 min:0 max:0.184314 sd:0.000763272\n",
            "\t259: \"data:0.330\" NUMERICAL mean:0.0993769 min:0 max:1 sd:0.268896\n",
            "\t260: \"data:0.331\" NUMERICAL mean:0.0493342 min:0 max:1 sd:0.190874\n",
            "\t261: \"data:0.332\" NUMERICAL mean:0.0156466 min:0 max:1 sd:0.104523\n",
            "\t262: \"data:0.333\" NUMERICAL mean:0.00237072 min:0 max:1 sd:0.0387934\n",
            "\t263: \"data:0.334\" NUMERICAL mean:0.000488235 min:0 max:0.992157 sd:0.0174298\n",
            "\t264: \"data:0.335\" NUMERICAL mean:3.20261e-05 min:0 max:0.513726 sd:0.00350968\n",
            "\t265: \"data:0.336\" NUMERICAL mean:1.4902e-05 min:0 max:0.639216 sd:0.00280938\n",
            "\t266: \"data:0.337\" NUMERICAL mean:0.000171307 min:0 max:1 sd:0.0105495\n",
            "\t267: \"data:0.338\" NUMERICAL mean:0.00094915 min:0 max:1 sd:0.0260909\n",
            "\t268: \"data:0.339\" NUMERICAL mean:0.00344634 min:0 max:1 sd:0.0502514\n",
            "\t269: \"data:0.34\" NUMERICAL mean:3.64052e-05 min:0 max:0.615686 sd:0.00413727\n",
            "\t270: \"data:0.340\" NUMERICAL mean:0.0120346 min:0 max:1 sd:0.0944868\n",
            "\t271: \"data:0.341\" NUMERICAL mean:0.0376763 min:0 max:1 sd:0.166603\n",
            "\t272: \"data:0.342\" NUMERICAL mean:0.0893254 min:0 max:1 sd:0.253619\n",
            "\t273: \"data:0.343\" NUMERICAL mean:0.170882 min:0 max:1 sd:0.336659\n",
            "\t274: \"data:0.344\" NUMERICAL mean:0.270476 min:0 max:1 sd:0.398081\n",
            "\t275: \"data:0.345\" NUMERICAL mean:0.353948 min:0 max:1 sd:0.427344\n",
            "\t276: \"data:0.346\" NUMERICAL mean:0.383897 min:0 max:1 sd:0.431913\n",
            "\t277: \"data:0.347\" NUMERICAL mean:0.357187 min:0 max:1 sd:0.424263\n",
            "\t278: \"data:0.348\" NUMERICAL mean:0.312575 min:0 max:1 sd:0.407777\n",
            "\t279: \"data:0.349\" NUMERICAL mean:0.311251 min:0 max:1 sd:0.404115\n",
            "\t280: \"data:0.35\" NUMERICAL mean:9.52288e-05 min:0 max:0.996078 sd:0.00821606\n",
            "\t281: \"data:0.350\" NUMERICAL mean:0.350348 min:0 max:1 sd:0.427074\n",
            "\t282: \"data:0.351\" NUMERICAL mean:0.39888 min:0 max:1 sd:0.43466\n",
            "\t283: \"data:0.352\" NUMERICAL mean:0.443286 min:0 max:1 sd:0.430753\n",
            "\t284: \"data:0.353\" NUMERICAL mean:0.461102 min:0 max:1 sd:0.43571\n",
            "\t285: \"data:0.354\" NUMERICAL mean:0.421281 min:0 max:1 sd:0.436256\n",
            "\t286: \"data:0.355\" NUMERICAL mean:0.331447 min:0 max:1 sd:0.417189\n",
            "\t287: \"data:0.356\" NUMERICAL mean:0.229754 min:0 max:1 sd:0.372523\n",
            "\t288: \"data:0.357\" NUMERICAL mean:0.150053 min:0 max:1 sd:0.319212\n",
            "\t289: \"data:0.358\" NUMERICAL mean:0.093095 min:0 max:1 sd:0.262148\n",
            "\t290: \"data:0.359\" NUMERICAL mean:0.0498514 min:0 max:1 sd:0.195184\n",
            "\t291: \"data:0.36\" NUMERICAL mean:0.000171438 min:0 max:1 sd:0.0116158\n",
            "\t292: \"data:0.360\" NUMERICAL mean:0.016842 min:0 max:1 sd:0.109489\n",
            "\t293: \"data:0.361\" NUMERICAL mean:0.00173824 min:0 max:0.996078 sd:0.0331381\n",
            "\t294: \"data:0.362\" NUMERICAL mean:0.000312876 min:0 max:0.988235 sd:0.0145484\n",
            "\t295: \"data:0.363\" NUMERICAL mean:3.98693e-05 min:0 max:0.596078 sd:0.00401828\n",
            "\t296: \"data:0.364\" NUMERICAL mean:2.0915e-06 min:0 max:0.12549 sd:0.000512307\n",
            "\t297: \"data:0.365\" NUMERICAL mean:7.15686e-05 min:0 max:0.992157 sd:0.00654528\n",
            "\t298: \"data:0.366\" NUMERICAL mean:0.00048085 min:0 max:1 sd:0.0188238\n",
            "\t299: \"data:0.367\" NUMERICAL mean:0.0023817 min:0 max:1 sd:0.0417307\n",
            "\t300: \"data:0.368\" NUMERICAL mean:0.0114425 min:0 max:1 sd:0.0917881\n",
            "\t301: \"data:0.369\" NUMERICAL mean:0.0417026 min:0 max:1 sd:0.174855\n",
            "\t302: \"data:0.37\" NUMERICAL mean:0.000251373 min:0 max:0.996078 sd:0.0130347\n",
            "\t303: \"data:0.370\" NUMERICAL mean:0.100211 min:0 max:1 sd:0.268476\n",
            "\t304: \"data:0.371\" NUMERICAL mean:0.186603 min:0 max:1 sd:0.35001\n",
            "\t305: \"data:0.372\" NUMERICAL mean:0.284832 min:0 max:1 sd:0.40569\n",
            "\t306: \"data:0.373\" NUMERICAL mean:0.359505 min:0 max:1 sd:0.429285\n",
            "\t307: \"data:0.374\" NUMERICAL mean:0.379955 min:0 max:1 sd:0.43173\n",
            "\t308: \"data:0.375\" NUMERICAL mean:0.357246 min:0 max:1 sd:0.42478\n",
            "\t309: \"data:0.376\" NUMERICAL mean:0.340656 min:0 max:1 sd:0.417066\n",
            "\t310: \"data:0.377\" NUMERICAL mean:0.380261 min:0 max:1 sd:0.426338\n",
            "\t311: \"data:0.378\" NUMERICAL mean:0.436752 min:0 max:1 sd:0.446326\n",
            "\t312: \"data:0.379\" NUMERICAL mean:0.486165 min:0 max:1 sd:0.43767\n",
            "\t313: \"data:0.38\" NUMERICAL mean:0.000471111 min:0 max:1 sd:0.0190951\n",
            "\t314: \"data:0.380\" NUMERICAL mean:0.509045 min:0 max:1 sd:0.431164\n",
            "\t315: \"data:0.381\" NUMERICAL mean:0.496469 min:0 max:1 sd:0.439798\n",
            "\t316: \"data:0.382\" NUMERICAL mean:0.426982 min:0 max:1 sd:0.43745\n",
            "\t317: \"data:0.383\" NUMERICAL mean:0.318265 min:0 max:1 sd:0.410561\n",
            "\t318: \"data:0.384\" NUMERICAL mean:0.216572 min:0 max:1 sd:0.364325\n",
            "\t319: \"data:0.385\" NUMERICAL mean:0.1459 min:0 max:1 sd:0.316548\n",
            "\t320: \"data:0.386\" NUMERICAL mean:0.094011 min:0 max:1 sd:0.264447\n",
            "\t321: \"data:0.387\" NUMERICAL mean:0.0535049 min:0 max:1 sd:0.203017\n",
            "\t322: \"data:0.388\" NUMERICAL mean:0.0200105 min:0 max:1 sd:0.121642\n",
            "\t323: \"data:0.389\" NUMERICAL mean:0.00229294 min:0 max:0.996078 sd:0.0385284\n",
            "\t324: \"data:0.39\" NUMERICAL mean:0.000630327 min:0 max:1 sd:0.0216823\n",
            "\t325: \"data:0.390\" NUMERICAL mean:0.000325425 min:0 max:0.988235 sd:0.0139257\n",
            "\t326: \"data:0.391\" NUMERICAL mean:4.26144e-05 min:0 max:0.968627 sd:0.00575534\n",
            "\t327: \"data:0.392\" NUMERICAL mean:7.38562e-06 min:0 max:0.443137 sd:0.00180909\n",
            "\t328: \"data:0.393\" NUMERICAL mean:3.23529e-05 min:0 max:0.737255 sd:0.00405002\n",
            "\t329: \"data:0.394\" NUMERICAL mean:0.000212418 min:0 max:0.996078 sd:0.0116098\n",
            "\t330: \"data:0.395\" NUMERICAL mean:0.00182817 min:0 max:1 sd:0.0356095\n",
            "\t331: \"data:0.396\" NUMERICAL mean:0.0120219 min:0 max:1 sd:0.0929434\n",
            "\t332: \"data:0.397\" NUMERICAL mean:0.0484363 min:0 max:1 sd:0.188087\n",
            "\t333: \"data:0.398\" NUMERICAL mean:0.111875 min:0 max:1 sd:0.283219\n",
            "\t334: \"data:0.399\" NUMERICAL mean:0.198072 min:0 max:1 sd:0.359855\n",
            "\t335: \"data:0.4\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t336: \"data:0.40\" NUMERICAL mean:0.000683072 min:0 max:1 sd:0.022328\n",
            "\t337: \"data:0.400\" NUMERICAL mean:0.289218 min:0 max:1 sd:0.408891\n",
            "\t338: \"data:0.401\" NUMERICAL mean:0.354389 min:0 max:1 sd:0.429016\n",
            "\t339: \"data:0.402\" NUMERICAL mean:0.372851 min:0 max:1 sd:0.429624\n",
            "\t340: \"data:0.403\" NUMERICAL mean:0.365837 min:0 max:1 sd:0.425025\n",
            "\t341: \"data:0.404\" NUMERICAL mean:0.383643 min:0 max:1 sd:0.424367\n",
            "\t342: \"data:0.405\" NUMERICAL mean:0.452633 min:0 max:1 sd:0.437452\n",
            "\t343: \"data:0.406\" NUMERICAL mean:0.510852 min:0 max:1 sd:0.445989\n",
            "\t344: \"data:0.407\" NUMERICAL mean:0.547269 min:0 max:1 sd:0.429497\n",
            "\t345: \"data:0.408\" NUMERICAL mean:0.53765 min:0 max:1 sd:0.430742\n",
            "\t346: \"data:0.409\" NUMERICAL mean:0.502297 min:0 max:1 sd:0.440698\n",
            "\t347: \"data:0.41\" NUMERICAL mean:0.000695817 min:0 max:1 sd:0.0223276\n",
            "\t348: \"data:0.410\" NUMERICAL mean:0.419586 min:0 max:1 sd:0.435579\n",
            "\t349: \"data:0.411\" NUMERICAL mean:0.311976 min:0 max:1 sd:0.408875\n",
            "\t350: \"data:0.412\" NUMERICAL mean:0.219987 min:0 max:1 sd:0.36847\n",
            "\t351: \"data:0.413\" NUMERICAL mean:0.152718 min:0 max:1 sd:0.323541\n",
            "\t352: \"data:0.414\" NUMERICAL mean:0.100147 min:0 max:1 sd:0.271865\n",
            "\t353: \"data:0.415\" NUMERICAL mean:0.0573186 min:0 max:1 sd:0.209708\n",
            "\t354: \"data:0.416\" NUMERICAL mean:0.0224376 min:0 max:1 sd:0.129408\n",
            "\t355: \"data:0.417\" NUMERICAL mean:0.00321686 min:0 max:1 sd:0.0466599\n",
            "\t356: \"data:0.418\" NUMERICAL mean:0.000362549 min:0 max:0.996078 sd:0.0147111\n",
            "\t357: \"data:0.419\" NUMERICAL mean:8.69281e-06 min:0 max:0.203922 sd:0.00124451\n",
            "\t358: \"data:0.42\" NUMERICAL mean:0.000742418 min:0 max:1 sd:0.0232275\n",
            "\t359: \"data:0.420\" NUMERICAL mean:2.87582e-06 min:0 max:0.145098 sd:0.000602861\n",
            "\t360: \"data:0.421\" NUMERICAL mean:1.51634e-05 min:0 max:0.886275 sd:0.00361944\n",
            "\t361: \"data:0.422\" NUMERICAL mean:0.000176863 min:0 max:0.996078 sd:0.00948414\n",
            "\t362: \"data:0.423\" NUMERICAL mean:0.00198268 min:0 max:1 sd:0.037218\n",
            "\t363: \"data:0.424\" NUMERICAL mean:0.013963 min:0 max:1 sd:0.0994371\n",
            "\t364: \"data:0.425\" NUMERICAL mean:0.0565025 min:0 max:1 sd:0.203847\n",
            "\t365: \"data:0.426\" NUMERICAL mean:0.121523 min:0 max:1 sd:0.294809\n",
            "\t366: \"data:0.427\" NUMERICAL mean:0.200822 min:0 max:1 sd:0.362493\n",
            "\t367: \"data:0.428\" NUMERICAL mean:0.280159 min:0 max:1 sd:0.40485\n",
            "\t368: \"data:0.429\" NUMERICAL mean:0.336205 min:0 max:1 sd:0.424189\n",
            "\t369: \"data:0.43\" NUMERICAL mean:0.000682941 min:0 max:1 sd:0.022612\n",
            "\t370: \"data:0.430\" NUMERICAL mean:0.358357 min:0 max:1 sd:0.425632\n",
            "\t371: \"data:0.431\" NUMERICAL mean:0.369578 min:0 max:1 sd:0.424916\n",
            "\t372: \"data:0.432\" NUMERICAL mean:0.411949 min:0 max:1 sd:0.429712\n",
            "\t373: \"data:0.433\" NUMERICAL mean:0.483154 min:0 max:1 sd:0.441598\n",
            "\t374: \"data:0.434\" NUMERICAL mean:0.532115 min:0 max:1 sd:0.441628\n",
            "\t375: \"data:0.435\" NUMERICAL mean:0.54553 min:0 max:1 sd:0.428732\n",
            "\t376: \"data:0.436\" NUMERICAL mean:0.51688 min:0 max:1 sd:0.436689\n",
            "\t377: \"data:0.437\" NUMERICAL mean:0.476222 min:0 max:1 sd:0.44162\n",
            "\t378: \"data:0.438\" NUMERICAL mean:0.397413 min:0 max:1 sd:0.43076\n",
            "\t379: \"data:0.439\" NUMERICAL mean:0.30737 min:0 max:1 sd:0.408475\n",
            "\t380: \"data:0.44\" NUMERICAL mean:0.000733072 min:0 max:1 sd:0.0234132\n",
            "\t381: \"data:0.440\" NUMERICAL mean:0.22856 min:0 max:1 sd:0.37482\n",
            "\t382: \"data:0.441\" NUMERICAL mean:0.161768 min:0 max:1 sd:0.332341\n",
            "\t383: \"data:0.442\" NUMERICAL mean:0.105804 min:0 max:1 sd:0.277777\n",
            "\t384: \"data:0.443\" NUMERICAL mean:0.0583945 min:0 max:1 sd:0.209827\n",
            "\t385: \"data:0.444\" NUMERICAL mean:0.022856 min:0 max:1 sd:0.13024\n",
            "\t386: \"data:0.445\" NUMERICAL mean:0.00423359 min:0 max:1 sd:0.0549631\n",
            "\t387: \"data:0.446\" NUMERICAL mean:0.000581242 min:0 max:1 sd:0.0196191\n",
            "\t388: \"data:0.447\" NUMERICAL mean:4.24837e-05 min:0 max:0.745098 sd:0.00466329\n",
            "\t389: \"data:0.448\" NUMERICAL mean:2.61438e-06 min:0 max:0.156863 sd:0.000640384\n",
            "\t390: \"data:0.449\" NUMERICAL mean:1.55556e-05 min:0 max:0.419608 sd:0.00231921\n",
            "\t391: \"data:0.45\" NUMERICAL mean:0.000602549 min:0 max:1 sd:0.0212289\n",
            "\t392: \"data:0.450\" NUMERICAL mean:0.000291503 min:0 max:0.996078 sd:0.0134946\n",
            "\t393: \"data:0.451\" NUMERICAL mean:0.00244301 min:0 max:1 sd:0.0402421\n",
            "\t394: \"data:0.452\" NUMERICAL mean:0.0175293 min:0 max:1 sd:0.111636\n",
            "\t395: \"data:0.453\" NUMERICAL mean:0.0648195 min:0 max:1 sd:0.218128\n",
            "\t396: \"data:0.454\" NUMERICAL mean:0.127666 min:0 max:1 sd:0.302307\n",
            "\t397: \"data:0.455\" NUMERICAL mean:0.195862 min:0 max:1 sd:0.358901\n",
            "\t398: \"data:0.456\" NUMERICAL mean:0.260046 min:0 max:1 sd:0.394547\n",
            "\t399: \"data:0.457\" NUMERICAL mean:0.305436 min:0 max:1 sd:0.412055\n",
            "\t400: \"data:0.458\" NUMERICAL mean:0.328263 min:0 max:1 sd:0.416377\n",
            "\t401: \"data:0.459\" NUMERICAL mean:0.350778 min:0 max:1 sd:0.420614\n",
            "\t402: \"data:0.46\" NUMERICAL mean:0.000392614 min:0 max:1 sd:0.0169822\n",
            "\t403: \"data:0.460\" NUMERICAL mean:0.396612 min:0 max:1 sd:0.431375\n",
            "\t404: \"data:0.461\" NUMERICAL mean:0.454343 min:0 max:1 sd:0.442848\n",
            "\t405: \"data:0.462\" NUMERICAL mean:0.495974 min:0 max:1 sd:0.441739\n",
            "\t406: \"data:0.463\" NUMERICAL mean:0.499712 min:0 max:1 sd:0.436406\n",
            "\t407: \"data:0.464\" NUMERICAL mean:0.474733 min:0 max:1 sd:0.439787\n",
            "\t408: \"data:0.465\" NUMERICAL mean:0.436149 min:0 max:1 sd:0.436199\n",
            "\t409: \"data:0.466\" NUMERICAL mean:0.374009 min:0 max:1 sd:0.425534\n",
            "\t410: \"data:0.467\" NUMERICAL mean:0.303352 min:0 max:1 sd:0.40796\n",
            "\t411: \"data:0.468\" NUMERICAL mean:0.233754 min:0 max:1 sd:0.379704\n",
            "\t412: \"data:0.469\" NUMERICAL mean:0.164864 min:0 max:1 sd:0.334356\n",
            "\t413: \"data:0.47\" NUMERICAL mean:0.000279346 min:0 max:1 sd:0.0145746\n",
            "\t414: \"data:0.470\" NUMERICAL mean:0.104819 min:0 max:1 sd:0.27593\n",
            "\t415: \"data:0.471\" NUMERICAL mean:0.0558554 min:0 max:1 sd:0.204211\n",
            "\t416: \"data:0.472\" NUMERICAL mean:0.0220218 min:0 max:1 sd:0.126898\n",
            "\t417: \"data:0.473\" NUMERICAL mean:0.00504745 min:0 max:1 sd:0.0600529\n",
            "\t418: \"data:0.474\" NUMERICAL mean:0.00075098 min:0 max:0.996078 sd:0.0219826\n",
            "\t419: \"data:0.475\" NUMERICAL mean:4.82353e-05 min:0 max:0.87451 sd:0.00539566\n",
            "\t420: \"data:0.476\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t421: \"data:0.477\" NUMERICAL mean:2.85621e-05 min:0 max:0.521569 sd:0.00319769\n",
            "\t422: \"data:0.478\" NUMERICAL mean:0.00044 min:0 max:0.996078 sd:0.0173244\n",
            "\t423: \"data:0.479\" NUMERICAL mean:0.00373863 min:0 max:1 sd:0.0505902\n",
            "\t424: \"data:0.48\" NUMERICAL mean:0.000211046 min:0 max:0.956863 sd:0.012583\n",
            "\t425: \"data:0.480\" NUMERICAL mean:0.0233421 min:0 max:1 sd:0.131239\n",
            "\t426: \"data:0.481\" NUMERICAL mean:0.0726447 min:0 max:1 sd:0.231808\n",
            "\t427: \"data:0.482\" NUMERICAL mean:0.131181 min:0 max:1 sd:0.305774\n",
            "\t428: \"data:0.483\" NUMERICAL mean:0.188927 min:0 max:1 sd:0.353076\n",
            "\t429: \"data:0.484\" NUMERICAL mean:0.2371 min:0 max:1 sd:0.381938\n",
            "\t430: \"data:0.485\" NUMERICAL mean:0.271443 min:0 max:1 sd:0.397609\n",
            "\t431: \"data:0.486\" NUMERICAL mean:0.292868 min:0 max:1 sd:0.40481\n",
            "\t432: \"data:0.487\" NUMERICAL mean:0.316615 min:0 max:1 sd:0.413573\n",
            "\t433: \"data:0.488\" NUMERICAL mean:0.35132 min:0 max:1 sd:0.425806\n",
            "\t434: \"data:0.489\" NUMERICAL mean:0.399806 min:0 max:1 sd:0.434859\n",
            "\t435: \"data:0.49\" NUMERICAL mean:8.37909e-05 min:0 max:1 sd:0.00761987\n",
            "\t436: \"data:0.490\" NUMERICAL mean:0.441633 min:0 max:1 sd:0.438886\n",
            "\t437: \"data:0.491\" NUMERICAL mean:0.452694 min:0 max:1 sd:0.438311\n",
            "\t438: \"data:0.492\" NUMERICAL mean:0.440176 min:0 max:1 sd:0.435528\n",
            "\t439: \"data:0.493\" NUMERICAL mean:0.409899 min:0 max:1 sd:0.430788\n",
            "\t440: \"data:0.494\" NUMERICAL mean:0.363242 min:0 max:1 sd:0.424613\n",
            "\t441: \"data:0.495\" NUMERICAL mean:0.302986 min:0 max:1 sd:0.409263\n",
            "\t442: \"data:0.496\" NUMERICAL mean:0.232661 min:0 max:1 sd:0.37938\n",
            "\t443: \"data:0.497\" NUMERICAL mean:0.160033 min:0 max:1 sd:0.329858\n",
            "\t444: \"data:0.498\" NUMERICAL mean:0.0978147 min:0 max:1 sd:0.265771\n",
            "\t445: \"data:0.499\" NUMERICAL mean:0.0503325 min:0 max:1 sd:0.193006\n",
            "\t446: \"data:0.5\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t447: \"data:0.50\" NUMERICAL mean:3.95425e-05 min:0 max:0.721569 sd:0.00474993\n",
            "\t448: \"data:0.500\" NUMERICAL mean:0.0202222 min:0 max:1 sd:0.120131\n",
            "\t449: \"data:0.501\" NUMERICAL mean:0.00555556 min:0 max:1 sd:0.0627444\n",
            "\t450: \"data:0.502\" NUMERICAL mean:0.00082366 min:0 max:0.992157 sd:0.02292\n",
            "\t451: \"data:0.503\" NUMERICAL mean:3.48366e-05 min:0 max:0.407843 sd:0.00325247\n",
            "\t452: \"data:0.504\" NUMERICAL mean:7.45098e-06 min:0 max:0.235294 sd:0.0012616\n",
            "\t453: \"data:0.505\" NUMERICAL mean:2.08497e-05 min:0 max:0.772549 sd:0.00328232\n",
            "\t454: \"data:0.506\" NUMERICAL mean:0.000707843 min:0 max:1 sd:0.0212437\n",
            "\t455: \"data:0.507\" NUMERICAL mean:0.00596137 min:0 max:1 sd:0.0652909\n",
            "\t456: \"data:0.508\" NUMERICAL mean:0.029888 min:0 max:1 sd:0.15011\n",
            "\t457: \"data:0.509\" NUMERICAL mean:0.0800701 min:0 max:1 sd:0.24414\n",
            "\t458: \"data:0.51\" NUMERICAL mean:1.38562e-05 min:0 max:0.772549 sd:0.00316302\n",
            "\t459: \"data:0.510\" NUMERICAL mean:0.136905 min:0 max:1 sd:0.31186\n",
            "\t460: \"data:0.511\" NUMERICAL mean:0.188951 min:0 max:1 sd:0.353541\n",
            "\t461: \"data:0.512\" NUMERICAL mean:0.228537 min:0 max:1 sd:0.377156\n",
            "\t462: \"data:0.513\" NUMERICAL mean:0.258802 min:0 max:1 sd:0.392478\n",
            "\t463: \"data:0.514\" NUMERICAL mean:0.281359 min:0 max:1 sd:0.403181\n",
            "\t464: \"data:0.515\" NUMERICAL mean:0.300327 min:0 max:1 sd:0.411168\n",
            "\t465: \"data:0.516\" NUMERICAL mean:0.325969 min:0 max:1 sd:0.417307\n",
            "\t466: \"data:0.517\" NUMERICAL mean:0.373059 min:0 max:1 sd:0.427972\n",
            "\t467: \"data:0.518\" NUMERICAL mean:0.417871 min:0 max:1 sd:0.435985\n",
            "\t468: \"data:0.519\" NUMERICAL mean:0.440005 min:0 max:1 sd:0.435112\n",
            "\t469: \"data:0.52\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t470: \"data:0.520\" NUMERICAL mean:0.436659 min:0 max:1 sd:0.432143\n",
            "\t471: \"data:0.521\" NUMERICAL mean:0.411836 min:0 max:1 sd:0.432172\n",
            "\t472: \"data:0.522\" NUMERICAL mean:0.367132 min:0 max:1 sd:0.427531\n",
            "\t473: \"data:0.523\" NUMERICAL mean:0.3005 min:0 max:1 sd:0.410344\n",
            "\t474: \"data:0.524\" NUMERICAL mean:0.222357 min:0 max:1 sd:0.373766\n",
            "\t475: \"data:0.525\" NUMERICAL mean:0.148088 min:0 max:1 sd:0.319549\n",
            "\t476: \"data:0.526\" NUMERICAL mean:0.0884185 min:0 max:1 sd:0.253514\n",
            "\t477: \"data:0.527\" NUMERICAL mean:0.0446366 min:0 max:1 sd:0.181535\n",
            "\t478: \"data:0.528\" NUMERICAL mean:0.0179571 min:0 max:1 sd:0.113508\n",
            "\t479: \"data:0.529\" NUMERICAL mean:0.00509235 min:0 max:1 sd:0.0596029\n",
            "\t480: \"data:0.53\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t481: \"data:0.530\" NUMERICAL mean:0.00060366 min:0 max:1 sd:0.0191286\n",
            "\t482: \"data:0.531\" NUMERICAL mean:4.77778e-05 min:0 max:0.6 sd:0.00489506\n",
            "\t483: \"data:0.532\" NUMERICAL mean:9.80392e-07 min:0 max:0.0588235 sd:0.000240144\n",
            "\t484: \"data:0.533\" NUMERICAL mean:4.77778e-05 min:0 max:0.65098 sd:0.00423499\n",
            "\t485: \"data:0.534\" NUMERICAL mean:0.00112281 min:0 max:1 sd:0.0282418\n",
            "\t486: \"data:0.535\" NUMERICAL mean:0.00801497 min:0 max:1 sd:0.0771766\n",
            "\t487: \"data:0.536\" NUMERICAL mean:0.0342099 min:0 max:1 sd:0.161382\n",
            "\t488: \"data:0.537\" NUMERICAL mean:0.0852332 min:0 max:1 sd:0.252559\n",
            "\t489: \"data:0.538\" NUMERICAL mean:0.144444 min:0 max:1 sd:0.319777\n",
            "\t490: \"data:0.539\" NUMERICAL mean:0.199918 min:0 max:1 sd:0.362084\n",
            "\t491: \"data:0.54\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t492: \"data:0.540\" NUMERICAL mean:0.24451 min:0 max:1 sd:0.386953\n",
            "\t493: \"data:0.541\" NUMERICAL mean:0.279496 min:0 max:1 sd:0.403183\n",
            "\t494: \"data:0.542\" NUMERICAL mean:0.305413 min:0 max:1 sd:0.413623\n",
            "\t495: \"data:0.543\" NUMERICAL mean:0.324058 min:0 max:1 sd:0.420455\n",
            "\t496: \"data:0.544\" NUMERICAL mean:0.352813 min:0 max:1 sd:0.425708\n",
            "\t497: \"data:0.545\" NUMERICAL mean:0.397672 min:0 max:1 sd:0.432594\n",
            "\t498: \"data:0.546\" NUMERICAL mean:0.440963 min:0 max:1 sd:0.437113\n",
            "\t499: \"data:0.547\" NUMERICAL mean:0.461974 min:0 max:1 sd:0.435485\n",
            "\t500: \"data:0.548\" NUMERICAL mean:0.454606 min:0 max:1 sd:0.433733\n",
            "\t501: \"data:0.549\" NUMERICAL mean:0.421304 min:0 max:1 sd:0.435657\n",
            "\t502: \"data:0.55\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t503: \"data:0.550\" NUMERICAL mean:0.361872 min:0 max:1 sd:0.427491\n",
            "\t504: \"data:0.551\" NUMERICAL mean:0.281895 min:0 max:1 sd:0.402005\n",
            "\t505: \"data:0.552\" NUMERICAL mean:0.199217 min:0 max:1 sd:0.3587\n",
            "\t506: \"data:0.553\" NUMERICAL mean:0.128212 min:0 max:1 sd:0.300209\n",
            "\t507: \"data:0.554\" NUMERICAL mean:0.0736195 min:0 max:1 sd:0.232377\n",
            "\t508: \"data:0.555\" NUMERICAL mean:0.0359073 min:0 max:1 sd:0.162708\n",
            "\t509: \"data:0.556\" NUMERICAL mean:0.0142747 min:0 max:1 sd:0.101198\n",
            "\t510: \"data:0.557\" NUMERICAL mean:0.0041902 min:0 max:1 sd:0.0536029\n",
            "\t511: \"data:0.558\" NUMERICAL mean:0.000575294 min:0 max:0.992157 sd:0.0197136\n",
            "\t512: \"data:0.559\" NUMERICAL mean:2.67974e-05 min:0 max:0.501961 sd:0.00333891\n",
            "\t513: \"data:0.56\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t514: \"data:0.560\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t515: \"data:0.561\" NUMERICAL mean:5.98693e-05 min:0 max:0.72549 sd:0.00578889\n",
            "\t516: \"data:0.562\" NUMERICAL mean:0.00130196 min:0 max:1 sd:0.0300867\n",
            "\t517: \"data:0.563\" NUMERICAL mean:0.00884575 min:0 max:1 sd:0.0810295\n",
            "\t518: \"data:0.564\" NUMERICAL mean:0.0333845 min:0 max:1 sd:0.15971\n",
            "\t519: \"data:0.565\" NUMERICAL mean:0.0811533 min:0 max:1 sd:0.245752\n",
            "\t520: \"data:0.566\" NUMERICAL mean:0.145432 min:0 max:1 sd:0.319719\n",
            "\t521: \"data:0.567\" NUMERICAL mean:0.210957 min:0 max:1 sd:0.370622\n",
            "\t522: \"data:0.568\" NUMERICAL mean:0.270076 min:0 max:1 sd:0.401336\n",
            "\t523: \"data:0.569\" NUMERICAL mean:0.318273 min:0 max:1 sd:0.418449\n",
            "\t524: \"data:0.57\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t525: \"data:0.570\" NUMERICAL mean:0.354533 min:0 max:1 sd:0.427789\n",
            "\t526: \"data:0.571\" NUMERICAL mean:0.383868 min:0 max:1 sd:0.433011\n",
            "\t527: \"data:0.572\" NUMERICAL mean:0.418567 min:0 max:1 sd:0.43608\n",
            "\t528: \"data:0.573\" NUMERICAL mean:0.460155 min:0 max:1 sd:0.437666\n",
            "\t529: \"data:0.574\" NUMERICAL mean:0.490009 min:0 max:1 sd:0.437155\n",
            "\t530: \"data:0.575\" NUMERICAL mean:0.492375 min:0 max:1 sd:0.436138\n",
            "\t531: \"data:0.576\" NUMERICAL mean:0.463593 min:0 max:1 sd:0.436225\n",
            "\t532: \"data:0.577\" NUMERICAL mean:0.407082 min:0 max:1 sd:0.433373\n",
            "\t533: \"data:0.578\" NUMERICAL mean:0.328927 min:0 max:1 sd:0.417766\n",
            "\t534: \"data:0.579\" NUMERICAL mean:0.24014 min:0 max:1 sd:0.383004\n",
            "\t535: \"data:0.58\" NUMERICAL mean:4.18301e-06 min:0 max:0.25098 sd:0.00102461\n",
            "\t536: \"data:0.580\" NUMERICAL mean:0.160598 min:0 max:1 sd:0.329052\n",
            "\t537: \"data:0.581\" NUMERICAL mean:0.0978197 min:0 max:1 sd:0.265129\n",
            "\t538: \"data:0.582\" NUMERICAL mean:0.0534456 min:0 max:1 sd:0.198467\n",
            "\t539: \"data:0.583\" NUMERICAL mean:0.0256373 min:0 max:1 sd:0.136942\n",
            "\t540: \"data:0.584\" NUMERICAL mean:0.0106427 min:0 max:1 sd:0.0875023\n",
            "\t541: \"data:0.585\" NUMERICAL mean:0.00293791 min:0 max:1 sd:0.0441832\n",
            "\t542: \"data:0.586\" NUMERICAL mean:0.000437974 min:0 max:1 sd:0.0168238\n",
            "\t543: \"data:0.587\" NUMERICAL mean:6.60131e-06 min:0 max:0.2 sd:0.00114342\n",
            "\t544: \"data:0.588\" NUMERICAL mean:2.0915e-06 min:0 max:0.12549 sd:0.000512307\n",
            "\t545: \"data:0.589\" NUMERICAL mean:4.98039e-05 min:0 max:0.72549 sd:0.00497566\n",
            "\t546: \"data:0.59\" NUMERICAL mean:2.7451e-06 min:0 max:0.113725 sd:0.00050879\n",
            "\t547: \"data:0.590\" NUMERICAL mean:0.00111464 min:0 max:1 sd:0.0275229\n",
            "\t548: \"data:0.591\" NUMERICAL mean:0.00721255 min:0 max:1 sd:0.0721365\n",
            "\t549: \"data:0.592\" NUMERICAL mean:0.0260101 min:0 max:1 sd:0.138203\n",
            "\t550: \"data:0.593\" NUMERICAL mean:0.0662764 min:0 max:1 sd:0.221193\n",
            "\t551: \"data:0.594\" NUMERICAL mean:0.128665 min:0 max:1 sd:0.301147\n",
            "\t552: \"data:0.595\" NUMERICAL mean:0.202239 min:0 max:1 sd:0.364229\n",
            "\t553: \"data:0.596\" NUMERICAL mean:0.276172 min:0 max:1 sd:0.405076\n",
            "\t554: \"data:0.597\" NUMERICAL mean:0.342165 min:0 max:1 sd:0.426859\n",
            "\t555: \"data:0.598\" NUMERICAL mean:0.39602 min:0 max:1 sd:0.43583\n",
            "\t556: \"data:0.599\" NUMERICAL mean:0.441003 min:0 max:1 sd:0.437093\n",
            "\t557: \"data:0.6\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t558: \"data:0.60\" NUMERICAL mean:2.72549e-05 min:0 max:0.52549 sd:0.00319803\n",
            "\t559: \"data:0.600\" NUMERICAL mean:0.480761 min:0 max:1 sd:0.435621\n",
            "\t560: \"data:0.601\" NUMERICAL mean:0.511264 min:0 max:1 sd:0.432786\n",
            "\t561: \"data:0.602\" NUMERICAL mean:0.517039 min:0 max:1 sd:0.43369\n",
            "\t562: \"data:0.603\" NUMERICAL mean:0.489679 min:0 max:1 sd:0.435152\n",
            "\t563: \"data:0.604\" NUMERICAL mean:0.431474 min:0 max:1 sd:0.433769\n",
            "\t564: \"data:0.605\" NUMERICAL mean:0.350847 min:0 max:1 sd:0.421573\n",
            "\t565: \"data:0.606\" NUMERICAL mean:0.261142 min:0 max:1 sd:0.391444\n",
            "\t566: \"data:0.607\" NUMERICAL mean:0.178813 min:0 max:1 sd:0.342099\n",
            "\t567: \"data:0.608\" NUMERICAL mean:0.111987 min:0 max:1 sd:0.280623\n",
            "\t568: \"data:0.609\" NUMERICAL mean:0.0639052 min:0 max:1 sd:0.215386\n",
            "\t569: \"data:0.61\" NUMERICAL mean:2.15033e-05 min:0 max:0.243137 sd:0.00179418\n",
            "\t570: \"data:0.610\" NUMERICAL mean:0.0333784 min:0 max:1 sd:0.156981\n",
            "\t571: \"data:0.611\" NUMERICAL mean:0.0161141 min:0 max:1 sd:0.108371\n",
            "\t572: \"data:0.612\" NUMERICAL mean:0.00667837 min:0 max:1 sd:0.0689232\n",
            "\t573: \"data:0.613\" NUMERICAL mean:0.00174046 min:0 max:1 sd:0.0341728\n",
            "\t574: \"data:0.614\" NUMERICAL mean:0.000231569 min:0 max:0.988235 sd:0.0114556\n",
            "\t575: \"data:0.615\" NUMERICAL mean:2.54902e-06 min:0 max:0.152941 sd:0.000624375\n",
            "\t576: \"data:0.616\" NUMERICAL mean:2.02614e-06 min:0 max:0.121569 sd:0.000496298\n",
            "\t577: \"data:0.617\" NUMERICAL mean:3.85621e-06 min:0 max:0.14902 sd:0.000642176\n",
            "\t578: \"data:0.618\" NUMERICAL mean:0.00073366 min:0 max:1 sd:0.0217662\n",
            "\t579: \"data:0.619\" NUMERICAL mean:0.00426654 min:0 max:1 sd:0.0540256\n",
            "\t580: \"data:0.62\" NUMERICAL mean:0.000184706 min:0 max:0.917647 sd:0.0104629\n",
            "\t581: \"data:0.620\" NUMERICAL mean:0.0154684 min:0 max:1 sd:0.104699\n",
            "\t582: \"data:0.621\" NUMERICAL mean:0.0425309 min:0 max:1 sd:0.174844\n",
            "\t583: \"data:0.622\" NUMERICAL mean:0.091728 min:0 max:1 sd:0.254555\n",
            "\t584: \"data:0.623\" NUMERICAL mean:0.159367 min:0 max:1 sd:0.327616\n",
            "\t585: \"data:0.624\" NUMERICAL mean:0.239095 min:0 max:1 sd:0.384144\n",
            "\t586: \"data:0.625\" NUMERICAL mean:0.317668 min:0 max:1 sd:0.419805\n",
            "\t587: \"data:0.626\" NUMERICAL mean:0.388672 min:0 max:1 sd:0.437331\n",
            "\t588: \"data:0.627\" NUMERICAL mean:0.443531 min:0 max:1 sd:0.442571\n",
            "\t589: \"data:0.628\" NUMERICAL mean:0.480488 min:0 max:1 sd:0.440979\n",
            "\t590: \"data:0.629\" NUMERICAL mean:0.491381 min:0 max:1 sd:0.439739\n",
            "\t591: \"data:0.63\" NUMERICAL mean:0.000542745 min:0 max:1 sd:0.019586\n",
            "\t592: \"data:0.630\" NUMERICAL mean:0.472994 min:0 max:1 sd:0.44006\n",
            "\t593: \"data:0.631\" NUMERICAL mean:0.420337 min:0 max:1 sd:0.436454\n",
            "\t594: \"data:0.632\" NUMERICAL mean:0.343947 min:0 max:1 sd:0.420643\n",
            "\t595: \"data:0.633\" NUMERICAL mean:0.258718 min:0 max:1 sd:0.389251\n",
            "\t596: \"data:0.634\" NUMERICAL mean:0.177779 min:0 max:1 sd:0.339536\n",
            "\t597: \"data:0.635\" NUMERICAL mean:0.11267 min:0 max:1 sd:0.280174\n",
            "\t598: \"data:0.636\" NUMERICAL mean:0.066288 min:0 max:1 sd:0.218722\n",
            "\t599: \"data:0.637\" NUMERICAL mean:0.0359273 min:0 max:1 sd:0.162067\n",
            "\t600: \"data:0.638\" NUMERICAL mean:0.0184665 min:0 max:1 sd:0.115875\n",
            "\t601: \"data:0.639\" NUMERICAL mean:0.00872556 min:0 max:1 sd:0.0792795\n",
            "\t602: \"data:0.64\" NUMERICAL mean:0.00103601 min:0 max:1 sd:0.0279852\n",
            "\t603: \"data:0.640\" NUMERICAL mean:0.00327503 min:0 max:1 sd:0.0467596\n",
            "\t604: \"data:0.641\" NUMERICAL mean:0.000741634 min:0 max:0.996078 sd:0.019971\n",
            "\t605: \"data:0.642\" NUMERICAL mean:6.99346e-05 min:0 max:0.882353 sd:0.00573169\n",
            "\t606: \"data:0.643\" NUMERICAL mean:4.70588e-06 min:0 max:0.282353 sd:0.00115269\n",
            "\t607: \"data:0.644\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t608: \"data:0.645\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t609: \"data:0.646\" NUMERICAL mean:0.000251634 min:0 max:0.85098 sd:0.0110663\n",
            "\t610: \"data:0.647\" NUMERICAL mean:0.00164222 min:0 max:1 sd:0.0316388\n",
            "\t611: \"data:0.648\" NUMERICAL mean:0.0067949 min:0 max:1 sd:0.0679572\n",
            "\t612: \"data:0.649\" NUMERICAL mean:0.0196656 min:0 max:1 sd:0.116757\n",
            "\t613: \"data:0.65\" NUMERICAL mean:0.00198673 min:0 max:1 sd:0.0380956\n",
            "\t614: \"data:0.650\" NUMERICAL mean:0.0471801 min:0 max:1 sd:0.181245\n",
            "\t615: \"data:0.651\" NUMERICAL mean:0.0938829 min:0 max:1 sd:0.253849\n",
            "\t616: \"data:0.652\" NUMERICAL mean:0.157869 min:0 max:1 sd:0.322117\n",
            "\t617: \"data:0.653\" NUMERICAL mean:0.230951 min:0 max:1 sd:0.375304\n",
            "\t618: \"data:0.654\" NUMERICAL mean:0.303015 min:0 max:1 sd:0.410046\n",
            "\t619: \"data:0.655\" NUMERICAL mean:0.360911 min:0 max:1 sd:0.428037\n",
            "\t620: \"data:0.656\" NUMERICAL mean:0.390998 min:0 max:1 sd:0.433502\n",
            "\t621: \"data:0.657\" NUMERICAL mean:0.388881 min:0 max:1 sd:0.432183\n",
            "\t622: \"data:0.658\" NUMERICAL mean:0.355263 min:0 max:1 sd:0.423059\n",
            "\t623: \"data:0.659\" NUMERICAL mean:0.296406 min:0 max:1 sd:0.403462\n",
            "\t624: \"data:0.66\" NUMERICAL mean:0.00339922 min:0 max:1 sd:0.0507072\n",
            "\t625: \"data:0.660\" NUMERICAL mean:0.225828 min:0 max:1 sd:0.368653\n",
            "\t626: \"data:0.661\" NUMERICAL mean:0.157623 min:0 max:1 sd:0.320325\n",
            "\t627: \"data:0.662\" NUMERICAL mean:0.0999892 min:0 max:1 sd:0.263179\n",
            "\t628: \"data:0.663\" NUMERICAL mean:0.0597641 min:0 max:1 sd:0.206927\n",
            "\t629: \"data:0.664\" NUMERICAL mean:0.0334262 min:0 max:1 sd:0.156606\n",
            "\t630: \"data:0.665\" NUMERICAL mean:0.0173303 min:0 max:1 sd:0.112778\n",
            "\t631: \"data:0.666\" NUMERICAL mean:0.00864732 min:0 max:1 sd:0.0792416\n",
            "\t632: \"data:0.667\" NUMERICAL mean:0.00384961 min:0 max:1 sd:0.0519524\n",
            "\t633: \"data:0.668\" NUMERICAL mean:0.00121712 min:0 max:1 sd:0.028098\n",
            "\t634: \"data:0.669\" NUMERICAL mean:0.00022732 min:0 max:0.996078 sd:0.0117516\n",
            "\t635: \"data:0.67\" NUMERICAL mean:0.00505915 min:0 max:1 sd:0.0609411\n",
            "\t636: \"data:0.670\" NUMERICAL mean:3.77124e-05 min:0 max:0.588235 sd:0.00362533\n",
            "\t637: \"data:0.671\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t638: \"data:0.672\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t639: \"data:0.673\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t640: \"data:0.674\" NUMERICAL mean:6.21569e-05 min:0 max:0.992157 sd:0.00600393\n",
            "\t641: \"data:0.675\" NUMERICAL mean:0.000479216 min:0 max:0.992157 sd:0.0166683\n",
            "\t642: \"data:0.676\" NUMERICAL mean:0.0021319 min:0 max:1 sd:0.0370324\n",
            "\t643: \"data:0.677\" NUMERICAL mean:0.00627784 min:0 max:1 sd:0.0658673\n",
            "\t644: \"data:0.678\" NUMERICAL mean:0.0164836 min:0 max:1 sd:0.107308\n",
            "\t645: \"data:0.679\" NUMERICAL mean:0.0358572 min:0 max:1 sd:0.160489\n",
            "\t646: \"data:0.68\" NUMERICAL mean:0.00733471 min:0 max:1 sd:0.0738052\n",
            "\t647: \"data:0.680\" NUMERICAL mean:0.0659907 min:0 max:1 sd:0.217376\n",
            "\t648: \"data:0.681\" NUMERICAL mean:0.106184 min:0 max:1 sd:0.273331\n",
            "\t649: \"data:0.682\" NUMERICAL mean:0.149425 min:0 max:1 sd:0.317793\n",
            "\t650: \"data:0.683\" NUMERICAL mean:0.184485 min:0 max:1 sd:0.346046\n",
            "\t651: \"data:0.684\" NUMERICAL mean:0.202387 min:0 max:1 sd:0.357255\n",
            "\t652: \"data:0.685\" NUMERICAL mean:0.199852 min:0 max:1 sd:0.355113\n",
            "\t653: \"data:0.686\" NUMERICAL mean:0.178187 min:0 max:1 sd:0.338009\n",
            "\t654: \"data:0.687\" NUMERICAL mean:0.144096 min:0 max:1 sd:0.30786\n",
            "\t655: \"data:0.688\" NUMERICAL mean:0.107615 min:0 max:1 sd:0.271888\n",
            "\t656: \"data:0.689\" NUMERICAL mean:0.0749356 min:0 max:1 sd:0.230721\n",
            "\t657: \"data:0.69\" NUMERICAL mean:0.00992137 min:0 max:1 sd:0.0861349\n",
            "\t658: \"data:0.690\" NUMERICAL mean:0.0475065 min:0 max:1 sd:0.185786\n",
            "\t659: \"data:0.691\" NUMERICAL mean:0.0282937 min:0 max:1 sd:0.145386\n",
            "\t660: \"data:0.692\" NUMERICAL mean:0.0155268 min:0 max:1 sd:0.107397\n",
            "\t661: \"data:0.693\" NUMERICAL mean:0.00781641 min:0 max:1 sd:0.0768019\n",
            "\t662: \"data:0.694\" NUMERICAL mean:0.00373033 min:0 max:1 sd:0.052227\n",
            "\t663: \"data:0.695\" NUMERICAL mean:0.00156719 min:0 max:1 sd:0.0328017\n",
            "\t664: \"data:0.696\" NUMERICAL mean:0.000399281 min:0 max:0.996078 sd:0.0155046\n",
            "\t665: \"data:0.697\" NUMERICAL mean:8.69935e-05 min:0 max:0.988235 sd:0.0076448\n",
            "\t666: \"data:0.698\" NUMERICAL mean:7.5817e-06 min:0 max:0.384314 sd:0.00159518\n",
            "\t667: \"data:0.699\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t668: \"data:0.7\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t669: \"data:0.70\" NUMERICAL mean:0.0125554 min:0 max:1 sd:0.0972279\n",
            "\t670: \"data:0.700\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t671: \"data:0.701\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t672: \"data:0.702\" NUMERICAL mean:6.14379e-06 min:0 max:0.164706 sd:0.000921896\n",
            "\t673: \"data:0.703\" NUMERICAL mean:6.97386e-05 min:0 max:0.996078 sd:0.00636056\n",
            "\t674: \"data:0.704\" NUMERICAL mean:0.000501111 min:0 max:1 sd:0.0181533\n",
            "\t675: \"data:0.705\" NUMERICAL mean:0.00186078 min:0 max:1 sd:0.0360942\n",
            "\t676: \"data:0.706\" NUMERICAL mean:0.00551176 min:0 max:1 sd:0.0635202\n",
            "\t677: \"data:0.707\" NUMERICAL mean:0.0124737 min:0 max:1 sd:0.0971529\n",
            "\t678: \"data:0.708\" NUMERICAL mean:0.0240918 min:0 max:1 sd:0.13706\n",
            "\t679: \"data:0.709\" NUMERICAL mean:0.0385439 min:0 max:1 sd:0.172801\n",
            "\t680: \"data:0.71\" NUMERICAL mean:0.0142178 min:0 max:1 sd:0.102734\n",
            "\t681: \"data:0.710\" NUMERICAL mean:0.0543895 min:0 max:1 sd:0.203981\n",
            "\t682: \"data:0.711\" NUMERICAL mean:0.0655621 min:0 max:1 sd:0.222362\n",
            "\t683: \"data:0.712\" NUMERICAL mean:0.0709805 min:0 max:1 sd:0.230827\n",
            "\t684: \"data:0.713\" NUMERICAL mean:0.0697075 min:0 max:1 sd:0.228414\n",
            "\t685: \"data:0.714\" NUMERICAL mean:0.0619909 min:0 max:1 sd:0.214329\n",
            "\t686: \"data:0.715\" NUMERICAL mean:0.0514649 min:0 max:1 sd:0.195512\n",
            "\t687: \"data:0.716\" NUMERICAL mean:0.0411688 min:0 max:1 sd:0.176143\n",
            "\t688: \"data:0.717\" NUMERICAL mean:0.0305536 min:0 max:1 sd:0.151987\n",
            "\t689: \"data:0.718\" NUMERICAL mean:0.0204782 min:0 max:1 sd:0.125103\n",
            "\t690: \"data:0.719\" NUMERICAL mean:0.0124005 min:0 max:1 sd:0.0971325\n",
            "\t691: \"data:0.72\" NUMERICAL mean:0.014596 min:0 max:1 sd:0.105095\n",
            "\t692: \"data:0.720\" NUMERICAL mean:0.00663268 min:0 max:1 sd:0.0705866\n",
            "\t693: \"data:0.721\" NUMERICAL mean:0.0032368 min:0 max:1 sd:0.0492789\n",
            "\t694: \"data:0.722\" NUMERICAL mean:0.00145327 min:0 max:1 sd:0.0316433\n",
            "\t695: \"data:0.723\" NUMERICAL mean:0.000548301 min:0 max:1 sd:0.019092\n",
            "\t696: \"data:0.724\" NUMERICAL mean:0.000122614 min:0 max:0.992157 sd:0.0078133\n",
            "\t697: \"data:0.725\" NUMERICAL mean:1.39869e-05 min:0 max:0.498039 sd:0.00246452\n",
            "\t698: \"data:0.726\" NUMERICAL mean:6.79739e-06 min:0 max:0.407843 sd:0.001665\n",
            "\t699: \"data:0.727\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t700: \"data:0.728\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t701: \"data:0.729\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t702: \"data:0.73\" NUMERICAL mean:0.0133041 min:0 max:1 sd:0.100908\n",
            "\t703: \"data:0.730\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t704: \"data:0.731\" NUMERICAL mean:2.48366e-06 min:0 max:0.14902 sd:0.000608365\n",
            "\t705: \"data:0.732\" NUMERICAL mean:0.00013902 min:0 max:1 sd:0.00919357\n",
            "\t706: \"data:0.733\" NUMERICAL mean:0.000639542 min:0 max:1 sd:0.0203874\n",
            "\t707: \"data:0.734\" NUMERICAL mean:0.00211092 min:0 max:1 sd:0.039582\n",
            "\t708: \"data:0.735\" NUMERICAL mean:0.00470333 min:0 max:1 sd:0.0593643\n",
            "\t709: \"data:0.736\" NUMERICAL mean:0.00908268 min:0 max:1 sd:0.0838066\n",
            "\t710: \"data:0.737\" NUMERICAL mean:0.0137703 min:0 max:1 sd:0.10278\n",
            "\t711: \"data:0.738\" NUMERICAL mean:0.0190205 min:0 max:1 sd:0.120755\n",
            "\t712: \"data:0.739\" NUMERICAL mean:0.0234519 min:0 max:1 sd:0.13393\n",
            "\t713: \"data:0.74\" NUMERICAL mean:0.0109919 min:0 max:1 sd:0.0912724\n",
            "\t714: \"data:0.740\" NUMERICAL mean:0.0252738 min:0 max:1 sd:0.13839\n",
            "\t715: \"data:0.741\" NUMERICAL mean:0.024546 min:0 max:1 sd:0.135962\n",
            "\t716: \"data:0.742\" NUMERICAL mean:0.0218452 min:0 max:1 sd:0.128594\n",
            "\t717: \"data:0.743\" NUMERICAL mean:0.017454 min:0 max:1 sd:0.113961\n",
            "\t718: \"data:0.744\" NUMERICAL mean:0.0138625 min:0 max:1 sd:0.102357\n",
            "\t719: \"data:0.745\" NUMERICAL mean:0.010164 min:0 max:1 sd:0.0872593\n",
            "\t720: \"data:0.746\" NUMERICAL mean:0.00667124 min:0 max:1 sd:0.0710075\n",
            "\t721: \"data:0.747\" NUMERICAL mean:0.00395529 min:0 max:1 sd:0.054498\n",
            "\t722: \"data:0.748\" NUMERICAL mean:0.00211876 min:0 max:1 sd:0.0404618\n",
            "\t723: \"data:0.749\" NUMERICAL mean:0.000934902 min:0 max:1 sd:0.0256961\n",
            "\t724: \"data:0.75\" NUMERICAL mean:0.00801719 min:0 max:1 sd:0.0786841\n",
            "\t725: \"data:0.750\" NUMERICAL mean:0.000295163 min:0 max:1 sd:0.0137266\n",
            "\t726: \"data:0.751\" NUMERICAL mean:6.33987e-05 min:0 max:0.537255 sd:0.0048696\n",
            "\t727: \"data:0.752\" NUMERICAL mean:2.02614e-06 min:0 max:0.109804 sd:0.000450834\n",
            "\t728: \"data:0.753\" NUMERICAL mean:3.85621e-06 min:0 max:0.231373 sd:0.000944567\n",
            "\t729: \"data:0.754\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t730: \"data:0.755\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t731: \"data:0.756\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t732: \"data:0.757\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t733: \"data:0.758\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t734: \"data:0.759\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t735: \"data:0.76\" NUMERICAL mean:0.00471418 min:0 max:1 sd:0.0599731\n",
            "\t736: \"data:0.760\" NUMERICAL mean:9.93464e-06 min:0 max:0.368627 sd:0.00171578\n",
            "\t737: \"data:0.761\" NUMERICAL mean:6.11111e-05 min:0 max:0.988235 sd:0.00674974\n",
            "\t738: \"data:0.762\" NUMERICAL mean:0.000163268 min:0 max:0.960784 sd:0.0102008\n",
            "\t739: \"data:0.763\" NUMERICAL mean:0.000349804 min:0 max:0.996078 sd:0.0158141\n",
            "\t740: \"data:0.764\" NUMERICAL mean:0.00050281 min:0 max:0.996078 sd:0.0187294\n",
            "\t741: \"data:0.765\" NUMERICAL mean:0.000771503 min:0 max:1 sd:0.0242268\n",
            "\t742: \"data:0.766\" NUMERICAL mean:0.00131771 min:0 max:1 sd:0.0301202\n",
            "\t743: \"data:0.767\" NUMERICAL mean:0.00168614 min:0 max:1 sd:0.0356607\n",
            "\t744: \"data:0.768\" NUMERICAL mean:0.00206268 min:0 max:1 sd:0.0388168\n",
            "\t745: \"data:0.769\" NUMERICAL mean:0.00231641 min:0 max:1 sd:0.0409094\n",
            "\t746: \"data:0.77\" NUMERICAL mean:0.00248412 min:0 max:1 sd:0.0435844\n",
            "\t747: \"data:0.770\" NUMERICAL mean:0.00269817 min:0 max:1 sd:0.0447173\n",
            "\t748: \"data:0.771\" NUMERICAL mean:0.00232183 min:0 max:1 sd:0.041244\n",
            "\t749: \"data:0.772\" NUMERICAL mean:0.00189307 min:0 max:1 sd:0.0368542\n",
            "\t750: \"data:0.773\" NUMERICAL mean:0.00134712 min:0 max:1 sd:0.0315987\n",
            "\t751: \"data:0.774\" NUMERICAL mean:0.000786013 min:0 max:0.996078 sd:0.0236958\n",
            "\t752: \"data:0.775\" NUMERICAL mean:0.000348497 min:0 max:0.996078 sd:0.0155143\n",
            "\t753: \"data:0.776\" NUMERICAL mean:0.000178954 min:0 max:0.992157 sd:0.0111366\n",
            "\t754: \"data:0.777\" NUMERICAL mean:7.56209e-05 min:0 max:0.992157 sd:0.00661473\n",
            "\t755: \"data:0.778\" NUMERICAL mean:5.9281e-05 min:0 max:0.996078 sd:0.00658145\n",
            "\t756: \"data:0.779\" NUMERICAL mean:7.84314e-06 min:0 max:0.243137 sd:0.0013592\n",
            "\t757: \"data:0.78\" NUMERICAL mean:0.00116144 min:0 max:1 sd:0.0292866\n",
            "\t758: \"data:0.780\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t759: \"data:0.781\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t760: \"data:0.782\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t761: \"data:0.783\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t762: \"data:0.79\" NUMERICAL mean:0.000368562 min:0 max:1 sd:0.0155325\n",
            "\t763: \"data:0.8\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t764: \"data:0.80\" NUMERICAL mean:0.000138105 min:0 max:1 sd:0.00980275\n",
            "\t765: \"data:0.81\" NUMERICAL mean:3.38562e-05 min:0 max:0.647059 sd:0.00432345\n",
            "\t766: \"data:0.82\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t767: \"data:0.83\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t768: \"data:0.84\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t769: \"data:0.85\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t770: \"data:0.86\" NUMERICAL mean:1.26797e-05 min:0 max:0.552941 sd:0.00236193\n",
            "\t771: \"data:0.87\" NUMERICAL mean:2.29412e-05 min:0 max:0.396078 sd:0.0025862\n",
            "\t772: \"data:0.88\" NUMERICAL mean:4.71242e-05 min:0 max:0.376471 sd:0.00334907\n",
            "\t773: \"data:0.89\" NUMERICAL mean:0.000273595 min:0 max:1 sd:0.0123537\n",
            "\t774: \"data:0.9\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t775: \"data:0.90\" NUMERICAL mean:0.000831699 min:0 max:1 sd:0.0236412\n",
            "\t776: \"data:0.91\" NUMERICAL mean:0.00214157 min:0 max:1 sd:0.0389209\n",
            "\t777: \"data:0.92\" NUMERICAL mean:0.00452712 min:0 max:1 sd:0.0572357\n",
            "\t778: \"data:0.93\" NUMERICAL mean:0.0086898 min:0 max:1 sd:0.0807235\n",
            "\t779: \"data:0.94\" NUMERICAL mean:0.0142731 min:0 max:1 sd:0.104054\n",
            "\t780: \"data:0.95\" NUMERICAL mean:0.0213255 min:0 max:1 sd:0.127617\n",
            "\t781: \"data:0.96\" NUMERICAL mean:0.0290473 min:0 max:1 sd:0.148194\n",
            "\t782: \"data:0.97\" NUMERICAL mean:0.0380264 min:0 max:1 sd:0.169389\n",
            "\t783: \"data:0.98\" NUMERICAL mean:0.0466003 min:0 max:1 sd:0.187409\n",
            "\t784: \"data:0.99\" NUMERICAL mean:0.0519112 min:0 max:1 sd:0.198045\n",
            "\n",
            "CATEGORICAL: 1 (0.127389%)\n",
            "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:11 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 23-05-27 16:46:14.3796 UTC kernel.cc:810] Configure learner\n",
            "[INFO 23-05-27 16:46:14.3801 UTC kernel.cc:824] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"^data:0\\\\.0$\"\n",
            "features: \"^data:0\\\\.1$\"\n",
            "features: \"^data:0\\\\.10$\"\n",
            "features: \"^data:0\\\\.100$\"\n",
            "features: \"^data:0\\\\.101$\"\n",
            "features: \"^data:0\\\\.102$\"\n",
            "features: \"^data:0\\\\.103$\"\n",
            "features: \"^data:0\\\\.104$\"\n",
            "features: \"^data:0\\\\.105$\"\n",
            "features: \"^data:0\\\\.106$\"\n",
            "features: \"^data:0\\\\.107$\"\n",
            "features: \"^data:0\\\\.108$\"\n",
            "features: \"^data:0\\\\.109$\"\n",
            "features: \"^data:0\\\\.11$\"\n",
            "features: \"^data:0\\\\.110$\"\n",
            "features: \"^data:0\\\\.111$\"\n",
            "features: \"^data:0\\\\.112$\"\n",
            "features: \"^data:0\\\\.113$\"\n",
            "features: \"^data:0\\\\.114$\"\n",
            "features: \"^data:0\\\\.115$\"\n",
            "features: \"^data:0\\\\.116$\"\n",
            "features: \"^data:0\\\\.117$\"\n",
            "features: \"^data:0\\\\.118$\"\n",
            "features: \"^data:0\\\\.119$\"\n",
            "features: \"^data:0\\\\.12$\"\n",
            "features: \"^data:0\\\\.120$\"\n",
            "features: \"^data:0\\\\.121$\"\n",
            "features: \"^data:0\\\\.122$\"\n",
            "features: \"^data:0\\\\.123$\"\n",
            "features: \"^data:0\\\\.124$\"\n",
            "features: \"^data:0\\\\.125$\"\n",
            "features: \"^data:0\\\\.126$\"\n",
            "features: \"^data:0\\\\.127$\"\n",
            "features: \"^data:0\\\\.128$\"\n",
            "features: \"^data:0\\\\.129$\"\n",
            "features: \"^data:0\\\\.13$\"\n",
            "features: \"^data:0\\\\.130$\"\n",
            "features: \"^data:0\\\\.131$\"\n",
            "features: \"^data:0\\\\.132$\"\n",
            "features: \"^data:0\\\\.133$\"\n",
            "features: \"^data:0\\\\.134$\"\n",
            "features: \"^data:0\\\\.135$\"\n",
            "features: \"^data:0\\\\.136$\"\n",
            "features: \"^data:0\\\\.137$\"\n",
            "features: \"^data:0\\\\.138$\"\n",
            "features: \"^data:0\\\\.139$\"\n",
            "features: \"^data:0\\\\.14$\"\n",
            "features: \"^data:0\\\\.140$\"\n",
            "features: \"^data:0\\\\.141$\"\n",
            "features: \"^data:0\\\\.142$\"\n",
            "features: \"^data:0\\\\.143$\"\n",
            "features: \"^data:0\\\\.144$\"\n",
            "features: \"^data:0\\\\.145$\"\n",
            "features: \"^data:0\\\\.146$\"\n",
            "features: \"^data:0\\\\.147$\"\n",
            "features: \"^data:0\\\\.148$\"\n",
            "features: \"^data:0\\\\.149$\"\n",
            "features: \"^data:0\\\\.15$\"\n",
            "features: \"^data:0\\\\.150$\"\n",
            "features: \"^data:0\\\\.151$\"\n",
            "features: \"^data:0\\\\.152$\"\n",
            "features: \"^data:0\\\\.153$\"\n",
            "features: \"^data:0\\\\.154$\"\n",
            "features: \"^data:0\\\\.155$\"\n",
            "features: \"^data:0\\\\.156$\"\n",
            "features: \"^data:0\\\\.157$\"\n",
            "features: \"^data:0\\\\.158$\"\n",
            "features: \"^data:0\\\\.159$\"\n",
            "features: \"^data:0\\\\.16$\"\n",
            "features: \"^data:0\\\\.160$\"\n",
            "features: \"^data:0\\\\.161$\"\n",
            "features: \"^data:0\\\\.162$\"\n",
            "features: \"^data:0\\\\.163$\"\n",
            "features: \"^data:0\\\\.164$\"\n",
            "features: \"^data:0\\\\.165$\"\n",
            "features: \"^data:0\\\\.166$\"\n",
            "features: \"^data:0\\\\.167$\"\n",
            "features: \"^data:0\\\\.168$\"\n",
            "features: \"^data:0\\\\.169$\"\n",
            "features: \"^data:0\\\\.17$\"\n",
            "features: \"^data:0\\\\.170$\"\n",
            "features: \"^data:0\\\\.171$\"\n",
            "features: \"^data:0\\\\.172$\"\n",
            "features: \"^data:0\\\\.173$\"\n",
            "features: \"^data:0\\\\.174$\"\n",
            "features: \"^data:0\\\\.175$\"\n",
            "features: \"^data:0\\\\.176$\"\n",
            "features: \"^data:0\\\\.177$\"\n",
            "features: \"^data:0\\\\.178$\"\n",
            "features: \"^data:0\\\\.179$\"\n",
            "features: \"^data:0\\\\.18$\"\n",
            "features: \"^data:0\\\\.180$\"\n",
            "features: \"^data:0\\\\.181$\"\n",
            "features: \"^data:0\\\\.182$\"\n",
            "features: \"^data:0\\\\.183$\"\n",
            "features: \"^data:0\\\\.184$\"\n",
            "features: \"^data:0\\\\.185$\"\n",
            "features: \"^data:0\\\\.186$\"\n",
            "features: \"^data:0\\\\.187$\"\n",
            "features: \"^data:0\\\\.188$\"\n",
            "features: \"^data:0\\\\.189$\"\n",
            "features: \"^data:0\\\\.19$\"\n",
            "features: \"^data:0\\\\.190$\"\n",
            "features: \"^data:0\\\\.191$\"\n",
            "features: \"^data:0\\\\.192$\"\n",
            "features: \"^data:0\\\\.193$\"\n",
            "features: \"^data:0\\\\.194$\"\n",
            "features: \"^data:0\\\\.195$\"\n",
            "features: \"^data:0\\\\.196$\"\n",
            "features: \"^data:0\\\\.197$\"\n",
            "features: \"^data:0\\\\.198$\"\n",
            "features: \"^data:0\\\\.199$\"\n",
            "features: \"^data:0\\\\.2$\"\n",
            "features: \"^data:0\\\\.20$\"\n",
            "features: \"^data:0\\\\.200$\"\n",
            "features: \"^data:0\\\\.201$\"\n",
            "features: \"^data:0\\\\.202$\"\n",
            "features: \"^data:0\\\\.203$\"\n",
            "features: \"^data:0\\\\.204$\"\n",
            "features: \"^data:0\\\\.205$\"\n",
            "features: \"^data:0\\\\.206$\"\n",
            "features: \"^data:0\\\\.207$\"\n",
            "features: \"^data:0\\\\.208$\"\n",
            "features: \"^data:0\\\\.209$\"\n",
            "features: \"^data:0\\\\.21$\"\n",
            "features: \"^data:0\\\\.210$\"\n",
            "features: \"^data:0\\\\.211$\"\n",
            "features: \"^data:0\\\\.212$\"\n",
            "features: \"^data:0\\\\.213$\"\n",
            "features: \"^data:0\\\\.214$\"\n",
            "features: \"^data:0\\\\.215$\"\n",
            "features: \"^data:0\\\\.216$\"\n",
            "features: \"^data:0\\\\.217$\"\n",
            "features: \"^data:0\\\\.218$\"\n",
            "features: \"^data:0\\\\.219$\"\n",
            "features: \"^data:0\\\\.22$\"\n",
            "features: \"^data:0\\\\.220$\"\n",
            "features: \"^data:0\\\\.221$\"\n",
            "features: \"^data:0\\\\.222$\"\n",
            "features: \"^data:0\\\\.223$\"\n",
            "features: \"^data:0\\\\.224$\"\n",
            "features: \"^data:0\\\\.225$\"\n",
            "features: \"^data:0\\\\.226$\"\n",
            "features: \"^data:0\\\\.227$\"\n",
            "features: \"^data:0\\\\.228$\"\n",
            "features: \"^data:0\\\\.229$\"\n",
            "features: \"^data:0\\\\.23$\"\n",
            "features: \"^data:0\\\\.230$\"\n",
            "features: \"^data:0\\\\.231$\"\n",
            "features: \"^data:0\\\\.232$\"\n",
            "features: \"^data:0\\\\.233$\"\n",
            "features: \"^data:0\\\\.234$\"\n",
            "features: \"^data:0\\\\.235$\"\n",
            "features: \"^data:0\\\\.236$\"\n",
            "features: \"^data:0\\\\.237$\"\n",
            "features: \"^data:0\\\\.238$\"\n",
            "features: \"^data:0\\\\.239$\"\n",
            "features: \"^data:0\\\\.24$\"\n",
            "features: \"^data:0\\\\.240$\"\n",
            "features: \"^data:0\\\\.241$\"\n",
            "features: \"^data:0\\\\.242$\"\n",
            "features: \"^data:0\\\\.243$\"\n",
            "features: \"^data:0\\\\.244$\"\n",
            "features: \"^data:0\\\\.245$\"\n",
            "features: \"^data:0\\\\.246$\"\n",
            "features: \"^data:0\\\\.247$\"\n",
            "features: \"^data:0\\\\.248$\"\n",
            "features: \"^data:0\\\\.249$\"\n",
            "features: \"^data:0\\\\.25$\"\n",
            "features: \"^data:0\\\\.250$\"\n",
            "features: \"^data:0\\\\.251$\"\n",
            "features: \"^data:0\\\\.252$\"\n",
            "features: \"^data:0\\\\.253$\"\n",
            "features: \"^data:0\\\\.254$\"\n",
            "features: \"^data:0\\\\.255$\"\n",
            "features: \"^data:0\\\\.256$\"\n",
            "features: \"^data:0\\\\.257$\"\n",
            "features: \"^data:0\\\\.258$\"\n",
            "features: \"^data:0\\\\.259$\"\n",
            "features: \"^data:0\\\\.26$\"\n",
            "features: \"^data:0\\\\.260$\"\n",
            "features: \"^data:0\\\\.261$\"\n",
            "features: \"^data:0\\\\.262$\"\n",
            "features: \"^data:0\\\\.263$\"\n",
            "features: \"^data:0\\\\.264$\"\n",
            "features: \"^data:0\\\\.265$\"\n",
            "features: \"^data:0\\\\.266$\"\n",
            "features: \"^data:0\\\\.267$\"\n",
            "features: \"^data:0\\\\.268$\"\n",
            "features: \"^data:0\\\\.269$\"\n",
            "features: \"^data:0\\\\.27$\"\n",
            "features: \"^data:0\\\\.270$\"\n",
            "features: \"^data:0\\\\.271$\"\n",
            "features: \"^data:0\\\\.272$\"\n",
            "features: \"^data:0\\\\.273$\"\n",
            "features: \"^data:0\\\\.274$\"\n",
            "features: \"^data:0\\\\.275$\"\n",
            "features: \"^data:0\\\\.276$\"\n",
            "features: \"^data:0\\\\.277$\"\n",
            "features: \"^data:0\\\\.278$\"\n",
            "features: \"^data:0\\\\.279$\"\n",
            "features: \"^data:0\\\\.28$\"\n",
            "features: \"^data:0\\\\.280$\"\n",
            "features: \"^data:0\\\\.281$\"\n",
            "features: \"^data:0\\\\.282$\"\n",
            "features: \"^data:0\\\\.283$\"\n",
            "features: \"^data:0\\\\.284$\"\n",
            "features: \"^data:0\\\\.285$\"\n",
            "features: \"^data:0\\\\.286$\"\n",
            "features: \"^data:0\\\\.287$\"\n",
            "features: \"^data:0\\\\.288$\"\n",
            "features: \"^data:0\\\\.289$\"\n",
            "features: \"^data:0\\\\.29$\"\n",
            "features: \"^data:0\\\\.290$\"\n",
            "features: \"^data:0\\\\.291$\"\n",
            "features: \"^data:0\\\\.292$\"\n",
            "features: \"^data:0\\\\.293$\"\n",
            "features: \"^data:0\\\\.294$\"\n",
            "features: \"^data:0\\\\.295$\"\n",
            "features: \"^data:0\\\\.296$\"\n",
            "features: \"^data:0\\\\.297$\"\n",
            "features: \"^data:0\\\\.298$\"\n",
            "features: \"^data:0\\\\.299$\"\n",
            "features: \"^data:0\\\\.3$\"\n",
            "features: \"^data:0\\\\.30$\"\n",
            "features: \"^data:0\\\\.300$\"\n",
            "features: \"^data:0\\\\.301$\"\n",
            "features: \"^data:0\\\\.302$\"\n",
            "features: \"^data:0\\\\.303$\"\n",
            "features: \"^data:0\\\\.304$\"\n",
            "features: \"^data:0\\\\.305$\"\n",
            "features: \"^data:0\\\\.306$\"\n",
            "features: \"^data:0\\\\.307$\"\n",
            "features: \"^data:0\\\\.308$\"\n",
            "features: \"^data:0\\\\.309$\"\n",
            "features: \"^data:0\\\\.31$\"\n",
            "features: \"^data:0\\\\.310$\"\n",
            "features: \"^data:0\\\\.311$\"\n",
            "features: \"^data:0\\\\.312$\"\n",
            "features: \"^data:0\\\\.313$\"\n",
            "features: \"^data:0\\\\.314$\"\n",
            "features: \"^data:0\\\\.315$\"\n",
            "features: \"^data:0\\\\.316$\"\n",
            "features: \"^data:0\\\\.317$\"\n",
            "features: \"^data:0\\\\.318$\"\n",
            "features: \"^data:0\\\\.319$\"\n",
            "features: \"^data:0\\\\.32$\"\n",
            "features: \"^data:0\\\\.320$\"\n",
            "features: \"^data:0\\\\.321$\"\n",
            "features: \"^data:0\\\\.322$\"\n",
            "features: \"^data:0\\\\.323$\"\n",
            "features: \"^data:0\\\\.324$\"\n",
            "features: \"^data:0\\\\.325$\"\n",
            "features: \"^data:0\\\\.326$\"\n",
            "features: \"^data:0\\\\.327$\"\n",
            "features: \"^data:0\\\\.328$\"\n",
            "features: \"^data:0\\\\.329$\"\n",
            "features: \"^data:0\\\\.33$\"\n",
            "features: \"^data:0\\\\.330$\"\n",
            "features: \"^data:0\\\\.331$\"\n",
            "features: \"^data:0\\\\.332$\"\n",
            "features: \"^data:0\\\\.333$\"\n",
            "features: \"^data:0\\\\.334$\"\n",
            "features: \"^data:0\\\\.335$\"\n",
            "features: \"^data:0\\\\.336$\"\n",
            "features: \"^data:0\\\\.337$\"\n",
            "features: \"^data:0\\\\.338$\"\n",
            "features: \"^data:0\\\\.339$\"\n",
            "features: \"^data:0\\\\.34$\"\n",
            "features: \"^data:0\\\\.340$\"\n",
            "features: \"^data:0\\\\.341$\"\n",
            "features: \"^data:0\\\\.342$\"\n",
            "features: \"^data:0\\\\.343$\"\n",
            "features: \"^data:0\\\\.344$\"\n",
            "features: \"^data:0\\\\.345$\"\n",
            "features: \"^data:0\\\\.346$\"\n",
            "features: \"^data:0\\\\.347$\"\n",
            "features: \"^data:0\\\\.348$\"\n",
            "features: \"^data:0\\\\.349$\"\n",
            "features: \"^data:0\\\\.35$\"\n",
            "features: \"^data:0\\\\.350$\"\n",
            "features: \"^data:0\\\\.351$\"\n",
            "features: \"^data:0\\\\.352$\"\n",
            "features: \"^data:0\\\\.353$\"\n",
            "features: \"^data:0\\\\.354$\"\n",
            "features: \"^data:0\\\\.355$\"\n",
            "features: \"^data:0\\\\.356$\"\n",
            "features: \"^data:0\\\\.357$\"\n",
            "features: \"^data:0\\\\.358$\"\n",
            "features: \"^data:0\\\\.359$\"\n",
            "features: \"^data:0\\\\.36$\"\n",
            "features: \"^data:0\\\\.360$\"\n",
            "features: \"^data:0\\\\.361$\"\n",
            "features: \"^data:0\\\\.362$\"\n",
            "features: \"^data:0\\\\.363$\"\n",
            "features: \"^data:0\\\\.364$\"\n",
            "features: \"^data:0\\\\.365$\"\n",
            "features: \"^data:0\\\\.366$\"\n",
            "features: \"^data:0\\\\.367$\"\n",
            "features: \"^data:0\\\\.368$\"\n",
            "features: \"^data:0\\\\.369$\"\n",
            "features: \"^data:0\\\\.37$\"\n",
            "features: \"^data:0\\\\.370$\"\n",
            "features: \"^data:0\\\\.371$\"\n",
            "features: \"^data:0\\\\.372$\"\n",
            "features: \"^data:0\\\\.373$\"\n",
            "features: \"^data:0\\\\.374$\"\n",
            "features: \"^data:0\\\\.375$\"\n",
            "features: \"^data:0\\\\.376$\"\n",
            "features: \"^data:0\\\\.377$\"\n",
            "features: \"^data:0\\\\.378$\"\n",
            "features: \"^data:0\\\\.379$\"\n",
            "features: \"^data:0\\\\.38$\"\n",
            "features: \"^data:0\\\\.380$\"\n",
            "features: \"^data:0\\\\.381$\"\n",
            "features: \"^data:0\\\\.382$\"\n",
            "features: \"^data:0\\\\.383$\"\n",
            "features: \"^data:0\\\\.384$\"\n",
            "features: \"^data:0\\\\.385$\"\n",
            "features: \"^data:0\\\\.386$\"\n",
            "features: \"^data:0\\\\.387$\"\n",
            "features: \"^data:0\\\\.388$\"\n",
            "features: \"^data:0\\\\.389$\"\n",
            "features: \"^data:0\\\\.39$\"\n",
            "features: \"^data:0\\\\.390$\"\n",
            "features: \"^data:0\\\\.391$\"\n",
            "features: \"^data:0\\\\.392$\"\n",
            "features: \"^data:0\\\\.393$\"\n",
            "features: \"^data:0\\\\.394$\"\n",
            "features: \"^data:0\\\\.395$\"\n",
            "features: \"^data:0\\\\.396$\"\n",
            "features: \"^data:0\\\\.397$\"\n",
            "features: \"^data:0\\\\.398$\"\n",
            "features: \"^data:0\\\\.399$\"\n",
            "features: \"^data:0\\\\.4$\"\n",
            "features: \"^data:0\\\\.40$\"\n",
            "features: \"^data:0\\\\.400$\"\n",
            "features: \"^data:0\\\\.401$\"\n",
            "features: \"^data:0\\\\.402$\"\n",
            "features: \"^data:0\\\\.403$\"\n",
            "features: \"^data:0\\\\.404$\"\n",
            "features: \"^data:0\\\\.405$\"\n",
            "features: \"^data:0\\\\.406$\"\n",
            "features: \"^data:0\\\\.407$\"\n",
            "features: \"^data:0\\\\.408$\"\n",
            "features: \"^data:0\\\\.409$\"\n",
            "features: \"^data:0\\\\.41$\"\n",
            "features: \"^data:0\\\\.410$\"\n",
            "features: \"^data:0\\\\.411$\"\n",
            "features: \"^data:0\\\\.412$\"\n",
            "features: \"^data:0\\\\.413$\"\n",
            "features: \"^data:0\\\\.414$\"\n",
            "features: \"^data:0\\\\.415$\"\n",
            "features: \"^data:0\\\\.416$\"\n",
            "features: \"^data:0\\\\.417$\"\n",
            "features: \"^data:0\\\\.418$\"\n",
            "features: \"^data:0\\\\.419$\"\n",
            "features: \"^data:0\\\\.42$\"\n",
            "features: \"^data:0\\\\.420$\"\n",
            "features: \"^data:0\\\\.421$\"\n",
            "features: \"^data:0\\\\.422$\"\n",
            "features: \"^data:0\\\\.423$\"\n",
            "features: \"^data:0\\\\.424$\"\n",
            "features: \"^data:0\\\\.425$\"\n",
            "features: \"^data:0\\\\.426$\"\n",
            "features: \"^data:0\\\\.427$\"\n",
            "features: \"^data:0\\\\.428$\"\n",
            "features: \"^data:0\\\\.429$\"\n",
            "features: \"^data:0\\\\.43$\"\n",
            "features: \"^data:0\\\\.430$\"\n",
            "features: \"^data:0\\\\.431$\"\n",
            "features: \"^data:0\\\\.432$\"\n",
            "features: \"^data:0\\\\.433$\"\n",
            "features: \"^data:0\\\\.434$\"\n",
            "features: \"^data:0\\\\.435$\"\n",
            "features: \"^data:0\\\\.436$\"\n",
            "features: \"^data:0\\\\.437$\"\n",
            "features: \"^data:0\\\\.438$\"\n",
            "features: \"^data:0\\\\.439$\"\n",
            "features: \"^data:0\\\\.44$\"\n",
            "features: \"^data:0\\\\.440$\"\n",
            "features: \"^data:0\\\\.441$\"\n",
            "features: \"^data:0\\\\.442$\"\n",
            "features: \"^data:0\\\\.443$\"\n",
            "features: \"^data:0\\\\.444$\"\n",
            "features: \"^data:0\\\\.445$\"\n",
            "features: \"^data:0\\\\.446$\"\n",
            "features: \"^data:0\\\\.447$\"\n",
            "features: \"^data:0\\\\.448$\"\n",
            "features: \"^data:0\\\\.449$\"\n",
            "features: \"^data:0\\\\.45$\"\n",
            "features: \"^data:0\\\\.450$\"\n",
            "features: \"^data:0\\\\.451$\"\n",
            "features: \"^data:0\\\\.452$\"\n",
            "features: \"^data:0\\\\.453$\"\n",
            "features: \"^data:0\\\\.454$\"\n",
            "features: \"^data:0\\\\.455$\"\n",
            "features: \"^data:0\\\\.456$\"\n",
            "features: \"^data:0\\\\.457$\"\n",
            "features: \"^data:0\\\\.458$\"\n",
            "features: \"^data:0\\\\.459$\"\n",
            "features: \"^data:0\\\\.46$\"\n",
            "features: \"^data:0\\\\.460$\"\n",
            "features: \"^data:0\\\\.461$\"\n",
            "features: \"^data:0\\\\.462$\"\n",
            "features: \"^data:0\\\\.463$\"\n",
            "features: \"^data:0\\\\.464$\"\n",
            "features: \"^data:0\\\\.465$\"\n",
            "features: \"^data:0\\\\.466$\"\n",
            "features: \"^data:0\\\\.467$\"\n",
            "features: \"^data:0\\\\.468$\"\n",
            "features: \"^data:0\\\\.469$\"\n",
            "features: \"^data:0\\\\.47$\"\n",
            "features: \"^data:0\\\\.470$\"\n",
            "features: \"^data:0\\\\.471$\"\n",
            "features: \"^data:0\\\\.472$\"\n",
            "features: \"^data:0\\\\.473$\"\n",
            "features: \"^data:0\\\\.474$\"\n",
            "features: \"^data:0\\\\.475$\"\n",
            "features: \"^data:0\\\\.476$\"\n",
            "features: \"^data:0\\\\.477$\"\n",
            "features: \"^data:0\\\\.478$\"\n",
            "features: \"^data:0\\\\.479$\"\n",
            "features: \"^data:0\\\\.48$\"\n",
            "features: \"^data:0\\\\.480$\"\n",
            "features: \"^data:0\\\\.481$\"\n",
            "features: \"^data:0\\\\.482$\"\n",
            "features: \"^data:0\\\\.483$\"\n",
            "features: \"^data:0\\\\.484$\"\n",
            "features: \"^data:0\\\\.485$\"\n",
            "features: \"^data:0\\\\.486$\"\n",
            "features: \"^data:0\\\\.487$\"\n",
            "features: \"^data:0\\\\.488$\"\n",
            "features: \"^data:0\\\\.489$\"\n",
            "features: \"^data:0\\\\.49$\"\n",
            "features: \"^data:0\\\\.490$\"\n",
            "features: \"^data:0\\\\.491$\"\n",
            "features: \"^data:0\\\\.492$\"\n",
            "features: \"^data:0\\\\.493$\"\n",
            "features: \"^data:0\\\\.494$\"\n",
            "features: \"^data:0\\\\.495$\"\n",
            "features: \"^data:0\\\\.496$\"\n",
            "features: \"^data:0\\\\.497$\"\n",
            "features: \"^data:0\\\\.498$\"\n",
            "features: \"^data:0\\\\.499$\"\n",
            "features: \"^data:0\\\\.5$\"\n",
            "features: \"^data:0\\\\.50$\"\n",
            "features: \"^data:0\\\\.500$\"\n",
            "features: \"^data:0\\\\.501$\"\n",
            "features: \"^data:0\\\\.502$\"\n",
            "features: \"^data:0\\\\.503$\"\n",
            "features: \"^data:0\\\\.504$\"\n",
            "features: \"^data:0\\\\.505$\"\n",
            "features: \"^data:0\\\\.506$\"\n",
            "features: \"^data:0\\\\.507$\"\n",
            "features: \"^data:0\\\\.508$\"\n",
            "features: \"^data:0\\\\.509$\"\n",
            "features: \"^data:0\\\\.51$\"\n",
            "features: \"^data:0\\\\.510$\"\n",
            "features: \"^data:0\\\\.511$\"\n",
            "features: \"^data:0\\\\.512$\"\n",
            "features: \"^data:0\\\\.513$\"\n",
            "features: \"^data:0\\\\.514$\"\n",
            "features: \"^data:0\\\\.515$\"\n",
            "features: \"^data:0\\\\.516$\"\n",
            "features: \"^data:0\\\\.517$\"\n",
            "features: \"^data:0\\\\.518$\"\n",
            "features: \"^data:0\\\\.519$\"\n",
            "features: \"^data:0\\\\.52$\"\n",
            "features: \"^data:0\\\\.520$\"\n",
            "features: \"^data:0\\\\.521$\"\n",
            "features: \"^data:0\\\\.522$\"\n",
            "features: \"^data:0\\\\.523$\"\n",
            "features: \"^data:0\\\\.524$\"\n",
            "features: \"^data:0\\\\.525$\"\n",
            "features: \"^data:0\\\\.526$\"\n",
            "features: \"^data:0\\\\.527$\"\n",
            "features: \"^data:0\\\\.528$\"\n",
            "features: \"^data:0\\\\.529$\"\n",
            "features: \"^data:0\\\\.53$\"\n",
            "features: \"^data:0\\\\.530$\"\n",
            "features: \"^data:0\\\\.531$\"\n",
            "features: \"^data:0\\\\.532$\"\n",
            "features: \"^data:0\\\\.533$\"\n",
            "features: \"^data:0\\\\.534$\"\n",
            "features: \"^data:0\\\\.535$\"\n",
            "features: \"^data:0\\\\.536$\"\n",
            "features: \"^data:0\\\\.537$\"\n",
            "features: \"^data:0\\\\.538$\"\n",
            "features: \"^data:0\\\\.539$\"\n",
            "features: \"^data:0\\\\.54$\"\n",
            "features: \"^data:0\\\\.540$\"\n",
            "features: \"^data:0\\\\.541$\"\n",
            "features: \"^data:0\\\\.542$\"\n",
            "features: \"^data:0\\\\.543$\"\n",
            "features: \"^data:0\\\\.544$\"\n",
            "features: \"^data:0\\\\.545$\"\n",
            "features: \"^data:0\\\\.546$\"\n",
            "features: \"^data:0\\\\.547$\"\n",
            "features: \"^data:0\\\\.548$\"\n",
            "features: \"^data:0\\\\.549$\"\n",
            "features: \"^data:0\\\\.55$\"\n",
            "features: \"^data:0\\\\.550$\"\n",
            "features: \"^data:0\\\\.551$\"\n",
            "features: \"^data:0\\\\.552$\"\n",
            "features: \"^data:0\\\\.553$\"\n",
            "features: \"^data:0\\\\.554$\"\n",
            "features: \"^data:0\\\\.555$\"\n",
            "features: \"^data:0\\\\.556$\"\n",
            "features: \"^data:0\\\\.557$\"\n",
            "features: \"^data:0\\\\.558$\"\n",
            "features: \"^data:0\\\\.559$\"\n",
            "features: \"^data:0\\\\.56$\"\n",
            "features: \"^data:0\\\\.560$\"\n",
            "features: \"^data:0\\\\.561$\"\n",
            "features: \"^data:0\\\\.562$\"\n",
            "features: \"^data:0\\\\.563$\"\n",
            "features: \"^data:0\\\\.564$\"\n",
            "features: \"^data:0\\\\.565$\"\n",
            "features: \"^data:0\\\\.566$\"\n",
            "features: \"^data:0\\\\.567$\"\n",
            "features: \"^data:0\\\\.568$\"\n",
            "features: \"^data:0\\\\.569$\"\n",
            "features: \"^data:0\\\\.57$\"\n",
            "features: \"^data:0\\\\.570$\"\n",
            "features: \"^data:0\\\\.571$\"\n",
            "features: \"^data:0\\\\.572$\"\n",
            "features: \"^data:0\\\\.573$\"\n",
            "features: \"^data:0\\\\.574$\"\n",
            "features: \"^data:0\\\\.575$\"\n",
            "features: \"^data:0\\\\.576$\"\n",
            "features: \"^data:0\\\\.577$\"\n",
            "features: \"^data:0\\\\.578$\"\n",
            "features: \"^data:0\\\\.579$\"\n",
            "features: \"^data:0\\\\.58$\"\n",
            "features: \"^data:0\\\\.580$\"\n",
            "features: \"^data:0\\\\.581$\"\n",
            "features: \"^data:0\\\\.582$\"\n",
            "features: \"^data:0\\\\.583$\"\n",
            "features: \"^data:0\\\\.584$\"\n",
            "features: \"^data:0\\\\.585$\"\n",
            "features: \"^data:0\\\\.586$\"\n",
            "features: \"^data:0\\\\.587$\"\n",
            "features: \"^data:0\\\\.588$\"\n",
            "features: \"^data:0\\\\.589$\"\n",
            "features: \"^data:0\\\\.59$\"\n",
            "features: \"^data:0\\\\.590$\"\n",
            "features: \"^data:0\\\\.591$\"\n",
            "features: \"^data:0\\\\.592$\"\n",
            "features: \"^data:0\\\\.593$\"\n",
            "features: \"^data:0\\\\.594$\"\n",
            "features: \"^data:0\\\\.595$\"\n",
            "features: \"^data:0\\\\.596$\"\n",
            "features: \"^data:0\\\\.597$\"\n",
            "features: \"^data:0\\\\.598$\"\n",
            "features: \"^data:0\\\\.599$\"\n",
            "features: \"^data:0\\\\.6$\"\n",
            "features: \"^data:0\\\\.60$\"\n",
            "features: \"^data:0\\\\.600$\"\n",
            "features: \"^data:0\\\\.601$\"\n",
            "features: \"^data:0\\\\.602$\"\n",
            "features: \"^data:0\\\\.603$\"\n",
            "features: \"^data:0\\\\.604$\"\n",
            "features: \"^data:0\\\\.605$\"\n",
            "features: \"^data:0\\\\.606$\"\n",
            "features: \"^data:0\\\\.607$\"\n",
            "features: \"^data:0\\\\.608$\"\n",
            "features: \"^data:0\\\\.609$\"\n",
            "features: \"^data:0\\\\.61$\"\n",
            "features: \"^data:0\\\\.610$\"\n",
            "features: \"^data:0\\\\.611$\"\n",
            "features: \"^data:0\\\\.612$\"\n",
            "features: \"^data:0\\\\.613$\"\n",
            "features: \"^data:0\\\\.614$\"\n",
            "features: \"^data:0\\\\.615$\"\n",
            "features: \"^data:0\\\\.616$\"\n",
            "features: \"^data:0\\\\.617$\"\n",
            "features: \"^data:0\\\\.618$\"\n",
            "features: \"^data:0\\\\.619$\"\n",
            "features: \"^data:0\\\\.62$\"\n",
            "features: \"^data:0\\\\.620$\"\n",
            "features: \"^data:0\\\\.621$\"\n",
            "features: \"^data:0\\\\.622$\"\n",
            "features: \"^data:0\\\\.623$\"\n",
            "features: \"^data:0\\\\.624$\"\n",
            "features: \"^data:0\\\\.625$\"\n",
            "features: \"^data:0\\\\.626$\"\n",
            "features: \"^data:0\\\\.627$\"\n",
            "features: \"^data:0\\\\.628$\"\n",
            "features: \"^data:0\\\\.629$\"\n",
            "features: \"^data:0\\\\.63$\"\n",
            "features: \"^data:0\\\\.630$\"\n",
            "features: \"^data:0\\\\.631$\"\n",
            "features: \"^data:0\\\\.632$\"\n",
            "features: \"^data:0\\\\.633$\"\n",
            "features: \"^data:0\\\\.634$\"\n",
            "features: \"^data:0\\\\.635$\"\n",
            "features: \"^data:0\\\\.636$\"\n",
            "features: \"^data:0\\\\.637$\"\n",
            "features: \"^data:0\\\\.638$\"\n",
            "features: \"^data:0\\\\.639$\"\n",
            "features: \"^data:0\\\\.64$\"\n",
            "features: \"^data:0\\\\.640$\"\n",
            "features: \"^data:0\\\\.641$\"\n",
            "features: \"^data:0\\\\.642$\"\n",
            "features: \"^data:0\\\\.643$\"\n",
            "features: \"^data:0\\\\.644$\"\n",
            "features: \"^data:0\\\\.645$\"\n",
            "features: \"^data:0\\\\.646$\"\n",
            "features: \"^data:0\\\\.647$\"\n",
            "features: \"^data:0\\\\.648$\"\n",
            "features: \"^data:0\\\\.649$\"\n",
            "features: \"^data:0\\\\.65$\"\n",
            "features: \"^data:0\\\\.650$\"\n",
            "features: \"^data:0\\\\.651$\"\n",
            "features: \"^data:0\\\\.652$\"\n",
            "features: \"^data:0\\\\.653$\"\n",
            "features: \"^data:0\\\\.654$\"\n",
            "features: \"^data:0\\\\.655$\"\n",
            "features: \"^data:0\\\\.656$\"\n",
            "features: \"^data:0\\\\.657$\"\n",
            "features: \"^data:0\\\\.658$\"\n",
            "features: \"^data:0\\\\.659$\"\n",
            "features: \"^data:0\\\\.66$\"\n",
            "features: \"^data:0\\\\.660$\"\n",
            "features: \"^data:0\\\\.661$\"\n",
            "features: \"^data:0\\\\.662$\"\n",
            "features: \"^data:0\\\\.663$\"\n",
            "features: \"^data:0\\\\.664$\"\n",
            "features: \"^data:0\\\\.665$\"\n",
            "features: \"^data:0\\\\.666$\"\n",
            "features: \"^data:0\\\\.667$\"\n",
            "features: \"^data:0\\\\.668$\"\n",
            "features: \"^data:0\\\\.669$\"\n",
            "features: \"^data:0\\\\.67$\"\n",
            "features: \"^data:0\\\\.670$\"\n",
            "features: \"^data:0\\\\.671$\"\n",
            "features: \"^data:0\\\\.672$\"\n",
            "features: \"^data:0\\\\.673$\"\n",
            "features: \"^data:0\\\\.674$\"\n",
            "features: \"^data:0\\\\.675$\"\n",
            "features: \"^data:0\\\\.676$\"\n",
            "features: \"^data:0\\\\.677$\"\n",
            "features: \"^data:0\\\\.678$\"\n",
            "features: \"^data:0\\\\.679$\"\n",
            "features: \"^data:0\\\\.68$\"\n",
            "features: \"^data:0\\\\.680$\"\n",
            "features: \"^data:0\\\\.681$\"\n",
            "features: \"^data:0\\\\.682$\"\n",
            "features: \"^data:0\\\\.683$\"\n",
            "features: \"^data:0\\\\.684$\"\n",
            "features: \"^data:0\\\\.685$\"\n",
            "features: \"^data:0\\\\.686$\"\n",
            "features: \"^data:0\\\\.687$\"\n",
            "features: \"^data:0\\\\.688$\"\n",
            "features: \"^data:0\\\\.689$\"\n",
            "features: \"^data:0\\\\.69$\"\n",
            "features: \"^data:0\\\\.690$\"\n",
            "features: \"^data:0\\\\.691$\"\n",
            "features: \"^data:0\\\\.692$\"\n",
            "features: \"^data:0\\\\.693$\"\n",
            "features: \"^data:0\\\\.694$\"\n",
            "features: \"^data:0\\\\.695$\"\n",
            "features: \"^data:0\\\\.696$\"\n",
            "features: \"^data:0\\\\.697$\"\n",
            "features: \"^data:0\\\\.698$\"\n",
            "features: \"^data:0\\\\.699$\"\n",
            "features: \"^data:0\\\\.7$\"\n",
            "features: \"^data:0\\\\.70$\"\n",
            "features: \"^data:0\\\\.700$\"\n",
            "features: \"^data:0\\\\.701$\"\n",
            "features: \"^data:0\\\\.702$\"\n",
            "features: \"^data:0\\\\.703$\"\n",
            "features: \"^data:0\\\\.704$\"\n",
            "features: \"^data:0\\\\.705$\"\n",
            "features: \"^data:0\\\\.706$\"\n",
            "features: \"^data:0\\\\.707$\"\n",
            "features: \"^data:0\\\\.708$\"\n",
            "features: \"^data:0\\\\.709$\"\n",
            "features: \"^data:0\\\\.71$\"\n",
            "features: \"^data:0\\\\.710$\"\n",
            "features: \"^data:0\\\\.711$\"\n",
            "features: \"^data:0\\\\.712$\"\n",
            "features: \"^data:0\\\\.713$\"\n",
            "features: \"^data:0\\\\.714$\"\n",
            "features: \"^data:0\\\\.715$\"\n",
            "features: \"^data:0\\\\.716$\"\n",
            "features: \"^data:0\\\\.717$\"\n",
            "features: \"^data:0\\\\.718$\"\n",
            "features: \"^data:0\\\\.719$\"\n",
            "features: \"^data:0\\\\.72$\"\n",
            "features: \"^data:0\\\\.720$\"\n",
            "features: \"^data:0\\\\.721$\"\n",
            "features: \"^data:0\\\\.722$\"\n",
            "features: \"^data:0\\\\.723$\"\n",
            "features: \"^data:0\\\\.724$\"\n",
            "features: \"^data:0\\\\.725$\"\n",
            "features: \"^data:0\\\\.726$\"\n",
            "features: \"^data:0\\\\.727$\"\n",
            "features: \"^data:0\\\\.728$\"\n",
            "features: \"^data:0\\\\.729$\"\n",
            "features: \"^data:0\\\\.73$\"\n",
            "features: \"^data:0\\\\.730$\"\n",
            "features: \"^data:0\\\\.731$\"\n",
            "features: \"^data:0\\\\.732$\"\n",
            "features: \"^data:0\\\\.733$\"\n",
            "features: \"^data:0\\\\.734$\"\n",
            "features: \"^data:0\\\\.735$\"\n",
            "features: \"^data:0\\\\.736$\"\n",
            "features: \"^data:0\\\\.737$\"\n",
            "features: \"^data:0\\\\.738$\"\n",
            "features: \"^data:0\\\\.739$\"\n",
            "features: \"^data:0\\\\.74$\"\n",
            "features: \"^data:0\\\\.740$\"\n",
            "features: \"^data:0\\\\.741$\"\n",
            "features: \"^data:0\\\\.742$\"\n",
            "features: \"^data:0\\\\.743$\"\n",
            "features: \"^data:0\\\\.744$\"\n",
            "features: \"^data:0\\\\.745$\"\n",
            "features: \"^data:0\\\\.746$\"\n",
            "features: \"^data:0\\\\.747$\"\n",
            "features: \"^data:0\\\\.748$\"\n",
            "features: \"^data:0\\\\.749$\"\n",
            "features: \"^data:0\\\\.75$\"\n",
            "features: \"^data:0\\\\.750$\"\n",
            "features: \"^data:0\\\\.751$\"\n",
            "features: \"^data:0\\\\.752$\"\n",
            "features: \"^data:0\\\\.753$\"\n",
            "features: \"^data:0\\\\.754$\"\n",
            "features: \"^data:0\\\\.755$\"\n",
            "features: \"^data:0\\\\.756$\"\n",
            "features: \"^data:0\\\\.757$\"\n",
            "features: \"^data:0\\\\.758$\"\n",
            "features: \"^data:0\\\\.759$\"\n",
            "features: \"^data:0\\\\.76$\"\n",
            "features: \"^data:0\\\\.760$\"\n",
            "features: \"^data:0\\\\.761$\"\n",
            "features: \"^data:0\\\\.762$\"\n",
            "features: \"^data:0\\\\.763$\"\n",
            "features: \"^data:0\\\\.764$\"\n",
            "features: \"^data:0\\\\.765$\"\n",
            "features: \"^data:0\\\\.766$\"\n",
            "features: \"^data:0\\\\.767$\"\n",
            "features: \"^data:0\\\\.768$\"\n",
            "features: \"^data:0\\\\.769$\"\n",
            "features: \"^data:0\\\\.77$\"\n",
            "features: \"^data:0\\\\.770$\"\n",
            "features: \"^data:0\\\\.771$\"\n",
            "features: \"^data:0\\\\.772$\"\n",
            "features: \"^data:0\\\\.773$\"\n",
            "features: \"^data:0\\\\.774$\"\n",
            "features: \"^data:0\\\\.775$\"\n",
            "features: \"^data:0\\\\.776$\"\n",
            "features: \"^data:0\\\\.777$\"\n",
            "features: \"^data:0\\\\.778$\"\n",
            "features: \"^data:0\\\\.779$\"\n",
            "features: \"^data:0\\\\.78$\"\n",
            "features: \"^data:0\\\\.780$\"\n",
            "features: \"^data:0\\\\.781$\"\n",
            "features: \"^data:0\\\\.782$\"\n",
            "features: \"^data:0\\\\.783$\"\n",
            "features: \"^data:0\\\\.79$\"\n",
            "features: \"^data:0\\\\.8$\"\n",
            "features: \"^data:0\\\\.80$\"\n",
            "features: \"^data:0\\\\.81$\"\n",
            "features: \"^data:0\\\\.82$\"\n",
            "features: \"^data:0\\\\.83$\"\n",
            "features: \"^data:0\\\\.84$\"\n",
            "features: \"^data:0\\\\.85$\"\n",
            "features: \"^data:0\\\\.86$\"\n",
            "features: \"^data:0\\\\.87$\"\n",
            "features: \"^data:0\\\\.88$\"\n",
            "features: \"^data:0\\\\.89$\"\n",
            "features: \"^data:0\\\\.9$\"\n",
            "features: \"^data:0\\\\.90$\"\n",
            "features: \"^data:0\\\\.91$\"\n",
            "features: \"^data:0\\\\.92$\"\n",
            "features: \"^data:0\\\\.93$\"\n",
            "features: \"^data:0\\\\.94$\"\n",
            "features: \"^data:0\\\\.95$\"\n",
            "features: \"^data:0\\\\.96$\"\n",
            "features: \"^data:0\\\\.97$\"\n",
            "features: \"^data:0\\\\.98$\"\n",
            "features: \"^data:0\\\\.99$\"\n",
            "label: \"^__LABEL$\"\n",
            "task: CLASSIFICATION\n",
            "random_seed: 123456\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "pure_serving_model: false\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 50\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    keep_non_leaf_label_distribution: true\n",
            "    num_candidate_attributes: 0\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "    uplift {\n",
            "      min_examples_in_treatment: 5\n",
            "      split_score: KULLBACK_LEIBLER\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  num_oob_variable_importances_permutations: 1\n",
            "  bootstrap_training_dataset: true\n",
            "  bootstrap_size_ratio: 1\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "  sampling_with_replacement: true\n",
            "}\n",
            "\n",
            "[INFO 23-05-27 16:46:14.3808 UTC kernel.cc:827] Deployment config:\n",
            "cache_path: \"/tmp/tmptw28g65i/working_cache\"\n",
            "num_threads: 2\n",
            "try_resume_training: true\n",
            "\n",
            "[INFO 23-05-27 16:46:14.3811 UTC kernel.cc:889] Train model\n",
            "[INFO 23-05-27 16:46:14.4509 UTC random_forest.cc:416] Training random forest on 60000 example(s) and 784 feature(s).\n",
            "[INFO 23-05-27 16:46:18.7240 UTC random_forest.cc:805] Training of tree  1/50 (tree index:0) done accuracy:0.830498 logloss:6.10945\n",
            "[INFO 23-05-27 16:46:29.3022 UTC random_forest.cc:805] Training of tree  11/50 (tree index:10) done accuracy:0.90397 logloss:1.33512\n",
            "[INFO 23-05-27 16:46:39.9019 UTC random_forest.cc:805] Training of tree  21/50 (tree index:20) done accuracy:0.938795 logloss:0.568085\n",
            "[INFO 23-05-27 16:46:50.6658 UTC random_forest.cc:805] Training of tree  31/50 (tree index:30) done accuracy:0.950167 logloss:0.393499\n",
            "[INFO 23-05-27 16:47:01.7816 UTC random_forest.cc:805] Training of tree  41/50 (tree index:40) done accuracy:0.954833 logloss:0.323543\n",
            "[INFO 23-05-27 16:47:09.6383 UTC random_forest.cc:805] Training of tree  50/50 (tree index:49) done accuracy:0.957 logloss:0.295299\n",
            "[INFO 23-05-27 16:47:09.6385 UTC random_forest.cc:885] Final OOB metrics: accuracy:0.957 logloss:0.295299\n",
            "[INFO 23-05-27 16:47:10.2656 UTC kernel.cc:926] Export model in log directory: /tmp/tmptw28g65i with prefix b244605116604869\n",
            "[INFO 23-05-27 16:47:10.4435 UTC kernel.cc:944] Save model in resources\n",
            "[INFO 23-05-27 16:47:10.4546 UTC abstract_model.cc:849] Model self evaluation:\n",
            "Number of predictions (without weights): 60000\n",
            "Number of predictions (with weights): 60000\n",
            "Task: CLASSIFICATION\n",
            "Label: __LABEL\n",
            "\n",
            "Accuracy: 0.957  CI95[W][0.955613 0.958354]\n",
            "LogLoss: : 0.295299\n",
            "ErrorRate: : 0.043\n",
            "\n",
            "Default Accuracy: : 0.112367\n",
            "Default LogLoss: : 2.30116\n",
            "Default ErrorRate: : 0.887633\n",
            "\n",
            "Confusion Table:\n",
            "truth\\prediction\n",
            "    0     1     2     3     4     5     6     7     8     9    10\n",
            " 0  0     0     0     0     0     0     0     0     0     0     0\n",
            " 1  0  5843     1    12     4     3     8    16     3    27     6\n",
            " 2  0     0  6630    38    13    14    10     6    16    13     2\n",
            " 3  0    24    19  5721    32    25     9    26    54    36    12\n",
            " 4  0    12    14   121  5757     4    84    10    51    53    25\n",
            " 5  0    13    11    11     4  5602     5    33    13    14   136\n",
            " 6  0    29    21    11    91    18  5141    41     4    39    26\n",
            " 7  0    32    17    15     2    27    50  5754     1    20     0\n",
            " 8  0     8    29    87    13    47     3     0  5988    10    80\n",
            " 9  0    24    40    67    73    39    54    33     7  5445    69\n",
            "10  0    27    15    25    88   118    26     6    60    45  5539\n",
            "Total: 60000\n",
            "\n",
            "One vs other classes:\n",
            "\n",
            "[INFO 23-05-27 16:47:10.5293 UTC kernel.cc:1242] Loading model from path /tmp/tmptw28g65i/model/ with prefix b244605116604869\n",
            "[INFO 23-05-27 16:47:11.9569 UTC decision_forest.cc:660] Model loaded with 50 root(s), 233670 node(s), and 538 input feature(s).\n",
            "[INFO 23-05-27 16:47:11.9569 UTC abstract_model.cc:1311] Engine \"RandomForestGeneric\" built\n",
            "[INFO 23-05-27 16:47:11.9574 UTC kernel.cc:1074] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:00:58.036107\n",
            "Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fa4cf8fc790> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fa4cf8fc790> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model compiled.\n",
            "Model: \"random_forest_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (784):\n",
            "\tdata:0.0\n",
            "\tdata:0.1\n",
            "\tdata:0.10\n",
            "\tdata:0.100\n",
            "\tdata:0.101\n",
            "\tdata:0.102\n",
            "\tdata:0.103\n",
            "\tdata:0.104\n",
            "\tdata:0.105\n",
            "\tdata:0.106\n",
            "\tdata:0.107\n",
            "\tdata:0.108\n",
            "\tdata:0.109\n",
            "\tdata:0.11\n",
            "\tdata:0.110\n",
            "\tdata:0.111\n",
            "\tdata:0.112\n",
            "\tdata:0.113\n",
            "\tdata:0.114\n",
            "\tdata:0.115\n",
            "\tdata:0.116\n",
            "\tdata:0.117\n",
            "\tdata:0.118\n",
            "\tdata:0.119\n",
            "\tdata:0.12\n",
            "\tdata:0.120\n",
            "\tdata:0.121\n",
            "\tdata:0.122\n",
            "\tdata:0.123\n",
            "\tdata:0.124\n",
            "\tdata:0.125\n",
            "\tdata:0.126\n",
            "\tdata:0.127\n",
            "\tdata:0.128\n",
            "\tdata:0.129\n",
            "\tdata:0.13\n",
            "\tdata:0.130\n",
            "\tdata:0.131\n",
            "\tdata:0.132\n",
            "\tdata:0.133\n",
            "\tdata:0.134\n",
            "\tdata:0.135\n",
            "\tdata:0.136\n",
            "\tdata:0.137\n",
            "\tdata:0.138\n",
            "\tdata:0.139\n",
            "\tdata:0.14\n",
            "\tdata:0.140\n",
            "\tdata:0.141\n",
            "\tdata:0.142\n",
            "\tdata:0.143\n",
            "\tdata:0.144\n",
            "\tdata:0.145\n",
            "\tdata:0.146\n",
            "\tdata:0.147\n",
            "\tdata:0.148\n",
            "\tdata:0.149\n",
            "\tdata:0.15\n",
            "\tdata:0.150\n",
            "\tdata:0.151\n",
            "\tdata:0.152\n",
            "\tdata:0.153\n",
            "\tdata:0.154\n",
            "\tdata:0.155\n",
            "\tdata:0.156\n",
            "\tdata:0.157\n",
            "\tdata:0.158\n",
            "\tdata:0.159\n",
            "\tdata:0.16\n",
            "\tdata:0.160\n",
            "\tdata:0.161\n",
            "\tdata:0.162\n",
            "\tdata:0.163\n",
            "\tdata:0.164\n",
            "\tdata:0.165\n",
            "\tdata:0.166\n",
            "\tdata:0.167\n",
            "\tdata:0.168\n",
            "\tdata:0.169\n",
            "\tdata:0.17\n",
            "\tdata:0.170\n",
            "\tdata:0.171\n",
            "\tdata:0.172\n",
            "\tdata:0.173\n",
            "\tdata:0.174\n",
            "\tdata:0.175\n",
            "\tdata:0.176\n",
            "\tdata:0.177\n",
            "\tdata:0.178\n",
            "\tdata:0.179\n",
            "\tdata:0.18\n",
            "\tdata:0.180\n",
            "\tdata:0.181\n",
            "\tdata:0.182\n",
            "\tdata:0.183\n",
            "\tdata:0.184\n",
            "\tdata:0.185\n",
            "\tdata:0.186\n",
            "\tdata:0.187\n",
            "\tdata:0.188\n",
            "\tdata:0.189\n",
            "\tdata:0.19\n",
            "\tdata:0.190\n",
            "\tdata:0.191\n",
            "\tdata:0.192\n",
            "\tdata:0.193\n",
            "\tdata:0.194\n",
            "\tdata:0.195\n",
            "\tdata:0.196\n",
            "\tdata:0.197\n",
            "\tdata:0.198\n",
            "\tdata:0.199\n",
            "\tdata:0.2\n",
            "\tdata:0.20\n",
            "\tdata:0.200\n",
            "\tdata:0.201\n",
            "\tdata:0.202\n",
            "\tdata:0.203\n",
            "\tdata:0.204\n",
            "\tdata:0.205\n",
            "\tdata:0.206\n",
            "\tdata:0.207\n",
            "\tdata:0.208\n",
            "\tdata:0.209\n",
            "\tdata:0.21\n",
            "\tdata:0.210\n",
            "\tdata:0.211\n",
            "\tdata:0.212\n",
            "\tdata:0.213\n",
            "\tdata:0.214\n",
            "\tdata:0.215\n",
            "\tdata:0.216\n",
            "\tdata:0.217\n",
            "\tdata:0.218\n",
            "\tdata:0.219\n",
            "\tdata:0.22\n",
            "\tdata:0.220\n",
            "\tdata:0.221\n",
            "\tdata:0.222\n",
            "\tdata:0.223\n",
            "\tdata:0.224\n",
            "\tdata:0.225\n",
            "\tdata:0.226\n",
            "\tdata:0.227\n",
            "\tdata:0.228\n",
            "\tdata:0.229\n",
            "\tdata:0.23\n",
            "\tdata:0.230\n",
            "\tdata:0.231\n",
            "\tdata:0.232\n",
            "\tdata:0.233\n",
            "\tdata:0.234\n",
            "\tdata:0.235\n",
            "\tdata:0.236\n",
            "\tdata:0.237\n",
            "\tdata:0.238\n",
            "\tdata:0.239\n",
            "\tdata:0.24\n",
            "\tdata:0.240\n",
            "\tdata:0.241\n",
            "\tdata:0.242\n",
            "\tdata:0.243\n",
            "\tdata:0.244\n",
            "\tdata:0.245\n",
            "\tdata:0.246\n",
            "\tdata:0.247\n",
            "\tdata:0.248\n",
            "\tdata:0.249\n",
            "\tdata:0.25\n",
            "\tdata:0.250\n",
            "\tdata:0.251\n",
            "\tdata:0.252\n",
            "\tdata:0.253\n",
            "\tdata:0.254\n",
            "\tdata:0.255\n",
            "\tdata:0.256\n",
            "\tdata:0.257\n",
            "\tdata:0.258\n",
            "\tdata:0.259\n",
            "\tdata:0.26\n",
            "\tdata:0.260\n",
            "\tdata:0.261\n",
            "\tdata:0.262\n",
            "\tdata:0.263\n",
            "\tdata:0.264\n",
            "\tdata:0.265\n",
            "\tdata:0.266\n",
            "\tdata:0.267\n",
            "\tdata:0.268\n",
            "\tdata:0.269\n",
            "\tdata:0.27\n",
            "\tdata:0.270\n",
            "\tdata:0.271\n",
            "\tdata:0.272\n",
            "\tdata:0.273\n",
            "\tdata:0.274\n",
            "\tdata:0.275\n",
            "\tdata:0.276\n",
            "\tdata:0.277\n",
            "\tdata:0.278\n",
            "\tdata:0.279\n",
            "\tdata:0.28\n",
            "\tdata:0.280\n",
            "\tdata:0.281\n",
            "\tdata:0.282\n",
            "\tdata:0.283\n",
            "\tdata:0.284\n",
            "\tdata:0.285\n",
            "\tdata:0.286\n",
            "\tdata:0.287\n",
            "\tdata:0.288\n",
            "\tdata:0.289\n",
            "\tdata:0.29\n",
            "\tdata:0.290\n",
            "\tdata:0.291\n",
            "\tdata:0.292\n",
            "\tdata:0.293\n",
            "\tdata:0.294\n",
            "\tdata:0.295\n",
            "\tdata:0.296\n",
            "\tdata:0.297\n",
            "\tdata:0.298\n",
            "\tdata:0.299\n",
            "\tdata:0.3\n",
            "\tdata:0.30\n",
            "\tdata:0.300\n",
            "\tdata:0.301\n",
            "\tdata:0.302\n",
            "\tdata:0.303\n",
            "\tdata:0.304\n",
            "\tdata:0.305\n",
            "\tdata:0.306\n",
            "\tdata:0.307\n",
            "\tdata:0.308\n",
            "\tdata:0.309\n",
            "\tdata:0.31\n",
            "\tdata:0.310\n",
            "\tdata:0.311\n",
            "\tdata:0.312\n",
            "\tdata:0.313\n",
            "\tdata:0.314\n",
            "\tdata:0.315\n",
            "\tdata:0.316\n",
            "\tdata:0.317\n",
            "\tdata:0.318\n",
            "\tdata:0.319\n",
            "\tdata:0.32\n",
            "\tdata:0.320\n",
            "\tdata:0.321\n",
            "\tdata:0.322\n",
            "\tdata:0.323\n",
            "\tdata:0.324\n",
            "\tdata:0.325\n",
            "\tdata:0.326\n",
            "\tdata:0.327\n",
            "\tdata:0.328\n",
            "\tdata:0.329\n",
            "\tdata:0.33\n",
            "\tdata:0.330\n",
            "\tdata:0.331\n",
            "\tdata:0.332\n",
            "\tdata:0.333\n",
            "\tdata:0.334\n",
            "\tdata:0.335\n",
            "\tdata:0.336\n",
            "\tdata:0.337\n",
            "\tdata:0.338\n",
            "\tdata:0.339\n",
            "\tdata:0.34\n",
            "\tdata:0.340\n",
            "\tdata:0.341\n",
            "\tdata:0.342\n",
            "\tdata:0.343\n",
            "\tdata:0.344\n",
            "\tdata:0.345\n",
            "\tdata:0.346\n",
            "\tdata:0.347\n",
            "\tdata:0.348\n",
            "\tdata:0.349\n",
            "\tdata:0.35\n",
            "\tdata:0.350\n",
            "\tdata:0.351\n",
            "\tdata:0.352\n",
            "\tdata:0.353\n",
            "\tdata:0.354\n",
            "\tdata:0.355\n",
            "\tdata:0.356\n",
            "\tdata:0.357\n",
            "\tdata:0.358\n",
            "\tdata:0.359\n",
            "\tdata:0.36\n",
            "\tdata:0.360\n",
            "\tdata:0.361\n",
            "\tdata:0.362\n",
            "\tdata:0.363\n",
            "\tdata:0.364\n",
            "\tdata:0.365\n",
            "\tdata:0.366\n",
            "\tdata:0.367\n",
            "\tdata:0.368\n",
            "\tdata:0.369\n",
            "\tdata:0.37\n",
            "\tdata:0.370\n",
            "\tdata:0.371\n",
            "\tdata:0.372\n",
            "\tdata:0.373\n",
            "\tdata:0.374\n",
            "\tdata:0.375\n",
            "\tdata:0.376\n",
            "\tdata:0.377\n",
            "\tdata:0.378\n",
            "\tdata:0.379\n",
            "\tdata:0.38\n",
            "\tdata:0.380\n",
            "\tdata:0.381\n",
            "\tdata:0.382\n",
            "\tdata:0.383\n",
            "\tdata:0.384\n",
            "\tdata:0.385\n",
            "\tdata:0.386\n",
            "\tdata:0.387\n",
            "\tdata:0.388\n",
            "\tdata:0.389\n",
            "\tdata:0.39\n",
            "\tdata:0.390\n",
            "\tdata:0.391\n",
            "\tdata:0.392\n",
            "\tdata:0.393\n",
            "\tdata:0.394\n",
            "\tdata:0.395\n",
            "\tdata:0.396\n",
            "\tdata:0.397\n",
            "\tdata:0.398\n",
            "\tdata:0.399\n",
            "\tdata:0.4\n",
            "\tdata:0.40\n",
            "\tdata:0.400\n",
            "\tdata:0.401\n",
            "\tdata:0.402\n",
            "\tdata:0.403\n",
            "\tdata:0.404\n",
            "\tdata:0.405\n",
            "\tdata:0.406\n",
            "\tdata:0.407\n",
            "\tdata:0.408\n",
            "\tdata:0.409\n",
            "\tdata:0.41\n",
            "\tdata:0.410\n",
            "\tdata:0.411\n",
            "\tdata:0.412\n",
            "\tdata:0.413\n",
            "\tdata:0.414\n",
            "\tdata:0.415\n",
            "\tdata:0.416\n",
            "\tdata:0.417\n",
            "\tdata:0.418\n",
            "\tdata:0.419\n",
            "\tdata:0.42\n",
            "\tdata:0.420\n",
            "\tdata:0.421\n",
            "\tdata:0.422\n",
            "\tdata:0.423\n",
            "\tdata:0.424\n",
            "\tdata:0.425\n",
            "\tdata:0.426\n",
            "\tdata:0.427\n",
            "\tdata:0.428\n",
            "\tdata:0.429\n",
            "\tdata:0.43\n",
            "\tdata:0.430\n",
            "\tdata:0.431\n",
            "\tdata:0.432\n",
            "\tdata:0.433\n",
            "\tdata:0.434\n",
            "\tdata:0.435\n",
            "\tdata:0.436\n",
            "\tdata:0.437\n",
            "\tdata:0.438\n",
            "\tdata:0.439\n",
            "\tdata:0.44\n",
            "\tdata:0.440\n",
            "\tdata:0.441\n",
            "\tdata:0.442\n",
            "\tdata:0.443\n",
            "\tdata:0.444\n",
            "\tdata:0.445\n",
            "\tdata:0.446\n",
            "\tdata:0.447\n",
            "\tdata:0.448\n",
            "\tdata:0.449\n",
            "\tdata:0.45\n",
            "\tdata:0.450\n",
            "\tdata:0.451\n",
            "\tdata:0.452\n",
            "\tdata:0.453\n",
            "\tdata:0.454\n",
            "\tdata:0.455\n",
            "\tdata:0.456\n",
            "\tdata:0.457\n",
            "\tdata:0.458\n",
            "\tdata:0.459\n",
            "\tdata:0.46\n",
            "\tdata:0.460\n",
            "\tdata:0.461\n",
            "\tdata:0.462\n",
            "\tdata:0.463\n",
            "\tdata:0.464\n",
            "\tdata:0.465\n",
            "\tdata:0.466\n",
            "\tdata:0.467\n",
            "\tdata:0.468\n",
            "\tdata:0.469\n",
            "\tdata:0.47\n",
            "\tdata:0.470\n",
            "\tdata:0.471\n",
            "\tdata:0.472\n",
            "\tdata:0.473\n",
            "\tdata:0.474\n",
            "\tdata:0.475\n",
            "\tdata:0.476\n",
            "\tdata:0.477\n",
            "\tdata:0.478\n",
            "\tdata:0.479\n",
            "\tdata:0.48\n",
            "\tdata:0.480\n",
            "\tdata:0.481\n",
            "\tdata:0.482\n",
            "\tdata:0.483\n",
            "\tdata:0.484\n",
            "\tdata:0.485\n",
            "\tdata:0.486\n",
            "\tdata:0.487\n",
            "\tdata:0.488\n",
            "\tdata:0.489\n",
            "\tdata:0.49\n",
            "\tdata:0.490\n",
            "\tdata:0.491\n",
            "\tdata:0.492\n",
            "\tdata:0.493\n",
            "\tdata:0.494\n",
            "\tdata:0.495\n",
            "\tdata:0.496\n",
            "\tdata:0.497\n",
            "\tdata:0.498\n",
            "\tdata:0.499\n",
            "\tdata:0.5\n",
            "\tdata:0.50\n",
            "\tdata:0.500\n",
            "\tdata:0.501\n",
            "\tdata:0.502\n",
            "\tdata:0.503\n",
            "\tdata:0.504\n",
            "\tdata:0.505\n",
            "\tdata:0.506\n",
            "\tdata:0.507\n",
            "\tdata:0.508\n",
            "\tdata:0.509\n",
            "\tdata:0.51\n",
            "\tdata:0.510\n",
            "\tdata:0.511\n",
            "\tdata:0.512\n",
            "\tdata:0.513\n",
            "\tdata:0.514\n",
            "\tdata:0.515\n",
            "\tdata:0.516\n",
            "\tdata:0.517\n",
            "\tdata:0.518\n",
            "\tdata:0.519\n",
            "\tdata:0.52\n",
            "\tdata:0.520\n",
            "\tdata:0.521\n",
            "\tdata:0.522\n",
            "\tdata:0.523\n",
            "\tdata:0.524\n",
            "\tdata:0.525\n",
            "\tdata:0.526\n",
            "\tdata:0.527\n",
            "\tdata:0.528\n",
            "\tdata:0.529\n",
            "\tdata:0.53\n",
            "\tdata:0.530\n",
            "\tdata:0.531\n",
            "\tdata:0.532\n",
            "\tdata:0.533\n",
            "\tdata:0.534\n",
            "\tdata:0.535\n",
            "\tdata:0.536\n",
            "\tdata:0.537\n",
            "\tdata:0.538\n",
            "\tdata:0.539\n",
            "\tdata:0.54\n",
            "\tdata:0.540\n",
            "\tdata:0.541\n",
            "\tdata:0.542\n",
            "\tdata:0.543\n",
            "\tdata:0.544\n",
            "\tdata:0.545\n",
            "\tdata:0.546\n",
            "\tdata:0.547\n",
            "\tdata:0.548\n",
            "\tdata:0.549\n",
            "\tdata:0.55\n",
            "\tdata:0.550\n",
            "\tdata:0.551\n",
            "\tdata:0.552\n",
            "\tdata:0.553\n",
            "\tdata:0.554\n",
            "\tdata:0.555\n",
            "\tdata:0.556\n",
            "\tdata:0.557\n",
            "\tdata:0.558\n",
            "\tdata:0.559\n",
            "\tdata:0.56\n",
            "\tdata:0.560\n",
            "\tdata:0.561\n",
            "\tdata:0.562\n",
            "\tdata:0.563\n",
            "\tdata:0.564\n",
            "\tdata:0.565\n",
            "\tdata:0.566\n",
            "\tdata:0.567\n",
            "\tdata:0.568\n",
            "\tdata:0.569\n",
            "\tdata:0.57\n",
            "\tdata:0.570\n",
            "\tdata:0.571\n",
            "\tdata:0.572\n",
            "\tdata:0.573\n",
            "\tdata:0.574\n",
            "\tdata:0.575\n",
            "\tdata:0.576\n",
            "\tdata:0.577\n",
            "\tdata:0.578\n",
            "\tdata:0.579\n",
            "\tdata:0.58\n",
            "\tdata:0.580\n",
            "\tdata:0.581\n",
            "\tdata:0.582\n",
            "\tdata:0.583\n",
            "\tdata:0.584\n",
            "\tdata:0.585\n",
            "\tdata:0.586\n",
            "\tdata:0.587\n",
            "\tdata:0.588\n",
            "\tdata:0.589\n",
            "\tdata:0.59\n",
            "\tdata:0.590\n",
            "\tdata:0.591\n",
            "\tdata:0.592\n",
            "\tdata:0.593\n",
            "\tdata:0.594\n",
            "\tdata:0.595\n",
            "\tdata:0.596\n",
            "\tdata:0.597\n",
            "\tdata:0.598\n",
            "\tdata:0.599\n",
            "\tdata:0.6\n",
            "\tdata:0.60\n",
            "\tdata:0.600\n",
            "\tdata:0.601\n",
            "\tdata:0.602\n",
            "\tdata:0.603\n",
            "\tdata:0.604\n",
            "\tdata:0.605\n",
            "\tdata:0.606\n",
            "\tdata:0.607\n",
            "\tdata:0.608\n",
            "\tdata:0.609\n",
            "\tdata:0.61\n",
            "\tdata:0.610\n",
            "\tdata:0.611\n",
            "\tdata:0.612\n",
            "\tdata:0.613\n",
            "\tdata:0.614\n",
            "\tdata:0.615\n",
            "\tdata:0.616\n",
            "\tdata:0.617\n",
            "\tdata:0.618\n",
            "\tdata:0.619\n",
            "\tdata:0.62\n",
            "\tdata:0.620\n",
            "\tdata:0.621\n",
            "\tdata:0.622\n",
            "\tdata:0.623\n",
            "\tdata:0.624\n",
            "\tdata:0.625\n",
            "\tdata:0.626\n",
            "\tdata:0.627\n",
            "\tdata:0.628\n",
            "\tdata:0.629\n",
            "\tdata:0.63\n",
            "\tdata:0.630\n",
            "\tdata:0.631\n",
            "\tdata:0.632\n",
            "\tdata:0.633\n",
            "\tdata:0.634\n",
            "\tdata:0.635\n",
            "\tdata:0.636\n",
            "\tdata:0.637\n",
            "\tdata:0.638\n",
            "\tdata:0.639\n",
            "\tdata:0.64\n",
            "\tdata:0.640\n",
            "\tdata:0.641\n",
            "\tdata:0.642\n",
            "\tdata:0.643\n",
            "\tdata:0.644\n",
            "\tdata:0.645\n",
            "\tdata:0.646\n",
            "\tdata:0.647\n",
            "\tdata:0.648\n",
            "\tdata:0.649\n",
            "\tdata:0.65\n",
            "\tdata:0.650\n",
            "\tdata:0.651\n",
            "\tdata:0.652\n",
            "\tdata:0.653\n",
            "\tdata:0.654\n",
            "\tdata:0.655\n",
            "\tdata:0.656\n",
            "\tdata:0.657\n",
            "\tdata:0.658\n",
            "\tdata:0.659\n",
            "\tdata:0.66\n",
            "\tdata:0.660\n",
            "\tdata:0.661\n",
            "\tdata:0.662\n",
            "\tdata:0.663\n",
            "\tdata:0.664\n",
            "\tdata:0.665\n",
            "\tdata:0.666\n",
            "\tdata:0.667\n",
            "\tdata:0.668\n",
            "\tdata:0.669\n",
            "\tdata:0.67\n",
            "\tdata:0.670\n",
            "\tdata:0.671\n",
            "\tdata:0.672\n",
            "\tdata:0.673\n",
            "\tdata:0.674\n",
            "\tdata:0.675\n",
            "\tdata:0.676\n",
            "\tdata:0.677\n",
            "\tdata:0.678\n",
            "\tdata:0.679\n",
            "\tdata:0.68\n",
            "\tdata:0.680\n",
            "\tdata:0.681\n",
            "\tdata:0.682\n",
            "\tdata:0.683\n",
            "\tdata:0.684\n",
            "\tdata:0.685\n",
            "\tdata:0.686\n",
            "\tdata:0.687\n",
            "\tdata:0.688\n",
            "\tdata:0.689\n",
            "\tdata:0.69\n",
            "\tdata:0.690\n",
            "\tdata:0.691\n",
            "\tdata:0.692\n",
            "\tdata:0.693\n",
            "\tdata:0.694\n",
            "\tdata:0.695\n",
            "\tdata:0.696\n",
            "\tdata:0.697\n",
            "\tdata:0.698\n",
            "\tdata:0.699\n",
            "\tdata:0.7\n",
            "\tdata:0.70\n",
            "\tdata:0.700\n",
            "\tdata:0.701\n",
            "\tdata:0.702\n",
            "\tdata:0.703\n",
            "\tdata:0.704\n",
            "\tdata:0.705\n",
            "\tdata:0.706\n",
            "\tdata:0.707\n",
            "\tdata:0.708\n",
            "\tdata:0.709\n",
            "\tdata:0.71\n",
            "\tdata:0.710\n",
            "\tdata:0.711\n",
            "\tdata:0.712\n",
            "\tdata:0.713\n",
            "\tdata:0.714\n",
            "\tdata:0.715\n",
            "\tdata:0.716\n",
            "\tdata:0.717\n",
            "\tdata:0.718\n",
            "\tdata:0.719\n",
            "\tdata:0.72\n",
            "\tdata:0.720\n",
            "\tdata:0.721\n",
            "\tdata:0.722\n",
            "\tdata:0.723\n",
            "\tdata:0.724\n",
            "\tdata:0.725\n",
            "\tdata:0.726\n",
            "\tdata:0.727\n",
            "\tdata:0.728\n",
            "\tdata:0.729\n",
            "\tdata:0.73\n",
            "\tdata:0.730\n",
            "\tdata:0.731\n",
            "\tdata:0.732\n",
            "\tdata:0.733\n",
            "\tdata:0.734\n",
            "\tdata:0.735\n",
            "\tdata:0.736\n",
            "\tdata:0.737\n",
            "\tdata:0.738\n",
            "\tdata:0.739\n",
            "\tdata:0.74\n",
            "\tdata:0.740\n",
            "\tdata:0.741\n",
            "\tdata:0.742\n",
            "\tdata:0.743\n",
            "\tdata:0.744\n",
            "\tdata:0.745\n",
            "\tdata:0.746\n",
            "\tdata:0.747\n",
            "\tdata:0.748\n",
            "\tdata:0.749\n",
            "\tdata:0.75\n",
            "\tdata:0.750\n",
            "\tdata:0.751\n",
            "\tdata:0.752\n",
            "\tdata:0.753\n",
            "\tdata:0.754\n",
            "\tdata:0.755\n",
            "\tdata:0.756\n",
            "\tdata:0.757\n",
            "\tdata:0.758\n",
            "\tdata:0.759\n",
            "\tdata:0.76\n",
            "\tdata:0.760\n",
            "\tdata:0.761\n",
            "\tdata:0.762\n",
            "\tdata:0.763\n",
            "\tdata:0.764\n",
            "\tdata:0.765\n",
            "\tdata:0.766\n",
            "\tdata:0.767\n",
            "\tdata:0.768\n",
            "\tdata:0.769\n",
            "\tdata:0.77\n",
            "\tdata:0.770\n",
            "\tdata:0.771\n",
            "\tdata:0.772\n",
            "\tdata:0.773\n",
            "\tdata:0.774\n",
            "\tdata:0.775\n",
            "\tdata:0.776\n",
            "\tdata:0.777\n",
            "\tdata:0.778\n",
            "\tdata:0.779\n",
            "\tdata:0.78\n",
            "\tdata:0.780\n",
            "\tdata:0.781\n",
            "\tdata:0.782\n",
            "\tdata:0.783\n",
            "\tdata:0.79\n",
            "\tdata:0.8\n",
            "\tdata:0.80\n",
            "\tdata:0.81\n",
            "\tdata:0.82\n",
            "\tdata:0.83\n",
            "\tdata:0.84\n",
            "\tdata:0.85\n",
            "\tdata:0.86\n",
            "\tdata:0.87\n",
            "\tdata:0.88\n",
            "\tdata:0.89\n",
            "\tdata:0.9\n",
            "\tdata:0.90\n",
            "\tdata:0.91\n",
            "\tdata:0.92\n",
            "\tdata:0.93\n",
            "\tdata:0.94\n",
            "\tdata:0.95\n",
            "\tdata:0.96\n",
            "\tdata:0.97\n",
            "\tdata:0.98\n",
            "\tdata:0.99\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1. \"data:0.378\"  0.089523 ################\n",
            "    2. \"data:0.569\"  0.088021 ##############\n",
            "    3. \"data:0.568\"  0.085900 ###########\n",
            "    4. \"data:0.345\"  0.085542 ###########\n",
            "    5. \"data:0.155\"  0.084849 ##########\n",
            "    6. \"data:0.515\"  0.084055 #########\n",
            "    7. \"data:0.406\"  0.083691 ########\n",
            "    8. \"data:0.377\"  0.083593 ########\n",
            "    9. \"data:0.350\"  0.083284 ########\n",
            "   10. \"data:0.428\"  0.082825 #######\n",
            "   11. \"data:0.291\"  0.082652 #######\n",
            "   12. \"data:0.461\"  0.082070 ######\n",
            "   13. \"data:0.409\"  0.082044 ######\n",
            "   14. \"data:0.290\"  0.081839 ######\n",
            "   15. \"data:0.154\"  0.081135 #####\n",
            "   16. \"data:0.489\"  0.080876 #####\n",
            "   17. \"data:0.375\"  0.080826 #####\n",
            "   18. \"data:0.625\"  0.080753 #####\n",
            "   19. \"data:0.401\"  0.080700 #####\n",
            "   20. \"data:0.487\"  0.080674 #####\n",
            "   21. \"data:0.462\"  0.080388 ####\n",
            "   22. \"data:0.460\"  0.080297 ####\n",
            "   23. \"data:0.346\"  0.080281 ####\n",
            "   24. \"data:0.405\"  0.080161 ####\n",
            "   25. \"data:0.153\"  0.080096 ####\n",
            "   26. \"data:0.433\"  0.079983 ####\n",
            "   27. \"data:0.318\"  0.079933 ####\n",
            "   28. \"data:0.539\"  0.079850 ####\n",
            "   29. \"data:0.514\"  0.079779 ####\n",
            "   30. \"data:0.596\"  0.079753 ####\n",
            "   31. \"data:0.408\"  0.079556 ###\n",
            "   32. \"data:0.317\"  0.079543 ###\n",
            "   33. \"data:0.542\"  0.079496 ###\n",
            "   34. \"data:0.540\"  0.079476 ###\n",
            "   35. \"data:0.456\"  0.079444 ###\n",
            "   36. \"data:0.484\"  0.079417 ###\n",
            "   37. \"data:0.657\"  0.079386 ###\n",
            "   38. \"data:0.263\"  0.079334 ###\n",
            "   39. \"data:0.488\"  0.079282 ###\n",
            "   40. \"data:0.543\"  0.079244 ###\n",
            "   41. \"data:0.156\"  0.079171 ###\n",
            "   42. \"data:0.374\"  0.079081 ###\n",
            "   43. \"data:0.655\"  0.079079 ###\n",
            "   44. \"data:0.347\"  0.079071 ###\n",
            "   45. \"data:0.570\"  0.079056 ###\n",
            "   46. \"data:0.658\"  0.079044 ###\n",
            "   47. \"data:0.429\"  0.079029 ###\n",
            "   48. \"data:0.656\"  0.078995 ###\n",
            "   49. \"data:0.457\"  0.078990 ###\n",
            "   50. \"data:0.211\"  0.078968 ###\n",
            "   51. \"data:0.490\"  0.078906 ###\n",
            "   52. \"data:0.373\"  0.078894 ###\n",
            "   53. \"data:0.269\"  0.078888 ###\n",
            "   54. \"data:0.430\"  0.078775 ##\n",
            "   55. \"data:0.351\"  0.078767 ##\n",
            "   56. \"data:0.354\"  0.078740 ##\n",
            "   57. \"data:0.183\"  0.078724 ##\n",
            "   58. \"data:0.326\"  0.078706 ##\n",
            "   59. \"data:0.551\"  0.078694 ##\n",
            "   60. \"data:0.400\"  0.078690 ##\n",
            "   61. \"data:0.458\"  0.078637 ##\n",
            "   62. \"data:0.348\"  0.078631 ##\n",
            "   63. \"data:0.435\"  0.078582 ##\n",
            "   64. \"data:0.516\"  0.078558 ##\n",
            "   65. \"data:0.298\"  0.078555 ##\n",
            "   66. \"data:0.403\"  0.078524 ##\n",
            "   67. \"data:0.157\"  0.078493 ##\n",
            "   68. \"data:0.432\"  0.078469 ##\n",
            "   69. \"data:0.597\"  0.078442 ##\n",
            "   70. \"data:0.376\"  0.078431 ##\n",
            "   71. \"data:0.240\"  0.078422 ##\n",
            "   72. \"data:0.379\"  0.078380 ##\n",
            "   73. \"data:0.238\"  0.078366 ##\n",
            "   74. \"data:0.349\"  0.078355 ##\n",
            "   75. \"data:0.541\"  0.078328 ##\n",
            "   76. \"data:0.654\"  0.078308 ##\n",
            "   77. \"data:0.322\"  0.078277 ##\n",
            "   78. \"data:0.522\"  0.078258 ##\n",
            "   79. \"data:0.410\"  0.078239 ##\n",
            "   80. \"data:0.465\"  0.078217 ##\n",
            "   81. \"data:0.463\"  0.078210 ##\n",
            "   82. \"data:0.210\"  0.078205 ##\n",
            "   83. \"data:0.434\"  0.078200 ##\n",
            "   84. \"data:0.152\"  0.078140 ##\n",
            "   85. \"data:0.352\"  0.078125 ##\n",
            "   86. \"data:0.486\"  0.078086 ##\n",
            "   87. \"data:0.567\"  0.078070 ##\n",
            "   88. \"data:0.270\"  0.078045 ##\n",
            "   89. \"data:0.381\"  0.078040 ##\n",
            "   90. \"data:0.319\"  0.078020 ##\n",
            "   91. \"data:0.550\"  0.078015 ##\n",
            "   92. \"data:0.267\"  0.078012 ##\n",
            "   93. \"data:0.513\"  0.078000 ##\n",
            "   94. \"data:0.459\"  0.077997 ##\n",
            "   95. \"data:0.431\"  0.077981 ##\n",
            "   96. \"data:0.320\"  0.077972 #\n",
            "   97. \"data:0.437\"  0.077942 #\n",
            "   98. \"data:0.299\"  0.077924 #\n",
            "   99. \"data:0.571\"  0.077911 #\n",
            "  100. \"data:0.380\"  0.077908 #\n",
            "  101. \"data:0.485\"  0.077885 #\n",
            "  102. \"data:0.404\"  0.077856 #\n",
            "  103. \"data:0.382\"  0.077831 #\n",
            "  104. \"data:0.325\"  0.077775 #\n",
            "  105. \"data:0.212\"  0.077775 #\n",
            "  106. \"data:0.545\"  0.077761 #\n",
            "  107. \"data:0.544\"  0.077754 #\n",
            "  108. \"data:0.207\"  0.077741 #\n",
            "  109. \"data:0.294\"  0.077711 #\n",
            "  110. \"data:0.517\"  0.077701 #\n",
            "  111. \"data:0.178\"  0.077699 #\n",
            "  112. \"data:0.100\"  0.077681 #\n",
            "  113. \"data:0.402\"  0.077640 #\n",
            "  114. \"data:0.209\"  0.077633 #\n",
            "  115. \"data:0.327\"  0.077588 #\n",
            "  116. \"data:0.595\"  0.077585 #\n",
            "  117. \"data:0.296\"  0.077585 #\n",
            "  118. \"data:0.182\"  0.077579 #\n",
            "  119. \"data:0.268\"  0.077579 #\n",
            "  120. \"data:0.466\"  0.077572 #\n",
            "  121. \"data:0.234\"  0.077570 #\n",
            "  122. \"data:0.292\"  0.077568 #\n",
            "  123. \"data:0.243\"  0.077547 #\n",
            "  124. \"data:0.578\"  0.077540 #\n",
            "  125. \"data:0.237\"  0.077536 #\n",
            "  126. \"data:0.266\"  0.077526 #\n",
            "  127. \"data:0.271\"  0.077520 #\n",
            "  128. \"data:0.239\"  0.077510 #\n",
            "  129. \"data:0.353\"  0.077505 #\n",
            "  130. \"data:0.321\"  0.077504 #\n",
            "  131. \"data:0.598\"  0.077503 #\n",
            "  132. \"data:0.185\"  0.077503 #\n",
            "  133. \"data:0.241\"  0.077498 #\n",
            "  134. \"data:0.151\"  0.077488 #\n",
            "  135. \"data:0.323\"  0.077484 #\n",
            "  136. \"data:0.427\"  0.077484 #\n",
            "  137. \"data:0.295\"  0.077474 #\n",
            "  138. \"data:0.324\"  0.077468 #\n",
            "  139. \"data:0.297\"  0.077467 #\n",
            "  140. \"data:0.184\"  0.077465 #\n",
            "  141. \"data:0.127\"  0.077458 #\n",
            "  142. \"data:0.372\"  0.077449 #\n",
            "  143. \"data:0.289\"  0.077418 #\n",
            "  144. \"data:0.236\"  0.077377 #\n",
            "  145. \"data:0.213\"  0.077377 #\n",
            "  146. \"data:0.265\"  0.077372 #\n",
            "  147. \"data:0.495\"  0.077348 #\n",
            "  148. \"data:0.651\"  0.077341 #\n",
            "  149. \"data:0.158\"  0.077328 #\n",
            "  150. \"data:0.496\"  0.077325 #\n",
            "  151. \"data:0.464\"  0.077311 #\n",
            "  152. \"data:0.467\"  0.077311 #\n",
            "  153. \"data:0.653\"  0.077293 #\n",
            "  154. \"data:0.627\"  0.077288 #\n",
            "  155. \"data:0.626\"  0.077279 #\n",
            "  156. \"data:0.573\"  0.077273 #\n",
            "  157. \"data:0.125\"  0.077264 #\n",
            "  158. \"data:0.407\"  0.077261 #\n",
            "  159. \"data:0.572\"  0.077258 #\n",
            "  160. \"data:0.399\"  0.077255 #\n",
            "  161. \"data:0.436\"  0.077250 #\n",
            "  162. \"data:0.524\"  0.077246 #\n",
            "  163. \"data:0.494\"  0.077245 #\n",
            "  164. \"data:0.124\"  0.077237 #\n",
            "  165. \"data:0.316\"  0.077216 #\n",
            "  166. \"data:0.491\"  0.077206 #\n",
            "  167. \"data:0.357\"  0.077205 #\n",
            "  168. \"data:0.218\"  0.077196 #\n",
            "  169. \"data:0.523\"  0.077194 #\n",
            "  170. \"data:0.455\"  0.077194 #\n",
            "  171. \"data:0.293\"  0.077191 #\n",
            "  172. \"data:0.300\"  0.077179 #\n",
            "  173. \"data:0.343\"  0.077177 #\n",
            "  174. \"data:0.179\"  0.077176 #\n",
            "  175. \"data:0.329\"  0.077173 #\n",
            "  176. \"data:0.577\"  0.077170 #\n",
            "  177. \"data:0.512\"  0.077158 #\n",
            "  178. \"data:0.206\"  0.077153 #\n",
            "  179. \"data:0.215\"  0.077152 \n",
            "  180. \"data:0.242\"  0.077149 \n",
            "  181. \"data:0.128\"  0.077132 \n",
            "  182. \"data:0.426\"  0.077121 \n",
            "  183. \"data:0.371\"  0.077117 \n",
            "  184. \"data:0.181\"  0.077116 \n",
            "  185. \"data:0.659\"  0.077102 \n",
            "  186. \"data:0.624\"  0.077094 \n",
            "  187. \"data:0.273\"  0.077088 \n",
            "  188. \"data:0.235\"  0.077086 \n",
            "  189. \"data:0.599\"  0.077079 \n",
            "  190. \"data:0.126\"  0.077075 \n",
            "  191. \"data:0.262\"  0.077073 \n",
            "  192. \"data:0.214\"  0.077072 \n",
            "  193. \"data:0.518\"  0.077070 \n",
            "  194. \"data:0.272\"  0.077058 \n",
            "  195. \"data:0.330\"  0.077052 \n",
            "  196. \"data:0.521\"  0.077050 \n",
            "  197. \"data:0.328\"  0.077049 \n",
            "  198. \"data:0.344\"  0.077034 \n",
            "  199. \"data:0.594\"  0.077034 \n",
            "  200. \"data:0.438\"  0.077001 \n",
            "  201. \"data:0.411\"  0.076998 \n",
            "  202. \"data:0.101\"  0.076995 \n",
            "  203. \"data:0.606\"  0.076991 \n",
            "  204. \"data:0.244\"  0.076970 \n",
            "  205. \"data:0.511\"  0.076957 \n",
            "  206. \"data:0.216\"  0.076953 \n",
            "  207. \"data:0.413\"  0.076947 \n",
            "  208. \"data:0.233\"  0.076945 \n",
            "  209. \"data:0.628\"  0.076942 \n",
            "  210. \"data:0.301\"  0.076922 \n",
            "  211. \"data:0.288\"  0.076919 \n",
            "  212. \"data:0.519\"  0.076914 \n",
            "  213. \"data:0.264\"  0.076906 \n",
            "  214. \"data:0.549\"  0.076906 \n",
            "  215. \"data:0.483\"  0.076903 \n",
            "  216. \"data:0.180\"  0.076900 \n",
            "  217. \"data:0.493\"  0.076890 \n",
            "  218. \"data:0.186\"  0.076885 \n",
            "  219. \"data:0.454\"  0.076885 \n",
            "  220. \"data:0.208\"  0.076881 \n",
            "  221. \"data:0.660\"  0.076876 \n",
            "  222. \"data:0.566\"  0.076868 \n",
            "  223. \"data:0.579\"  0.076868 \n",
            "  224. \"data:0.150\"  0.076867 \n",
            "  225.  \"data:0.97\"  0.076866 \n",
            "  226. \"data:0.623\"  0.076860 \n",
            "  227. \"data:0.492\"  0.076858 \n",
            "  228. \"data:0.355\"  0.076853 \n",
            "  229. \"data:0.603\"  0.076850 \n",
            "  230. \"data:0.358\"  0.076826 \n",
            "  231. \"data:0.315\"  0.076822 \n",
            "  232. \"data:0.631\"  0.076811 \n",
            "  233. \"data:0.601\"  0.076795 \n",
            "  234. \"data:0.546\"  0.076793 \n",
            "  235. \"data:0.538\"  0.076783 \n",
            "  236. \"data:0.129\"  0.076778 \n",
            "  237. \"data:0.652\"  0.076777 \n",
            "  238. \"data:0.600\"  0.076766 \n",
            "  239. \"data:0.383\"  0.076752 \n",
            "  240. \"data:0.576\"  0.076747 \n",
            "  241. \"data:0.548\"  0.076742 \n",
            "  242. \"data:0.245\"  0.076741 \n",
            "  243. \"data:0.159\"  0.076726 \n",
            "  244. \"data:0.630\"  0.076726 \n",
            "  245. \"data:0.470\"  0.076726 \n",
            "  246. \"data:0.342\"  0.076723 \n",
            "  247. \"data:0.177\"  0.076717 \n",
            "  248. \"data:0.683\"  0.076716 \n",
            "  249. \"data:0.685\"  0.076707 \n",
            "  250. \"data:0.439\"  0.076706 \n",
            "  251. \"data:0.219\"  0.076706 \n",
            "  252. \"data:0.510\"  0.076702 \n",
            "  253. \"data:0.274\"  0.076694 \n",
            "  254. \"data:0.661\"  0.076689 \n",
            "  255. \"data:0.552\"  0.076688 \n",
            "  256. \"data:0.686\"  0.076684 \n",
            "  257. \"data:0.684\"  0.076682 \n",
            "  258. \"data:0.629\"  0.076681 \n",
            "  259. \"data:0.188\"  0.076681 \n",
            "  260. \"data:0.575\"  0.076677 \n",
            "  261. \"data:0.469\"  0.076673 \n",
            "  262. \"data:0.247\"  0.076671 \n",
            "  263. \"data:0.398\"  0.076666 \n",
            "  264. \"data:0.187\"  0.076661 \n",
            "  265. \"data:0.123\"  0.076659 \n",
            "  266. \"data:0.261\"  0.076656 \n",
            "  267. \"data:0.608\"  0.076653 \n",
            "  268. \"data:0.189\"  0.076651 \n",
            "  269. \"data:0.149\"  0.076648 \n",
            "  270. \"data:0.468\"  0.076644 \n",
            "  271. \"data:0.260\"  0.076644 \n",
            "  272. \"data:0.526\"  0.076643 \n",
            "  273. \"data:0.520\"  0.076641 \n",
            "  274. \"data:0.574\"  0.076640 \n",
            "  275. \"data:0.440\"  0.076638 \n",
            "  276. \"data:0.176\"  0.076635 \n",
            "  277. \"data:0.356\"  0.076634 \n",
            "  278.  \"data:0.98\"  0.076631 \n",
            "  279. \"data:0.607\"  0.076629 \n",
            "  280. \"data:0.217\"  0.076618 \n",
            "  281. \"data:0.602\"  0.076616 \n",
            "  282. \"data:0.441\"  0.076610 \n",
            "  283. \"data:0.205\"  0.076609 \n",
            "  284. \"data:0.248\"  0.076598 \n",
            "  285. \"data:0.714\"  0.076597 \n",
            "  286. \"data:0.414\"  0.076596 \n",
            "  287. \"data:0.482\"  0.076595 \n",
            "  288. \"data:0.537\"  0.076589 \n",
            "  289. \"data:0.547\"  0.076584 \n",
            "  290. \"data:0.633\"  0.076581 \n",
            "  291. \"data:0.204\"  0.076580 \n",
            "  292. \"data:0.580\"  0.076577 \n",
            "  293. \"data:0.122\"  0.076576 \n",
            "  294. \"data:0.385\"  0.076574 \n",
            "  295. \"data:0.682\"  0.076562 \n",
            "  296. \"data:0.609\"  0.076556 \n",
            "  297. \"data:0.634\"  0.076552 \n",
            "  298. \"data:0.605\"  0.076549 \n",
            "  299. \"data:0.604\"  0.076549 \n",
            "  300. \"data:0.554\"  0.076549 \n",
            "  301. \"data:0.370\"  0.076548 \n",
            "  302. \"data:0.190\"  0.076547 \n",
            "  303.  \"data:0.99\"  0.076542 \n",
            "  304. \"data:0.384\"  0.076542 \n",
            "  305. \"data:0.246\"  0.076539 \n",
            "  306. \"data:0.497\"  0.076539 \n",
            "  307. \"data:0.302\"  0.076537 \n",
            "  308. \"data:0.632\"  0.076532 \n",
            "  309. \"data:0.679\"  0.076528 \n",
            "  310. \"data:0.287\"  0.076520 \n",
            "  311. \"data:0.412\"  0.076519 \n",
            "  312. \"data:0.453\"  0.076517 \n",
            "  313. \"data:0.386\"  0.076513 \n",
            "  314. \"data:0.509\"  0.076512 \n",
            "  315. \"data:0.681\"  0.076505 \n",
            "  316. \"data:0.130\"  0.076505 \n",
            "  317. \"data:0.553\"  0.076504 \n",
            "  318. \"data:0.314\"  0.076492 \n",
            "  319. \"data:0.709\"  0.076489 \n",
            "  320. \"data:0.498\"  0.076488 \n",
            "  321. \"data:0.710\"  0.076486 \n",
            "  322. \"data:0.525\"  0.076485 \n",
            "  323. \"data:0.565\"  0.076480 \n",
            "  324. \"data:0.275\"  0.076475 \n",
            "  325. \"data:0.687\"  0.076472 \n",
            "  326. \"data:0.231\"  0.076471 \n",
            "  327. \"data:0.160\"  0.076470 \n",
            "  328. \"data:0.397\"  0.076469 \n",
            "  329. \"data:0.581\"  0.076469 \n",
            "  330. \"data:0.663\"  0.076468 \n",
            "  331. \"data:0.635\"  0.076467 \n",
            "  332. \"data:0.359\"  0.076463 \n",
            "  333. \"data:0.102\"  0.076455 \n",
            "  334. \"data:0.622\"  0.076453 \n",
            "  335. \"data:0.132\"  0.076451 \n",
            "  336. \"data:0.161\"  0.076445 \n",
            "  337. \"data:0.191\"  0.076443 \n",
            "  338. \"data:0.593\"  0.076442 \n",
            "  339. \"data:0.387\"  0.076441 \n",
            "  340. \"data:0.303\"  0.076439 \n",
            "  341. \"data:0.662\"  0.076438 \n",
            "  342. \"data:0.708\"  0.076436 \n",
            "  343. \"data:0.712\"  0.076435 \n",
            "  344. \"data:0.442\"  0.076432 \n",
            "  345. \"data:0.103\"  0.076427 \n",
            "  346. \"data:0.220\"  0.076427 \n",
            "  347. \"data:0.711\"  0.076426 \n",
            "  348. \"data:0.232\"  0.076426 \n",
            "  349. \"data:0.203\"  0.076420 \n",
            "  350. \"data:0.582\"  0.076415 \n",
            "  351. \"data:0.707\"  0.076415 \n",
            "  352. \"data:0.425\"  0.076414 \n",
            "  353. \"data:0.131\"  0.076409 \n",
            "  354. \"data:0.162\"  0.076409 \n",
            "  355. \"data:0.680\"  0.076408 \n",
            "  356.  \"data:0.70\"  0.076405 \n",
            "  357. \"data:0.499\"  0.076405 \n",
            "  358.  \"data:0.69\"  0.076404 \n",
            "  359. \"data:0.121\"  0.076404 \n",
            "  360. \"data:0.147\"  0.076403 \n",
            "  361.  \"data:0.68\"  0.076403 \n",
            "  362. \"data:0.341\"  0.076402 \n",
            "  363. \"data:0.527\"  0.076401 \n",
            "  364. \"data:0.688\"  0.076400 \n",
            "  365. \"data:0.415\"  0.076399 \n",
            "  366. \"data:0.369\"  0.076397 \n",
            "  367. \"data:0.331\"  0.076396 \n",
            "  368. \"data:0.740\"  0.076396 \n",
            "  369. \"data:0.286\"  0.076395 \n",
            "  370. \"data:0.443\"  0.076391 \n",
            "  371. \"data:0.148\"  0.076389 \n",
            "  372. \"data:0.192\"  0.076389 \n",
            "  373. \"data:0.716\"  0.076387 \n",
            "  374. \"data:0.481\"  0.076386 \n",
            "  375. \"data:0.713\"  0.076385 \n",
            "  376. \"data:0.258\"  0.076383 \n",
            "  377.  \"data:0.96\"  0.076382 \n",
            "  378. \"data:0.471\"  0.076381 \n",
            "  379. \"data:0.259\"  0.076379 \n",
            "  380.  \"data:0.95\"  0.076376 \n",
            "  381. \"data:0.276\"  0.076373 \n",
            "  382. \"data:0.583\"  0.076373 \n",
            "  383. \"data:0.555\"  0.076372 \n",
            "  384. \"data:0.175\"  0.076370 \n",
            "  385. \"data:0.689\"  0.076369 \n",
            "  386. \"data:0.163\"  0.076368 \n",
            "  387. \"data:0.650\"  0.076366 \n",
            "  388. \"data:0.636\"  0.076365 \n",
            "  389. \"data:0.202\"  0.076363 \n",
            "  390. \"data:0.536\"  0.076363 \n",
            "  391. \"data:0.313\"  0.076363 \n",
            "  392. \"data:0.230\"  0.076360 \n",
            "  393. \"data:0.664\"  0.076358 \n",
            "  394. \"data:0.717\"  0.076358 \n",
            "  395. \"data:0.500\"  0.076358 \n",
            "  396. \"data:0.678\"  0.076358 \n",
            "  397.  \"data:0.94\"  0.076358 \n",
            "  398. \"data:0.610\"  0.076356 \n",
            "  399. \"data:0.637\"  0.076356 \n",
            "  400. \"data:0.304\"  0.076356 \n",
            "  401. \"data:0.104\"  0.076354 \n",
            "  402. \"data:0.690\"  0.076353 \n",
            "  403. \"data:0.473\"  0.076353 \n",
            "  404.  \"data:0.67\"  0.076352 \n",
            "  405. \"data:0.691\"  0.076352 \n",
            "  406. \"data:0.133\"  0.076351 \n",
            "  407. \"data:0.416\"  0.076351 \n",
            "  408. \"data:0.257\"  0.076350 \n",
            "  409. \"data:0.592\"  0.076349 \n",
            "  410. \"data:0.611\"  0.076346 \n",
            "  411. \"data:0.285\"  0.076346 \n",
            "  412. \"data:0.174\"  0.076346 \n",
            "  413. \"data:0.649\"  0.076345 \n",
            "  414. \"data:0.472\"  0.076344 \n",
            "  415. \"data:0.556\"  0.076343 \n",
            "  416. \"data:0.135\"  0.076343 \n",
            "  417. \"data:0.229\"  0.076343 \n",
            "  418. \"data:0.564\"  0.076342 \n",
            "  419.  \"data:0.93\"  0.076342 \n",
            "  420. \"data:0.508\"  0.076341 \n",
            "  421. \"data:0.715\"  0.076341 \n",
            "  422. \"data:0.621\"  0.076340 \n",
            "  423. \"data:0.480\"  0.076340 \n",
            "  424. \"data:0.744\"  0.076339 \n",
            "  425. \"data:0.528\"  0.076339 \n",
            "  426.  \"data:0.92\"  0.076339 \n",
            "  427. \"data:0.719\"  0.076339 \n",
            "  428. \"data:0.360\"  0.076338 \n",
            "  429. \"data:0.692\"  0.076338 \n",
            "  430. \"data:0.284\"  0.076337 \n",
            "  431. \"data:0.164\"  0.076337 \n",
            "  432. \"data:0.737\"  0.076336 \n",
            "  433. \"data:0.444\"  0.076336 \n",
            "  434. \"data:0.105\"  0.076336 \n",
            "  435. \"data:0.249\"  0.076336 \n",
            "  436. \"data:0.718\"  0.076336 \n",
            "  437. \"data:0.396\"  0.076336 \n",
            "  438. \"data:0.340\"  0.076335 \n",
            "  439. \"data:0.665\"  0.076335 \n",
            "  440. \"data:0.739\"  0.076335 \n",
            "  441. \"data:0.201\"  0.076334 \n",
            "  442.  \"data:0.71\"  0.076334 \n",
            "  443. \"data:0.134\"  0.076334 \n",
            "  444. \"data:0.638\"  0.076333 \n",
            "  445. \"data:0.388\"  0.076333 \n",
            "  446. \"data:0.738\"  0.076333 \n",
            "  447. \"data:0.745\"  0.076333 \n",
            "  448. \"data:0.743\"  0.076333 \n",
            "  449. \"data:0.677\"  0.076333 \n",
            "  450. \"data:0.120\"  0.076333 \n",
            "  451. \"data:0.173\"  0.076333 \n",
            "  452. \"data:0.563\"  0.076333 \n",
            "  453.  \"data:0.66\"  0.076333 \n",
            "  454. \"data:0.146\"  0.076333 \n",
            "  455. \"data:0.277\"  0.076333 \n",
            "  456. \"data:0.620\"  0.076332 \n",
            "  457. \"data:0.312\"  0.076332 \n",
            "  458. \"data:0.452\"  0.076332 \n",
            "  459. \"data:0.501\"  0.076332 \n",
            "  460. \"data:0.720\"  0.076332 \n",
            "  461.  \"data:0.72\"  0.076332 \n",
            "  462. \"data:0.706\"  0.076332 \n",
            "  463.  \"data:0.73\"  0.076331 \n",
            "  464. \"data:0.694\"  0.076331 \n",
            "  465. \"data:0.332\"  0.076331 \n",
            "  466. \"data:0.639\"  0.076331 \n",
            "  467. \"data:0.445\"  0.076331 \n",
            "  468. \"data:0.368\"  0.076331 \n",
            "  469. \"data:0.529\"  0.076331 \n",
            "  470. \"data:0.256\"  0.076331 \n",
            "  471. \"data:0.474\"  0.076331 \n",
            "  472. \"data:0.119\"  0.076330 \n",
            "  473. \"data:0.424\"  0.076330 \n",
            "  474. \"data:0.705\"  0.076330 \n",
            "  475. \"data:0.748\"  0.076330 \n",
            "  476.  \"data:0.65\"  0.076330 \n",
            "  477. \"data:0.612\"  0.076329 \n",
            "  478. \"data:0.693\"  0.076329 \n",
            "  479. \"data:0.704\"  0.076329 \n",
            "  480. \"data:0.106\"  0.076329 \n",
            "  481. \"data:0.228\"  0.076329 \n",
            "  482. \"data:0.742\"  0.076329 \n",
            "  483. \"data:0.640\"  0.076329 \n",
            "  484. \"data:0.193\"  0.076329 \n",
            "  485. \"data:0.145\"  0.076329 \n",
            "  486. \"data:0.200\"  0.076329 \n",
            "  487. \"data:0.747\"  0.076329 \n",
            "  488. \"data:0.311\"  0.076329 \n",
            "  489. \"data:0.535\"  0.076329 \n",
            "  490. \"data:0.648\"  0.076329 \n",
            "  491. \"data:0.507\"  0.076329 \n",
            "  492. \"data:0.118\"  0.076328 \n",
            "  493.  \"data:0.76\"  0.076328 \n",
            "  494. \"data:0.305\"  0.076328 \n",
            "  495. \"data:0.668\"  0.076328 \n",
            "  496. \"data:0.221\"  0.076328 \n",
            "  497. \"data:0.278\"  0.076328 \n",
            "  498. \"data:0.666\"  0.076328 \n",
            "  499. \"data:0.647\"  0.076328 \n",
            "  500. \"data:0.172\"  0.076328 \n",
            "  501. \"data:0.721\"  0.076328 \n",
            "  502. \"data:0.733\"  0.076328 \n",
            "  503. \"data:0.741\"  0.076328 \n",
            "  504. \"data:0.562\"  0.076328 \n",
            "  505. \"data:0.389\"  0.076328 \n",
            "  506. \"data:0.722\"  0.076328 \n",
            "  507. \"data:0.107\"  0.076328 \n",
            "  508. \"data:0.584\"  0.076328 \n",
            "  509.  \"data:0.90\"  0.076328 \n",
            "  510.  \"data:0.91\"  0.076328 \n",
            "  511.  \"data:0.74\"  0.076328 \n",
            "  512. \"data:0.136\"  0.076327 \n",
            "  513. \"data:0.417\"  0.076327 \n",
            "  514. \"data:0.619\"  0.076327 \n",
            "  515. \"data:0.746\"  0.076327 \n",
            "  516. \"data:0.255\"  0.076327 \n",
            "  517. \"data:0.735\"  0.076327 \n",
            "  518. \"data:0.557\"  0.076327 \n",
            "  519. \"data:0.479\"  0.076327 \n",
            "  520.  \"data:0.64\"  0.076327 \n",
            "  521. \"data:0.736\"  0.076327 \n",
            "  522. \"data:0.194\"  0.076327 \n",
            "  523. \"data:0.451\"  0.076327 \n",
            "  524. \"data:0.734\"  0.076327 \n",
            "  525. \"data:0.732\"  0.076327 \n",
            "  526. \"data:0.199\"  0.076327 \n",
            "  527. \"data:0.676\"  0.076327 \n",
            "  528. \"data:0.367\"  0.076327 \n",
            "  529. \"data:0.772\"  0.076327 \n",
            "  530. \"data:0.770\"  0.076327 \n",
            "  531. \"data:0.108\"  0.076327 \n",
            "  532. \"data:0.667\"  0.076327 \n",
            "  533. \"data:0.591\"  0.076327 \n",
            "  534. \"data:0.585\"  0.076327 \n",
            "  535. \"data:0.165\"  0.076327 \n",
            "  536. \"data:0.333\"  0.076327 \n",
            "  537.  \"data:0.89\"  0.076327 \n",
            "  538. \"data:0.339\"  0.076327 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"data:0.378\"  5.000000 ################\n",
            "    2. \"data:0.569\"  5.000000 ################\n",
            "    3. \"data:0.568\"  4.000000 ############\n",
            "    4. \"data:0.155\"  3.000000 ########\n",
            "    5. \"data:0.345\"  3.000000 ########\n",
            "    6. \"data:0.350\"  3.000000 ########\n",
            "    7. \"data:0.290\"  2.000000 ####\n",
            "    8. \"data:0.377\"  2.000000 ####\n",
            "    9. \"data:0.428\"  2.000000 ####\n",
            "   10. \"data:0.515\"  2.000000 ####\n",
            "   11. \"data:0.153\"  1.000000 \n",
            "   12. \"data:0.154\"  1.000000 \n",
            "   13. \"data:0.291\"  1.000000 \n",
            "   14. \"data:0.317\"  1.000000 \n",
            "   15. \"data:0.318\"  1.000000 \n",
            "   16. \"data:0.346\"  1.000000 \n",
            "   17. \"data:0.401\"  1.000000 \n",
            "   18. \"data:0.406\"  1.000000 \n",
            "   19. \"data:0.409\"  1.000000 \n",
            "   20. \"data:0.433\"  1.000000 \n",
            "   21. \"data:0.461\"  1.000000 \n",
            "   22. \"data:0.462\"  1.000000 \n",
            "   23. \"data:0.484\"  1.000000 \n",
            "   24. \"data:0.489\"  1.000000 \n",
            "   25. \"data:0.539\"  1.000000 \n",
            "   26. \"data:0.540\"  1.000000 \n",
            "   27. \"data:0.551\"  1.000000 \n",
            "   28. \"data:0.596\"  1.000000 \n",
            "   29. \"data:0.625\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"data:0.211\" 658.000000 ################\n",
            "    2. \"data:0.321\" 651.000000 ###############\n",
            "    3. \"data:0.296\" 631.000000 ###############\n",
            "    4. \"data:0.324\" 625.000000 ###############\n",
            "    5. \"data:0.266\" 623.000000 ###############\n",
            "    6. \"data:0.294\" 621.000000 ###############\n",
            "    7. \"data:0.267\" 615.000000 ##############\n",
            "    8. \"data:0.295\" 615.000000 ##############\n",
            "    9. \"data:0.210\" 614.000000 ##############\n",
            "   10. \"data:0.515\" 614.000000 ##############\n",
            "   11. \"data:0.378\" 610.000000 ##############\n",
            "   12. \"data:0.212\" 609.000000 ##############\n",
            "   13. \"data:0.319\" 609.000000 ##############\n",
            "   14. \"data:0.486\" 609.000000 ##############\n",
            "   15. \"data:0.322\" 607.000000 ##############\n",
            "   16. \"data:0.320\" 602.000000 ##############\n",
            "   17. \"data:0.351\" 598.000000 ##############\n",
            "   18. \"data:0.268\" 596.000000 ##############\n",
            "   19. \"data:0.269\" 596.000000 ##############\n",
            "   20. \"data:0.323\" 594.000000 ##############\n",
            "   21. \"data:0.405\" 594.000000 ##############\n",
            "   22. \"data:0.293\" 590.000000 ##############\n",
            "   23. \"data:0.543\" 588.000000 ##############\n",
            "   24. \"data:0.239\" 587.000000 ##############\n",
            "   25. \"data:0.487\" 587.000000 ##############\n",
            "   26. \"data:0.238\" 583.000000 ##############\n",
            "   27. \"data:0.347\" 581.000000 ##############\n",
            "   28. \"data:0.352\" 580.000000 ##############\n",
            "   29. \"data:0.240\" 576.000000 ##############\n",
            "   30. \"data:0.325\" 576.000000 ##############\n",
            "   31. \"data:0.297\" 574.000000 #############\n",
            "   32. \"data:0.292\" 571.000000 #############\n",
            "   33. \"data:0.376\" 571.000000 #############\n",
            "   34. \"data:0.377\" 571.000000 #############\n",
            "   35. \"data:0.350\" 570.000000 #############\n",
            "   36. \"data:0.514\" 565.000000 #############\n",
            "   37. \"data:0.380\" 557.000000 #############\n",
            "   38. \"data:0.348\" 555.000000 #############\n",
            "   39. \"data:0.375\" 555.000000 #############\n",
            "   40. \"data:0.326\" 554.000000 #############\n",
            "   41. \"data:0.460\" 554.000000 #############\n",
            "   42. \"data:0.353\" 545.000000 #############\n",
            "   43. \"data:0.488\" 543.000000 #############\n",
            "   44. \"data:0.409\" 542.000000 #############\n",
            "   45. \"data:0.432\" 541.000000 #############\n",
            "   46. \"data:0.544\" 541.000000 #############\n",
            "   47. \"data:0.490\" 540.000000 #############\n",
            "   48. \"data:0.209\" 536.000000 #############\n",
            "   49. \"data:0.461\" 533.000000 ############\n",
            "   50. \"data:0.241\" 531.000000 ############\n",
            "   51. \"data:0.434\" 531.000000 ############\n",
            "   52. \"data:0.346\" 530.000000 ############\n",
            "   53. \"data:0.291\" 529.000000 ############\n",
            "   54. \"data:0.457\" 527.000000 ############\n",
            "   55. \"data:0.459\" 526.000000 ############\n",
            "   56. \"data:0.349\" 521.000000 ############\n",
            "   57. \"data:0.458\" 521.000000 ############\n",
            "   58. \"data:0.265\" 519.000000 ############\n",
            "   59. \"data:0.298\" 517.000000 ############\n",
            "   60. \"data:0.406\" 515.000000 ############\n",
            "   61. \"data:0.408\" 515.000000 ############\n",
            "   62. \"data:0.462\" 513.000000 ############\n",
            "   63. \"data:0.516\" 511.000000 ############\n",
            "   64. \"data:0.433\" 509.000000 ############\n",
            "   65. \"data:0.463\" 508.000000 ############\n",
            "   66. \"data:0.403\" 505.000000 ############\n",
            "   67. \"data:0.437\" 505.000000 ############\n",
            "   68. \"data:0.183\" 504.000000 ############\n",
            "   69. \"data:0.213\" 504.000000 ############\n",
            "   70. \"data:0.485\" 504.000000 ############\n",
            "   71. \"data:0.489\" 504.000000 ############\n",
            "   72. \"data:0.379\" 502.000000 ############\n",
            "   73. \"data:0.407\" 502.000000 ############\n",
            "   74. \"data:0.517\" 501.000000 ############\n",
            "   75. \"data:0.381\" 499.000000 ############\n",
            "   76. \"data:0.237\" 498.000000 ############\n",
            "   77. \"data:0.354\" 497.000000 ############\n",
            "   78. \"data:0.518\" 494.000000 ############\n",
            "   79. \"data:0.374\" 492.000000 ###########\n",
            "   80. \"data:0.464\" 492.000000 ###########\n",
            "   81. \"data:0.435\" 489.000000 ###########\n",
            "   82. \"data:0.572\" 486.000000 ###########\n",
            "   83. \"data:0.436\" 485.000000 ###########\n",
            "   84. \"data:0.184\" 484.000000 ###########\n",
            "   85. \"data:0.318\" 480.000000 ###########\n",
            "   86. \"data:0.491\" 478.000000 ###########\n",
            "   87. \"data:0.290\" 475.000000 ###########\n",
            "   88. \"data:0.404\" 475.000000 ###########\n",
            "   89. \"data:0.270\" 473.000000 ###########\n",
            "   90. \"data:0.573\" 473.000000 ###########\n",
            "   91. \"data:0.657\" 471.000000 ###########\n",
            "   92. \"data:0.431\" 470.000000 ###########\n",
            "   93. \"data:0.264\" 467.000000 ###########\n",
            "   94. \"data:0.430\" 464.000000 ###########\n",
            "   95. \"data:0.571\" 462.000000 ###########\n",
            "   96. \"data:0.545\" 461.000000 ###########\n",
            "   97. \"data:0.345\" 459.000000 ###########\n",
            "   98. \"data:0.542\" 459.000000 ###########\n",
            "   99. \"data:0.182\" 457.000000 ###########\n",
            "  100. \"data:0.208\" 456.000000 ###########\n",
            "  101. \"data:0.299\" 455.000000 ###########\n",
            "  102. \"data:0.574\" 454.000000 ###########\n",
            "  103. \"data:0.214\" 453.000000 ###########\n",
            "  104. \"data:0.656\" 453.000000 ###########\n",
            "  105. \"data:0.263\" 452.000000 ##########\n",
            "  106. \"data:0.465\" 450.000000 ##########\n",
            "  107. \"data:0.236\" 449.000000 ##########\n",
            "  108. \"data:0.382\" 448.000000 ##########\n",
            "  109. \"data:0.242\" 446.000000 ##########\n",
            "  110. \"data:0.492\" 446.000000 ##########\n",
            "  111. \"data:0.401\" 444.000000 ##########\n",
            "  112. \"data:0.402\" 444.000000 ##########\n",
            "  113. \"data:0.429\" 438.000000 ##########\n",
            "  114. \"data:0.513\" 432.000000 ##########\n",
            "  115. \"data:0.185\" 429.000000 ##########\n",
            "  116. \"data:0.373\" 429.000000 ##########\n",
            "  117. \"data:0.235\" 428.000000 ##########\n",
            "  118. \"data:0.271\" 427.000000 ##########\n",
            "  119. \"data:0.546\" 423.000000 ##########\n",
            "  120. \"data:0.154\" 422.000000 ##########\n",
            "  121. \"data:0.456\" 421.000000 ##########\n",
            "  122. \"data:0.289\" 417.000000 ##########\n",
            "  123. \"data:0.438\" 416.000000 ##########\n",
            "  124. \"data:0.410\" 415.000000 ##########\n",
            "  125. \"data:0.655\" 412.000000 ##########\n",
            "  126. \"data:0.317\" 411.000000 #########\n",
            "  127. \"data:0.155\" 408.000000 #########\n",
            "  128. \"data:0.428\" 408.000000 #########\n",
            "  129. \"data:0.658\" 408.000000 #########\n",
            "  130. \"data:0.601\" 406.000000 #########\n",
            "  131. \"data:0.181\" 405.000000 #########\n",
            "  132. \"data:0.519\" 403.000000 #########\n",
            "  133. \"data:0.262\" 401.000000 #########\n",
            "  134. \"data:0.156\" 398.000000 #########\n",
            "  135. \"data:0.600\" 397.000000 #########\n",
            "  136. \"data:0.599\" 391.000000 #########\n",
            "  137. \"data:0.355\" 389.000000 #########\n",
            "  138. \"data:0.541\" 387.000000 #########\n",
            "  139. \"data:0.180\" 384.000000 #########\n",
            "  140. \"data:0.602\" 383.000000 #########\n",
            "  141. \"data:0.243\" 381.000000 #########\n",
            "  142. \"data:0.327\" 381.000000 #########\n",
            "  143. \"data:0.207\" 376.000000 #########\n",
            "  144. \"data:0.466\" 376.000000 #########\n",
            "  145. \"data:0.153\" 373.000000 #########\n",
            "  146. \"data:0.484\" 373.000000 #########\n",
            "  147. \"data:0.575\" 371.000000 #########\n",
            "  148. \"data:0.629\" 371.000000 #########\n",
            "  149. \"data:0.630\" 363.000000 ########\n",
            "  150. \"data:0.344\" 360.000000 ########\n",
            "  151. \"data:0.547\" 360.000000 ########\n",
            "  152. \"data:0.179\" 357.000000 ########\n",
            "  153. \"data:0.548\" 356.000000 ########\n",
            "  154. \"data:0.520\" 355.000000 ########\n",
            "  155. \"data:0.627\" 353.000000 ########\n",
            "  156. \"data:0.570\" 351.000000 ########\n",
            "  157. \"data:0.467\" 350.000000 ########\n",
            "  158. \"data:0.186\" 348.000000 ########\n",
            "  159. \"data:0.439\" 347.000000 ########\n",
            "  160. \"data:0.549\" 346.000000 ########\n",
            "  161. \"data:0.569\" 346.000000 ########\n",
            "  162. \"data:0.603\" 346.000000 ########\n",
            "  163. \"data:0.493\" 345.000000 ########\n",
            "  164. \"data:0.234\" 343.000000 ########\n",
            "  165. \"data:0.215\" 342.000000 ########\n",
            "  166. \"data:0.576\" 342.000000 ########\n",
            "  167. \"data:0.400\" 341.000000 ########\n",
            "  168. \"data:0.628\" 341.000000 ########\n",
            "  169. \"data:0.577\" 339.000000 ########\n",
            "  170. \"data:0.152\" 337.000000 ########\n",
            "  171. \"data:0.157\" 332.000000 ########\n",
            "  172. \"data:0.372\" 328.000000 #######\n",
            "  173. \"data:0.411\" 326.000000 #######\n",
            "  174. \"data:0.631\" 325.000000 #######\n",
            "  175. \"data:0.654\" 323.000000 #######\n",
            "  176. \"data:0.604\" 319.000000 #######\n",
            "  177. \"data:0.512\" 314.000000 #######\n",
            "  178. \"data:0.598\" 313.000000 #######\n",
            "  179. \"data:0.383\" 312.000000 #######\n",
            "  180. \"data:0.300\" 311.000000 #######\n",
            "  181. \"data:0.550\" 310.000000 #######\n",
            "  182. \"data:0.206\" 309.000000 #######\n",
            "  183. \"data:0.626\" 309.000000 #######\n",
            "  184. \"data:0.272\" 307.000000 #######\n",
            "  185. \"data:0.659\" 307.000000 #######\n",
            "  186. \"data:0.522\" 306.000000 #######\n",
            "  187. \"data:0.244\" 305.000000 #######\n",
            "  188. \"data:0.521\" 304.000000 #######\n",
            "  189. \"data:0.261\" 303.000000 #######\n",
            "  190. \"data:0.625\" 302.000000 #######\n",
            "  191. \"data:0.356\" 296.000000 #######\n",
            "  192. \"data:0.632\" 291.000000 #######\n",
            "  193. \"data:0.494\" 289.000000 #######\n",
            "  194. \"data:0.328\" 288.000000 ######\n",
            "  195. \"data:0.316\" 286.000000 ######\n",
            "  196. \"data:0.187\" 280.000000 ######\n",
            "  197. \"data:0.216\" 278.000000 ######\n",
            "  198. \"data:0.288\" 272.000000 ######\n",
            "  199. \"data:0.605\" 270.000000 ######\n",
            "  200. \"data:0.455\" 268.000000 ######\n",
            "  201. \"data:0.427\" 267.000000 ######\n",
            "  202. \"data:0.233\" 266.000000 ######\n",
            "  203. \"data:0.483\" 266.000000 ######\n",
            "  204. \"data:0.578\" 266.000000 ######\n",
            "  205. \"data:0.158\" 265.000000 ######\n",
            "  206. \"data:0.399\" 265.000000 ######\n",
            "  207. \"data:0.495\" 265.000000 ######\n",
            "  208. \"data:0.151\" 260.000000 ######\n",
            "  209. \"data:0.371\" 259.000000 ######\n",
            "  210. \"data:0.568\" 257.000000 ######\n",
            "  211. \"data:0.540\" 256.000000 ######\n",
            "  212. \"data:0.178\" 255.000000 ######\n",
            "  213. \"data:0.653\" 255.000000 ######\n",
            "  214. \"data:0.523\" 252.000000 ######\n",
            "  215. \"data:0.596\" 248.000000 ######\n",
            "  216. \"data:0.597\" 246.000000 #####\n",
            "  217. \"data:0.567\" 245.000000 #####\n",
            "  218. \"data:0.606\" 244.000000 #####\n",
            "  219. \"data:0.539\" 243.000000 #####\n",
            "  220. \"data:0.660\" 239.000000 #####\n",
            "  221. \"data:0.315\" 237.000000 #####\n",
            "  222. \"data:0.384\" 233.000000 #####\n",
            "  223. \"data:0.260\" 231.000000 #####\n",
            "  224. \"data:0.343\" 231.000000 #####\n",
            "  225. \"data:0.511\" 230.000000 #####\n",
            "  226. \"data:0.440\" 229.000000 #####\n",
            "  227. \"data:0.245\" 226.000000 #####\n",
            "  228. \"data:0.468\" 224.000000 #####\n",
            "  229. \"data:0.579\" 223.000000 #####\n",
            "  230. \"data:0.301\" 220.000000 #####\n",
            "  231. \"data:0.633\" 220.000000 #####\n",
            "  232. \"data:0.595\" 219.000000 #####\n",
            "  233. \"data:0.188\" 213.000000 #####\n",
            "  234. \"data:0.205\" 213.000000 #####\n",
            "  235. \"data:0.624\" 212.000000 #####\n",
            "  236. \"data:0.159\" 210.000000 #####\n",
            "  237. \"data:0.496\" 207.000000 #####\n",
            "  238. \"data:0.177\" 199.000000 ####\n",
            "  239. \"data:0.329\" 199.000000 ####\n",
            "  240. \"data:0.412\" 199.000000 ####\n",
            "  241. \"data:0.551\" 199.000000 ####\n",
            "  242. \"data:0.217\" 198.000000 ####\n",
            "  243. \"data:0.273\" 197.000000 ####\n",
            "  244. \"data:0.634\" 192.000000 ####\n",
            "  245. \"data:0.128\" 189.000000 ####\n",
            "  246. \"data:0.126\" 188.000000 ####\n",
            "  247. \"data:0.357\" 188.000000 ####\n",
            "  248. \"data:0.524\" 188.000000 ####\n",
            "  249. \"data:0.685\" 185.000000 ####\n",
            "  250. \"data:0.426\" 181.000000 ####\n",
            "  251. \"data:0.510\" 181.000000 ####\n",
            "  252. \"data:0.150\" 179.000000 ####\n",
            "  253. \"data:0.607\" 177.000000 ####\n",
            "  254. \"data:0.125\" 175.000000 ####\n",
            "  255. \"data:0.552\" 173.000000 ####\n",
            "  256. \"data:0.127\" 171.000000 ####\n",
            "  257. \"data:0.683\" 169.000000 ####\n",
            "  258. \"data:0.686\" 165.000000 ###\n",
            "  259. \"data:0.413\" 164.000000 ###\n",
            "  260. \"data:0.232\" 163.000000 ###\n",
            "  261. \"data:0.482\" 163.000000 ###\n",
            "  262. \"data:0.580\" 163.000000 ###\n",
            "  263. \"data:0.189\" 162.000000 ###\n",
            "  264. \"data:0.538\" 162.000000 ###\n",
            "  265. \"data:0.661\" 162.000000 ###\n",
            "  266. \"data:0.684\" 162.000000 ###\n",
            "  267. \"data:0.623\" 161.000000 ###\n",
            "  268. \"data:0.454\" 159.000000 ###\n",
            "  269. \"data:0.204\" 156.000000 ###\n",
            "  270. \"data:0.218\" 155.000000 ###\n",
            "  271. \"data:0.274\" 155.000000 ###\n",
            "  272. \"data:0.385\" 155.000000 ###\n",
            "  273. \"data:0.398\" 154.000000 ###\n",
            "  274. \"data:0.246\" 152.000000 ###\n",
            "  275. \"data:0.608\" 147.000000 ###\n",
            "  276. \"data:0.441\" 146.000000 ###\n",
            "  277. \"data:0.635\" 146.000000 ###\n",
            "  278. \"data:0.129\" 143.000000 ###\n",
            "  279. \"data:0.330\" 143.000000 ###\n",
            "  280. \"data:0.469\" 143.000000 ###\n",
            "  281. \"data:0.553\" 143.000000 ###\n",
            "  282. \"data:0.687\" 142.000000 ###\n",
            "  283. \"data:0.358\" 140.000000 ###\n",
            "  284. \"data:0.497\" 138.000000 ###\n",
            "  285. \"data:0.287\" 137.000000 ###\n",
            "  286. \"data:0.525\" 135.000000 ###\n",
            "  287. \"data:0.124\" 134.000000 ###\n",
            "  288. \"data:0.566\" 134.000000 ###\n",
            "  289. \"data:0.302\" 133.000000 ###\n",
            "  290. \"data:0.652\" 133.000000 ###\n",
            "  291. \"data:0.681\" 132.000000 ###\n",
            "  292. \"data:0.342\" 131.000000 ###\n",
            "  293. \"data:0.594\" 129.000000 ###\n",
            "  294. \"data:0.662\" 129.000000 ###\n",
            "  295. \"data:0.682\" 127.000000 ###\n",
            "  296. \"data:0.149\" 126.000000 ###\n",
            "  297. \"data:0.370\" 125.000000 ###\n",
            "  298. \"data:0.386\" 123.000000 ##\n",
            "  299. \"data:0.130\" 121.000000 ##\n",
            "  300. \"data:0.470\" 120.000000 ##\n",
            "  301. \"data:0.231\" 118.000000 ##\n",
            "  302. \"data:0.160\" 116.000000 ##\n",
            "  303. \"data:0.176\" 115.000000 ##\n",
            "  304. \"data:0.498\" 115.000000 ##\n",
            "  305. \"data:0.581\" 115.000000 ##\n",
            "  306. \"data:0.688\" 113.000000 ##\n",
            "  307. \"data:0.247\" 112.000000 ##\n",
            "  308. \"data:0.414\" 109.000000 ##\n",
            "  309. \"data:0.131\" 108.000000 ##\n",
            "  310. \"data:0.123\" 107.000000 ##\n",
            "  311. \"data:0.554\" 106.000000 ##\n",
            "  312. \"data:0.259\" 105.000000 ##\n",
            "  313. \"data:0.161\" 100.000000 ##\n",
            "  314. \"data:0.190\" 98.000000 ##\n",
            "  315. \"data:0.219\" 98.000000 ##\n",
            "  316. \"data:0.442\" 96.000000 ##\n",
            "  317. \"data:0.680\" 95.000000 ##\n",
            "  318. \"data:0.275\" 92.000000 ##\n",
            "  319. \"data:0.526\" 91.000000 ##\n",
            "  320. \"data:0.286\" 90.000000 ##\n",
            "  321. \"data:0.314\" 90.000000 ##\n",
            "  322. \"data:0.689\" 88.000000 ##\n",
            "  323. \"data:0.537\" 87.000000 ##\n",
            "  324. \"data:0.203\" 86.000000 ##\n",
            "  325. \"data:0.609\" 86.000000 ##\n",
            "  326. \"data:0.651\" 86.000000 ##\n",
            "  327. \"data:0.622\" 85.000000 ##\n",
            "  328. \"data:0.258\" 81.000000 #\n",
            "  329. \"data:0.663\" 79.000000 #\n",
            "  330. \"data:0.679\" 73.000000 #\n",
            "  331. \"data:0.132\" 71.000000 #\n",
            "  332. \"data:0.509\" 71.000000 #\n",
            "  333. \"data:0.101\" 70.000000 #\n",
            "  334. \"data:0.122\" 70.000000 #\n",
            "  335. \"data:0.230\" 69.000000 #\n",
            "  336. \"data:0.636\" 69.000000 #\n",
            "  337. \"data:0.162\" 68.000000 #\n",
            "  338. \"data:0.331\" 68.000000 #\n",
            "  339. \"data:0.443\" 68.000000 #\n",
            "  340. \"data:0.565\" 68.000000 #\n",
            "  341. \"data:0.175\" 67.000000 #\n",
            "  342. \"data:0.425\" 67.000000 #\n",
            "  343. \"data:0.100\" 66.000000 #\n",
            "  344. \"data:0.527\" 64.000000 #\n",
            "  345. \"data:0.709\" 64.000000 #\n",
            "  346. \"data:0.303\" 63.000000 #\n",
            "  347. \"data:0.359\" 63.000000 #\n",
            "  348. \"data:0.415\" 63.000000 #\n",
            "  349. \"data:0.453\" 62.000000 #\n",
            "  350. \"data:0.712\" 62.000000 #\n",
            "  351. \"data:0.248\" 61.000000 #\n",
            "  352. \"data:0.690\" 61.000000 #\n",
            "  353. \"data:0.102\" 59.000000 #\n",
            "  354. \"data:0.191\" 59.000000 #\n",
            "  355. \"data:0.711\" 59.000000 #\n",
            "  356.  \"data:0.99\" 59.000000 #\n",
            "  357. \"data:0.582\" 58.000000 #\n",
            "  358. \"data:0.637\" 58.000000 #\n",
            "  359. \"data:0.710\" 58.000000 #\n",
            "  360. \"data:0.341\" 57.000000 #\n",
            "  361. \"data:0.397\" 57.000000 #\n",
            "  362. \"data:0.387\" 56.000000 #\n",
            "  363. \"data:0.481\" 56.000000 #\n",
            "  364. \"data:0.202\" 54.000000 #\n",
            "  365. \"data:0.148\" 52.000000 #\n",
            "  366.  \"data:0.98\" 52.000000 #\n",
            "  367. \"data:0.220\" 51.000000 #\n",
            "  368. \"data:0.650\" 51.000000 #\n",
            "  369. \"data:0.715\" 51.000000 #\n",
            "  370. \"data:0.471\" 50.000000 #\n",
            "  371. \"data:0.713\" 49.000000 #\n",
            "  372. \"data:0.499\" 47.000000 #\n",
            "  373. \"data:0.593\" 47.000000 #\n",
            "  374. \"data:0.103\" 45.000000 #\n",
            "  375. \"data:0.313\" 44.000000 #\n",
            "  376. \"data:0.716\" 43.000000 #\n",
            "  377. \"data:0.714\" 42.000000 \n",
            "  378. \"data:0.708\" 40.000000 \n",
            "  379. \"data:0.285\" 39.000000 \n",
            "  380. \"data:0.369\" 39.000000 \n",
            "  381. \"data:0.555\" 39.000000 \n",
            "  382. \"data:0.691\" 39.000000 \n",
            "  383. \"data:0.121\" 38.000000 \n",
            "  384. \"data:0.610\" 37.000000 \n",
            "  385.  \"data:0.97\" 37.000000 \n",
            "  386. \"data:0.536\" 35.000000 \n",
            "  387. \"data:0.583\" 35.000000 \n",
            "  388. \"data:0.664\" 34.000000 \n",
            "  389. \"data:0.678\" 33.000000 \n",
            "  390.  \"data:0.96\" 31.000000 \n",
            "  391. \"data:0.133\" 30.000000 \n",
            "  392. \"data:0.717\" 29.000000 \n",
            "  393. \"data:0.257\" 28.000000 \n",
            "  394. \"data:0.276\" 28.000000 \n",
            "  395. \"data:0.707\" 28.000000 \n",
            "  396. \"data:0.621\" 27.000000 \n",
            "  397. \"data:0.649\" 27.000000 \n",
            "  398. \"data:0.147\" 26.000000 \n",
            "  399. \"data:0.163\" 26.000000 \n",
            "  400. \"data:0.564\" 25.000000 \n",
            "  401.  \"data:0.95\" 25.000000 \n",
            "  402. \"data:0.229\" 24.000000 \n",
            "  403. \"data:0.480\" 24.000000 \n",
            "  404. \"data:0.692\" 24.000000 \n",
            "  405. \"data:0.174\" 23.000000 \n",
            "  406. \"data:0.192\" 23.000000 \n",
            "  407. \"data:0.472\" 22.000000 \n",
            "  408. \"data:0.500\" 21.000000 \n",
            "  409. \"data:0.528\" 19.000000 \n",
            "  410. \"data:0.592\" 19.000000 \n",
            "  411. \"data:0.611\" 19.000000 \n",
            "  412. \"data:0.304\" 18.000000 \n",
            "  413. \"data:0.444\" 18.000000 \n",
            "  414. \"data:0.508\" 18.000000 \n",
            "  415. \"data:0.718\" 18.000000 \n",
            "  416. \"data:0.120\" 17.000000 \n",
            "  417. \"data:0.146\" 16.000000 \n",
            "  418. \"data:0.719\" 16.000000 \n",
            "  419. \"data:0.104\" 15.000000 \n",
            "  420. \"data:0.134\" 15.000000 \n",
            "  421. \"data:0.173\" 15.000000 \n",
            "  422. \"data:0.201\" 15.000000 \n",
            "  423. \"data:0.340\" 15.000000 \n",
            "  424. \"data:0.638\" 15.000000 \n",
            "  425. \"data:0.416\" 14.000000 \n",
            "  426. \"data:0.424\" 14.000000 \n",
            "  427. \"data:0.452\" 14.000000 \n",
            "  428.  \"data:0.94\" 14.000000 \n",
            "  429. \"data:0.256\" 13.000000 \n",
            "  430. \"data:0.556\" 13.000000 \n",
            "  431. \"data:0.744\" 13.000000 \n",
            "  432. \"data:0.135\" 12.000000 \n",
            "  433. \"data:0.368\" 12.000000 \n",
            "  434. \"data:0.396\" 12.000000 \n",
            "  435. \"data:0.665\" 12.000000 \n",
            "  436. \"data:0.677\" 12.000000 \n",
            "  437. \"data:0.164\" 11.000000 \n",
            "  438. \"data:0.249\" 11.000000 \n",
            "  439. \"data:0.312\" 10.000000 \n",
            "  440. \"data:0.332\" 10.000000 \n",
            "  441. \"data:0.388\" 10.000000 \n",
            "  442. \"data:0.105\"  9.000000 \n",
            "  443. \"data:0.228\"  9.000000 \n",
            "  444. \"data:0.284\"  9.000000 \n",
            "  445. \"data:0.360\"  9.000000 \n",
            "  446. \"data:0.740\"  9.000000 \n",
            "  447. \"data:0.620\"  8.000000 \n",
            "  448.  \"data:0.69\"  8.000000 \n",
            "  449.  \"data:0.92\"  8.000000 \n",
            "  450. \"data:0.106\"  7.000000 \n",
            "  451. \"data:0.529\"  7.000000 \n",
            "  452. \"data:0.706\"  7.000000 \n",
            "  453. \"data:0.720\"  7.000000 \n",
            "  454. \"data:0.742\"  7.000000 \n",
            "  455.  \"data:0.93\"  7.000000 \n",
            "  456. \"data:0.145\"  6.000000 \n",
            "  457.  \"data:0.67\"  6.000000 \n",
            "  458. \"data:0.693\"  6.000000 \n",
            "  459.  \"data:0.71\"  6.000000 \n",
            "  460. \"data:0.737\"  6.000000 \n",
            "  461. \"data:0.741\"  6.000000 \n",
            "  462. \"data:0.743\"  6.000000 \n",
            "  463. \"data:0.648\"  5.000000 \n",
            "  464.  \"data:0.68\"  5.000000 \n",
            "  465.  \"data:0.72\"  5.000000 \n",
            "  466. \"data:0.739\"  5.000000 \n",
            "  467. \"data:0.193\"  4.000000 \n",
            "  468. \"data:0.200\"  4.000000 \n",
            "  469. \"data:0.694\"  4.000000 \n",
            "  470.  \"data:0.70\"  4.000000 \n",
            "  471. \"data:0.705\"  4.000000 \n",
            "  472. \"data:0.119\"  3.000000 \n",
            "  473. \"data:0.255\"  3.000000 \n",
            "  474. \"data:0.277\"  3.000000 \n",
            "  475. \"data:0.305\"  3.000000 \n",
            "  476. \"data:0.311\"  3.000000 \n",
            "  477. \"data:0.445\"  3.000000 \n",
            "  478. \"data:0.501\"  3.000000 \n",
            "  479. \"data:0.584\"  3.000000 \n",
            "  480. \"data:0.612\"  3.000000 \n",
            "  481. \"data:0.639\"  3.000000 \n",
            "  482. \"data:0.666\"  3.000000 \n",
            "  483. \"data:0.738\"  3.000000 \n",
            "  484. \"data:0.745\"  3.000000 \n",
            "  485. \"data:0.746\"  3.000000 \n",
            "  486. \"data:0.118\"  2.000000 \n",
            "  487. \"data:0.136\"  2.000000 \n",
            "  488. \"data:0.172\"  2.000000 \n",
            "  489. \"data:0.221\"  2.000000 \n",
            "  490. \"data:0.389\"  2.000000 \n",
            "  491. \"data:0.417\"  2.000000 \n",
            "  492. \"data:0.451\"  2.000000 \n",
            "  493. \"data:0.473\"  2.000000 \n",
            "  494. \"data:0.507\"  2.000000 \n",
            "  495. \"data:0.563\"  2.000000 \n",
            "  496. \"data:0.619\"  2.000000 \n",
            "  497. \"data:0.640\"  2.000000 \n",
            "  498.  \"data:0.65\"  2.000000 \n",
            "  499.  \"data:0.66\"  2.000000 \n",
            "  500. \"data:0.704\"  2.000000 \n",
            "  501. \"data:0.721\"  2.000000 \n",
            "  502. \"data:0.722\"  2.000000 \n",
            "  503.  \"data:0.73\"  2.000000 \n",
            "  504. \"data:0.732\"  2.000000 \n",
            "  505. \"data:0.733\"  2.000000 \n",
            "  506. \"data:0.734\"  2.000000 \n",
            "  507. \"data:0.748\"  2.000000 \n",
            "  508.  \"data:0.91\"  2.000000 \n",
            "  509. \"data:0.107\"  1.000000 \n",
            "  510. \"data:0.108\"  1.000000 \n",
            "  511. \"data:0.165\"  1.000000 \n",
            "  512. \"data:0.194\"  1.000000 \n",
            "  513. \"data:0.199\"  1.000000 \n",
            "  514. \"data:0.278\"  1.000000 \n",
            "  515. \"data:0.333\"  1.000000 \n",
            "  516. \"data:0.339\"  1.000000 \n",
            "  517. \"data:0.367\"  1.000000 \n",
            "  518. \"data:0.474\"  1.000000 \n",
            "  519. \"data:0.479\"  1.000000 \n",
            "  520. \"data:0.535\"  1.000000 \n",
            "  521. \"data:0.557\"  1.000000 \n",
            "  522. \"data:0.562\"  1.000000 \n",
            "  523. \"data:0.585\"  1.000000 \n",
            "  524. \"data:0.591\"  1.000000 \n",
            "  525.  \"data:0.64\"  1.000000 \n",
            "  526. \"data:0.647\"  1.000000 \n",
            "  527. \"data:0.667\"  1.000000 \n",
            "  528. \"data:0.668\"  1.000000 \n",
            "  529. \"data:0.676\"  1.000000 \n",
            "  530. \"data:0.735\"  1.000000 \n",
            "  531. \"data:0.736\"  1.000000 \n",
            "  532.  \"data:0.74\"  1.000000 \n",
            "  533. \"data:0.747\"  1.000000 \n",
            "  534.  \"data:0.76\"  1.000000 \n",
            "  535. \"data:0.770\"  1.000000 \n",
            "  536. \"data:0.772\"  1.000000 \n",
            "  537.  \"data:0.89\"  1.000000 \n",
            "  538.  \"data:0.90\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1. \"data:0.378\" 127863.424975 ################\n",
            "    2. \"data:0.569\" 101800.097179 ############\n",
            "    3. \"data:0.568\" 92565.809838 ###########\n",
            "    4. \"data:0.155\" 85859.193055 ##########\n",
            "    5. \"data:0.345\" 85596.885605 ##########\n",
            "    6. \"data:0.406\" 82531.871914 ##########\n",
            "    7. \"data:0.515\" 81421.485706 ##########\n",
            "    8. \"data:0.461\" 76558.462504 #########\n",
            "    9. \"data:0.377\" 72088.236816 #########\n",
            "   10. \"data:0.350\" 70680.781442 ########\n",
            "   11. \"data:0.291\" 63460.985676 #######\n",
            "   12. \"data:0.409\" 61186.629508 #######\n",
            "   13. \"data:0.428\" 60685.311302 #######\n",
            "   14. \"data:0.487\" 59903.811512 #######\n",
            "   15. \"data:0.489\" 58004.310525 #######\n",
            "   16. \"data:0.154\" 56252.804571 #######\n",
            "   17. \"data:0.460\" 56146.484397 #######\n",
            "   18. \"data:0.290\" 54691.184965 ######\n",
            "   19. \"data:0.375\" 53918.281193 ######\n",
            "   20. \"data:0.462\" 50854.201688 ######\n",
            "   21. \"data:0.405\" 49542.330162 ######\n",
            "   22. \"data:0.514\" 48060.672891 ######\n",
            "   23. \"data:0.211\" 46439.995099 #####\n",
            "   24. \"data:0.433\" 46333.253242 #####\n",
            "   25. \"data:0.401\" 45052.462886 #####\n",
            "   26. \"data:0.346\" 44763.587312 #####\n",
            "   27. \"data:0.542\" 44141.151895 #####\n",
            "   28. \"data:0.347\" 43978.996662 #####\n",
            "   29. \"data:0.657\" 42331.731661 #####\n",
            "   30. \"data:0.625\" 42193.733311 #####\n",
            "   31. \"data:0.656\" 40981.246465 #####\n",
            "   32. \"data:0.408\" 40852.686219 #####\n",
            "   33. \"data:0.596\" 40748.706833 #####\n",
            "   34. \"data:0.543\" 40508.602926 #####\n",
            "   35. \"data:0.153\" 39419.054773 ####\n",
            "   36. \"data:0.318\" 39082.145698 ####\n",
            "   37. \"data:0.488\" 38839.779758 ####\n",
            "   38. \"data:0.655\" 38020.188437 ####\n",
            "   39. \"data:0.539\" 36999.140629 ####\n",
            "   40. \"data:0.210\" 36886.198061 ####\n",
            "   41. \"data:0.490\" 36653.899232 ####\n",
            "   42. \"data:0.263\" 36189.937580 ####\n",
            "   43. \"data:0.457\" 35818.281060 ####\n",
            "   44. \"data:0.458\" 35710.140921 ####\n",
            "   45. \"data:0.403\" 35570.781374 ####\n",
            "   46. \"data:0.429\" 35478.984042 ####\n",
            "   47. \"data:0.374\" 35267.819900 ####\n",
            "   48. \"data:0.658\" 34985.853325 ####\n",
            "   49. \"data:0.570\" 34955.581746 ####\n",
            "   50. \"data:0.351\" 34276.660799 ####\n",
            "   51. \"data:0.156\" 34003.722302 ####\n",
            "   52. \"data:0.348\" 33918.367896 ####\n",
            "   53. \"data:0.456\" 33848.293415 ####\n",
            "   54. \"data:0.376\" 33847.294318 ####\n",
            "   55. \"data:0.326\" 33765.908866 ####\n",
            "   56. \"data:0.317\" 33462.705256 ####\n",
            "   57. \"data:0.430\" 33284.516369 ####\n",
            "   58. \"data:0.435\" 33227.541736 ####\n",
            "   59. \"data:0.354\" 33208.268555 ####\n",
            "   60. \"data:0.379\" 32942.598562 ####\n",
            "   61. \"data:0.238\" 32647.804548 ####\n",
            "   62. \"data:0.459\" 32523.348594 ####\n",
            "   63. \"data:0.373\" 31794.433684 ###\n",
            "   64. \"data:0.183\" 31792.677783 ###\n",
            "   65. \"data:0.484\" 31468.704124 ###\n",
            "   66. \"data:0.516\" 31030.658932 ###\n",
            "   67. \"data:0.269\" 30865.943832 ###\n",
            "   68. \"data:0.240\" 30603.609099 ###\n",
            "   69. \"data:0.349\" 30420.303634 ###\n",
            "   70. \"data:0.540\" 30329.671771 ###\n",
            "   71. \"data:0.432\" 29476.123891 ###\n",
            "   72. \"data:0.319\" 29397.837582 ###\n",
            "   73. \"data:0.298\" 29334.982715 ###\n",
            "   74. \"data:0.597\" 29326.912667 ###\n",
            "   75. \"data:0.486\" 29034.304163 ###\n",
            "   76. \"data:0.463\" 27746.132310 ###\n",
            "   77. \"data:0.400\" 27735.572824 ###\n",
            "   78. \"data:0.320\" 27382.051502 ###\n",
            "   79. \"data:0.404\" 27245.068048 ###\n",
            "   80. \"data:0.322\" 27164.133673 ###\n",
            "   81. \"data:0.434\" 27062.322189 ###\n",
            "   82. \"data:0.410\" 27037.175127 ###\n",
            "   83. \"data:0.654\" 26962.711026 ###\n",
            "   84. \"data:0.381\" 26799.691260 ###\n",
            "   85. \"data:0.157\" 26280.521010 ###\n",
            "   86. \"data:0.270\" 26240.154749 ###\n",
            "   87. \"data:0.380\" 26234.372717 ###\n",
            "   88. \"data:0.267\" 25674.737434 ###\n",
            "   89. \"data:0.352\" 25607.859655 ###\n",
            "   90. \"data:0.431\" 25466.110220 ###\n",
            "   91. \"data:0.437\" 25222.743190 ###\n",
            "   92. \"data:0.212\" 24219.117103 ###\n",
            "   93. \"data:0.294\" 24174.837552 ###\n",
            "   94. \"data:0.550\" 24051.155778 ###\n",
            "   95. \"data:0.382\" 23897.433588 ##\n",
            "   96. \"data:0.465\" 23852.761983 ##\n",
            "   97. \"data:0.485\" 23798.365749 ##\n",
            "   98. \"data:0.239\" 23773.113735 ##\n",
            "   99. \"data:0.541\" 23678.338328 ##\n",
            "  100. \"data:0.466\" 23489.918744 ##\n",
            "  101. \"data:0.513\" 23461.049998 ##\n",
            "  102. \"data:0.325\" 22912.538197 ##\n",
            "  103. \"data:0.296\" 22869.565455 ##\n",
            "  104. \"data:0.544\" 22674.456875 ##\n",
            "  105. \"data:0.152\" 22503.000427 ##\n",
            "  106. \"data:0.551\" 22395.725861 ##\n",
            "  107. \"data:0.402\" 22388.935980 ##\n",
            "  108. \"data:0.571\" 22298.938543 ##\n",
            "  109. \"data:0.321\" 22250.240985 ##\n",
            "  110. \"data:0.299\" 22096.128951 ##\n",
            "  111. \"data:0.292\" 22065.235757 ##\n",
            "  112. \"data:0.209\" 21965.478395 ##\n",
            "  113. \"data:0.295\" 21879.134326 ##\n",
            "  114. \"data:0.178\" 21785.007067 ##\n",
            "  115. \"data:0.268\" 21729.868145 ##\n",
            "  116. \"data:0.522\" 21420.340201 ##\n",
            "  117. \"data:0.323\" 21332.233752 ##\n",
            "  118. \"data:0.271\" 21324.845271 ##\n",
            "  119. \"data:0.517\" 21193.990145 ##\n",
            "  120. \"data:0.353\" 20722.411674 ##\n",
            "  121. \"data:0.266\" 20576.030703 ##\n",
            "  122. \"data:0.324\" 20310.261028 ##\n",
            "  123. \"data:0.237\" 19956.378980 ##\n",
            "  124. \"data:0.297\" 19922.411789 ##\n",
            "  125. \"data:0.207\" 19646.759710 ##\n",
            "  126. \"data:0.545\" 19356.505403 ##\n",
            "  127. \"data:0.184\" 19202.592566 ##\n",
            "  128. \"data:0.567\" 18627.563847 ##\n",
            "  129. \"data:0.327\" 18193.062426 ##\n",
            "  130. \"data:0.372\" 18155.269738 ##\n",
            "  131. \"data:0.243\" 18137.308205 ##\n",
            "  132. \"data:0.572\" 18028.565445 ##\n",
            "  133. \"data:0.241\" 18019.405819 ##\n",
            "  134. \"data:0.182\" 17915.866109 ##\n",
            "  135. \"data:0.407\" 17724.587586 ##\n",
            "  136. \"data:0.265\" 17629.798245 ##\n",
            "  137. \"data:0.293\" 17407.355080 ##\n",
            "  138. \"data:0.234\" 16935.621377 ##\n",
            "  139. \"data:0.242\" 16813.950071 ##\n",
            "  140. \"data:0.436\" 16755.024105 ##\n",
            "  141. \"data:0.206\" 16653.558561 ##\n",
            "  142. \"data:0.578\" 16577.127900 ##\n",
            "  143. \"data:0.213\" 16542.516848 ##\n",
            "  144. \"data:0.595\" 16297.752962 ##\n",
            "  145. \"data:0.464\" 16274.792725 ##\n",
            "  146. \"data:0.289\" 16182.031389 ##\n",
            "  147. \"data:0.626\" 16099.440342 ##\n",
            "  148. \"data:0.573\" 15949.802864 #\n",
            "  149. \"data:0.598\" 15887.827544 #\n",
            "  150. \"data:0.653\" 15787.555180 #\n",
            "  151. \"data:0.316\" 15545.874592 #\n",
            "  152. \"data:0.427\" 15204.399536 #\n",
            "  153. \"data:0.399\" 15203.744419 #\n",
            "  154. \"data:0.272\" 15153.595045 #\n",
            "  155. \"data:0.151\" 15082.846822 #\n",
            "  156. \"data:0.236\" 14902.333734 #\n",
            "  157. \"data:0.518\" 14767.311248 #\n",
            "  158. \"data:0.467\" 14718.411072 #\n",
            "  159. \"data:0.179\" 14593.738080 #\n",
            "  160. \"data:0.344\" 14569.459427 #\n",
            "  161. \"data:0.185\" 14533.439552 #\n",
            "  162. \"data:0.491\" 14309.308396 #\n",
            "  163. \"data:0.343\" 14028.666361 #\n",
            "  164. \"data:0.300\" 13960.382225 #\n",
            "  165. \"data:0.329\" 13911.100637 #\n",
            "  166. \"data:0.627\" 13574.654245 #\n",
            "  167. \"data:0.371\" 13489.148329 #\n",
            "  168. \"data:0.158\" 13383.869575 #\n",
            "  169. \"data:0.215\" 13359.266596 #\n",
            "  170. \"data:0.494\" 13338.302182 #\n",
            "  171. \"data:0.357\" 13188.064289 #\n",
            "  172. \"data:0.100\" 13153.509866 #\n",
            "  173. \"data:0.624\" 13091.386995 #\n",
            "  174. \"data:0.127\" 12985.103763 #\n",
            "  175. \"data:0.181\" 12889.028390 #\n",
            "  176. \"data:0.512\" 12769.526073 #\n",
            "  177. \"data:0.521\" 12623.705655 #\n",
            "  178. \"data:0.659\" 12589.554881 #\n",
            "  179. \"data:0.233\" 12528.521838 #\n",
            "  180. \"data:0.235\" 12342.159116 #\n",
            "  181. \"data:0.214\" 12263.680006 #\n",
            "  182. \"data:0.438\" 12137.288431 #\n",
            "  183. \"data:0.426\" 12099.976423 #\n",
            "  184. \"data:0.455\" 12061.357514 #\n",
            "  185. \"data:0.328\" 11768.176751 #\n",
            "  186. \"data:0.126\" 11571.767331 #\n",
            "  187. \"data:0.599\" 11506.648516 #\n",
            "  188. \"data:0.262\" 11486.847892 #\n",
            "  189. \"data:0.264\" 11383.262603 #\n",
            "  190. \"data:0.495\" 11261.925482 #\n",
            "  191. \"data:0.330\" 11256.831039 #\n",
            "  192. \"data:0.216\" 11235.120456 #\n",
            "  193. \"data:0.273\" 11215.401796 #\n",
            "  194. \"data:0.244\" 11197.186260 #\n",
            "  195. \"data:0.208\" 11067.150188 #\n",
            "  196. \"data:0.606\" 11060.487707 #\n",
            "  197. \"data:0.411\" 11043.413954 #\n",
            "  198. \"data:0.355\" 11025.252733 #\n",
            "  199. \"data:0.125\" 10957.943767 #\n",
            "  200. \"data:0.577\" 10558.266583 #\n",
            "  201. \"data:0.180\" 10437.233433 #\n",
            "  202. \"data:0.549\" 10409.868062 #\n",
            "  203. \"data:0.128\" 10268.961404 #\n",
            "  204. \"data:0.519\" 10212.972776 #\n",
            "  205. \"data:0.124\" 10200.851143 #\n",
            "  206. \"data:0.496\" 10193.508569 #\n",
            "  207. \"data:0.413\" 10077.836055 #\n",
            "  208. \"data:0.628\" 10026.842924 #\n",
            "  209. \"data:0.492\" 9880.040342 #\n",
            "  210. \"data:0.511\" 9850.615215 #\n",
            "  211. \"data:0.493\" 9786.441367 #\n",
            "  212. \"data:0.524\" 9781.972999 #\n",
            "  213. \"data:0.651\" 9605.267483 #\n",
            "  214. \"data:0.288\" 9407.711113 #\n",
            "  215. \"data:0.483\" 9385.899099 #\n",
            "  216. \"data:0.186\" 9367.970289 #\n",
            "  217. \"data:0.546\" 9161.361952 #\n",
            "  218. \"data:0.523\" 9147.129480 #\n",
            "  219. \"data:0.548\" 8915.944221 #\n",
            "  220. \"data:0.594\" 8890.385345 #\n",
            "  221. \"data:0.603\" 8678.398575 #\n",
            "  222. \"data:0.600\" 8569.427796 #\n",
            "  223. \"data:0.601\" 8528.137114 #\n",
            "  224. \"data:0.218\" 8407.735741 #\n",
            "  225. \"data:0.177\" 8271.186233 #\n",
            "  226. \"data:0.301\" 8271.016388 #\n",
            "  227. \"data:0.454\" 8265.847342 #\n",
            "  228. \"data:0.383\" 8059.729948 #\n",
            "  229. \"data:0.245\" 8045.991562 #\n",
            "  230. \"data:0.660\" 8022.620136 #\n",
            "  231. \"data:0.315\" 8005.757309 #\n",
            "  232. \"data:0.576\" 7966.956220 \n",
            "  233. \"data:0.579\" 7768.959190 \n",
            "  234. \"data:0.356\" 7723.591245 \n",
            "  235. \"data:0.631\" 7617.307164 \n",
            "  236. \"data:0.520\" 7602.938418 \n",
            "  237. \"data:0.358\" 7559.039230 \n",
            "  238. \"data:0.439\" 7539.574896 \n",
            "  239. \"data:0.574\" 7371.453649 \n",
            "  240. \"data:0.575\" 7348.611646 \n",
            "  241. \"data:0.150\" 7281.567260 \n",
            "  242. \"data:0.538\" 7156.678504 \n",
            "  243. \"data:0.398\" 7106.267689 \n",
            "  244. \"data:0.623\" 6753.649451 \n",
            "  245. \"data:0.629\" 6748.733224 \n",
            "  246. \"data:0.205\" 6645.445093 \n",
            "  247. \"data:0.468\" 6633.273948 \n",
            "  248. \"data:0.342\" 6609.781589 \n",
            "  249. \"data:0.566\" 6555.009300 \n",
            "  250. \"data:0.630\" 6548.692900 \n",
            "  251. \"data:0.510\" 6541.797299 \n",
            "  252. \"data:0.602\" 6512.681709 \n",
            "  253. \"data:0.547\" 6417.107528 \n",
            "  254. \"data:0.101\" 6398.612378 \n",
            "  255. \"data:0.187\" 6335.386800 \n",
            "  256. \"data:0.261\" 6283.928399 \n",
            "  257. \"data:0.188\" 6125.698221 \n",
            "  258. \"data:0.607\" 6103.759514 \n",
            "  259. \"data:0.661\" 6000.025995 \n",
            "  260. \"data:0.129\" 5990.494664 \n",
            "  261. \"data:0.159\" 5895.192416 \n",
            "  262. \"data:0.470\" 5866.305378 \n",
            "  263. \"data:0.652\" 5845.620474 \n",
            "  264. \"data:0.217\" 5832.386981 \n",
            "  265. \"data:0.552\" 5696.439505 \n",
            "  266. \"data:0.274\" 5629.557394 \n",
            "  267. \"data:0.482\" 5613.485112 \n",
            "  268. \"data:0.683\" 5564.543342 \n",
            "  269. \"data:0.685\" 5547.467274 \n",
            "  270. \"data:0.260\" 5524.810062 \n",
            "  271. \"data:0.247\" 5503.774711 \n",
            "  272. \"data:0.189\" 5149.136959 \n",
            "  273. \"data:0.123\" 5053.186185 \n",
            "  274. \"data:0.580\" 5032.336490 \n",
            "  275. \"data:0.219\" 4985.903087 \n",
            "  276. \"data:0.686\" 4920.871575 \n",
            "  277. \"data:0.605\" 4901.053918 \n",
            "  278.  \"data:0.98\" 4900.699685 \n",
            "  279. \"data:0.440\" 4889.962714 \n",
            "  280. \"data:0.385\" 4879.795789 \n",
            "  281. \"data:0.384\" 4820.540968 \n",
            "  282. \"data:0.684\" 4769.447059 \n",
            "  283. \"data:0.634\" 4709.783426 \n",
            "  284. \"data:0.604\" 4647.456919 \n",
            "  285. \"data:0.608\" 4601.676847 \n",
            "  286. \"data:0.302\" 4520.918468 \n",
            "  287. \"data:0.469\" 4468.708473 \n",
            "  288. \"data:0.204\" 4392.410949 \n",
            "  289. \"data:0.632\" 4355.406202 \n",
            "  290. \"data:0.370\" 4324.490600 \n",
            "  291. \"data:0.412\" 4269.069286 \n",
            "  292. \"data:0.246\" 4256.882832 \n",
            "  293. \"data:0.441\" 4221.975057 \n",
            "  294.  \"data:0.97\" 4112.127971 \n",
            "  295. \"data:0.122\" 3993.623791 \n",
            "  296. \"data:0.149\" 3929.164304 \n",
            "  297. \"data:0.497\" 3916.157809 \n",
            "  298. \"data:0.176\" 3839.660210 \n",
            "  299. \"data:0.386\" 3745.904353 \n",
            "  300. \"data:0.633\" 3743.190198 \n",
            "  301. \"data:0.414\" 3647.988532 \n",
            "  302. \"data:0.682\" 3646.474315 \n",
            "  303. \"data:0.526\" 3584.087774 \n",
            "  304. \"data:0.554\" 3472.265242 \n",
            "  305. \"data:0.709\" 3467.937124 \n",
            "  306. \"data:0.453\" 3410.326870 \n",
            "  307. \"data:0.509\" 3391.279124 \n",
            "  308. \"data:0.248\" 3387.979850 \n",
            "  309. \"data:0.314\" 3375.077600 \n",
            "  310. \"data:0.190\" 3345.822769 \n",
            "  311. \"data:0.537\" 3333.309597 \n",
            "  312.  \"data:0.99\" 3311.028033 \n",
            "  313. \"data:0.609\" 3297.509384 \n",
            "  314. \"data:0.287\" 3262.979382 \n",
            "  315. \"data:0.553\" 3187.510534 \n",
            "  316. \"data:0.681\" 2974.707700 \n",
            "  317. \"data:0.635\" 2937.112965 \n",
            "  318. \"data:0.687\" 2911.559401 \n",
            "  319. \"data:0.160\" 2858.979372 \n",
            "  320. \"data:0.525\" 2836.564800 \n",
            "  321. \"data:0.130\" 2752.388363 \n",
            "  322. \"data:0.359\" 2738.957696 \n",
            "  323. \"data:0.581\" 2650.206122 \n",
            "  324. \"data:0.679\" 2640.364522 \n",
            "  325. \"data:0.275\" 2629.862288 \n",
            "  326. \"data:0.231\" 2515.746396 \n",
            "  327. \"data:0.232\" 2406.511646 \n",
            "  328. \"data:0.663\" 2381.794953 \n",
            "  329. \"data:0.710\" 2356.673496 \n",
            "  330. \"data:0.662\" 2343.064076 \n",
            "  331. \"data:0.442\" 2338.143174 \n",
            "  332. \"data:0.498\" 2280.702814 \n",
            "  333. \"data:0.565\" 2270.172215 \n",
            "  334. \"data:0.622\" 2239.229427 \n",
            "  335. \"data:0.714\" 2160.096529 \n",
            "  336. \"data:0.387\" 2105.066738 \n",
            "  337. \"data:0.397\" 2097.200684 \n",
            "  338. \"data:0.102\" 2095.004474 \n",
            "  339. \"data:0.132\" 2050.669006 \n",
            "  340. \"data:0.191\" 1986.216327 \n",
            "  341. \"data:0.161\" 1964.492262 \n",
            "  342. \"data:0.131\" 1936.902165 \n",
            "  343. \"data:0.708\" 1935.014619 \n",
            "  344. \"data:0.425\" 1873.563365 \n",
            "  345. \"data:0.680\" 1865.102510 \n",
            "  346. \"data:0.303\" 1796.345676 \n",
            "  347. \"data:0.331\" 1792.960228 \n",
            "  348. \"data:0.593\" 1744.595964 \n",
            "  349. \"data:0.103\" 1735.302743 \n",
            "  350. \"data:0.415\" 1693.096951 \n",
            "  351. \"data:0.341\" 1685.555944 \n",
            "  352. \"data:0.203\" 1678.084244 \n",
            "  353. \"data:0.688\" 1647.802523 \n",
            "  354. \"data:0.711\" 1588.806447 \n",
            "  355. \"data:0.220\" 1564.950534 \n",
            "  356. \"data:0.527\" 1472.435760 \n",
            "  357. \"data:0.443\" 1471.203117 \n",
            "  358. \"data:0.712\" 1467.616700 \n",
            "  359. \"data:0.259\" 1462.498502 \n",
            "  360. \"data:0.707\" 1437.216246 \n",
            "  361.  \"data:0.68\" 1396.795868 \n",
            "  362. \"data:0.286\" 1308.418878 \n",
            "  363. \"data:0.162\" 1241.604639 \n",
            "  364.  \"data:0.96\" 1232.656219 \n",
            "  365. \"data:0.582\" 1208.523441 \n",
            "  366. \"data:0.258\" 1195.422939 \n",
            "  367. \"data:0.369\" 1187.005817 \n",
            "  368. \"data:0.499\" 1178.369471 \n",
            "  369. \"data:0.121\" 1108.696381 \n",
            "  370.  \"data:0.70\" 1090.407647 \n",
            "  371. \"data:0.471\" 1069.106055 \n",
            "  372. \"data:0.689\" 1053.523482 \n",
            "  373. \"data:0.713\" 1047.630455 \n",
            "  374. \"data:0.148\" 1033.232709 \n",
            "  375. \"data:0.481\" 1020.345289 \n",
            "  376.  \"data:0.95\" 1019.006037 \n",
            "  377. \"data:0.147\" 994.270414 \n",
            "  378. \"data:0.175\" 981.001266 \n",
            "  379. \"data:0.636\" 943.487228 \n",
            "  380. \"data:0.230\" 905.923765 \n",
            "  381. \"data:0.650\" 876.538448 \n",
            "  382. \"data:0.276\" 867.203871 \n",
            "  383. \"data:0.716\" 855.341043 \n",
            "  384.  \"data:0.69\" 816.481983 \n",
            "  385. \"data:0.313\" 766.170411 \n",
            "  386. \"data:0.690\" 760.834563 \n",
            "  387. \"data:0.583\" 743.507154 \n",
            "  388. \"data:0.202\" 733.973389 \n",
            "  389. \"data:0.637\" 725.006940 \n",
            "  390. \"data:0.555\" 699.891524 \n",
            "  391. \"data:0.163\" 690.887059 \n",
            "  392. \"data:0.536\" 683.626345 \n",
            "  393. \"data:0.192\" 680.968333 \n",
            "  394. \"data:0.678\" 649.328676 \n",
            "  395. \"data:0.717\" 612.061453 \n",
            "  396. \"data:0.133\" 578.301352 \n",
            "  397. \"data:0.610\" 540.765736 \n",
            "  398. \"data:0.304\" 539.830567 \n",
            "  399. \"data:0.691\" 534.003837 \n",
            "  400. \"data:0.715\" 521.670697 \n",
            "  401. \"data:0.740\" 504.474133 \n",
            "  402. \"data:0.664\" 498.461341 \n",
            "  403. \"data:0.285\" 496.059192 \n",
            "  404.  \"data:0.94\" 490.989197 \n",
            "  405.  \"data:0.67\" 487.351029 \n",
            "  406. \"data:0.104\" 482.855115 \n",
            "  407. \"data:0.500\" 481.315876 \n",
            "  408. \"data:0.257\" 464.711357 \n",
            "  409. \"data:0.416\" 372.697202 \n",
            "  410. \"data:0.592\" 369.463537 \n",
            "  411. \"data:0.174\" 366.617263 \n",
            "  412. \"data:0.649\" 340.095608 \n",
            "  413. \"data:0.611\" 327.044472 \n",
            "  414. \"data:0.472\" 324.028768 \n",
            "  415. \"data:0.480\" 314.037827 \n",
            "  416. \"data:0.528\" 311.657826 \n",
            "  417. \"data:0.692\" 304.406708 \n",
            "  418.  \"data:0.93\" 287.225296 \n",
            "  419. \"data:0.621\" 283.281179 \n",
            "  420. \"data:0.556\" 281.938473 \n",
            "  421. \"data:0.508\" 270.256058 \n",
            "  422. \"data:0.564\" 269.132670 \n",
            "  423. \"data:0.396\" 253.571718 \n",
            "  424. \"data:0.744\" 250.092020 \n",
            "  425. \"data:0.229\" 242.798799 \n",
            "  426. \"data:0.718\" 227.123695 \n",
            "  427. \"data:0.388\" 226.357653 \n",
            "  428.  \"data:0.92\" 221.987093 \n",
            "  429. \"data:0.444\" 221.399478 \n",
            "  430. \"data:0.719\" 216.219258 \n",
            "  431. \"data:0.473\" 213.091542 \n",
            "  432. \"data:0.164\" 209.138839 \n",
            "  433. \"data:0.340\" 208.189557 \n",
            "  434. \"data:0.452\" 200.701794 \n",
            "  435. \"data:0.360\" 198.485082 \n",
            "  436. \"data:0.638\" 178.943935 \n",
            "  437. \"data:0.284\" 178.592028 \n",
            "  438. \"data:0.173\" 177.123049 \n",
            "  439. \"data:0.105\" 174.464039 \n",
            "  440. \"data:0.677\" 174.279875 \n",
            "  441. \"data:0.201\" 169.434746 \n",
            "  442. \"data:0.120\" 165.806357 \n",
            "  443. \"data:0.249\" 165.253919 \n",
            "  444. \"data:0.665\" 161.708591 \n",
            "  445. \"data:0.135\" 161.556304 \n",
            "  446. \"data:0.737\" 159.441821 \n",
            "  447. \"data:0.368\" 158.733369 \n",
            "  448. \"data:0.134\" 158.242498 \n",
            "  449. \"data:0.146\" 157.823487 \n",
            "  450.  \"data:0.66\" 135.688380 \n",
            "  451. \"data:0.424\" 134.757507 \n",
            "  452. \"data:0.739\" 134.065615 \n",
            "  453. \"data:0.332\" 133.576802 \n",
            "  454.  \"data:0.71\" 128.813353 \n",
            "  455. \"data:0.312\" 127.253496 \n",
            "  456. \"data:0.706\" 124.259159 \n",
            "  457. \"data:0.620\" 114.544159 \n",
            "  458. \"data:0.720\" 114.390201 \n",
            "  459. \"data:0.228\" 112.100504 \n",
            "  460. \"data:0.256\" 110.687913 \n",
            "  461. \"data:0.563\" 101.690248 \n",
            "  462. \"data:0.529\" 99.035334 \n",
            "  463.  \"data:0.72\" 92.982707 \n",
            "  464. \"data:0.743\" 90.608798 \n",
            "  465. \"data:0.106\" 86.027738 \n",
            "  466. \"data:0.745\" 85.283313 \n",
            "  467. \"data:0.742\" 84.114322 \n",
            "  468. \"data:0.501\" 81.260216 \n",
            "  469. \"data:0.277\" 80.805873 \n",
            "  470. \"data:0.694\" 78.422866 \n",
            "  471. \"data:0.119\" 72.237093 \n",
            "  472. \"data:0.193\" 64.773006 \n",
            "  473.  \"data:0.73\" 63.849713 \n",
            "  474. \"data:0.705\" 62.729818 \n",
            "  475. \"data:0.738\" 61.496614 \n",
            "  476. \"data:0.648\" 56.383252 \n",
            "  477. \"data:0.305\" 55.786820 \n",
            "  478. \"data:0.639\" 55.574277 \n",
            "  479. \"data:0.145\" 54.919486 \n",
            "  480. \"data:0.693\" 49.381171 \n",
            "  481.  \"data:0.65\" 47.602170 \n",
            "  482. \"data:0.445\" 47.404866 \n",
            "  483. \"data:0.748\" 47.154212 \n",
            "  484. \"data:0.200\" 46.667968 \n",
            "  485. \"data:0.612\" 41.708836 \n",
            "  486. \"data:0.741\" 36.108183 \n",
            "  487. \"data:0.118\" 35.038863 \n",
            "  488. \"data:0.704\" 33.975676 \n",
            "  489. \"data:0.474\" 33.723548 \n",
            "  490. \"data:0.746\" 32.427942 \n",
            "  491. \"data:0.584\" 31.583236 \n",
            "  492. \"data:0.221\" 29.317046 \n",
            "  493. \"data:0.507\" 29.079129 \n",
            "  494.  \"data:0.64\" 27.057976 \n",
            "  495. \"data:0.721\" 25.617596 \n",
            "  496. \"data:0.562\" 24.432385 \n",
            "  497. \"data:0.389\" 24.399747 \n",
            "  498.  \"data:0.91\" 24.086239 \n",
            "  499. \"data:0.666\" 23.261677 \n",
            "  500. \"data:0.417\" 23.093681 \n",
            "  501. \"data:0.640\" 22.982683 \n",
            "  502. \"data:0.172\" 20.554454 \n",
            "  503.  \"data:0.90\" 20.523589 \n",
            "  504. \"data:0.722\" 19.557966 \n",
            "  505. \"data:0.732\" 19.050504 \n",
            "  506. \"data:0.311\" 19.017846 \n",
            "  507. \"data:0.734\" 17.968520 \n",
            "  508. \"data:0.278\" 17.180483 \n",
            "  509. \"data:0.339\" 15.330972 \n",
            "  510. \"data:0.735\" 13.776998 \n",
            "  511. \"data:0.668\" 13.736494 \n",
            "  512. \"data:0.535\" 13.400657 \n",
            "  513. \"data:0.479\" 13.201183 \n",
            "  514. \"data:0.107\" 11.987861 \n",
            "  515. \"data:0.136\" 11.663686 \n",
            "  516. \"data:0.736\" 11.567046 \n",
            "  517.  \"data:0.76\" 11.556426 \n",
            "  518.  \"data:0.74\" 11.216253 \n",
            "  519. \"data:0.591\" 11.037222 \n",
            "  520. \"data:0.733\" 10.822368 \n",
            "  521. \"data:0.747\" 10.695122 \n",
            "  522. \"data:0.255\" 10.604509 \n",
            "  523. \"data:0.676\"  9.704061 \n",
            "  524. \"data:0.585\"  9.236568 \n",
            "  525. \"data:0.619\"  8.946419 \n",
            "  526. \"data:0.108\"  7.736734 \n",
            "  527. \"data:0.647\"  5.952423 \n",
            "  528. \"data:0.194\"  5.558938 \n",
            "  529. \"data:0.333\"  5.502829 \n",
            "  530. \"data:0.199\"  5.171348 \n",
            "  531. \"data:0.367\"  5.136158 \n",
            "  532. \"data:0.451\"  4.399866 \n",
            "  533. \"data:0.770\"  4.228105 \n",
            "  534. \"data:0.667\"  4.116275 \n",
            "  535. \"data:0.165\"  3.788776 \n",
            "  536. \"data:0.772\"  3.530150 \n",
            "  537. \"data:0.557\"  2.329644 \n",
            "  538.  \"data:0.89\"  0.748818 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: true\n",
            "Out-of-bag evaluation: accuracy:0.957 logloss:0.295299\n",
            "Number of trees: 50\n",
            "Total number of nodes: 233670\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 50 Average: 4673.4 StdDev: 112.501\n",
            "Min: 4417 Max: 4883 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 4417, 4440) 2   4.00%   4.00% ###\n",
            "[ 4440, 4463) 1   2.00%   6.00% ##\n",
            "[ 4463, 4487) 1   2.00%   8.00% ##\n",
            "[ 4487, 4510) 1   2.00%  10.00% ##\n",
            "[ 4510, 4533) 3   6.00%  16.00% #####\n",
            "[ 4533, 4557) 0   0.00%  16.00%\n",
            "[ 4557, 4580) 1   2.00%  18.00% ##\n",
            "[ 4580, 4603) 4   8.00%  26.00% #######\n",
            "[ 4603, 4627) 2   4.00%  30.00% ###\n",
            "[ 4627, 4650) 2   4.00%  34.00% ###\n",
            "[ 4650, 4673) 5  10.00%  44.00% ########\n",
            "[ 4673, 4697) 6  12.00%  56.00% ##########\n",
            "[ 4697, 4720) 5  10.00%  66.00% ########\n",
            "[ 4720, 4743) 5  10.00%  76.00% ########\n",
            "[ 4743, 4767) 2   4.00%  80.00% ###\n",
            "[ 4767, 4790) 0   0.00%  80.00%\n",
            "[ 4790, 4813) 3   6.00%  86.00% #####\n",
            "[ 4813, 4837) 4   8.00%  94.00% #######\n",
            "[ 4837, 4860) 1   2.00%  96.00% ##\n",
            "[ 4860, 4883] 2   4.00% 100.00% ###\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 116860 Average: 12.1011 StdDev: 1.6409\n",
            "Min: 5 Max: 15 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  5,  6)     1   0.00%   0.00%\n",
            "[  6,  7)    12   0.01%   0.01%\n",
            "[  7,  8)   127   0.11%   0.12%\n",
            "[  8,  9)   994   0.85%   0.97%\n",
            "[  9, 10)  5011   4.29%   5.26% ##\n",
            "[ 10, 11) 13496  11.55%  16.81% #####\n",
            "[ 11, 12) 23543  20.15%  36.95% #########\n",
            "[ 12, 13) 26900  23.02%  59.97% ##########\n",
            "[ 13, 14) 21988  18.82%  78.79% ########\n",
            "[ 14, 15) 14284  12.22%  91.01% #####\n",
            "[ 15, 15] 10504   8.99% 100.00% ####\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 116860 Average: 25.6717 StdDev: 121.064\n",
            "Min: 5 Max: 4864 Ignored: 0\n",
            "----------------------------------------------\n",
            "[    5,  248) 115134  98.52%  98.52% ##########\n",
            "[  248,  491)    988   0.85%  99.37%\n",
            "[  491,  734)    289   0.25%  99.62%\n",
            "[  734,  977)    153   0.13%  99.75%\n",
            "[  977, 1220)     67   0.06%  99.80%\n",
            "[ 1220, 1463)     50   0.04%  99.85%\n",
            "[ 1463, 1706)     34   0.03%  99.88%\n",
            "[ 1706, 1949)     36   0.03%  99.91%\n",
            "[ 1949, 2192)     25   0.02%  99.93%\n",
            "[ 2192, 2435)     26   0.02%  99.95%\n",
            "[ 2435, 2678)     14   0.01%  99.96%\n",
            "[ 2678, 2921)      8   0.01%  99.97%\n",
            "[ 2921, 3164)      3   0.00%  99.97%\n",
            "[ 3164, 3407)      3   0.00%  99.97%\n",
            "[ 3407, 3650)      8   0.01%  99.98%\n",
            "[ 3650, 3893)      3   0.00%  99.98%\n",
            "[ 3893, 4136)      4   0.00%  99.99%\n",
            "[ 4136, 4379)      5   0.00%  99.99%\n",
            "[ 4379, 4622)      5   0.00% 100.00%\n",
            "[ 4622, 4864]      5   0.00% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t658 : data:0.211 [NUMERICAL]\n",
            "\t651 : data:0.321 [NUMERICAL]\n",
            "\t631 : data:0.296 [NUMERICAL]\n",
            "\t625 : data:0.324 [NUMERICAL]\n",
            "\t623 : data:0.266 [NUMERICAL]\n",
            "\t621 : data:0.294 [NUMERICAL]\n",
            "\t615 : data:0.295 [NUMERICAL]\n",
            "\t615 : data:0.267 [NUMERICAL]\n",
            "\t614 : data:0.515 [NUMERICAL]\n",
            "\t614 : data:0.210 [NUMERICAL]\n",
            "\t610 : data:0.378 [NUMERICAL]\n",
            "\t609 : data:0.486 [NUMERICAL]\n",
            "\t609 : data:0.319 [NUMERICAL]\n",
            "\t609 : data:0.212 [NUMERICAL]\n",
            "\t607 : data:0.322 [NUMERICAL]\n",
            "\t602 : data:0.320 [NUMERICAL]\n",
            "\t598 : data:0.351 [NUMERICAL]\n",
            "\t596 : data:0.269 [NUMERICAL]\n",
            "\t596 : data:0.268 [NUMERICAL]\n",
            "\t594 : data:0.405 [NUMERICAL]\n",
            "\t594 : data:0.323 [NUMERICAL]\n",
            "\t590 : data:0.293 [NUMERICAL]\n",
            "\t588 : data:0.543 [NUMERICAL]\n",
            "\t587 : data:0.487 [NUMERICAL]\n",
            "\t587 : data:0.239 [NUMERICAL]\n",
            "\t583 : data:0.238 [NUMERICAL]\n",
            "\t581 : data:0.347 [NUMERICAL]\n",
            "\t580 : data:0.352 [NUMERICAL]\n",
            "\t576 : data:0.325 [NUMERICAL]\n",
            "\t576 : data:0.240 [NUMERICAL]\n",
            "\t574 : data:0.297 [NUMERICAL]\n",
            "\t571 : data:0.377 [NUMERICAL]\n",
            "\t571 : data:0.376 [NUMERICAL]\n",
            "\t571 : data:0.292 [NUMERICAL]\n",
            "\t570 : data:0.350 [NUMERICAL]\n",
            "\t565 : data:0.514 [NUMERICAL]\n",
            "\t557 : data:0.380 [NUMERICAL]\n",
            "\t555 : data:0.375 [NUMERICAL]\n",
            "\t555 : data:0.348 [NUMERICAL]\n",
            "\t554 : data:0.460 [NUMERICAL]\n",
            "\t554 : data:0.326 [NUMERICAL]\n",
            "\t545 : data:0.353 [NUMERICAL]\n",
            "\t543 : data:0.488 [NUMERICAL]\n",
            "\t542 : data:0.409 [NUMERICAL]\n",
            "\t541 : data:0.544 [NUMERICAL]\n",
            "\t541 : data:0.432 [NUMERICAL]\n",
            "\t540 : data:0.490 [NUMERICAL]\n",
            "\t536 : data:0.209 [NUMERICAL]\n",
            "\t533 : data:0.461 [NUMERICAL]\n",
            "\t531 : data:0.434 [NUMERICAL]\n",
            "\t531 : data:0.241 [NUMERICAL]\n",
            "\t530 : data:0.346 [NUMERICAL]\n",
            "\t529 : data:0.291 [NUMERICAL]\n",
            "\t527 : data:0.457 [NUMERICAL]\n",
            "\t526 : data:0.459 [NUMERICAL]\n",
            "\t521 : data:0.458 [NUMERICAL]\n",
            "\t521 : data:0.349 [NUMERICAL]\n",
            "\t519 : data:0.265 [NUMERICAL]\n",
            "\t517 : data:0.298 [NUMERICAL]\n",
            "\t515 : data:0.408 [NUMERICAL]\n",
            "\t515 : data:0.406 [NUMERICAL]\n",
            "\t513 : data:0.462 [NUMERICAL]\n",
            "\t511 : data:0.516 [NUMERICAL]\n",
            "\t509 : data:0.433 [NUMERICAL]\n",
            "\t508 : data:0.463 [NUMERICAL]\n",
            "\t505 : data:0.437 [NUMERICAL]\n",
            "\t505 : data:0.403 [NUMERICAL]\n",
            "\t504 : data:0.489 [NUMERICAL]\n",
            "\t504 : data:0.485 [NUMERICAL]\n",
            "\t504 : data:0.213 [NUMERICAL]\n",
            "\t504 : data:0.183 [NUMERICAL]\n",
            "\t502 : data:0.407 [NUMERICAL]\n",
            "\t502 : data:0.379 [NUMERICAL]\n",
            "\t501 : data:0.517 [NUMERICAL]\n",
            "\t499 : data:0.381 [NUMERICAL]\n",
            "\t498 : data:0.237 [NUMERICAL]\n",
            "\t497 : data:0.354 [NUMERICAL]\n",
            "\t494 : data:0.518 [NUMERICAL]\n",
            "\t492 : data:0.464 [NUMERICAL]\n",
            "\t492 : data:0.374 [NUMERICAL]\n",
            "\t489 : data:0.435 [NUMERICAL]\n",
            "\t486 : data:0.572 [NUMERICAL]\n",
            "\t485 : data:0.436 [NUMERICAL]\n",
            "\t484 : data:0.184 [NUMERICAL]\n",
            "\t480 : data:0.318 [NUMERICAL]\n",
            "\t478 : data:0.491 [NUMERICAL]\n",
            "\t475 : data:0.404 [NUMERICAL]\n",
            "\t475 : data:0.290 [NUMERICAL]\n",
            "\t473 : data:0.573 [NUMERICAL]\n",
            "\t473 : data:0.270 [NUMERICAL]\n",
            "\t471 : data:0.657 [NUMERICAL]\n",
            "\t470 : data:0.431 [NUMERICAL]\n",
            "\t467 : data:0.264 [NUMERICAL]\n",
            "\t464 : data:0.430 [NUMERICAL]\n",
            "\t462 : data:0.571 [NUMERICAL]\n",
            "\t461 : data:0.545 [NUMERICAL]\n",
            "\t459 : data:0.542 [NUMERICAL]\n",
            "\t459 : data:0.345 [NUMERICAL]\n",
            "\t457 : data:0.182 [NUMERICAL]\n",
            "\t456 : data:0.208 [NUMERICAL]\n",
            "\t455 : data:0.299 [NUMERICAL]\n",
            "\t454 : data:0.574 [NUMERICAL]\n",
            "\t453 : data:0.656 [NUMERICAL]\n",
            "\t453 : data:0.214 [NUMERICAL]\n",
            "\t452 : data:0.263 [NUMERICAL]\n",
            "\t450 : data:0.465 [NUMERICAL]\n",
            "\t449 : data:0.236 [NUMERICAL]\n",
            "\t448 : data:0.382 [NUMERICAL]\n",
            "\t446 : data:0.492 [NUMERICAL]\n",
            "\t446 : data:0.242 [NUMERICAL]\n",
            "\t444 : data:0.402 [NUMERICAL]\n",
            "\t444 : data:0.401 [NUMERICAL]\n",
            "\t438 : data:0.429 [NUMERICAL]\n",
            "\t432 : data:0.513 [NUMERICAL]\n",
            "\t429 : data:0.373 [NUMERICAL]\n",
            "\t429 : data:0.185 [NUMERICAL]\n",
            "\t428 : data:0.235 [NUMERICAL]\n",
            "\t427 : data:0.271 [NUMERICAL]\n",
            "\t423 : data:0.546 [NUMERICAL]\n",
            "\t422 : data:0.154 [NUMERICAL]\n",
            "\t421 : data:0.456 [NUMERICAL]\n",
            "\t417 : data:0.289 [NUMERICAL]\n",
            "\t416 : data:0.438 [NUMERICAL]\n",
            "\t415 : data:0.410 [NUMERICAL]\n",
            "\t412 : data:0.655 [NUMERICAL]\n",
            "\t411 : data:0.317 [NUMERICAL]\n",
            "\t408 : data:0.658 [NUMERICAL]\n",
            "\t408 : data:0.428 [NUMERICAL]\n",
            "\t408 : data:0.155 [NUMERICAL]\n",
            "\t406 : data:0.601 [NUMERICAL]\n",
            "\t405 : data:0.181 [NUMERICAL]\n",
            "\t403 : data:0.519 [NUMERICAL]\n",
            "\t401 : data:0.262 [NUMERICAL]\n",
            "\t398 : data:0.156 [NUMERICAL]\n",
            "\t397 : data:0.600 [NUMERICAL]\n",
            "\t391 : data:0.599 [NUMERICAL]\n",
            "\t389 : data:0.355 [NUMERICAL]\n",
            "\t387 : data:0.541 [NUMERICAL]\n",
            "\t384 : data:0.180 [NUMERICAL]\n",
            "\t383 : data:0.602 [NUMERICAL]\n",
            "\t381 : data:0.327 [NUMERICAL]\n",
            "\t381 : data:0.243 [NUMERICAL]\n",
            "\t376 : data:0.466 [NUMERICAL]\n",
            "\t376 : data:0.207 [NUMERICAL]\n",
            "\t373 : data:0.484 [NUMERICAL]\n",
            "\t373 : data:0.153 [NUMERICAL]\n",
            "\t371 : data:0.629 [NUMERICAL]\n",
            "\t371 : data:0.575 [NUMERICAL]\n",
            "\t363 : data:0.630 [NUMERICAL]\n",
            "\t360 : data:0.547 [NUMERICAL]\n",
            "\t360 : data:0.344 [NUMERICAL]\n",
            "\t357 : data:0.179 [NUMERICAL]\n",
            "\t356 : data:0.548 [NUMERICAL]\n",
            "\t355 : data:0.520 [NUMERICAL]\n",
            "\t353 : data:0.627 [NUMERICAL]\n",
            "\t351 : data:0.570 [NUMERICAL]\n",
            "\t350 : data:0.467 [NUMERICAL]\n",
            "\t348 : data:0.186 [NUMERICAL]\n",
            "\t347 : data:0.439 [NUMERICAL]\n",
            "\t346 : data:0.603 [NUMERICAL]\n",
            "\t346 : data:0.569 [NUMERICAL]\n",
            "\t346 : data:0.549 [NUMERICAL]\n",
            "\t345 : data:0.493 [NUMERICAL]\n",
            "\t343 : data:0.234 [NUMERICAL]\n",
            "\t342 : data:0.576 [NUMERICAL]\n",
            "\t342 : data:0.215 [NUMERICAL]\n",
            "\t341 : data:0.628 [NUMERICAL]\n",
            "\t341 : data:0.400 [NUMERICAL]\n",
            "\t339 : data:0.577 [NUMERICAL]\n",
            "\t337 : data:0.152 [NUMERICAL]\n",
            "\t332 : data:0.157 [NUMERICAL]\n",
            "\t328 : data:0.372 [NUMERICAL]\n",
            "\t326 : data:0.411 [NUMERICAL]\n",
            "\t325 : data:0.631 [NUMERICAL]\n",
            "\t323 : data:0.654 [NUMERICAL]\n",
            "\t319 : data:0.604 [NUMERICAL]\n",
            "\t314 : data:0.512 [NUMERICAL]\n",
            "\t313 : data:0.598 [NUMERICAL]\n",
            "\t312 : data:0.383 [NUMERICAL]\n",
            "\t311 : data:0.300 [NUMERICAL]\n",
            "\t310 : data:0.550 [NUMERICAL]\n",
            "\t309 : data:0.626 [NUMERICAL]\n",
            "\t309 : data:0.206 [NUMERICAL]\n",
            "\t307 : data:0.659 [NUMERICAL]\n",
            "\t307 : data:0.272 [NUMERICAL]\n",
            "\t306 : data:0.522 [NUMERICAL]\n",
            "\t305 : data:0.244 [NUMERICAL]\n",
            "\t304 : data:0.521 [NUMERICAL]\n",
            "\t303 : data:0.261 [NUMERICAL]\n",
            "\t302 : data:0.625 [NUMERICAL]\n",
            "\t296 : data:0.356 [NUMERICAL]\n",
            "\t291 : data:0.632 [NUMERICAL]\n",
            "\t289 : data:0.494 [NUMERICAL]\n",
            "\t288 : data:0.328 [NUMERICAL]\n",
            "\t286 : data:0.316 [NUMERICAL]\n",
            "\t280 : data:0.187 [NUMERICAL]\n",
            "\t278 : data:0.216 [NUMERICAL]\n",
            "\t272 : data:0.288 [NUMERICAL]\n",
            "\t270 : data:0.605 [NUMERICAL]\n",
            "\t268 : data:0.455 [NUMERICAL]\n",
            "\t267 : data:0.427 [NUMERICAL]\n",
            "\t266 : data:0.578 [NUMERICAL]\n",
            "\t266 : data:0.483 [NUMERICAL]\n",
            "\t266 : data:0.233 [NUMERICAL]\n",
            "\t265 : data:0.495 [NUMERICAL]\n",
            "\t265 : data:0.399 [NUMERICAL]\n",
            "\t265 : data:0.158 [NUMERICAL]\n",
            "\t260 : data:0.151 [NUMERICAL]\n",
            "\t259 : data:0.371 [NUMERICAL]\n",
            "\t257 : data:0.568 [NUMERICAL]\n",
            "\t256 : data:0.540 [NUMERICAL]\n",
            "\t255 : data:0.653 [NUMERICAL]\n",
            "\t255 : data:0.178 [NUMERICAL]\n",
            "\t252 : data:0.523 [NUMERICAL]\n",
            "\t248 : data:0.596 [NUMERICAL]\n",
            "\t246 : data:0.597 [NUMERICAL]\n",
            "\t245 : data:0.567 [NUMERICAL]\n",
            "\t244 : data:0.606 [NUMERICAL]\n",
            "\t243 : data:0.539 [NUMERICAL]\n",
            "\t239 : data:0.660 [NUMERICAL]\n",
            "\t237 : data:0.315 [NUMERICAL]\n",
            "\t233 : data:0.384 [NUMERICAL]\n",
            "\t231 : data:0.343 [NUMERICAL]\n",
            "\t231 : data:0.260 [NUMERICAL]\n",
            "\t230 : data:0.511 [NUMERICAL]\n",
            "\t229 : data:0.440 [NUMERICAL]\n",
            "\t226 : data:0.245 [NUMERICAL]\n",
            "\t224 : data:0.468 [NUMERICAL]\n",
            "\t223 : data:0.579 [NUMERICAL]\n",
            "\t220 : data:0.633 [NUMERICAL]\n",
            "\t220 : data:0.301 [NUMERICAL]\n",
            "\t219 : data:0.595 [NUMERICAL]\n",
            "\t213 : data:0.205 [NUMERICAL]\n",
            "\t213 : data:0.188 [NUMERICAL]\n",
            "\t212 : data:0.624 [NUMERICAL]\n",
            "\t210 : data:0.159 [NUMERICAL]\n",
            "\t207 : data:0.496 [NUMERICAL]\n",
            "\t199 : data:0.551 [NUMERICAL]\n",
            "\t199 : data:0.412 [NUMERICAL]\n",
            "\t199 : data:0.329 [NUMERICAL]\n",
            "\t199 : data:0.177 [NUMERICAL]\n",
            "\t198 : data:0.217 [NUMERICAL]\n",
            "\t197 : data:0.273 [NUMERICAL]\n",
            "\t192 : data:0.634 [NUMERICAL]\n",
            "\t189 : data:0.128 [NUMERICAL]\n",
            "\t188 : data:0.524 [NUMERICAL]\n",
            "\t188 : data:0.357 [NUMERICAL]\n",
            "\t188 : data:0.126 [NUMERICAL]\n",
            "\t185 : data:0.685 [NUMERICAL]\n",
            "\t181 : data:0.510 [NUMERICAL]\n",
            "\t181 : data:0.426 [NUMERICAL]\n",
            "\t179 : data:0.150 [NUMERICAL]\n",
            "\t177 : data:0.607 [NUMERICAL]\n",
            "\t175 : data:0.125 [NUMERICAL]\n",
            "\t173 : data:0.552 [NUMERICAL]\n",
            "\t171 : data:0.127 [NUMERICAL]\n",
            "\t169 : data:0.683 [NUMERICAL]\n",
            "\t165 : data:0.686 [NUMERICAL]\n",
            "\t164 : data:0.413 [NUMERICAL]\n",
            "\t163 : data:0.580 [NUMERICAL]\n",
            "\t163 : data:0.482 [NUMERICAL]\n",
            "\t163 : data:0.232 [NUMERICAL]\n",
            "\t162 : data:0.684 [NUMERICAL]\n",
            "\t162 : data:0.661 [NUMERICAL]\n",
            "\t162 : data:0.538 [NUMERICAL]\n",
            "\t162 : data:0.189 [NUMERICAL]\n",
            "\t161 : data:0.623 [NUMERICAL]\n",
            "\t159 : data:0.454 [NUMERICAL]\n",
            "\t156 : data:0.204 [NUMERICAL]\n",
            "\t155 : data:0.385 [NUMERICAL]\n",
            "\t155 : data:0.274 [NUMERICAL]\n",
            "\t155 : data:0.218 [NUMERICAL]\n",
            "\t154 : data:0.398 [NUMERICAL]\n",
            "\t152 : data:0.246 [NUMERICAL]\n",
            "\t147 : data:0.608 [NUMERICAL]\n",
            "\t146 : data:0.635 [NUMERICAL]\n",
            "\t146 : data:0.441 [NUMERICAL]\n",
            "\t143 : data:0.553 [NUMERICAL]\n",
            "\t143 : data:0.469 [NUMERICAL]\n",
            "\t143 : data:0.330 [NUMERICAL]\n",
            "\t143 : data:0.129 [NUMERICAL]\n",
            "\t142 : data:0.687 [NUMERICAL]\n",
            "\t140 : data:0.358 [NUMERICAL]\n",
            "\t138 : data:0.497 [NUMERICAL]\n",
            "\t137 : data:0.287 [NUMERICAL]\n",
            "\t135 : data:0.525 [NUMERICAL]\n",
            "\t134 : data:0.566 [NUMERICAL]\n",
            "\t134 : data:0.124 [NUMERICAL]\n",
            "\t133 : data:0.652 [NUMERICAL]\n",
            "\t133 : data:0.302 [NUMERICAL]\n",
            "\t132 : data:0.681 [NUMERICAL]\n",
            "\t131 : data:0.342 [NUMERICAL]\n",
            "\t129 : data:0.662 [NUMERICAL]\n",
            "\t129 : data:0.594 [NUMERICAL]\n",
            "\t127 : data:0.682 [NUMERICAL]\n",
            "\t126 : data:0.149 [NUMERICAL]\n",
            "\t125 : data:0.370 [NUMERICAL]\n",
            "\t123 : data:0.386 [NUMERICAL]\n",
            "\t121 : data:0.130 [NUMERICAL]\n",
            "\t120 : data:0.470 [NUMERICAL]\n",
            "\t118 : data:0.231 [NUMERICAL]\n",
            "\t116 : data:0.160 [NUMERICAL]\n",
            "\t115 : data:0.581 [NUMERICAL]\n",
            "\t115 : data:0.498 [NUMERICAL]\n",
            "\t115 : data:0.176 [NUMERICAL]\n",
            "\t113 : data:0.688 [NUMERICAL]\n",
            "\t112 : data:0.247 [NUMERICAL]\n",
            "\t109 : data:0.414 [NUMERICAL]\n",
            "\t108 : data:0.131 [NUMERICAL]\n",
            "\t107 : data:0.123 [NUMERICAL]\n",
            "\t106 : data:0.554 [NUMERICAL]\n",
            "\t105 : data:0.259 [NUMERICAL]\n",
            "\t100 : data:0.161 [NUMERICAL]\n",
            "\t98 : data:0.219 [NUMERICAL]\n",
            "\t98 : data:0.190 [NUMERICAL]\n",
            "\t96 : data:0.442 [NUMERICAL]\n",
            "\t95 : data:0.680 [NUMERICAL]\n",
            "\t92 : data:0.275 [NUMERICAL]\n",
            "\t91 : data:0.526 [NUMERICAL]\n",
            "\t90 : data:0.314 [NUMERICAL]\n",
            "\t90 : data:0.286 [NUMERICAL]\n",
            "\t88 : data:0.689 [NUMERICAL]\n",
            "\t87 : data:0.537 [NUMERICAL]\n",
            "\t86 : data:0.651 [NUMERICAL]\n",
            "\t86 : data:0.609 [NUMERICAL]\n",
            "\t86 : data:0.203 [NUMERICAL]\n",
            "\t85 : data:0.622 [NUMERICAL]\n",
            "\t81 : data:0.258 [NUMERICAL]\n",
            "\t79 : data:0.663 [NUMERICAL]\n",
            "\t73 : data:0.679 [NUMERICAL]\n",
            "\t71 : data:0.509 [NUMERICAL]\n",
            "\t71 : data:0.132 [NUMERICAL]\n",
            "\t70 : data:0.122 [NUMERICAL]\n",
            "\t70 : data:0.101 [NUMERICAL]\n",
            "\t69 : data:0.636 [NUMERICAL]\n",
            "\t69 : data:0.230 [NUMERICAL]\n",
            "\t68 : data:0.565 [NUMERICAL]\n",
            "\t68 : data:0.443 [NUMERICAL]\n",
            "\t68 : data:0.331 [NUMERICAL]\n",
            "\t68 : data:0.162 [NUMERICAL]\n",
            "\t67 : data:0.425 [NUMERICAL]\n",
            "\t67 : data:0.175 [NUMERICAL]\n",
            "\t66 : data:0.100 [NUMERICAL]\n",
            "\t64 : data:0.709 [NUMERICAL]\n",
            "\t64 : data:0.527 [NUMERICAL]\n",
            "\t63 : data:0.415 [NUMERICAL]\n",
            "\t63 : data:0.359 [NUMERICAL]\n",
            "\t63 : data:0.303 [NUMERICAL]\n",
            "\t62 : data:0.712 [NUMERICAL]\n",
            "\t62 : data:0.453 [NUMERICAL]\n",
            "\t61 : data:0.690 [NUMERICAL]\n",
            "\t61 : data:0.248 [NUMERICAL]\n",
            "\t59 : data:0.99 [NUMERICAL]\n",
            "\t59 : data:0.711 [NUMERICAL]\n",
            "\t59 : data:0.191 [NUMERICAL]\n",
            "\t59 : data:0.102 [NUMERICAL]\n",
            "\t58 : data:0.710 [NUMERICAL]\n",
            "\t58 : data:0.637 [NUMERICAL]\n",
            "\t58 : data:0.582 [NUMERICAL]\n",
            "\t57 : data:0.397 [NUMERICAL]\n",
            "\t57 : data:0.341 [NUMERICAL]\n",
            "\t56 : data:0.481 [NUMERICAL]\n",
            "\t56 : data:0.387 [NUMERICAL]\n",
            "\t54 : data:0.202 [NUMERICAL]\n",
            "\t52 : data:0.98 [NUMERICAL]\n",
            "\t52 : data:0.148 [NUMERICAL]\n",
            "\t51 : data:0.715 [NUMERICAL]\n",
            "\t51 : data:0.650 [NUMERICAL]\n",
            "\t51 : data:0.220 [NUMERICAL]\n",
            "\t50 : data:0.471 [NUMERICAL]\n",
            "\t49 : data:0.713 [NUMERICAL]\n",
            "\t47 : data:0.593 [NUMERICAL]\n",
            "\t47 : data:0.499 [NUMERICAL]\n",
            "\t45 : data:0.103 [NUMERICAL]\n",
            "\t44 : data:0.313 [NUMERICAL]\n",
            "\t43 : data:0.716 [NUMERICAL]\n",
            "\t42 : data:0.714 [NUMERICAL]\n",
            "\t40 : data:0.708 [NUMERICAL]\n",
            "\t39 : data:0.691 [NUMERICAL]\n",
            "\t39 : data:0.555 [NUMERICAL]\n",
            "\t39 : data:0.369 [NUMERICAL]\n",
            "\t39 : data:0.285 [NUMERICAL]\n",
            "\t38 : data:0.121 [NUMERICAL]\n",
            "\t37 : data:0.97 [NUMERICAL]\n",
            "\t37 : data:0.610 [NUMERICAL]\n",
            "\t35 : data:0.583 [NUMERICAL]\n",
            "\t35 : data:0.536 [NUMERICAL]\n",
            "\t34 : data:0.664 [NUMERICAL]\n",
            "\t33 : data:0.678 [NUMERICAL]\n",
            "\t31 : data:0.96 [NUMERICAL]\n",
            "\t30 : data:0.133 [NUMERICAL]\n",
            "\t29 : data:0.717 [NUMERICAL]\n",
            "\t28 : data:0.707 [NUMERICAL]\n",
            "\t28 : data:0.276 [NUMERICAL]\n",
            "\t28 : data:0.257 [NUMERICAL]\n",
            "\t27 : data:0.649 [NUMERICAL]\n",
            "\t27 : data:0.621 [NUMERICAL]\n",
            "\t26 : data:0.163 [NUMERICAL]\n",
            "\t26 : data:0.147 [NUMERICAL]\n",
            "\t25 : data:0.95 [NUMERICAL]\n",
            "\t25 : data:0.564 [NUMERICAL]\n",
            "\t24 : data:0.692 [NUMERICAL]\n",
            "\t24 : data:0.480 [NUMERICAL]\n",
            "\t24 : data:0.229 [NUMERICAL]\n",
            "\t23 : data:0.192 [NUMERICAL]\n",
            "\t23 : data:0.174 [NUMERICAL]\n",
            "\t22 : data:0.472 [NUMERICAL]\n",
            "\t21 : data:0.500 [NUMERICAL]\n",
            "\t19 : data:0.611 [NUMERICAL]\n",
            "\t19 : data:0.592 [NUMERICAL]\n",
            "\t19 : data:0.528 [NUMERICAL]\n",
            "\t18 : data:0.718 [NUMERICAL]\n",
            "\t18 : data:0.508 [NUMERICAL]\n",
            "\t18 : data:0.444 [NUMERICAL]\n",
            "\t18 : data:0.304 [NUMERICAL]\n",
            "\t17 : data:0.120 [NUMERICAL]\n",
            "\t16 : data:0.719 [NUMERICAL]\n",
            "\t16 : data:0.146 [NUMERICAL]\n",
            "\t15 : data:0.638 [NUMERICAL]\n",
            "\t15 : data:0.340 [NUMERICAL]\n",
            "\t15 : data:0.201 [NUMERICAL]\n",
            "\t15 : data:0.173 [NUMERICAL]\n",
            "\t15 : data:0.134 [NUMERICAL]\n",
            "\t15 : data:0.104 [NUMERICAL]\n",
            "\t14 : data:0.94 [NUMERICAL]\n",
            "\t14 : data:0.452 [NUMERICAL]\n",
            "\t14 : data:0.424 [NUMERICAL]\n",
            "\t14 : data:0.416 [NUMERICAL]\n",
            "\t13 : data:0.744 [NUMERICAL]\n",
            "\t13 : data:0.556 [NUMERICAL]\n",
            "\t13 : data:0.256 [NUMERICAL]\n",
            "\t12 : data:0.677 [NUMERICAL]\n",
            "\t12 : data:0.665 [NUMERICAL]\n",
            "\t12 : data:0.396 [NUMERICAL]\n",
            "\t12 : data:0.368 [NUMERICAL]\n",
            "\t12 : data:0.135 [NUMERICAL]\n",
            "\t11 : data:0.249 [NUMERICAL]\n",
            "\t11 : data:0.164 [NUMERICAL]\n",
            "\t10 : data:0.388 [NUMERICAL]\n",
            "\t10 : data:0.332 [NUMERICAL]\n",
            "\t10 : data:0.312 [NUMERICAL]\n",
            "\t9 : data:0.740 [NUMERICAL]\n",
            "\t9 : data:0.360 [NUMERICAL]\n",
            "\t9 : data:0.284 [NUMERICAL]\n",
            "\t9 : data:0.228 [NUMERICAL]\n",
            "\t9 : data:0.105 [NUMERICAL]\n",
            "\t8 : data:0.92 [NUMERICAL]\n",
            "\t8 : data:0.69 [NUMERICAL]\n",
            "\t8 : data:0.620 [NUMERICAL]\n",
            "\t7 : data:0.93 [NUMERICAL]\n",
            "\t7 : data:0.742 [NUMERICAL]\n",
            "\t7 : data:0.720 [NUMERICAL]\n",
            "\t7 : data:0.706 [NUMERICAL]\n",
            "\t7 : data:0.529 [NUMERICAL]\n",
            "\t7 : data:0.106 [NUMERICAL]\n",
            "\t6 : data:0.743 [NUMERICAL]\n",
            "\t6 : data:0.741 [NUMERICAL]\n",
            "\t6 : data:0.737 [NUMERICAL]\n",
            "\t6 : data:0.71 [NUMERICAL]\n",
            "\t6 : data:0.693 [NUMERICAL]\n",
            "\t6 : data:0.67 [NUMERICAL]\n",
            "\t6 : data:0.145 [NUMERICAL]\n",
            "\t5 : data:0.739 [NUMERICAL]\n",
            "\t5 : data:0.72 [NUMERICAL]\n",
            "\t5 : data:0.68 [NUMERICAL]\n",
            "\t5 : data:0.648 [NUMERICAL]\n",
            "\t4 : data:0.705 [NUMERICAL]\n",
            "\t4 : data:0.70 [NUMERICAL]\n",
            "\t4 : data:0.694 [NUMERICAL]\n",
            "\t4 : data:0.200 [NUMERICAL]\n",
            "\t4 : data:0.193 [NUMERICAL]\n",
            "\t3 : data:0.746 [NUMERICAL]\n",
            "\t3 : data:0.745 [NUMERICAL]\n",
            "\t3 : data:0.738 [NUMERICAL]\n",
            "\t3 : data:0.666 [NUMERICAL]\n",
            "\t3 : data:0.639 [NUMERICAL]\n",
            "\t3 : data:0.612 [NUMERICAL]\n",
            "\t3 : data:0.584 [NUMERICAL]\n",
            "\t3 : data:0.501 [NUMERICAL]\n",
            "\t3 : data:0.445 [NUMERICAL]\n",
            "\t3 : data:0.311 [NUMERICAL]\n",
            "\t3 : data:0.305 [NUMERICAL]\n",
            "\t3 : data:0.277 [NUMERICAL]\n",
            "\t3 : data:0.255 [NUMERICAL]\n",
            "\t3 : data:0.119 [NUMERICAL]\n",
            "\t2 : data:0.91 [NUMERICAL]\n",
            "\t2 : data:0.748 [NUMERICAL]\n",
            "\t2 : data:0.734 [NUMERICAL]\n",
            "\t2 : data:0.733 [NUMERICAL]\n",
            "\t2 : data:0.732 [NUMERICAL]\n",
            "\t2 : data:0.73 [NUMERICAL]\n",
            "\t2 : data:0.722 [NUMERICAL]\n",
            "\t2 : data:0.721 [NUMERICAL]\n",
            "\t2 : data:0.704 [NUMERICAL]\n",
            "\t2 : data:0.66 [NUMERICAL]\n",
            "\t2 : data:0.65 [NUMERICAL]\n",
            "\t2 : data:0.640 [NUMERICAL]\n",
            "\t2 : data:0.619 [NUMERICAL]\n",
            "\t2 : data:0.563 [NUMERICAL]\n",
            "\t2 : data:0.507 [NUMERICAL]\n",
            "\t2 : data:0.473 [NUMERICAL]\n",
            "\t2 : data:0.451 [NUMERICAL]\n",
            "\t2 : data:0.417 [NUMERICAL]\n",
            "\t2 : data:0.389 [NUMERICAL]\n",
            "\t2 : data:0.221 [NUMERICAL]\n",
            "\t2 : data:0.172 [NUMERICAL]\n",
            "\t2 : data:0.136 [NUMERICAL]\n",
            "\t2 : data:0.118 [NUMERICAL]\n",
            "\t1 : data:0.90 [NUMERICAL]\n",
            "\t1 : data:0.89 [NUMERICAL]\n",
            "\t1 : data:0.772 [NUMERICAL]\n",
            "\t1 : data:0.770 [NUMERICAL]\n",
            "\t1 : data:0.76 [NUMERICAL]\n",
            "\t1 : data:0.747 [NUMERICAL]\n",
            "\t1 : data:0.74 [NUMERICAL]\n",
            "\t1 : data:0.736 [NUMERICAL]\n",
            "\t1 : data:0.735 [NUMERICAL]\n",
            "\t1 : data:0.676 [NUMERICAL]\n",
            "\t1 : data:0.668 [NUMERICAL]\n",
            "\t1 : data:0.667 [NUMERICAL]\n",
            "\t1 : data:0.647 [NUMERICAL]\n",
            "\t1 : data:0.64 [NUMERICAL]\n",
            "\t1 : data:0.591 [NUMERICAL]\n",
            "\t1 : data:0.585 [NUMERICAL]\n",
            "\t1 : data:0.562 [NUMERICAL]\n",
            "\t1 : data:0.557 [NUMERICAL]\n",
            "\t1 : data:0.535 [NUMERICAL]\n",
            "\t1 : data:0.479 [NUMERICAL]\n",
            "\t1 : data:0.474 [NUMERICAL]\n",
            "\t1 : data:0.367 [NUMERICAL]\n",
            "\t1 : data:0.339 [NUMERICAL]\n",
            "\t1 : data:0.333 [NUMERICAL]\n",
            "\t1 : data:0.278 [NUMERICAL]\n",
            "\t1 : data:0.199 [NUMERICAL]\n",
            "\t1 : data:0.194 [NUMERICAL]\n",
            "\t1 : data:0.165 [NUMERICAL]\n",
            "\t1 : data:0.108 [NUMERICAL]\n",
            "\t1 : data:0.107 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t5 : data:0.569 [NUMERICAL]\n",
            "\t5 : data:0.378 [NUMERICAL]\n",
            "\t4 : data:0.568 [NUMERICAL]\n",
            "\t3 : data:0.350 [NUMERICAL]\n",
            "\t3 : data:0.345 [NUMERICAL]\n",
            "\t3 : data:0.155 [NUMERICAL]\n",
            "\t2 : data:0.515 [NUMERICAL]\n",
            "\t2 : data:0.428 [NUMERICAL]\n",
            "\t2 : data:0.377 [NUMERICAL]\n",
            "\t2 : data:0.290 [NUMERICAL]\n",
            "\t1 : data:0.625 [NUMERICAL]\n",
            "\t1 : data:0.596 [NUMERICAL]\n",
            "\t1 : data:0.551 [NUMERICAL]\n",
            "\t1 : data:0.540 [NUMERICAL]\n",
            "\t1 : data:0.539 [NUMERICAL]\n",
            "\t1 : data:0.489 [NUMERICAL]\n",
            "\t1 : data:0.484 [NUMERICAL]\n",
            "\t1 : data:0.462 [NUMERICAL]\n",
            "\t1 : data:0.461 [NUMERICAL]\n",
            "\t1 : data:0.433 [NUMERICAL]\n",
            "\t1 : data:0.409 [NUMERICAL]\n",
            "\t1 : data:0.406 [NUMERICAL]\n",
            "\t1 : data:0.401 [NUMERICAL]\n",
            "\t1 : data:0.346 [NUMERICAL]\n",
            "\t1 : data:0.318 [NUMERICAL]\n",
            "\t1 : data:0.317 [NUMERICAL]\n",
            "\t1 : data:0.291 [NUMERICAL]\n",
            "\t1 : data:0.154 [NUMERICAL]\n",
            "\t1 : data:0.153 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t8 : data:0.569 [NUMERICAL]\n",
            "\t7 : data:0.568 [NUMERICAL]\n",
            "\t7 : data:0.378 [NUMERICAL]\n",
            "\t6 : data:0.406 [NUMERICAL]\n",
            "\t6 : data:0.345 [NUMERICAL]\n",
            "\t4 : data:0.461 [NUMERICAL]\n",
            "\t4 : data:0.377 [NUMERICAL]\n",
            "\t4 : data:0.350 [NUMERICAL]\n",
            "\t4 : data:0.291 [NUMERICAL]\n",
            "\t4 : data:0.155 [NUMERICAL]\n",
            "\t3 : data:0.625 [NUMERICAL]\n",
            "\t3 : data:0.539 [NUMERICAL]\n",
            "\t3 : data:0.489 [NUMERICAL]\n",
            "\t3 : data:0.460 [NUMERICAL]\n",
            "\t3 : data:0.409 [NUMERICAL]\n",
            "\t3 : data:0.408 [NUMERICAL]\n",
            "\t3 : data:0.401 [NUMERICAL]\n",
            "\t3 : data:0.375 [NUMERICAL]\n",
            "\t3 : data:0.290 [NUMERICAL]\n",
            "\t2 : data:0.540 [NUMERICAL]\n",
            "\t2 : data:0.515 [NUMERICAL]\n",
            "\t2 : data:0.487 [NUMERICAL]\n",
            "\t2 : data:0.484 [NUMERICAL]\n",
            "\t2 : data:0.462 [NUMERICAL]\n",
            "\t2 : data:0.456 [NUMERICAL]\n",
            "\t2 : data:0.435 [NUMERICAL]\n",
            "\t2 : data:0.433 [NUMERICAL]\n",
            "\t2 : data:0.428 [NUMERICAL]\n",
            "\t2 : data:0.405 [NUMERICAL]\n",
            "\t2 : data:0.346 [NUMERICAL]\n",
            "\t2 : data:0.318 [NUMERICAL]\n",
            "\t2 : data:0.317 [NUMERICAL]\n",
            "\t2 : data:0.263 [NUMERICAL]\n",
            "\t2 : data:0.156 [NUMERICAL]\n",
            "\t1 : data:0.658 [NUMERICAL]\n",
            "\t1 : data:0.657 [NUMERICAL]\n",
            "\t1 : data:0.597 [NUMERICAL]\n",
            "\t1 : data:0.596 [NUMERICAL]\n",
            "\t1 : data:0.578 [NUMERICAL]\n",
            "\t1 : data:0.577 [NUMERICAL]\n",
            "\t1 : data:0.570 [NUMERICAL]\n",
            "\t1 : data:0.567 [NUMERICAL]\n",
            "\t1 : data:0.551 [NUMERICAL]\n",
            "\t1 : data:0.543 [NUMERICAL]\n",
            "\t1 : data:0.522 [NUMERICAL]\n",
            "\t1 : data:0.516 [NUMERICAL]\n",
            "\t1 : data:0.495 [NUMERICAL]\n",
            "\t1 : data:0.490 [NUMERICAL]\n",
            "\t1 : data:0.488 [NUMERICAL]\n",
            "\t1 : data:0.465 [NUMERICAL]\n",
            "\t1 : data:0.463 [NUMERICAL]\n",
            "\t1 : data:0.432 [NUMERICAL]\n",
            "\t1 : data:0.430 [NUMERICAL]\n",
            "\t1 : data:0.429 [NUMERICAL]\n",
            "\t1 : data:0.427 [NUMERICAL]\n",
            "\t1 : data:0.413 [NUMERICAL]\n",
            "\t1 : data:0.410 [NUMERICAL]\n",
            "\t1 : data:0.400 [NUMERICAL]\n",
            "\t1 : data:0.379 [NUMERICAL]\n",
            "\t1 : data:0.373 [NUMERICAL]\n",
            "\t1 : data:0.354 [NUMERICAL]\n",
            "\t1 : data:0.352 [NUMERICAL]\n",
            "\t1 : data:0.351 [NUMERICAL]\n",
            "\t1 : data:0.326 [NUMERICAL]\n",
            "\t1 : data:0.322 [NUMERICAL]\n",
            "\t1 : data:0.269 [NUMERICAL]\n",
            "\t1 : data:0.238 [NUMERICAL]\n",
            "\t1 : data:0.234 [NUMERICAL]\n",
            "\t1 : data:0.207 [NUMERICAL]\n",
            "\t1 : data:0.183 [NUMERICAL]\n",
            "\t1 : data:0.157 [NUMERICAL]\n",
            "\t1 : data:0.154 [NUMERICAL]\n",
            "\t1 : data:0.153 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t9 : data:0.569 [NUMERICAL]\n",
            "\t9 : data:0.378 [NUMERICAL]\n",
            "\t8 : data:0.406 [NUMERICAL]\n",
            "\t7 : data:0.568 [NUMERICAL]\n",
            "\t7 : data:0.515 [NUMERICAL]\n",
            "\t7 : data:0.428 [NUMERICAL]\n",
            "\t7 : data:0.345 [NUMERICAL]\n",
            "\t7 : data:0.155 [NUMERICAL]\n",
            "\t6 : data:0.409 [NUMERICAL]\n",
            "\t6 : data:0.291 [NUMERICAL]\n",
            "\t5 : data:0.487 [NUMERICAL]\n",
            "\t5 : data:0.461 [NUMERICAL]\n",
            "\t5 : data:0.460 [NUMERICAL]\n",
            "\t5 : data:0.408 [NUMERICAL]\n",
            "\t5 : data:0.377 [NUMERICAL]\n",
            "\t5 : data:0.350 [NUMERICAL]\n",
            "\t5 : data:0.290 [NUMERICAL]\n",
            "\t4 : data:0.625 [NUMERICAL]\n",
            "\t4 : data:0.542 [NUMERICAL]\n",
            "\t4 : data:0.540 [NUMERICAL]\n",
            "\t4 : data:0.539 [NUMERICAL]\n",
            "\t4 : data:0.489 [NUMERICAL]\n",
            "\t4 : data:0.488 [NUMERICAL]\n",
            "\t4 : data:0.405 [NUMERICAL]\n",
            "\t4 : data:0.401 [NUMERICAL]\n",
            "\t4 : data:0.375 [NUMERICAL]\n",
            "\t4 : data:0.374 [NUMERICAL]\n",
            "\t4 : data:0.349 [NUMERICAL]\n",
            "\t3 : data:0.658 [NUMERICAL]\n",
            "\t3 : data:0.657 [NUMERICAL]\n",
            "\t3 : data:0.656 [NUMERICAL]\n",
            "\t3 : data:0.655 [NUMERICAL]\n",
            "\t3 : data:0.570 [NUMERICAL]\n",
            "\t3 : data:0.550 [NUMERICAL]\n",
            "\t3 : data:0.522 [NUMERICAL]\n",
            "\t3 : data:0.484 [NUMERICAL]\n",
            "\t3 : data:0.463 [NUMERICAL]\n",
            "\t3 : data:0.462 [NUMERICAL]\n",
            "\t3 : data:0.456 [NUMERICAL]\n",
            "\t3 : data:0.435 [NUMERICAL]\n",
            "\t3 : data:0.433 [NUMERICAL]\n",
            "\t3 : data:0.379 [NUMERICAL]\n",
            "\t3 : data:0.373 [NUMERICAL]\n",
            "\t3 : data:0.346 [NUMERICAL]\n",
            "\t3 : data:0.318 [NUMERICAL]\n",
            "\t3 : data:0.156 [NUMERICAL]\n",
            "\t3 : data:0.154 [NUMERICAL]\n",
            "\t3 : data:0.153 [NUMERICAL]\n",
            "\t2 : data:0.651 [NUMERICAL]\n",
            "\t2 : data:0.598 [NUMERICAL]\n",
            "\t2 : data:0.597 [NUMERICAL]\n",
            "\t2 : data:0.596 [NUMERICAL]\n",
            "\t2 : data:0.541 [NUMERICAL]\n",
            "\t2 : data:0.516 [NUMERICAL]\n",
            "\t2 : data:0.514 [NUMERICAL]\n",
            "\t2 : data:0.496 [NUMERICAL]\n",
            "\t2 : data:0.494 [NUMERICAL]\n",
            "\t2 : data:0.490 [NUMERICAL]\n",
            "\t2 : data:0.467 [NUMERICAL]\n",
            "\t2 : data:0.465 [NUMERICAL]\n",
            "\t2 : data:0.437 [NUMERICAL]\n",
            "\t2 : data:0.434 [NUMERICAL]\n",
            "\t2 : data:0.430 [NUMERICAL]\n",
            "\t2 : data:0.429 [NUMERICAL]\n",
            "\t2 : data:0.426 [NUMERICAL]\n",
            "\t2 : data:0.410 [NUMERICAL]\n",
            "\t2 : data:0.400 [NUMERICAL]\n",
            "\t2 : data:0.381 [NUMERICAL]\n",
            "\t2 : data:0.372 [NUMERICAL]\n",
            "\t2 : data:0.354 [NUMERICAL]\n",
            "\t2 : data:0.351 [NUMERICAL]\n",
            "\t2 : data:0.348 [NUMERICAL]\n",
            "\t2 : data:0.330 [NUMERICAL]\n",
            "\t2 : data:0.329 [NUMERICAL]\n",
            "\t2 : data:0.322 [NUMERICAL]\n",
            "\t2 : data:0.317 [NUMERICAL]\n",
            "\t2 : data:0.269 [NUMERICAL]\n",
            "\t2 : data:0.263 [NUMERICAL]\n",
            "\t2 : data:0.207 [NUMERICAL]\n",
            "\t2 : data:0.185 [NUMERICAL]\n",
            "\t2 : data:0.157 [NUMERICAL]\n",
            "\t2 : data:0.152 [NUMERICAL]\n",
            "\t2 : data:0.125 [NUMERICAL]\n",
            "\t2 : data:0.124 [NUMERICAL]\n",
            "\t1 : data:0.97 [NUMERICAL]\n",
            "\t1 : data:0.654 [NUMERICAL]\n",
            "\t1 : data:0.628 [NUMERICAL]\n",
            "\t1 : data:0.626 [NUMERICAL]\n",
            "\t1 : data:0.603 [NUMERICAL]\n",
            "\t1 : data:0.595 [NUMERICAL]\n",
            "\t1 : data:0.578 [NUMERICAL]\n",
            "\t1 : data:0.577 [NUMERICAL]\n",
            "\t1 : data:0.571 [NUMERICAL]\n",
            "\t1 : data:0.567 [NUMERICAL]\n",
            "\t1 : data:0.566 [NUMERICAL]\n",
            "\t1 : data:0.551 [NUMERICAL]\n",
            "\t1 : data:0.545 [NUMERICAL]\n",
            "\t1 : data:0.543 [NUMERICAL]\n",
            "\t1 : data:0.526 [NUMERICAL]\n",
            "\t1 : data:0.524 [NUMERICAL]\n",
            "\t1 : data:0.523 [NUMERICAL]\n",
            "\t1 : data:0.521 [NUMERICAL]\n",
            "\t1 : data:0.517 [NUMERICAL]\n",
            "\t1 : data:0.513 [NUMERICAL]\n",
            "\t1 : data:0.511 [NUMERICAL]\n",
            "\t1 : data:0.495 [NUMERICAL]\n",
            "\t1 : data:0.485 [NUMERICAL]\n",
            "\t1 : data:0.466 [NUMERICAL]\n",
            "\t1 : data:0.464 [NUMERICAL]\n",
            "\t1 : data:0.457 [NUMERICAL]\n",
            "\t1 : data:0.455 [NUMERICAL]\n",
            "\t1 : data:0.436 [NUMERICAL]\n",
            "\t1 : data:0.432 [NUMERICAL]\n",
            "\t1 : data:0.427 [NUMERICAL]\n",
            "\t1 : data:0.413 [NUMERICAL]\n",
            "\t1 : data:0.407 [NUMERICAL]\n",
            "\t1 : data:0.404 [NUMERICAL]\n",
            "\t1 : data:0.403 [NUMERICAL]\n",
            "\t1 : data:0.402 [NUMERICAL]\n",
            "\t1 : data:0.399 [NUMERICAL]\n",
            "\t1 : data:0.382 [NUMERICAL]\n",
            "\t1 : data:0.380 [NUMERICAL]\n",
            "\t1 : data:0.376 [NUMERICAL]\n",
            "\t1 : data:0.357 [NUMERICAL]\n",
            "\t1 : data:0.352 [NUMERICAL]\n",
            "\t1 : data:0.347 [NUMERICAL]\n",
            "\t1 : data:0.343 [NUMERICAL]\n",
            "\t1 : data:0.327 [NUMERICAL]\n",
            "\t1 : data:0.326 [NUMERICAL]\n",
            "\t1 : data:0.319 [NUMERICAL]\n",
            "\t1 : data:0.316 [NUMERICAL]\n",
            "\t1 : data:0.298 [NUMERICAL]\n",
            "\t1 : data:0.273 [NUMERICAL]\n",
            "\t1 : data:0.271 [NUMERICAL]\n",
            "\t1 : data:0.268 [NUMERICAL]\n",
            "\t1 : data:0.267 [NUMERICAL]\n",
            "\t1 : data:0.243 [NUMERICAL]\n",
            "\t1 : data:0.240 [NUMERICAL]\n",
            "\t1 : data:0.238 [NUMERICAL]\n",
            "\t1 : data:0.235 [NUMERICAL]\n",
            "\t1 : data:0.234 [NUMERICAL]\n",
            "\t1 : data:0.218 [NUMERICAL]\n",
            "\t1 : data:0.212 [NUMERICAL]\n",
            "\t1 : data:0.211 [NUMERICAL]\n",
            "\t1 : data:0.186 [NUMERICAL]\n",
            "\t1 : data:0.184 [NUMERICAL]\n",
            "\t1 : data:0.183 [NUMERICAL]\n",
            "\t1 : data:0.151 [NUMERICAL]\n",
            "\t1 : data:0.127 [NUMERICAL]\n",
            "\t1 : data:0.100 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t14 : data:0.378 [NUMERICAL]\n",
            "\t12 : data:0.406 [NUMERICAL]\n",
            "\t11 : data:0.515 [NUMERICAL]\n",
            "\t11 : data:0.461 [NUMERICAL]\n",
            "\t11 : data:0.409 [NUMERICAL]\n",
            "\t11 : data:0.155 [NUMERICAL]\n",
            "\t10 : data:0.428 [NUMERICAL]\n",
            "\t9 : data:0.569 [NUMERICAL]\n",
            "\t9 : data:0.568 [NUMERICAL]\n",
            "\t9 : data:0.487 [NUMERICAL]\n",
            "\t9 : data:0.377 [NUMERICAL]\n",
            "\t9 : data:0.291 [NUMERICAL]\n",
            "\t8 : data:0.656 [NUMERICAL]\n",
            "\t8 : data:0.596 [NUMERICAL]\n",
            "\t8 : data:0.347 [NUMERICAL]\n",
            "\t8 : data:0.345 [NUMERICAL]\n",
            "\t7 : data:0.625 [NUMERICAL]\n",
            "\t7 : data:0.489 [NUMERICAL]\n",
            "\t7 : data:0.457 [NUMERICAL]\n",
            "\t7 : data:0.405 [NUMERICAL]\n",
            "\t7 : data:0.351 [NUMERICAL]\n",
            "\t7 : data:0.154 [NUMERICAL]\n",
            "\t7 : data:0.153 [NUMERICAL]\n",
            "\t6 : data:0.658 [NUMERICAL]\n",
            "\t6 : data:0.655 [NUMERICAL]\n",
            "\t6 : data:0.654 [NUMERICAL]\n",
            "\t6 : data:0.570 [NUMERICAL]\n",
            "\t6 : data:0.542 [NUMERICAL]\n",
            "\t6 : data:0.490 [NUMERICAL]\n",
            "\t6 : data:0.488 [NUMERICAL]\n",
            "\t6 : data:0.462 [NUMERICAL]\n",
            "\t6 : data:0.460 [NUMERICAL]\n",
            "\t6 : data:0.456 [NUMERICAL]\n",
            "\t6 : data:0.401 [NUMERICAL]\n",
            "\t6 : data:0.375 [NUMERICAL]\n",
            "\t6 : data:0.350 [NUMERICAL]\n",
            "\t6 : data:0.349 [NUMERICAL]\n",
            "\t6 : data:0.348 [NUMERICAL]\n",
            "\t6 : data:0.290 [NUMERICAL]\n",
            "\t6 : data:0.263 [NUMERICAL]\n",
            "\t5 : data:0.550 [NUMERICAL]\n",
            "\t5 : data:0.540 [NUMERICAL]\n",
            "\t5 : data:0.466 [NUMERICAL]\n",
            "\t5 : data:0.463 [NUMERICAL]\n",
            "\t5 : data:0.458 [NUMERICAL]\n",
            "\t5 : data:0.435 [NUMERICAL]\n",
            "\t5 : data:0.410 [NUMERICAL]\n",
            "\t5 : data:0.408 [NUMERICAL]\n",
            "\t5 : data:0.403 [NUMERICAL]\n",
            "\t5 : data:0.400 [NUMERICAL]\n",
            "\t5 : data:0.379 [NUMERICAL]\n",
            "\t5 : data:0.374 [NUMERICAL]\n",
            "\t5 : data:0.346 [NUMERICAL]\n",
            "\t5 : data:0.211 [NUMERICAL]\n",
            "\t5 : data:0.156 [NUMERICAL]\n",
            "\t4 : data:0.657 [NUMERICAL]\n",
            "\t4 : data:0.597 [NUMERICAL]\n",
            "\t4 : data:0.595 [NUMERICAL]\n",
            "\t4 : data:0.551 [NUMERICAL]\n",
            "\t4 : data:0.541 [NUMERICAL]\n",
            "\t4 : data:0.539 [NUMERICAL]\n",
            "\t4 : data:0.522 [NUMERICAL]\n",
            "\t4 : data:0.516 [NUMERICAL]\n",
            "\t4 : data:0.514 [NUMERICAL]\n",
            "\t4 : data:0.485 [NUMERICAL]\n",
            "\t4 : data:0.433 [NUMERICAL]\n",
            "\t4 : data:0.432 [NUMERICAL]\n",
            "\t4 : data:0.429 [NUMERICAL]\n",
            "\t4 : data:0.380 [NUMERICAL]\n",
            "\t4 : data:0.373 [NUMERICAL]\n",
            "\t4 : data:0.354 [NUMERICAL]\n",
            "\t4 : data:0.352 [NUMERICAL]\n",
            "\t4 : data:0.322 [NUMERICAL]\n",
            "\t4 : data:0.320 [NUMERICAL]\n",
            "\t4 : data:0.292 [NUMERICAL]\n",
            "\t4 : data:0.270 [NUMERICAL]\n",
            "\t4 : data:0.152 [NUMERICAL]\n",
            "\t4 : data:0.127 [NUMERICAL]\n",
            "\t3 : data:0.660 [NUMERICAL]\n",
            "\t3 : data:0.651 [NUMERICAL]\n",
            "\t3 : data:0.578 [NUMERICAL]\n",
            "\t3 : data:0.571 [NUMERICAL]\n",
            "\t3 : data:0.543 [NUMERICAL]\n",
            "\t3 : data:0.524 [NUMERICAL]\n",
            "\t3 : data:0.484 [NUMERICAL]\n",
            "\t3 : data:0.437 [NUMERICAL]\n",
            "\t3 : data:0.436 [NUMERICAL]\n",
            "\t3 : data:0.434 [NUMERICAL]\n",
            "\t3 : data:0.430 [NUMERICAL]\n",
            "\t3 : data:0.427 [NUMERICAL]\n",
            "\t3 : data:0.407 [NUMERICAL]\n",
            "\t3 : data:0.382 [NUMERICAL]\n",
            "\t3 : data:0.381 [NUMERICAL]\n",
            "\t3 : data:0.357 [NUMERICAL]\n",
            "\t3 : data:0.319 [NUMERICAL]\n",
            "\t3 : data:0.318 [NUMERICAL]\n",
            "\t3 : data:0.317 [NUMERICAL]\n",
            "\t3 : data:0.316 [NUMERICAL]\n",
            "\t3 : data:0.298 [NUMERICAL]\n",
            "\t3 : data:0.269 [NUMERICAL]\n",
            "\t3 : data:0.267 [NUMERICAL]\n",
            "\t3 : data:0.243 [NUMERICAL]\n",
            "\t3 : data:0.240 [NUMERICAL]\n",
            "\t3 : data:0.216 [NUMERICAL]\n",
            "\t3 : data:0.215 [NUMERICAL]\n",
            "\t3 : data:0.209 [NUMERICAL]\n",
            "\t3 : data:0.207 [NUMERICAL]\n",
            "\t3 : data:0.182 [NUMERICAL]\n",
            "\t3 : data:0.100 [NUMERICAL]\n",
            "\t2 : data:0.659 [NUMERICAL]\n",
            "\t2 : data:0.631 [NUMERICAL]\n",
            "\t2 : data:0.628 [NUMERICAL]\n",
            "\t2 : data:0.627 [NUMERICAL]\n",
            "\t2 : data:0.606 [NUMERICAL]\n",
            "\t2 : data:0.599 [NUMERICAL]\n",
            "\t2 : data:0.598 [NUMERICAL]\n",
            "\t2 : data:0.594 [NUMERICAL]\n",
            "\t2 : data:0.567 [NUMERICAL]\n",
            "\t2 : data:0.545 [NUMERICAL]\n",
            "\t2 : data:0.523 [NUMERICAL]\n",
            "\t2 : data:0.521 [NUMERICAL]\n",
            "\t2 : data:0.517 [NUMERICAL]\n",
            "\t2 : data:0.513 [NUMERICAL]\n",
            "\t2 : data:0.512 [NUMERICAL]\n",
            "\t2 : data:0.496 [NUMERICAL]\n",
            "\t2 : data:0.494 [NUMERICAL]\n",
            "\t2 : data:0.493 [NUMERICAL]\n",
            "\t2 : data:0.486 [NUMERICAL]\n",
            "\t2 : data:0.467 [NUMERICAL]\n",
            "\t2 : data:0.465 [NUMERICAL]\n",
            "\t2 : data:0.464 [NUMERICAL]\n",
            "\t2 : data:0.459 [NUMERICAL]\n",
            "\t2 : data:0.454 [NUMERICAL]\n",
            "\t2 : data:0.438 [NUMERICAL]\n",
            "\t2 : data:0.431 [NUMERICAL]\n",
            "\t2 : data:0.426 [NUMERICAL]\n",
            "\t2 : data:0.411 [NUMERICAL]\n",
            "\t2 : data:0.402 [NUMERICAL]\n",
            "\t2 : data:0.399 [NUMERICAL]\n",
            "\t2 : data:0.376 [NUMERICAL]\n",
            "\t2 : data:0.372 [NUMERICAL]\n",
            "\t2 : data:0.358 [NUMERICAL]\n",
            "\t2 : data:0.330 [NUMERICAL]\n",
            "\t2 : data:0.329 [NUMERICAL]\n",
            "\t2 : data:0.327 [NUMERICAL]\n",
            "\t2 : data:0.326 [NUMERICAL]\n",
            "\t2 : data:0.323 [NUMERICAL]\n",
            "\t2 : data:0.297 [NUMERICAL]\n",
            "\t2 : data:0.294 [NUMERICAL]\n",
            "\t2 : data:0.289 [NUMERICAL]\n",
            "\t2 : data:0.273 [NUMERICAL]\n",
            "\t2 : data:0.265 [NUMERICAL]\n",
            "\t2 : data:0.241 [NUMERICAL]\n",
            "\t2 : data:0.237 [NUMERICAL]\n",
            "\t2 : data:0.233 [NUMERICAL]\n",
            "\t2 : data:0.214 [NUMERICAL]\n",
            "\t2 : data:0.210 [NUMERICAL]\n",
            "\t2 : data:0.185 [NUMERICAL]\n",
            "\t2 : data:0.184 [NUMERICAL]\n",
            "\t2 : data:0.178 [NUMERICAL]\n",
            "\t2 : data:0.157 [NUMERICAL]\n",
            "\t2 : data:0.151 [NUMERICAL]\n",
            "\t2 : data:0.126 [NUMERICAL]\n",
            "\t2 : data:0.125 [NUMERICAL]\n",
            "\t2 : data:0.124 [NUMERICAL]\n",
            "\t2 : data:0.101 [NUMERICAL]\n",
            "\t1 : data:0.97 [NUMERICAL]\n",
            "\t1 : data:0.714 [NUMERICAL]\n",
            "\t1 : data:0.70 [NUMERICAL]\n",
            "\t1 : data:0.686 [NUMERICAL]\n",
            "\t1 : data:0.661 [NUMERICAL]\n",
            "\t1 : data:0.652 [NUMERICAL]\n",
            "\t1 : data:0.633 [NUMERICAL]\n",
            "\t1 : data:0.630 [NUMERICAL]\n",
            "\t1 : data:0.626 [NUMERICAL]\n",
            "\t1 : data:0.623 [NUMERICAL]\n",
            "\t1 : data:0.608 [NUMERICAL]\n",
            "\t1 : data:0.603 [NUMERICAL]\n",
            "\t1 : data:0.577 [NUMERICAL]\n",
            "\t1 : data:0.576 [NUMERICAL]\n",
            "\t1 : data:0.572 [NUMERICAL]\n",
            "\t1 : data:0.566 [NUMERICAL]\n",
            "\t1 : data:0.549 [NUMERICAL]\n",
            "\t1 : data:0.546 [NUMERICAL]\n",
            "\t1 : data:0.544 [NUMERICAL]\n",
            "\t1 : data:0.526 [NUMERICAL]\n",
            "\t1 : data:0.518 [NUMERICAL]\n",
            "\t1 : data:0.511 [NUMERICAL]\n",
            "\t1 : data:0.510 [NUMERICAL]\n",
            "\t1 : data:0.497 [NUMERICAL]\n",
            "\t1 : data:0.495 [NUMERICAL]\n",
            "\t1 : data:0.491 [NUMERICAL]\n",
            "\t1 : data:0.483 [NUMERICAL]\n",
            "\t1 : data:0.482 [NUMERICAL]\n",
            "\t1 : data:0.470 [NUMERICAL]\n",
            "\t1 : data:0.469 [NUMERICAL]\n",
            "\t1 : data:0.468 [NUMERICAL]\n",
            "\t1 : data:0.455 [NUMERICAL]\n",
            "\t1 : data:0.441 [NUMERICAL]\n",
            "\t1 : data:0.414 [NUMERICAL]\n",
            "\t1 : data:0.413 [NUMERICAL]\n",
            "\t1 : data:0.404 [NUMERICAL]\n",
            "\t1 : data:0.371 [NUMERICAL]\n",
            "\t1 : data:0.353 [NUMERICAL]\n",
            "\t1 : data:0.344 [NUMERICAL]\n",
            "\t1 : data:0.343 [NUMERICAL]\n",
            "\t1 : data:0.328 [NUMERICAL]\n",
            "\t1 : data:0.301 [NUMERICAL]\n",
            "\t1 : data:0.300 [NUMERICAL]\n",
            "\t1 : data:0.299 [NUMERICAL]\n",
            "\t1 : data:0.288 [NUMERICAL]\n",
            "\t1 : data:0.274 [NUMERICAL]\n",
            "\t1 : data:0.271 [NUMERICAL]\n",
            "\t1 : data:0.268 [NUMERICAL]\n",
            "\t1 : data:0.266 [NUMERICAL]\n",
            "\t1 : data:0.262 [NUMERICAL]\n",
            "\t1 : data:0.244 [NUMERICAL]\n",
            "\t1 : data:0.242 [NUMERICAL]\n",
            "\t1 : data:0.238 [NUMERICAL]\n",
            "\t1 : data:0.236 [NUMERICAL]\n",
            "\t1 : data:0.235 [NUMERICAL]\n",
            "\t1 : data:0.234 [NUMERICAL]\n",
            "\t1 : data:0.219 [NUMERICAL]\n",
            "\t1 : data:0.218 [NUMERICAL]\n",
            "\t1 : data:0.213 [NUMERICAL]\n",
            "\t1 : data:0.212 [NUMERICAL]\n",
            "\t1 : data:0.206 [NUMERICAL]\n",
            "\t1 : data:0.186 [NUMERICAL]\n",
            "\t1 : data:0.183 [NUMERICAL]\n",
            "\t1 : data:0.181 [NUMERICAL]\n",
            "\t1 : data:0.158 [NUMERICAL]\n",
            "\t1 : data:0.129 [NUMERICAL]\n",
            "\t1 : data:0.128 [NUMERICAL]\n",
            "\t1 : data:0.123 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t36 : data:0.515 [NUMERICAL]\n",
            "\t33 : data:0.378 [NUMERICAL]\n",
            "\t32 : data:0.514 [NUMERICAL]\n",
            "\t31 : data:0.409 [NUMERICAL]\n",
            "\t30 : data:0.377 [NUMERICAL]\n",
            "\t29 : data:0.487 [NUMERICAL]\n",
            "\t29 : data:0.461 [NUMERICAL]\n",
            "\t28 : data:0.462 [NUMERICAL]\n",
            "\t27 : data:0.543 [NUMERICAL]\n",
            "\t27 : data:0.457 [NUMERICAL]\n",
            "\t26 : data:0.657 [NUMERICAL]\n",
            "\t26 : data:0.155 [NUMERICAL]\n",
            "\t26 : data:0.154 [NUMERICAL]\n",
            "\t25 : data:0.656 [NUMERICAL]\n",
            "\t25 : data:0.655 [NUMERICAL]\n",
            "\t25 : data:0.542 [NUMERICAL]\n",
            "\t25 : data:0.489 [NUMERICAL]\n",
            "\t25 : data:0.460 [NUMERICAL]\n",
            "\t25 : data:0.291 [NUMERICAL]\n",
            "\t24 : data:0.490 [NUMERICAL]\n",
            "\t24 : data:0.347 [NUMERICAL]\n",
            "\t23 : data:0.458 [NUMERICAL]\n",
            "\t23 : data:0.405 [NUMERICAL]\n",
            "\t23 : data:0.345 [NUMERICAL]\n",
            "\t22 : data:0.406 [NUMERICAL]\n",
            "\t22 : data:0.375 [NUMERICAL]\n",
            "\t21 : data:0.654 [NUMERICAL]\n",
            "\t21 : data:0.488 [NUMERICAL]\n",
            "\t21 : data:0.269 [NUMERICAL]\n",
            "\t20 : data:0.486 [NUMERICAL]\n",
            "\t20 : data:0.350 [NUMERICAL]\n",
            "\t20 : data:0.298 [NUMERICAL]\n",
            "\t19 : data:0.658 [NUMERICAL]\n",
            "\t19 : data:0.596 [NUMERICAL]\n",
            "\t19 : data:0.433 [NUMERICAL]\n",
            "\t19 : data:0.351 [NUMERICAL]\n",
            "\t19 : data:0.346 [NUMERICAL]\n",
            "\t19 : data:0.270 [NUMERICAL]\n",
            "\t18 : data:0.569 [NUMERICAL]\n",
            "\t18 : data:0.456 [NUMERICAL]\n",
            "\t18 : data:0.434 [NUMERICAL]\n",
            "\t18 : data:0.319 [NUMERICAL]\n",
            "\t18 : data:0.271 [NUMERICAL]\n",
            "\t18 : data:0.211 [NUMERICAL]\n",
            "\t17 : data:0.544 [NUMERICAL]\n",
            "\t17 : data:0.428 [NUMERICAL]\n",
            "\t17 : data:0.379 [NUMERICAL]\n",
            "\t17 : data:0.376 [NUMERICAL]\n",
            "\t17 : data:0.352 [NUMERICAL]\n",
            "\t17 : data:0.348 [NUMERICAL]\n",
            "\t17 : data:0.299 [NUMERICAL]\n",
            "\t17 : data:0.272 [NUMERICAL]\n",
            "\t17 : data:0.183 [NUMERICAL]\n",
            "\t16 : data:0.541 [NUMERICAL]\n",
            "\t16 : data:0.463 [NUMERICAL]\n",
            "\t16 : data:0.459 [NUMERICAL]\n",
            "\t16 : data:0.374 [NUMERICAL]\n",
            "\t16 : data:0.326 [NUMERICAL]\n",
            "\t16 : data:0.325 [NUMERICAL]\n",
            "\t16 : data:0.240 [NUMERICAL]\n",
            "\t15 : data:0.627 [NUMERICAL]\n",
            "\t15 : data:0.626 [NUMERICAL]\n",
            "\t15 : data:0.403 [NUMERICAL]\n",
            "\t15 : data:0.349 [NUMERICAL]\n",
            "\t15 : data:0.320 [NUMERICAL]\n",
            "\t15 : data:0.241 [NUMERICAL]\n",
            "\t15 : data:0.210 [NUMERICAL]\n",
            "\t15 : data:0.156 [NUMERICAL]\n",
            "\t14 : data:0.653 [NUMERICAL]\n",
            "\t14 : data:0.625 [NUMERICAL]\n",
            "\t14 : data:0.624 [NUMERICAL]\n",
            "\t14 : data:0.570 [NUMERICAL]\n",
            "\t14 : data:0.517 [NUMERICAL]\n",
            "\t14 : data:0.484 [NUMERICAL]\n",
            "\t14 : data:0.353 [NUMERICAL]\n",
            "\t14 : data:0.317 [NUMERICAL]\n",
            "\t14 : data:0.296 [NUMERICAL]\n",
            "\t14 : data:0.263 [NUMERICAL]\n",
            "\t14 : data:0.153 [NUMERICAL]\n",
            "\t13 : data:0.595 [NUMERICAL]\n",
            "\t13 : data:0.568 [NUMERICAL]\n",
            "\t13 : data:0.513 [NUMERICAL]\n",
            "\t13 : data:0.466 [NUMERICAL]\n",
            "\t13 : data:0.404 [NUMERICAL]\n",
            "\t13 : data:0.344 [NUMERICAL]\n",
            "\t13 : data:0.324 [NUMERICAL]\n",
            "\t13 : data:0.318 [NUMERICAL]\n",
            "\t13 : data:0.290 [NUMERICAL]\n",
            "\t13 : data:0.243 [NUMERICAL]\n",
            "\t13 : data:0.152 [NUMERICAL]\n",
            "\t12 : data:0.597 [NUMERICAL]\n",
            "\t12 : data:0.516 [NUMERICAL]\n",
            "\t12 : data:0.485 [NUMERICAL]\n",
            "\t12 : data:0.455 [NUMERICAL]\n",
            "\t12 : data:0.401 [NUMERICAL]\n",
            "\t12 : data:0.380 [NUMERICAL]\n",
            "\t12 : data:0.354 [NUMERICAL]\n",
            "\t12 : data:0.328 [NUMERICAL]\n",
            "\t12 : data:0.294 [NUMERICAL]\n",
            "\t12 : data:0.213 [NUMERICAL]\n",
            "\t12 : data:0.178 [NUMERICAL]\n",
            "\t11 : data:0.571 [NUMERICAL]\n",
            "\t11 : data:0.545 [NUMERICAL]\n",
            "\t11 : data:0.539 [NUMERICAL]\n",
            "\t11 : data:0.491 [NUMERICAL]\n",
            "\t11 : data:0.436 [NUMERICAL]\n",
            "\t11 : data:0.435 [NUMERICAL]\n",
            "\t11 : data:0.432 [NUMERICAL]\n",
            "\t11 : data:0.431 [NUMERICAL]\n",
            "\t11 : data:0.430 [NUMERICAL]\n",
            "\t11 : data:0.429 [NUMERICAL]\n",
            "\t11 : data:0.410 [NUMERICAL]\n",
            "\t11 : data:0.408 [NUMERICAL]\n",
            "\t11 : data:0.400 [NUMERICAL]\n",
            "\t11 : data:0.357 [NUMERICAL]\n",
            "\t11 : data:0.329 [NUMERICAL]\n",
            "\t11 : data:0.300 [NUMERICAL]\n",
            "\t11 : data:0.267 [NUMERICAL]\n",
            "\t11 : data:0.238 [NUMERICAL]\n",
            "\t11 : data:0.215 [NUMERICAL]\n",
            "\t10 : data:0.598 [NUMERICAL]\n",
            "\t10 : data:0.572 [NUMERICAL]\n",
            "\t10 : data:0.550 [NUMERICAL]\n",
            "\t10 : data:0.540 [NUMERICAL]\n",
            "\t10 : data:0.407 [NUMERICAL]\n",
            "\t10 : data:0.382 [NUMERICAL]\n",
            "\t10 : data:0.372 [NUMERICAL]\n",
            "\t10 : data:0.371 [NUMERICAL]\n",
            "\t10 : data:0.323 [NUMERICAL]\n",
            "\t10 : data:0.322 [NUMERICAL]\n",
            "\t10 : data:0.292 [NUMERICAL]\n",
            "\t10 : data:0.273 [NUMERICAL]\n",
            "\t10 : data:0.265 [NUMERICAL]\n",
            "\t10 : data:0.242 [NUMERICAL]\n",
            "\t9 : data:0.519 [NUMERICAL]\n",
            "\t9 : data:0.492 [NUMERICAL]\n",
            "\t9 : data:0.437 [NUMERICAL]\n",
            "\t9 : data:0.427 [NUMERICAL]\n",
            "\t9 : data:0.402 [NUMERICAL]\n",
            "\t9 : data:0.399 [NUMERICAL]\n",
            "\t9 : data:0.381 [NUMERICAL]\n",
            "\t9 : data:0.373 [NUMERICAL]\n",
            "\t9 : data:0.327 [NUMERICAL]\n",
            "\t9 : data:0.321 [NUMERICAL]\n",
            "\t9 : data:0.295 [NUMERICAL]\n",
            "\t9 : data:0.289 [NUMERICAL]\n",
            "\t9 : data:0.214 [NUMERICAL]\n",
            "\t9 : data:0.212 [NUMERICAL]\n",
            "\t9 : data:0.184 [NUMERICAL]\n",
            "\t9 : data:0.182 [NUMERICAL]\n",
            "\t8 : data:0.623 [NUMERICAL]\n",
            "\t8 : data:0.578 [NUMERICAL]\n",
            "\t8 : data:0.573 [NUMERICAL]\n",
            "\t8 : data:0.510 [NUMERICAL]\n",
            "\t8 : data:0.483 [NUMERICAL]\n",
            "\t8 : data:0.467 [NUMERICAL]\n",
            "\t8 : data:0.464 [NUMERICAL]\n",
            "\t8 : data:0.426 [NUMERICAL]\n",
            "\t8 : data:0.343 [NUMERICAL]\n",
            "\t8 : data:0.316 [NUMERICAL]\n",
            "\t8 : data:0.301 [NUMERICAL]\n",
            "\t8 : data:0.268 [NUMERICAL]\n",
            "\t8 : data:0.266 [NUMERICAL]\n",
            "\t8 : data:0.239 [NUMERICAL]\n",
            "\t8 : data:0.209 [NUMERICAL]\n",
            "\t8 : data:0.185 [NUMERICAL]\n",
            "\t8 : data:0.179 [NUMERICAL]\n",
            "\t8 : data:0.157 [NUMERICAL]\n",
            "\t8 : data:0.127 [NUMERICAL]\n",
            "\t8 : data:0.126 [NUMERICAL]\n",
            "\t8 : data:0.101 [NUMERICAL]\n",
            "\t7 : data:0.659 [NUMERICAL]\n",
            "\t7 : data:0.579 [NUMERICAL]\n",
            "\t7 : data:0.567 [NUMERICAL]\n",
            "\t7 : data:0.551 [NUMERICAL]\n",
            "\t7 : data:0.454 [NUMERICAL]\n",
            "\t7 : data:0.414 [NUMERICAL]\n",
            "\t7 : data:0.411 [NUMERICAL]\n",
            "\t7 : data:0.355 [NUMERICAL]\n",
            "\t7 : data:0.330 [NUMERICAL]\n",
            "\t7 : data:0.297 [NUMERICAL]\n",
            "\t7 : data:0.244 [NUMERICAL]\n",
            "\t7 : data:0.237 [NUMERICAL]\n",
            "\t7 : data:0.216 [NUMERICAL]\n",
            "\t7 : data:0.206 [NUMERICAL]\n",
            "\t7 : data:0.181 [NUMERICAL]\n",
            "\t7 : data:0.158 [NUMERICAL]\n",
            "\t7 : data:0.128 [NUMERICAL]\n",
            "\t7 : data:0.124 [NUMERICAL]\n",
            "\t7 : data:0.100 [NUMERICAL]\n",
            "\t6 : data:0.660 [NUMERICAL]\n",
            "\t6 : data:0.628 [NUMERICAL]\n",
            "\t6 : data:0.524 [NUMERICAL]\n",
            "\t6 : data:0.522 [NUMERICAL]\n",
            "\t6 : data:0.512 [NUMERICAL]\n",
            "\t6 : data:0.511 [NUMERICAL]\n",
            "\t6 : data:0.482 [NUMERICAL]\n",
            "\t6 : data:0.438 [NUMERICAL]\n",
            "\t6 : data:0.413 [NUMERICAL]\n",
            "\t6 : data:0.385 [NUMERICAL]\n",
            "\t6 : data:0.358 [NUMERICAL]\n",
            "\t6 : data:0.315 [NUMERICAL]\n",
            "\t6 : data:0.245 [NUMERICAL]\n",
            "\t6 : data:0.236 [NUMERICAL]\n",
            "\t6 : data:0.125 [NUMERICAL]\n",
            "\t5 : data:0.98 [NUMERICAL]\n",
            "\t5 : data:0.686 [NUMERICAL]\n",
            "\t5 : data:0.683 [NUMERICAL]\n",
            "\t5 : data:0.652 [NUMERICAL]\n",
            "\t5 : data:0.651 [NUMERICAL]\n",
            "\t5 : data:0.631 [NUMERICAL]\n",
            "\t5 : data:0.606 [NUMERICAL]\n",
            "\t5 : data:0.594 [NUMERICAL]\n",
            "\t5 : data:0.549 [NUMERICAL]\n",
            "\t5 : data:0.538 [NUMERICAL]\n",
            "\t5 : data:0.521 [NUMERICAL]\n",
            "\t5 : data:0.518 [NUMERICAL]\n",
            "\t5 : data:0.470 [NUMERICAL]\n",
            "\t5 : data:0.469 [NUMERICAL]\n",
            "\t5 : data:0.359 [NUMERICAL]\n",
            "\t5 : data:0.314 [NUMERICAL]\n",
            "\t5 : data:0.302 [NUMERICAL]\n",
            "\t5 : data:0.288 [NUMERICAL]\n",
            "\t5 : data:0.264 [NUMERICAL]\n",
            "\t5 : data:0.248 [NUMERICAL]\n",
            "\t5 : data:0.233 [NUMERICAL]\n",
            "\t5 : data:0.207 [NUMERICAL]\n",
            "\t5 : data:0.186 [NUMERICAL]\n",
            "\t5 : data:0.151 [NUMERICAL]\n",
            "\t5 : data:0.150 [NUMERICAL]\n",
            "\t4 : data:0.685 [NUMERICAL]\n",
            "\t4 : data:0.661 [NUMERICAL]\n",
            "\t4 : data:0.629 [NUMERICAL]\n",
            "\t4 : data:0.607 [NUMERICAL]\n",
            "\t4 : data:0.601 [NUMERICAL]\n",
            "\t4 : data:0.600 [NUMERICAL]\n",
            "\t4 : data:0.599 [NUMERICAL]\n",
            "\t4 : data:0.581 [NUMERICAL]\n",
            "\t4 : data:0.546 [NUMERICAL]\n",
            "\t4 : data:0.523 [NUMERICAL]\n",
            "\t4 : data:0.497 [NUMERICAL]\n",
            "\t4 : data:0.465 [NUMERICAL]\n",
            "\t4 : data:0.453 [NUMERICAL]\n",
            "\t4 : data:0.439 [NUMERICAL]\n",
            "\t4 : data:0.398 [NUMERICAL]\n",
            "\t4 : data:0.387 [NUMERICAL]\n",
            "\t4 : data:0.342 [NUMERICAL]\n",
            "\t4 : data:0.274 [NUMERICAL]\n",
            "\t4 : data:0.262 [NUMERICAL]\n",
            "\t4 : data:0.260 [NUMERICAL]\n",
            "\t4 : data:0.247 [NUMERICAL]\n",
            "\t4 : data:0.234 [NUMERICAL]\n",
            "\t4 : data:0.180 [NUMERICAL]\n",
            "\t4 : data:0.123 [NUMERICAL]\n",
            "\t3 : data:0.99 [NUMERICAL]\n",
            "\t3 : data:0.97 [NUMERICAL]\n",
            "\t3 : data:0.682 [NUMERICAL]\n",
            "\t3 : data:0.633 [NUMERICAL]\n",
            "\t3 : data:0.630 [NUMERICAL]\n",
            "\t3 : data:0.609 [NUMERICAL]\n",
            "\t3 : data:0.608 [NUMERICAL]\n",
            "\t3 : data:0.604 [NUMERICAL]\n",
            "\t3 : data:0.603 [NUMERICAL]\n",
            "\t3 : data:0.574 [NUMERICAL]\n",
            "\t3 : data:0.566 [NUMERICAL]\n",
            "\t3 : data:0.554 [NUMERICAL]\n",
            "\t3 : data:0.548 [NUMERICAL]\n",
            "\t3 : data:0.496 [NUMERICAL]\n",
            "\t3 : data:0.495 [NUMERICAL]\n",
            "\t3 : data:0.468 [NUMERICAL]\n",
            "\t3 : data:0.441 [NUMERICAL]\n",
            "\t3 : data:0.440 [NUMERICAL]\n",
            "\t3 : data:0.397 [NUMERICAL]\n",
            "\t3 : data:0.386 [NUMERICAL]\n",
            "\t3 : data:0.384 [NUMERICAL]\n",
            "\t3 : data:0.383 [NUMERICAL]\n",
            "\t3 : data:0.293 [NUMERICAL]\n",
            "\t3 : data:0.219 [NUMERICAL]\n",
            "\t3 : data:0.218 [NUMERICAL]\n",
            "\t3 : data:0.208 [NUMERICAL]\n",
            "\t3 : data:0.204 [NUMERICAL]\n",
            "\t3 : data:0.190 [NUMERICAL]\n",
            "\t3 : data:0.160 [NUMERICAL]\n",
            "\t3 : data:0.149 [NUMERICAL]\n",
            "\t3 : data:0.129 [NUMERICAL]\n",
            "\t3 : data:0.122 [NUMERICAL]\n",
            "\t2 : data:0.96 [NUMERICAL]\n",
            "\t2 : data:0.714 [NUMERICAL]\n",
            "\t2 : data:0.707 [NUMERICAL]\n",
            "\t2 : data:0.687 [NUMERICAL]\n",
            "\t2 : data:0.684 [NUMERICAL]\n",
            "\t2 : data:0.68 [NUMERICAL]\n",
            "\t2 : data:0.679 [NUMERICAL]\n",
            "\t2 : data:0.634 [NUMERICAL]\n",
            "\t2 : data:0.605 [NUMERICAL]\n",
            "\t2 : data:0.577 [NUMERICAL]\n",
            "\t2 : data:0.576 [NUMERICAL]\n",
            "\t2 : data:0.575 [NUMERICAL]\n",
            "\t2 : data:0.537 [NUMERICAL]\n",
            "\t2 : data:0.526 [NUMERICAL]\n",
            "\t2 : data:0.509 [NUMERICAL]\n",
            "\t2 : data:0.494 [NUMERICAL]\n",
            "\t2 : data:0.493 [NUMERICAL]\n",
            "\t2 : data:0.356 [NUMERICAL]\n",
            "\t2 : data:0.303 [NUMERICAL]\n",
            "\t2 : data:0.235 [NUMERICAL]\n",
            "\t2 : data:0.205 [NUMERICAL]\n",
            "\t2 : data:0.189 [NUMERICAL]\n",
            "\t2 : data:0.188 [NUMERICAL]\n",
            "\t2 : data:0.177 [NUMERICAL]\n",
            "\t2 : data:0.176 [NUMERICAL]\n",
            "\t2 : data:0.159 [NUMERICAL]\n",
            "\t2 : data:0.130 [NUMERICAL]\n",
            "\t1 : data:0.94 [NUMERICAL]\n",
            "\t1 : data:0.740 [NUMERICAL]\n",
            "\t1 : data:0.710 [NUMERICAL]\n",
            "\t1 : data:0.709 [NUMERICAL]\n",
            "\t1 : data:0.70 [NUMERICAL]\n",
            "\t1 : data:0.69 [NUMERICAL]\n",
            "\t1 : data:0.688 [NUMERICAL]\n",
            "\t1 : data:0.681 [NUMERICAL]\n",
            "\t1 : data:0.663 [NUMERICAL]\n",
            "\t1 : data:0.662 [NUMERICAL]\n",
            "\t1 : data:0.632 [NUMERICAL]\n",
            "\t1 : data:0.622 [NUMERICAL]\n",
            "\t1 : data:0.602 [NUMERICAL]\n",
            "\t1 : data:0.593 [NUMERICAL]\n",
            "\t1 : data:0.583 [NUMERICAL]\n",
            "\t1 : data:0.580 [NUMERICAL]\n",
            "\t1 : data:0.565 [NUMERICAL]\n",
            "\t1 : data:0.552 [NUMERICAL]\n",
            "\t1 : data:0.547 [NUMERICAL]\n",
            "\t1 : data:0.536 [NUMERICAL]\n",
            "\t1 : data:0.525 [NUMERICAL]\n",
            "\t1 : data:0.520 [NUMERICAL]\n",
            "\t1 : data:0.499 [NUMERICAL]\n",
            "\t1 : data:0.498 [NUMERICAL]\n",
            "\t1 : data:0.481 [NUMERICAL]\n",
            "\t1 : data:0.473 [NUMERICAL]\n",
            "\t1 : data:0.442 [NUMERICAL]\n",
            "\t1 : data:0.425 [NUMERICAL]\n",
            "\t1 : data:0.415 [NUMERICAL]\n",
            "\t1 : data:0.412 [NUMERICAL]\n",
            "\t1 : data:0.369 [NUMERICAL]\n",
            "\t1 : data:0.341 [NUMERICAL]\n",
            "\t1 : data:0.304 [NUMERICAL]\n",
            "\t1 : data:0.287 [NUMERICAL]\n",
            "\t1 : data:0.275 [NUMERICAL]\n",
            "\t1 : data:0.261 [NUMERICAL]\n",
            "\t1 : data:0.246 [NUMERICAL]\n",
            "\t1 : data:0.231 [NUMERICAL]\n",
            "\t1 : data:0.217 [NUMERICAL]\n",
            "\t1 : data:0.192 [NUMERICAL]\n",
            "\t1 : data:0.187 [NUMERICAL]\n",
            "\t1 : data:0.147 [NUMERICAL]\n",
            "\t1 : data:0.133 [NUMERICAL]\n",
            "\t1 : data:0.121 [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t116810 : HigherCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t50 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t150 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t350 : HigherCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t750 : HigherCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t3149 : HigherCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.830498 logloss:6.10945\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.90397 logloss:1.33512\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.938795 logloss:0.568085\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:0.950167 logloss:0.393499\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:0.954833 logloss:0.323543\n",
            "\ttrees: 50, Out-of-bag evaluation: accuracy:0.957 logloss:0.295299\n",
            "\n",
            "313/313 [==============================] - 4s 4ms/step - loss: 0.0000e+00 - accuracy: 0.9656\n",
            "\n",
            "loss: 0.0000\n",
            "accuracy: 0.9656\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_decision_forests\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "mnistDataSet = tf.keras.datasets.mnist\n",
        "\n",
        "(data_train, labels_train), (data_test, labels_test) = mnistDataSet.load_data()\n",
        "data_train, data_test = data_train / 255.0, data_test / 255.0\n",
        "data_train = data_train.reshape((-1, data_train.shape[1]*data_train.shape[2]))\n",
        "data_test = data_test.reshape((-1, data_test.shape[1]*data_test.shape[2]))\n",
        "\n",
        "model_1 = tfdf.keras.RandomForestModel(verbose=2, num_trees=50)\n",
        "model_1.fit(data_train, labels_train)\n",
        "model_1.summary()\n",
        "model_1.compile(metrics=[\"accuracy\"])\n",
        "evaluation = model_1.evaluate(data_test, labels_test, return_dict=True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print(f\"{name}: {value:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = tfdf.keras.RandomForestModel(verbose=2, num_trees=500)\n",
        "model_2.fit(data_train, labels_train)\n",
        "model_2.summary()\n",
        "model_2.compile(metrics=[\"accuracy\"])\n",
        "evaluation = model_1.evaluate(data_test, labels_test, return_dict=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qczZjzN1GDT9",
        "outputId": "eabf0914-9412-4cf5-d6ea-49e4d2227d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use 2 thread(s) for training\n",
            "Use /tmp/tmp6puxm1wr as temporary training directory\n",
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: Tensor(\"data:0\", shape=(32, 784), dtype=float32)\n",
            "Label: Tensor(\"data_1:0\", shape=(32,), dtype=uint8)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(32,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(32,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(32,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(32,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(32,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(32,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(32,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(32,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(32,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(32,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(32,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(32,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(32,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(32,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(32,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(32,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(32,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(32,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(32,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(32,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(32,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(32,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(32,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(32,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(32,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(32,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(32,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(32,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(32,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(32,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(32,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(32,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(32,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(32,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(32,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(32,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(32,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(32,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(32,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(32,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(32,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(32,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(32,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(32,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(32,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(32,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(32,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(32,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(32,) dtype=float32>), 'data:0.49': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_49:0' shape=(32,) dtype=float32>), 'data:0.50': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_50:0' shape=(32,) dtype=float32>), 'data:0.51': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_51:0' shape=(32,) dtype=float32>), 'data:0.52': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_52:0' shape=(32,) dtype=float32>), 'data:0.53': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_53:0' shape=(32,) dtype=float32>), 'data:0.54': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_54:0' shape=(32,) dtype=float32>), 'data:0.55': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_55:0' shape=(32,) dtype=float32>), 'data:0.56': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_56:0' shape=(32,) dtype=float32>), 'data:0.57': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_57:0' shape=(32,) dtype=float32>), 'data:0.58': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_58:0' shape=(32,) dtype=float32>), 'data:0.59': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_59:0' shape=(32,) dtype=float32>), 'data:0.60': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_60:0' shape=(32,) dtype=float32>), 'data:0.61': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_61:0' shape=(32,) dtype=float32>), 'data:0.62': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_62:0' shape=(32,) dtype=float32>), 'data:0.63': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_63:0' shape=(32,) dtype=float32>), 'data:0.64': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_64:0' shape=(32,) dtype=float32>), 'data:0.65': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_65:0' shape=(32,) dtype=float32>), 'data:0.66': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_66:0' shape=(32,) dtype=float32>), 'data:0.67': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_67:0' shape=(32,) dtype=float32>), 'data:0.68': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_68:0' shape=(32,) dtype=float32>), 'data:0.69': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_69:0' shape=(32,) dtype=float32>), 'data:0.70': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_70:0' shape=(32,) dtype=float32>), 'data:0.71': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_71:0' shape=(32,) dtype=float32>), 'data:0.72': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_72:0' shape=(32,) dtype=float32>), 'data:0.73': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_73:0' shape=(32,) dtype=float32>), 'data:0.74': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_74:0' shape=(32,) dtype=float32>), 'data:0.75': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_75:0' shape=(32,) dtype=float32>), 'data:0.76': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_76:0' shape=(32,) dtype=float32>), 'data:0.77': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_77:0' shape=(32,) dtype=float32>), 'data:0.78': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_78:0' shape=(32,) dtype=float32>), 'data:0.79': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_79:0' shape=(32,) dtype=float32>), 'data:0.80': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_80:0' shape=(32,) dtype=float32>), 'data:0.81': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_81:0' shape=(32,) dtype=float32>), 'data:0.82': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_82:0' shape=(32,) dtype=float32>), 'data:0.83': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_83:0' shape=(32,) dtype=float32>), 'data:0.84': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_84:0' shape=(32,) dtype=float32>), 'data:0.85': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_85:0' shape=(32,) dtype=float32>), 'data:0.86': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_86:0' shape=(32,) dtype=float32>), 'data:0.87': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_87:0' shape=(32,) dtype=float32>), 'data:0.88': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_88:0' shape=(32,) dtype=float32>), 'data:0.89': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_89:0' shape=(32,) dtype=float32>), 'data:0.90': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_90:0' shape=(32,) dtype=float32>), 'data:0.91': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_91:0' shape=(32,) dtype=float32>), 'data:0.92': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_92:0' shape=(32,) dtype=float32>), 'data:0.93': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_93:0' shape=(32,) dtype=float32>), 'data:0.94': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_94:0' shape=(32,) dtype=float32>), 'data:0.95': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_95:0' shape=(32,) dtype=float32>), 'data:0.96': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_96:0' shape=(32,) dtype=float32>), 'data:0.97': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_97:0' shape=(32,) dtype=float32>), 'data:0.98': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_98:0' shape=(32,) dtype=float32>), 'data:0.99': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_99:0' shape=(32,) dtype=float32>), 'data:0.100': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_100:0' shape=(32,) dtype=float32>), 'data:0.101': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_101:0' shape=(32,) dtype=float32>), 'data:0.102': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_102:0' shape=(32,) dtype=float32>), 'data:0.103': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_103:0' shape=(32,) dtype=float32>), 'data:0.104': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_104:0' shape=(32,) dtype=float32>), 'data:0.105': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_105:0' shape=(32,) dtype=float32>), 'data:0.106': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_106:0' shape=(32,) dtype=float32>), 'data:0.107': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_107:0' shape=(32,) dtype=float32>), 'data:0.108': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_108:0' shape=(32,) dtype=float32>), 'data:0.109': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_109:0' shape=(32,) dtype=float32>), 'data:0.110': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_110:0' shape=(32,) dtype=float32>), 'data:0.111': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_111:0' shape=(32,) dtype=float32>), 'data:0.112': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_112:0' shape=(32,) dtype=float32>), 'data:0.113': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_113:0' shape=(32,) dtype=float32>), 'data:0.114': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_114:0' shape=(32,) dtype=float32>), 'data:0.115': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_115:0' shape=(32,) dtype=float32>), 'data:0.116': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_116:0' shape=(32,) dtype=float32>), 'data:0.117': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_117:0' shape=(32,) dtype=float32>), 'data:0.118': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_118:0' shape=(32,) dtype=float32>), 'data:0.119': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_119:0' shape=(32,) dtype=float32>), 'data:0.120': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_120:0' shape=(32,) dtype=float32>), 'data:0.121': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_121:0' shape=(32,) dtype=float32>), 'data:0.122': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_122:0' shape=(32,) dtype=float32>), 'data:0.123': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_123:0' shape=(32,) dtype=float32>), 'data:0.124': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_124:0' shape=(32,) dtype=float32>), 'data:0.125': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_125:0' shape=(32,) dtype=float32>), 'data:0.126': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_126:0' shape=(32,) dtype=float32>), 'data:0.127': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_127:0' shape=(32,) dtype=float32>), 'data:0.128': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_128:0' shape=(32,) dtype=float32>), 'data:0.129': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_129:0' shape=(32,) dtype=float32>), 'data:0.130': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_130:0' shape=(32,) dtype=float32>), 'data:0.131': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_131:0' shape=(32,) dtype=float32>), 'data:0.132': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_132:0' shape=(32,) dtype=float32>), 'data:0.133': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_133:0' shape=(32,) dtype=float32>), 'data:0.134': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_134:0' shape=(32,) dtype=float32>), 'data:0.135': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_135:0' shape=(32,) dtype=float32>), 'data:0.136': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_136:0' shape=(32,) dtype=float32>), 'data:0.137': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_137:0' shape=(32,) dtype=float32>), 'data:0.138': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_138:0' shape=(32,) dtype=float32>), 'data:0.139': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_139:0' shape=(32,) dtype=float32>), 'data:0.140': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_140:0' shape=(32,) dtype=float32>), 'data:0.141': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_141:0' shape=(32,) dtype=float32>), 'data:0.142': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_142:0' shape=(32,) dtype=float32>), 'data:0.143': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_143:0' shape=(32,) dtype=float32>), 'data:0.144': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_144:0' shape=(32,) dtype=float32>), 'data:0.145': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_145:0' shape=(32,) dtype=float32>), 'data:0.146': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_146:0' shape=(32,) dtype=float32>), 'data:0.147': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_147:0' shape=(32,) dtype=float32>), 'data:0.148': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_148:0' shape=(32,) dtype=float32>), 'data:0.149': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_149:0' shape=(32,) dtype=float32>), 'data:0.150': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_150:0' shape=(32,) dtype=float32>), 'data:0.151': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_151:0' shape=(32,) dtype=float32>), 'data:0.152': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_152:0' shape=(32,) dtype=float32>), 'data:0.153': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_153:0' shape=(32,) dtype=float32>), 'data:0.154': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_154:0' shape=(32,) dtype=float32>), 'data:0.155': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_155:0' shape=(32,) dtype=float32>), 'data:0.156': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_156:0' shape=(32,) dtype=float32>), 'data:0.157': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_157:0' shape=(32,) dtype=float32>), 'data:0.158': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_158:0' shape=(32,) dtype=float32>), 'data:0.159': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_159:0' shape=(32,) dtype=float32>), 'data:0.160': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_160:0' shape=(32,) dtype=float32>), 'data:0.161': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_161:0' shape=(32,) dtype=float32>), 'data:0.162': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_162:0' shape=(32,) dtype=float32>), 'data:0.163': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_163:0' shape=(32,) dtype=float32>), 'data:0.164': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_164:0' shape=(32,) dtype=float32>), 'data:0.165': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_165:0' shape=(32,) dtype=float32>), 'data:0.166': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_166:0' shape=(32,) dtype=float32>), 'data:0.167': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_167:0' shape=(32,) dtype=float32>), 'data:0.168': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_168:0' shape=(32,) dtype=float32>), 'data:0.169': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_169:0' shape=(32,) dtype=float32>), 'data:0.170': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_170:0' shape=(32,) dtype=float32>), 'data:0.171': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_171:0' shape=(32,) dtype=float32>), 'data:0.172': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_172:0' shape=(32,) dtype=float32>), 'data:0.173': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_173:0' shape=(32,) dtype=float32>), 'data:0.174': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_174:0' shape=(32,) dtype=float32>), 'data:0.175': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_175:0' shape=(32,) dtype=float32>), 'data:0.176': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_176:0' shape=(32,) dtype=float32>), 'data:0.177': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_177:0' shape=(32,) dtype=float32>), 'data:0.178': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_178:0' shape=(32,) dtype=float32>), 'data:0.179': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_179:0' shape=(32,) dtype=float32>), 'data:0.180': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_180:0' shape=(32,) dtype=float32>), 'data:0.181': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_181:0' shape=(32,) dtype=float32>), 'data:0.182': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_182:0' shape=(32,) dtype=float32>), 'data:0.183': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_183:0' shape=(32,) dtype=float32>), 'data:0.184': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_184:0' shape=(32,) dtype=float32>), 'data:0.185': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_185:0' shape=(32,) dtype=float32>), 'data:0.186': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_186:0' shape=(32,) dtype=float32>), 'data:0.187': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_187:0' shape=(32,) dtype=float32>), 'data:0.188': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_188:0' shape=(32,) dtype=float32>), 'data:0.189': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_189:0' shape=(32,) dtype=float32>), 'data:0.190': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_190:0' shape=(32,) dtype=float32>), 'data:0.191': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_191:0' shape=(32,) dtype=float32>), 'data:0.192': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_192:0' shape=(32,) dtype=float32>), 'data:0.193': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_193:0' shape=(32,) dtype=float32>), 'data:0.194': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_194:0' shape=(32,) dtype=float32>), 'data:0.195': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_195:0' shape=(32,) dtype=float32>), 'data:0.196': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_196:0' shape=(32,) dtype=float32>), 'data:0.197': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_197:0' shape=(32,) dtype=float32>), 'data:0.198': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_198:0' shape=(32,) dtype=float32>), 'data:0.199': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_199:0' shape=(32,) dtype=float32>), 'data:0.200': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_200:0' shape=(32,) dtype=float32>), 'data:0.201': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_201:0' shape=(32,) dtype=float32>), 'data:0.202': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_202:0' shape=(32,) dtype=float32>), 'data:0.203': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_203:0' shape=(32,) dtype=float32>), 'data:0.204': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_204:0' shape=(32,) dtype=float32>), 'data:0.205': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_205:0' shape=(32,) dtype=float32>), 'data:0.206': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_206:0' shape=(32,) dtype=float32>), 'data:0.207': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_207:0' shape=(32,) dtype=float32>), 'data:0.208': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_208:0' shape=(32,) dtype=float32>), 'data:0.209': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_209:0' shape=(32,) dtype=float32>), 'data:0.210': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_210:0' shape=(32,) dtype=float32>), 'data:0.211': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_211:0' shape=(32,) dtype=float32>), 'data:0.212': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_212:0' shape=(32,) dtype=float32>), 'data:0.213': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_213:0' shape=(32,) dtype=float32>), 'data:0.214': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_214:0' shape=(32,) dtype=float32>), 'data:0.215': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_215:0' shape=(32,) dtype=float32>), 'data:0.216': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_216:0' shape=(32,) dtype=float32>), 'data:0.217': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_217:0' shape=(32,) dtype=float32>), 'data:0.218': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_218:0' shape=(32,) dtype=float32>), 'data:0.219': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_219:0' shape=(32,) dtype=float32>), 'data:0.220': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_220:0' shape=(32,) dtype=float32>), 'data:0.221': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_221:0' shape=(32,) dtype=float32>), 'data:0.222': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_222:0' shape=(32,) dtype=float32>), 'data:0.223': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_223:0' shape=(32,) dtype=float32>), 'data:0.224': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_224:0' shape=(32,) dtype=float32>), 'data:0.225': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_225:0' shape=(32,) dtype=float32>), 'data:0.226': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_226:0' shape=(32,) dtype=float32>), 'data:0.227': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_227:0' shape=(32,) dtype=float32>), 'data:0.228': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_228:0' shape=(32,) dtype=float32>), 'data:0.229': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_229:0' shape=(32,) dtype=float32>), 'data:0.230': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_230:0' shape=(32,) dtype=float32>), 'data:0.231': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_231:0' shape=(32,) dtype=float32>), 'data:0.232': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_232:0' shape=(32,) dtype=float32>), 'data:0.233': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_233:0' shape=(32,) dtype=float32>), 'data:0.234': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_234:0' shape=(32,) dtype=float32>), 'data:0.235': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_235:0' shape=(32,) dtype=float32>), 'data:0.236': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_236:0' shape=(32,) dtype=float32>), 'data:0.237': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_237:0' shape=(32,) dtype=float32>), 'data:0.238': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_238:0' shape=(32,) dtype=float32>), 'data:0.239': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_239:0' shape=(32,) dtype=float32>), 'data:0.240': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_240:0' shape=(32,) dtype=float32>), 'data:0.241': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_241:0' shape=(32,) dtype=float32>), 'data:0.242': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_242:0' shape=(32,) dtype=float32>), 'data:0.243': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_243:0' shape=(32,) dtype=float32>), 'data:0.244': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_244:0' shape=(32,) dtype=float32>), 'data:0.245': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_245:0' shape=(32,) dtype=float32>), 'data:0.246': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_246:0' shape=(32,) dtype=float32>), 'data:0.247': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_247:0' shape=(32,) dtype=float32>), 'data:0.248': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_248:0' shape=(32,) dtype=float32>), 'data:0.249': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_249:0' shape=(32,) dtype=float32>), 'data:0.250': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_250:0' shape=(32,) dtype=float32>), 'data:0.251': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_251:0' shape=(32,) dtype=float32>), 'data:0.252': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_252:0' shape=(32,) dtype=float32>), 'data:0.253': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_253:0' shape=(32,) dtype=float32>), 'data:0.254': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_254:0' shape=(32,) dtype=float32>), 'data:0.255': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_255:0' shape=(32,) dtype=float32>), 'data:0.256': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_256:0' shape=(32,) dtype=float32>), 'data:0.257': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_257:0' shape=(32,) dtype=float32>), 'data:0.258': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_258:0' shape=(32,) dtype=float32>), 'data:0.259': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_259:0' shape=(32,) dtype=float32>), 'data:0.260': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_260:0' shape=(32,) dtype=float32>), 'data:0.261': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_261:0' shape=(32,) dtype=float32>), 'data:0.262': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_262:0' shape=(32,) dtype=float32>), 'data:0.263': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_263:0' shape=(32,) dtype=float32>), 'data:0.264': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_264:0' shape=(32,) dtype=float32>), 'data:0.265': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_265:0' shape=(32,) dtype=float32>), 'data:0.266': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_266:0' shape=(32,) dtype=float32>), 'data:0.267': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_267:0' shape=(32,) dtype=float32>), 'data:0.268': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_268:0' shape=(32,) dtype=float32>), 'data:0.269': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_269:0' shape=(32,) dtype=float32>), 'data:0.270': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_270:0' shape=(32,) dtype=float32>), 'data:0.271': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_271:0' shape=(32,) dtype=float32>), 'data:0.272': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_272:0' shape=(32,) dtype=float32>), 'data:0.273': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_273:0' shape=(32,) dtype=float32>), 'data:0.274': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_274:0' shape=(32,) dtype=float32>), 'data:0.275': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_275:0' shape=(32,) dtype=float32>), 'data:0.276': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_276:0' shape=(32,) dtype=float32>), 'data:0.277': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_277:0' shape=(32,) dtype=float32>), 'data:0.278': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_278:0' shape=(32,) dtype=float32>), 'data:0.279': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_279:0' shape=(32,) dtype=float32>), 'data:0.280': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_280:0' shape=(32,) dtype=float32>), 'data:0.281': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_281:0' shape=(32,) dtype=float32>), 'data:0.282': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_282:0' shape=(32,) dtype=float32>), 'data:0.283': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_283:0' shape=(32,) dtype=float32>), 'data:0.284': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_284:0' shape=(32,) dtype=float32>), 'data:0.285': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_285:0' shape=(32,) dtype=float32>), 'data:0.286': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_286:0' shape=(32,) dtype=float32>), 'data:0.287': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_287:0' shape=(32,) dtype=float32>), 'data:0.288': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_288:0' shape=(32,) dtype=float32>), 'data:0.289': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_289:0' shape=(32,) dtype=float32>), 'data:0.290': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_290:0' shape=(32,) dtype=float32>), 'data:0.291': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_291:0' shape=(32,) dtype=float32>), 'data:0.292': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_292:0' shape=(32,) dtype=float32>), 'data:0.293': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_293:0' shape=(32,) dtype=float32>), 'data:0.294': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_294:0' shape=(32,) dtype=float32>), 'data:0.295': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_295:0' shape=(32,) dtype=float32>), 'data:0.296': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_296:0' shape=(32,) dtype=float32>), 'data:0.297': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_297:0' shape=(32,) dtype=float32>), 'data:0.298': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_298:0' shape=(32,) dtype=float32>), 'data:0.299': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_299:0' shape=(32,) dtype=float32>), 'data:0.300': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_300:0' shape=(32,) dtype=float32>), 'data:0.301': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_301:0' shape=(32,) dtype=float32>), 'data:0.302': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_302:0' shape=(32,) dtype=float32>), 'data:0.303': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_303:0' shape=(32,) dtype=float32>), 'data:0.304': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_304:0' shape=(32,) dtype=float32>), 'data:0.305': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_305:0' shape=(32,) dtype=float32>), 'data:0.306': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_306:0' shape=(32,) dtype=float32>), 'data:0.307': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_307:0' shape=(32,) dtype=float32>), 'data:0.308': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_308:0' shape=(32,) dtype=float32>), 'data:0.309': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_309:0' shape=(32,) dtype=float32>), 'data:0.310': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_310:0' shape=(32,) dtype=float32>), 'data:0.311': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_311:0' shape=(32,) dtype=float32>), 'data:0.312': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_312:0' shape=(32,) dtype=float32>), 'data:0.313': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_313:0' shape=(32,) dtype=float32>), 'data:0.314': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_314:0' shape=(32,) dtype=float32>), 'data:0.315': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_315:0' shape=(32,) dtype=float32>), 'data:0.316': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_316:0' shape=(32,) dtype=float32>), 'data:0.317': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_317:0' shape=(32,) dtype=float32>), 'data:0.318': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_318:0' shape=(32,) dtype=float32>), 'data:0.319': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_319:0' shape=(32,) dtype=float32>), 'data:0.320': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_320:0' shape=(32,) dtype=float32>), 'data:0.321': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_321:0' shape=(32,) dtype=float32>), 'data:0.322': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_322:0' shape=(32,) dtype=float32>), 'data:0.323': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_323:0' shape=(32,) dtype=float32>), 'data:0.324': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_324:0' shape=(32,) dtype=float32>), 'data:0.325': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_325:0' shape=(32,) dtype=float32>), 'data:0.326': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_326:0' shape=(32,) dtype=float32>), 'data:0.327': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_327:0' shape=(32,) dtype=float32>), 'data:0.328': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_328:0' shape=(32,) dtype=float32>), 'data:0.329': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_329:0' shape=(32,) dtype=float32>), 'data:0.330': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_330:0' shape=(32,) dtype=float32>), 'data:0.331': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_331:0' shape=(32,) dtype=float32>), 'data:0.332': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_332:0' shape=(32,) dtype=float32>), 'data:0.333': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_333:0' shape=(32,) dtype=float32>), 'data:0.334': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_334:0' shape=(32,) dtype=float32>), 'data:0.335': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_335:0' shape=(32,) dtype=float32>), 'data:0.336': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_336:0' shape=(32,) dtype=float32>), 'data:0.337': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_337:0' shape=(32,) dtype=float32>), 'data:0.338': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_338:0' shape=(32,) dtype=float32>), 'data:0.339': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_339:0' shape=(32,) dtype=float32>), 'data:0.340': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_340:0' shape=(32,) dtype=float32>), 'data:0.341': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_341:0' shape=(32,) dtype=float32>), 'data:0.342': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_342:0' shape=(32,) dtype=float32>), 'data:0.343': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_343:0' shape=(32,) dtype=float32>), 'data:0.344': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_344:0' shape=(32,) dtype=float32>), 'data:0.345': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_345:0' shape=(32,) dtype=float32>), 'data:0.346': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_346:0' shape=(32,) dtype=float32>), 'data:0.347': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_347:0' shape=(32,) dtype=float32>), 'data:0.348': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_348:0' shape=(32,) dtype=float32>), 'data:0.349': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_349:0' shape=(32,) dtype=float32>), 'data:0.350': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_350:0' shape=(32,) dtype=float32>), 'data:0.351': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_351:0' shape=(32,) dtype=float32>), 'data:0.352': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_352:0' shape=(32,) dtype=float32>), 'data:0.353': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_353:0' shape=(32,) dtype=float32>), 'data:0.354': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_354:0' shape=(32,) dtype=float32>), 'data:0.355': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_355:0' shape=(32,) dtype=float32>), 'data:0.356': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_356:0' shape=(32,) dtype=float32>), 'data:0.357': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_357:0' shape=(32,) dtype=float32>), 'data:0.358': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_358:0' shape=(32,) dtype=float32>), 'data:0.359': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_359:0' shape=(32,) dtype=float32>), 'data:0.360': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_360:0' shape=(32,) dtype=float32>), 'data:0.361': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_361:0' shape=(32,) dtype=float32>), 'data:0.362': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_362:0' shape=(32,) dtype=float32>), 'data:0.363': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_363:0' shape=(32,) dtype=float32>), 'data:0.364': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_364:0' shape=(32,) dtype=float32>), 'data:0.365': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_365:0' shape=(32,) dtype=float32>), 'data:0.366': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_366:0' shape=(32,) dtype=float32>), 'data:0.367': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_367:0' shape=(32,) dtype=float32>), 'data:0.368': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_368:0' shape=(32,) dtype=float32>), 'data:0.369': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_369:0' shape=(32,) dtype=float32>), 'data:0.370': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_370:0' shape=(32,) dtype=float32>), 'data:0.371': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_371:0' shape=(32,) dtype=float32>), 'data:0.372': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_372:0' shape=(32,) dtype=float32>), 'data:0.373': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_373:0' shape=(32,) dtype=float32>), 'data:0.374': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_374:0' shape=(32,) dtype=float32>), 'data:0.375': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_375:0' shape=(32,) dtype=float32>), 'data:0.376': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_376:0' shape=(32,) dtype=float32>), 'data:0.377': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_377:0' shape=(32,) dtype=float32>), 'data:0.378': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_378:0' shape=(32,) dtype=float32>), 'data:0.379': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_379:0' shape=(32,) dtype=float32>), 'data:0.380': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_380:0' shape=(32,) dtype=float32>), 'data:0.381': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_381:0' shape=(32,) dtype=float32>), 'data:0.382': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_382:0' shape=(32,) dtype=float32>), 'data:0.383': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_383:0' shape=(32,) dtype=float32>), 'data:0.384': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_384:0' shape=(32,) dtype=float32>), 'data:0.385': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_385:0' shape=(32,) dtype=float32>), 'data:0.386': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_386:0' shape=(32,) dtype=float32>), 'data:0.387': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_387:0' shape=(32,) dtype=float32>), 'data:0.388': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_388:0' shape=(32,) dtype=float32>), 'data:0.389': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_389:0' shape=(32,) dtype=float32>), 'data:0.390': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_390:0' shape=(32,) dtype=float32>), 'data:0.391': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_391:0' shape=(32,) dtype=float32>), 'data:0.392': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_392:0' shape=(32,) dtype=float32>), 'data:0.393': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_393:0' shape=(32,) dtype=float32>), 'data:0.394': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_394:0' shape=(32,) dtype=float32>), 'data:0.395': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_395:0' shape=(32,) dtype=float32>), 'data:0.396': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_396:0' shape=(32,) dtype=float32>), 'data:0.397': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_397:0' shape=(32,) dtype=float32>), 'data:0.398': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_398:0' shape=(32,) dtype=float32>), 'data:0.399': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_399:0' shape=(32,) dtype=float32>), 'data:0.400': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_400:0' shape=(32,) dtype=float32>), 'data:0.401': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_401:0' shape=(32,) dtype=float32>), 'data:0.402': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_402:0' shape=(32,) dtype=float32>), 'data:0.403': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_403:0' shape=(32,) dtype=float32>), 'data:0.404': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_404:0' shape=(32,) dtype=float32>), 'data:0.405': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_405:0' shape=(32,) dtype=float32>), 'data:0.406': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_406:0' shape=(32,) dtype=float32>), 'data:0.407': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_407:0' shape=(32,) dtype=float32>), 'data:0.408': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_408:0' shape=(32,) dtype=float32>), 'data:0.409': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_409:0' shape=(32,) dtype=float32>), 'data:0.410': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_410:0' shape=(32,) dtype=float32>), 'data:0.411': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_411:0' shape=(32,) dtype=float32>), 'data:0.412': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_412:0' shape=(32,) dtype=float32>), 'data:0.413': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_413:0' shape=(32,) dtype=float32>), 'data:0.414': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_414:0' shape=(32,) dtype=float32>), 'data:0.415': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_415:0' shape=(32,) dtype=float32>), 'data:0.416': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_416:0' shape=(32,) dtype=float32>), 'data:0.417': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_417:0' shape=(32,) dtype=float32>), 'data:0.418': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_418:0' shape=(32,) dtype=float32>), 'data:0.419': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_419:0' shape=(32,) dtype=float32>), 'data:0.420': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_420:0' shape=(32,) dtype=float32>), 'data:0.421': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_421:0' shape=(32,) dtype=float32>), 'data:0.422': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_422:0' shape=(32,) dtype=float32>), 'data:0.423': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_423:0' shape=(32,) dtype=float32>), 'data:0.424': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_424:0' shape=(32,) dtype=float32>), 'data:0.425': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_425:0' shape=(32,) dtype=float32>), 'data:0.426': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_426:0' shape=(32,) dtype=float32>), 'data:0.427': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_427:0' shape=(32,) dtype=float32>), 'data:0.428': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_428:0' shape=(32,) dtype=float32>), 'data:0.429': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_429:0' shape=(32,) dtype=float32>), 'data:0.430': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_430:0' shape=(32,) dtype=float32>), 'data:0.431': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_431:0' shape=(32,) dtype=float32>), 'data:0.432': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_432:0' shape=(32,) dtype=float32>), 'data:0.433': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_433:0' shape=(32,) dtype=float32>), 'data:0.434': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_434:0' shape=(32,) dtype=float32>), 'data:0.435': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_435:0' shape=(32,) dtype=float32>), 'data:0.436': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_436:0' shape=(32,) dtype=float32>), 'data:0.437': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_437:0' shape=(32,) dtype=float32>), 'data:0.438': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_438:0' shape=(32,) dtype=float32>), 'data:0.439': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_439:0' shape=(32,) dtype=float32>), 'data:0.440': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_440:0' shape=(32,) dtype=float32>), 'data:0.441': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_441:0' shape=(32,) dtype=float32>), 'data:0.442': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_442:0' shape=(32,) dtype=float32>), 'data:0.443': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_443:0' shape=(32,) dtype=float32>), 'data:0.444': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_444:0' shape=(32,) dtype=float32>), 'data:0.445': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_445:0' shape=(32,) dtype=float32>), 'data:0.446': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_446:0' shape=(32,) dtype=float32>), 'data:0.447': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_447:0' shape=(32,) dtype=float32>), 'data:0.448': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_448:0' shape=(32,) dtype=float32>), 'data:0.449': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_449:0' shape=(32,) dtype=float32>), 'data:0.450': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_450:0' shape=(32,) dtype=float32>), 'data:0.451': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_451:0' shape=(32,) dtype=float32>), 'data:0.452': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_452:0' shape=(32,) dtype=float32>), 'data:0.453': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_453:0' shape=(32,) dtype=float32>), 'data:0.454': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_454:0' shape=(32,) dtype=float32>), 'data:0.455': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_455:0' shape=(32,) dtype=float32>), 'data:0.456': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_456:0' shape=(32,) dtype=float32>), 'data:0.457': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_457:0' shape=(32,) dtype=float32>), 'data:0.458': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_458:0' shape=(32,) dtype=float32>), 'data:0.459': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_459:0' shape=(32,) dtype=float32>), 'data:0.460': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_460:0' shape=(32,) dtype=float32>), 'data:0.461': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_461:0' shape=(32,) dtype=float32>), 'data:0.462': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_462:0' shape=(32,) dtype=float32>), 'data:0.463': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_463:0' shape=(32,) dtype=float32>), 'data:0.464': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_464:0' shape=(32,) dtype=float32>), 'data:0.465': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_465:0' shape=(32,) dtype=float32>), 'data:0.466': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_466:0' shape=(32,) dtype=float32>), 'data:0.467': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_467:0' shape=(32,) dtype=float32>), 'data:0.468': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_468:0' shape=(32,) dtype=float32>), 'data:0.469': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_469:0' shape=(32,) dtype=float32>), 'data:0.470': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_470:0' shape=(32,) dtype=float32>), 'data:0.471': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_471:0' shape=(32,) dtype=float32>), 'data:0.472': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_472:0' shape=(32,) dtype=float32>), 'data:0.473': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_473:0' shape=(32,) dtype=float32>), 'data:0.474': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_474:0' shape=(32,) dtype=float32>), 'data:0.475': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_475:0' shape=(32,) dtype=float32>), 'data:0.476': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_476:0' shape=(32,) dtype=float32>), 'data:0.477': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_477:0' shape=(32,) dtype=float32>), 'data:0.478': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_478:0' shape=(32,) dtype=float32>), 'data:0.479': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_479:0' shape=(32,) dtype=float32>), 'data:0.480': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_480:0' shape=(32,) dtype=float32>), 'data:0.481': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_481:0' shape=(32,) dtype=float32>), 'data:0.482': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_482:0' shape=(32,) dtype=float32>), 'data:0.483': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_483:0' shape=(32,) dtype=float32>), 'data:0.484': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_484:0' shape=(32,) dtype=float32>), 'data:0.485': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_485:0' shape=(32,) dtype=float32>), 'data:0.486': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_486:0' shape=(32,) dtype=float32>), 'data:0.487': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_487:0' shape=(32,) dtype=float32>), 'data:0.488': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_488:0' shape=(32,) dtype=float32>), 'data:0.489': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_489:0' shape=(32,) dtype=float32>), 'data:0.490': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_490:0' shape=(32,) dtype=float32>), 'data:0.491': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_491:0' shape=(32,) dtype=float32>), 'data:0.492': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_492:0' shape=(32,) dtype=float32>), 'data:0.493': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_493:0' shape=(32,) dtype=float32>), 'data:0.494': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_494:0' shape=(32,) dtype=float32>), 'data:0.495': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_495:0' shape=(32,) dtype=float32>), 'data:0.496': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_496:0' shape=(32,) dtype=float32>), 'data:0.497': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_497:0' shape=(32,) dtype=float32>), 'data:0.498': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_498:0' shape=(32,) dtype=float32>), 'data:0.499': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_499:0' shape=(32,) dtype=float32>), 'data:0.500': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_500:0' shape=(32,) dtype=float32>), 'data:0.501': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_501:0' shape=(32,) dtype=float32>), 'data:0.502': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_502:0' shape=(32,) dtype=float32>), 'data:0.503': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_503:0' shape=(32,) dtype=float32>), 'data:0.504': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_504:0' shape=(32,) dtype=float32>), 'data:0.505': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_505:0' shape=(32,) dtype=float32>), 'data:0.506': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_506:0' shape=(32,) dtype=float32>), 'data:0.507': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_507:0' shape=(32,) dtype=float32>), 'data:0.508': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_508:0' shape=(32,) dtype=float32>), 'data:0.509': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_509:0' shape=(32,) dtype=float32>), 'data:0.510': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_510:0' shape=(32,) dtype=float32>), 'data:0.511': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_511:0' shape=(32,) dtype=float32>), 'data:0.512': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_512:0' shape=(32,) dtype=float32>), 'data:0.513': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_513:0' shape=(32,) dtype=float32>), 'data:0.514': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_514:0' shape=(32,) dtype=float32>), 'data:0.515': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_515:0' shape=(32,) dtype=float32>), 'data:0.516': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_516:0' shape=(32,) dtype=float32>), 'data:0.517': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_517:0' shape=(32,) dtype=float32>), 'data:0.518': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_518:0' shape=(32,) dtype=float32>), 'data:0.519': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_519:0' shape=(32,) dtype=float32>), 'data:0.520': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_520:0' shape=(32,) dtype=float32>), 'data:0.521': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_521:0' shape=(32,) dtype=float32>), 'data:0.522': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_522:0' shape=(32,) dtype=float32>), 'data:0.523': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_523:0' shape=(32,) dtype=float32>), 'data:0.524': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_524:0' shape=(32,) dtype=float32>), 'data:0.525': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_525:0' shape=(32,) dtype=float32>), 'data:0.526': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_526:0' shape=(32,) dtype=float32>), 'data:0.527': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_527:0' shape=(32,) dtype=float32>), 'data:0.528': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_528:0' shape=(32,) dtype=float32>), 'data:0.529': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_529:0' shape=(32,) dtype=float32>), 'data:0.530': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_530:0' shape=(32,) dtype=float32>), 'data:0.531': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_531:0' shape=(32,) dtype=float32>), 'data:0.532': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_532:0' shape=(32,) dtype=float32>), 'data:0.533': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_533:0' shape=(32,) dtype=float32>), 'data:0.534': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_534:0' shape=(32,) dtype=float32>), 'data:0.535': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_535:0' shape=(32,) dtype=float32>), 'data:0.536': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_536:0' shape=(32,) dtype=float32>), 'data:0.537': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_537:0' shape=(32,) dtype=float32>), 'data:0.538': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_538:0' shape=(32,) dtype=float32>), 'data:0.539': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_539:0' shape=(32,) dtype=float32>), 'data:0.540': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_540:0' shape=(32,) dtype=float32>), 'data:0.541': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_541:0' shape=(32,) dtype=float32>), 'data:0.542': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_542:0' shape=(32,) dtype=float32>), 'data:0.543': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_543:0' shape=(32,) dtype=float32>), 'data:0.544': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_544:0' shape=(32,) dtype=float32>), 'data:0.545': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_545:0' shape=(32,) dtype=float32>), 'data:0.546': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_546:0' shape=(32,) dtype=float32>), 'data:0.547': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_547:0' shape=(32,) dtype=float32>), 'data:0.548': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_548:0' shape=(32,) dtype=float32>), 'data:0.549': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_549:0' shape=(32,) dtype=float32>), 'data:0.550': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_550:0' shape=(32,) dtype=float32>), 'data:0.551': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_551:0' shape=(32,) dtype=float32>), 'data:0.552': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_552:0' shape=(32,) dtype=float32>), 'data:0.553': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_553:0' shape=(32,) dtype=float32>), 'data:0.554': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_554:0' shape=(32,) dtype=float32>), 'data:0.555': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_555:0' shape=(32,) dtype=float32>), 'data:0.556': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_556:0' shape=(32,) dtype=float32>), 'data:0.557': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_557:0' shape=(32,) dtype=float32>), 'data:0.558': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_558:0' shape=(32,) dtype=float32>), 'data:0.559': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_559:0' shape=(32,) dtype=float32>), 'data:0.560': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_560:0' shape=(32,) dtype=float32>), 'data:0.561': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_561:0' shape=(32,) dtype=float32>), 'data:0.562': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_562:0' shape=(32,) dtype=float32>), 'data:0.563': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_563:0' shape=(32,) dtype=float32>), 'data:0.564': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_564:0' shape=(32,) dtype=float32>), 'data:0.565': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_565:0' shape=(32,) dtype=float32>), 'data:0.566': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_566:0' shape=(32,) dtype=float32>), 'data:0.567': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_567:0' shape=(32,) dtype=float32>), 'data:0.568': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_568:0' shape=(32,) dtype=float32>), 'data:0.569': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_569:0' shape=(32,) dtype=float32>), 'data:0.570': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_570:0' shape=(32,) dtype=float32>), 'data:0.571': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_571:0' shape=(32,) dtype=float32>), 'data:0.572': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_572:0' shape=(32,) dtype=float32>), 'data:0.573': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_573:0' shape=(32,) dtype=float32>), 'data:0.574': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_574:0' shape=(32,) dtype=float32>), 'data:0.575': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_575:0' shape=(32,) dtype=float32>), 'data:0.576': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_576:0' shape=(32,) dtype=float32>), 'data:0.577': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_577:0' shape=(32,) dtype=float32>), 'data:0.578': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_578:0' shape=(32,) dtype=float32>), 'data:0.579': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_579:0' shape=(32,) dtype=float32>), 'data:0.580': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_580:0' shape=(32,) dtype=float32>), 'data:0.581': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_581:0' shape=(32,) dtype=float32>), 'data:0.582': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_582:0' shape=(32,) dtype=float32>), 'data:0.583': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_583:0' shape=(32,) dtype=float32>), 'data:0.584': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_584:0' shape=(32,) dtype=float32>), 'data:0.585': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_585:0' shape=(32,) dtype=float32>), 'data:0.586': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_586:0' shape=(32,) dtype=float32>), 'data:0.587': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_587:0' shape=(32,) dtype=float32>), 'data:0.588': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_588:0' shape=(32,) dtype=float32>), 'data:0.589': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_589:0' shape=(32,) dtype=float32>), 'data:0.590': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_590:0' shape=(32,) dtype=float32>), 'data:0.591': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_591:0' shape=(32,) dtype=float32>), 'data:0.592': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_592:0' shape=(32,) dtype=float32>), 'data:0.593': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_593:0' shape=(32,) dtype=float32>), 'data:0.594': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_594:0' shape=(32,) dtype=float32>), 'data:0.595': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_595:0' shape=(32,) dtype=float32>), 'data:0.596': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_596:0' shape=(32,) dtype=float32>), 'data:0.597': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_597:0' shape=(32,) dtype=float32>), 'data:0.598': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_598:0' shape=(32,) dtype=float32>), 'data:0.599': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_599:0' shape=(32,) dtype=float32>), 'data:0.600': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_600:0' shape=(32,) dtype=float32>), 'data:0.601': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_601:0' shape=(32,) dtype=float32>), 'data:0.602': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_602:0' shape=(32,) dtype=float32>), 'data:0.603': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_603:0' shape=(32,) dtype=float32>), 'data:0.604': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_604:0' shape=(32,) dtype=float32>), 'data:0.605': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_605:0' shape=(32,) dtype=float32>), 'data:0.606': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_606:0' shape=(32,) dtype=float32>), 'data:0.607': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_607:0' shape=(32,) dtype=float32>), 'data:0.608': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_608:0' shape=(32,) dtype=float32>), 'data:0.609': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_609:0' shape=(32,) dtype=float32>), 'data:0.610': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_610:0' shape=(32,) dtype=float32>), 'data:0.611': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_611:0' shape=(32,) dtype=float32>), 'data:0.612': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_612:0' shape=(32,) dtype=float32>), 'data:0.613': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_613:0' shape=(32,) dtype=float32>), 'data:0.614': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_614:0' shape=(32,) dtype=float32>), 'data:0.615': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_615:0' shape=(32,) dtype=float32>), 'data:0.616': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_616:0' shape=(32,) dtype=float32>), 'data:0.617': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_617:0' shape=(32,) dtype=float32>), 'data:0.618': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_618:0' shape=(32,) dtype=float32>), 'data:0.619': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_619:0' shape=(32,) dtype=float32>), 'data:0.620': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_620:0' shape=(32,) dtype=float32>), 'data:0.621': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_621:0' shape=(32,) dtype=float32>), 'data:0.622': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_622:0' shape=(32,) dtype=float32>), 'data:0.623': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_623:0' shape=(32,) dtype=float32>), 'data:0.624': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_624:0' shape=(32,) dtype=float32>), 'data:0.625': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_625:0' shape=(32,) dtype=float32>), 'data:0.626': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_626:0' shape=(32,) dtype=float32>), 'data:0.627': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_627:0' shape=(32,) dtype=float32>), 'data:0.628': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_628:0' shape=(32,) dtype=float32>), 'data:0.629': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_629:0' shape=(32,) dtype=float32>), 'data:0.630': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_630:0' shape=(32,) dtype=float32>), 'data:0.631': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_631:0' shape=(32,) dtype=float32>), 'data:0.632': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_632:0' shape=(32,) dtype=float32>), 'data:0.633': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_633:0' shape=(32,) dtype=float32>), 'data:0.634': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_634:0' shape=(32,) dtype=float32>), 'data:0.635': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_635:0' shape=(32,) dtype=float32>), 'data:0.636': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_636:0' shape=(32,) dtype=float32>), 'data:0.637': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_637:0' shape=(32,) dtype=float32>), 'data:0.638': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_638:0' shape=(32,) dtype=float32>), 'data:0.639': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_639:0' shape=(32,) dtype=float32>), 'data:0.640': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_640:0' shape=(32,) dtype=float32>), 'data:0.641': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_641:0' shape=(32,) dtype=float32>), 'data:0.642': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_642:0' shape=(32,) dtype=float32>), 'data:0.643': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_643:0' shape=(32,) dtype=float32>), 'data:0.644': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_644:0' shape=(32,) dtype=float32>), 'data:0.645': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_645:0' shape=(32,) dtype=float32>), 'data:0.646': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_646:0' shape=(32,) dtype=float32>), 'data:0.647': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_647:0' shape=(32,) dtype=float32>), 'data:0.648': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_648:0' shape=(32,) dtype=float32>), 'data:0.649': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_649:0' shape=(32,) dtype=float32>), 'data:0.650': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_650:0' shape=(32,) dtype=float32>), 'data:0.651': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_651:0' shape=(32,) dtype=float32>), 'data:0.652': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_652:0' shape=(32,) dtype=float32>), 'data:0.653': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_653:0' shape=(32,) dtype=float32>), 'data:0.654': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_654:0' shape=(32,) dtype=float32>), 'data:0.655': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_655:0' shape=(32,) dtype=float32>), 'data:0.656': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_656:0' shape=(32,) dtype=float32>), 'data:0.657': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_657:0' shape=(32,) dtype=float32>), 'data:0.658': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_658:0' shape=(32,) dtype=float32>), 'data:0.659': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_659:0' shape=(32,) dtype=float32>), 'data:0.660': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_660:0' shape=(32,) dtype=float32>), 'data:0.661': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_661:0' shape=(32,) dtype=float32>), 'data:0.662': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_662:0' shape=(32,) dtype=float32>), 'data:0.663': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_663:0' shape=(32,) dtype=float32>), 'data:0.664': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_664:0' shape=(32,) dtype=float32>), 'data:0.665': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_665:0' shape=(32,) dtype=float32>), 'data:0.666': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_666:0' shape=(32,) dtype=float32>), 'data:0.667': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_667:0' shape=(32,) dtype=float32>), 'data:0.668': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_668:0' shape=(32,) dtype=float32>), 'data:0.669': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_669:0' shape=(32,) dtype=float32>), 'data:0.670': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_670:0' shape=(32,) dtype=float32>), 'data:0.671': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_671:0' shape=(32,) dtype=float32>), 'data:0.672': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_672:0' shape=(32,) dtype=float32>), 'data:0.673': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_673:0' shape=(32,) dtype=float32>), 'data:0.674': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_674:0' shape=(32,) dtype=float32>), 'data:0.675': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_675:0' shape=(32,) dtype=float32>), 'data:0.676': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_676:0' shape=(32,) dtype=float32>), 'data:0.677': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_677:0' shape=(32,) dtype=float32>), 'data:0.678': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_678:0' shape=(32,) dtype=float32>), 'data:0.679': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_679:0' shape=(32,) dtype=float32>), 'data:0.680': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_680:0' shape=(32,) dtype=float32>), 'data:0.681': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_681:0' shape=(32,) dtype=float32>), 'data:0.682': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_682:0' shape=(32,) dtype=float32>), 'data:0.683': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_683:0' shape=(32,) dtype=float32>), 'data:0.684': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_684:0' shape=(32,) dtype=float32>), 'data:0.685': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_685:0' shape=(32,) dtype=float32>), 'data:0.686': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_686:0' shape=(32,) dtype=float32>), 'data:0.687': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_687:0' shape=(32,) dtype=float32>), 'data:0.688': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_688:0' shape=(32,) dtype=float32>), 'data:0.689': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_689:0' shape=(32,) dtype=float32>), 'data:0.690': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_690:0' shape=(32,) dtype=float32>), 'data:0.691': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_691:0' shape=(32,) dtype=float32>), 'data:0.692': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_692:0' shape=(32,) dtype=float32>), 'data:0.693': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_693:0' shape=(32,) dtype=float32>), 'data:0.694': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_694:0' shape=(32,) dtype=float32>), 'data:0.695': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_695:0' shape=(32,) dtype=float32>), 'data:0.696': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_696:0' shape=(32,) dtype=float32>), 'data:0.697': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_697:0' shape=(32,) dtype=float32>), 'data:0.698': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_698:0' shape=(32,) dtype=float32>), 'data:0.699': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_699:0' shape=(32,) dtype=float32>), 'data:0.700': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_700:0' shape=(32,) dtype=float32>), 'data:0.701': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_701:0' shape=(32,) dtype=float32>), 'data:0.702': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_702:0' shape=(32,) dtype=float32>), 'data:0.703': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_703:0' shape=(32,) dtype=float32>), 'data:0.704': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_704:0' shape=(32,) dtype=float32>), 'data:0.705': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_705:0' shape=(32,) dtype=float32>), 'data:0.706': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_706:0' shape=(32,) dtype=float32>), 'data:0.707': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_707:0' shape=(32,) dtype=float32>), 'data:0.708': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_708:0' shape=(32,) dtype=float32>), 'data:0.709': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_709:0' shape=(32,) dtype=float32>), 'data:0.710': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_710:0' shape=(32,) dtype=float32>), 'data:0.711': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_711:0' shape=(32,) dtype=float32>), 'data:0.712': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_712:0' shape=(32,) dtype=float32>), 'data:0.713': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_713:0' shape=(32,) dtype=float32>), 'data:0.714': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_714:0' shape=(32,) dtype=float32>), 'data:0.715': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_715:0' shape=(32,) dtype=float32>), 'data:0.716': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_716:0' shape=(32,) dtype=float32>), 'data:0.717': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_717:0' shape=(32,) dtype=float32>), 'data:0.718': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_718:0' shape=(32,) dtype=float32>), 'data:0.719': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_719:0' shape=(32,) dtype=float32>), 'data:0.720': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_720:0' shape=(32,) dtype=float32>), 'data:0.721': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_721:0' shape=(32,) dtype=float32>), 'data:0.722': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_722:0' shape=(32,) dtype=float32>), 'data:0.723': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_723:0' shape=(32,) dtype=float32>), 'data:0.724': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_724:0' shape=(32,) dtype=float32>), 'data:0.725': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_725:0' shape=(32,) dtype=float32>), 'data:0.726': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_726:0' shape=(32,) dtype=float32>), 'data:0.727': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_727:0' shape=(32,) dtype=float32>), 'data:0.728': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_728:0' shape=(32,) dtype=float32>), 'data:0.729': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_729:0' shape=(32,) dtype=float32>), 'data:0.730': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_730:0' shape=(32,) dtype=float32>), 'data:0.731': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_731:0' shape=(32,) dtype=float32>), 'data:0.732': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_732:0' shape=(32,) dtype=float32>), 'data:0.733': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_733:0' shape=(32,) dtype=float32>), 'data:0.734': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_734:0' shape=(32,) dtype=float32>), 'data:0.735': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_735:0' shape=(32,) dtype=float32>), 'data:0.736': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_736:0' shape=(32,) dtype=float32>), 'data:0.737': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_737:0' shape=(32,) dtype=float32>), 'data:0.738': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_738:0' shape=(32,) dtype=float32>), 'data:0.739': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_739:0' shape=(32,) dtype=float32>), 'data:0.740': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_740:0' shape=(32,) dtype=float32>), 'data:0.741': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_741:0' shape=(32,) dtype=float32>), 'data:0.742': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_742:0' shape=(32,) dtype=float32>), 'data:0.743': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_743:0' shape=(32,) dtype=float32>), 'data:0.744': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_744:0' shape=(32,) dtype=float32>), 'data:0.745': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_745:0' shape=(32,) dtype=float32>), 'data:0.746': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_746:0' shape=(32,) dtype=float32>), 'data:0.747': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_747:0' shape=(32,) dtype=float32>), 'data:0.748': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_748:0' shape=(32,) dtype=float32>), 'data:0.749': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_749:0' shape=(32,) dtype=float32>), 'data:0.750': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_750:0' shape=(32,) dtype=float32>), 'data:0.751': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_751:0' shape=(32,) dtype=float32>), 'data:0.752': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_752:0' shape=(32,) dtype=float32>), 'data:0.753': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_753:0' shape=(32,) dtype=float32>), 'data:0.754': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_754:0' shape=(32,) dtype=float32>), 'data:0.755': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_755:0' shape=(32,) dtype=float32>), 'data:0.756': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_756:0' shape=(32,) dtype=float32>), 'data:0.757': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_757:0' shape=(32,) dtype=float32>), 'data:0.758': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_758:0' shape=(32,) dtype=float32>), 'data:0.759': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_759:0' shape=(32,) dtype=float32>), 'data:0.760': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_760:0' shape=(32,) dtype=float32>), 'data:0.761': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_761:0' shape=(32,) dtype=float32>), 'data:0.762': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_762:0' shape=(32,) dtype=float32>), 'data:0.763': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_763:0' shape=(32,) dtype=float32>), 'data:0.764': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_764:0' shape=(32,) dtype=float32>), 'data:0.765': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_765:0' shape=(32,) dtype=float32>), 'data:0.766': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_766:0' shape=(32,) dtype=float32>), 'data:0.767': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_767:0' shape=(32,) dtype=float32>), 'data:0.768': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_768:0' shape=(32,) dtype=float32>), 'data:0.769': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_769:0' shape=(32,) dtype=float32>), 'data:0.770': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_770:0' shape=(32,) dtype=float32>), 'data:0.771': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_771:0' shape=(32,) dtype=float32>), 'data:0.772': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_772:0' shape=(32,) dtype=float32>), 'data:0.773': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_773:0' shape=(32,) dtype=float32>), 'data:0.774': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_774:0' shape=(32,) dtype=float32>), 'data:0.775': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_775:0' shape=(32,) dtype=float32>), 'data:0.776': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_776:0' shape=(32,) dtype=float32>), 'data:0.777': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_777:0' shape=(32,) dtype=float32>), 'data:0.778': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_778:0' shape=(32,) dtype=float32>), 'data:0.779': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_779:0' shape=(32,) dtype=float32>), 'data:0.780': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_780:0' shape=(32,) dtype=float32>), 'data:0.781': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_781:0' shape=(32,) dtype=float32>), 'data:0.782': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_782:0' shape=(32,) dtype=float32>), 'data:0.783': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_783:0' shape=(32,) dtype=float32>)}\n",
            "Training dataset read in 0:00:11.743355. Found 60000 examples.\n",
            "Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO 23-05-27 16:47:48.2561 UTC kernel.cc:773] Start Yggdrasil model training\n",
            "[INFO 23-05-27 16:47:48.2562 UTC kernel.cc:774] Collect training examples\n",
            "[INFO 23-05-27 16:47:48.2562 UTC kernel.cc:787] Dataspec guide:\n",
            "column_guides {\n",
            "  column_name_pattern: \"^__LABEL$\"\n",
            "  type: CATEGORICAL\n",
            "  categorial {\n",
            "    min_vocab_frequency: 0\n",
            "    max_vocab_count: -1\n",
            "  }\n",
            "}\n",
            "default_column_guide {\n",
            "  categorial {\n",
            "    max_vocab_count: 2000\n",
            "  }\n",
            "  discretized_numerical {\n",
            "    maximum_num_bins: 255\n",
            "  }\n",
            "}\n",
            "ignore_columns_without_guides: false\n",
            "detect_numerical_as_discretized_numerical: false\n",
            "\n",
            "[INFO 23-05-27 16:47:48.2585 UTC kernel.cc:393] Number of batches: 1875\n",
            "[INFO 23-05-27 16:47:48.2585 UTC kernel.cc:394] Number of examples: 60000\n",
            "[INFO 23-05-27 16:47:49.1211 UTC kernel.cc:794] Training dataset:\n",
            "Number of records: 60000\n",
            "Number of columns: 785\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 784 (99.8726%)\n",
            "\tCATEGORICAL: 1 (0.127389%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 784 (99.8726%)\n",
            "\t1: \"data:0.0\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t2: \"data:0.1\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t3: \"data:0.10\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t4: \"data:0.100\" NUMERICAL mean:0.0514691 min:0 max:1 sd:0.196\n",
            "\t5: \"data:0.101\" NUMERICAL mean:0.0463275 min:0 max:1 sd:0.186913\n",
            "\t6: \"data:0.102\" NUMERICAL mean:0.0374261 min:0 max:1 sd:0.168626\n",
            "\t7: \"data:0.103\" NUMERICAL mean:0.0269139 min:0 max:1 sd:0.143762\n",
            "\t8: \"data:0.104\" NUMERICAL mean:0.0164457 min:0 max:1 sd:0.11139\n",
            "\t9: \"data:0.105\" NUMERICAL mean:0.00892013 min:0 max:1 sd:0.0824683\n",
            "\t10: \"data:0.106\" NUMERICAL mean:0.00416092 min:0 max:1 sd:0.05417\n",
            "\t11: \"data:0.107\" NUMERICAL mean:0.00161987 min:0 max:1 sd:0.0344102\n",
            "\t12: \"data:0.108\" NUMERICAL mean:0.000635621 min:0 max:1 sd:0.0210457\n",
            "\t13: \"data:0.109\" NUMERICAL mean:0.000108889 min:0 max:0.752941 sd:0.00714436\n",
            "\t14: \"data:0.11\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t15: \"data:0.110\" NUMERICAL mean:1.09804e-05 min:0 max:0.47451 sd:0.00207816\n",
            "\t16: \"data:0.111\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t17: \"data:0.112\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t18: \"data:0.113\" NUMERICAL mean:2.48366e-06 min:0 max:0.14902 sd:0.000608365\n",
            "\t19: \"data:0.114\" NUMERICAL mean:2.04575e-05 min:0 max:0.564706 sd:0.00263512\n",
            "\t20: \"data:0.115\" NUMERICAL mean:5.62745e-05 min:0 max:0.396078 sd:0.00377852\n",
            "\t21: \"data:0.116\" NUMERICAL mean:0.00031719 min:0 max:0.996078 sd:0.0132368\n",
            "\t22: \"data:0.117\" NUMERICAL mean:0.00160869 min:0 max:1 sd:0.031956\n",
            "\t23: \"data:0.118\" NUMERICAL mean:0.00409111 min:0 max:1 sd:0.0519391\n",
            "\t24: \"data:0.119\" NUMERICAL mean:0.00948739 min:0 max:1 sd:0.08166\n",
            "\t25: \"data:0.12\" NUMERICAL mean:8.23529e-06 min:0 max:0.454902 sd:0.001864\n",
            "\t26: \"data:0.120\" NUMERICAL mean:0.0187284 min:0 max:1 sd:0.116147\n",
            "\t27: \"data:0.121\" NUMERICAL mean:0.0329193 min:0 max:1 sd:0.155308\n",
            "\t28: \"data:0.122\" NUMERICAL mean:0.0521971 min:0 max:1 sd:0.195569\n",
            "\t29: \"data:0.123\" NUMERICAL mean:0.0763816 min:0 max:1 sd:0.234531\n",
            "\t30: \"data:0.124\" NUMERICAL mean:0.106026 min:0 max:1 sd:0.271694\n",
            "\t31: \"data:0.125\" NUMERICAL mean:0.138087 min:0 max:1 sd:0.30545\n",
            "\t32: \"data:0.126\" NUMERICAL mean:0.164082 min:0 max:1 sd:0.328559\n",
            "\t33: \"data:0.127\" NUMERICAL mean:0.177461 min:0 max:1 sd:0.339036\n",
            "\t34: \"data:0.128\" NUMERICAL mean:0.173878 min:0 max:1 sd:0.335919\n",
            "\t35: \"data:0.129\" NUMERICAL mean:0.153496 min:0 max:1 sd:0.319183\n",
            "\t36: \"data:0.13\" NUMERICAL mean:3.0719e-05 min:0 max:0.996078 sd:0.00533795\n",
            "\t37: \"data:0.130\" NUMERICAL mean:0.122856 min:0 max:1 sd:0.290384\n",
            "\t38: \"data:0.131\" NUMERICAL mean:0.0898978 min:0 max:1 sd:0.251998\n",
            "\t39: \"data:0.132\" NUMERICAL mean:0.0581609 min:0 max:1 sd:0.20502\n",
            "\t40: \"data:0.133\" NUMERICAL mean:0.0339663 min:0 max:1 sd:0.156645\n",
            "\t41: \"data:0.134\" NUMERICAL mean:0.0178352 min:0 max:1 sd:0.112507\n",
            "\t42: \"data:0.135\" NUMERICAL mean:0.00838046 min:0 max:1 sd:0.0770372\n",
            "\t43: \"data:0.136\" NUMERICAL mean:0.00338392 min:0 max:1 sd:0.0477129\n",
            "\t44: \"data:0.137\" NUMERICAL mean:0.000814706 min:0 max:0.996078 sd:0.0209148\n",
            "\t45: \"data:0.138\" NUMERICAL mean:0.000116275 min:0 max:0.866667 sd:0.00815825\n",
            "\t46: \"data:0.139\" NUMERICAL mean:7.97386e-06 min:0 max:0.247059 sd:0.00138183\n",
            "\t47: \"data:0.14\" NUMERICAL mean:1.41176e-05 min:0 max:0.847059 sd:0.00345807\n",
            "\t48: \"data:0.140\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t49: \"data:0.141\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t50: \"data:0.142\" NUMERICAL mean:4.04575e-05 min:0 max:0.372549 sd:0.00339929\n",
            "\t51: \"data:0.143\" NUMERICAL mean:0.000248431 min:0 max:1 sd:0.0112666\n",
            "\t52: \"data:0.144\" NUMERICAL mean:0.00155085 min:0 max:1 sd:0.0299172\n",
            "\t53: \"data:0.145\" NUMERICAL mean:0.00573882 min:0 max:1 sd:0.0633007\n",
            "\t54: \"data:0.146\" NUMERICAL mean:0.0140697 min:0 max:1 sd:0.100738\n",
            "\t55: \"data:0.147\" NUMERICAL mean:0.0283444 min:0 max:1 sd:0.14382\n",
            "\t56: \"data:0.148\" NUMERICAL mean:0.0510475 min:0 max:1 sd:0.19308\n",
            "\t57: \"data:0.149\" NUMERICAL mean:0.0832075 min:0 max:1 sd:0.244203\n",
            "\t58: \"data:0.15\" NUMERICAL mean:5.88235e-07 min:0 max:0.0352941 sd:0.000144086\n",
            "\t59: \"data:0.150\" NUMERICAL mean:0.123531 min:0 max:1 sd:0.292356\n",
            "\t60: \"data:0.151\" NUMERICAL mean:0.173358 min:0 max:1 sd:0.336351\n",
            "\t61: \"data:0.152\" NUMERICAL mean:0.230995 min:0 max:1 sd:0.374971\n",
            "\t62: \"data:0.153\" NUMERICAL mean:0.289428 min:0 max:1 sd:0.404239\n",
            "\t63: \"data:0.154\" NUMERICAL mean:0.333736 min:0 max:1 sd:0.420259\n",
            "\t64: \"data:0.155\" NUMERICAL mean:0.355293 min:0 max:1 sd:0.425476\n",
            "\t65: \"data:0.156\" NUMERICAL mean:0.348721 min:0 max:1 sd:0.42311\n",
            "\t66: \"data:0.157\" NUMERICAL mean:0.314436 min:0 max:1 sd:0.412192\n",
            "\t67: \"data:0.158\" NUMERICAL mean:0.258599 min:0 max:1 sd:0.387961\n",
            "\t68: \"data:0.159\" NUMERICAL mean:0.19527 min:0 max:1 sd:0.351047\n",
            "\t69: \"data:0.16\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t70: \"data:0.160\" NUMERICAL mean:0.134705 min:0 max:1 sd:0.300919\n",
            "\t71: \"data:0.161\" NUMERICAL mean:0.0843529 min:0 max:1 sd:0.242655\n",
            "\t72: \"data:0.162\" NUMERICAL mean:0.0485895 min:0 max:1 sd:0.18628\n",
            "\t73: \"data:0.163\" NUMERICAL mean:0.0260358 min:0 max:1 sd:0.13681\n",
            "\t74: \"data:0.164\" NUMERICAL mean:0.0117361 min:0 max:1 sd:0.0895341\n",
            "\t75: \"data:0.165\" NUMERICAL mean:0.0033085 min:0 max:1 sd:0.044204\n",
            "\t76: \"data:0.166\" NUMERICAL mean:0.000555425 min:0 max:1 sd:0.017395\n",
            "\t77: \"data:0.167\" NUMERICAL mean:1.84314e-05 min:0 max:0.364706 sd:0.00224529\n",
            "\t78: \"data:0.168\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t79: \"data:0.169\" NUMERICAL mean:7.18954e-07 min:0 max:0.027451 sd:0.000129073\n",
            "\t80: \"data:0.17\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t81: \"data:0.170\" NUMERICAL mean:0.000107843 min:0 max:0.823529 sd:0.00688569\n",
            "\t82: \"data:0.171\" NUMERICAL mean:0.000868366 min:0 max:1 sd:0.0238787\n",
            "\t83: \"data:0.172\" NUMERICAL mean:0.00439026 min:0 max:1 sd:0.0555558\n",
            "\t84: \"data:0.173\" NUMERICAL mean:0.0129016 min:0 max:1 sd:0.0967939\n",
            "\t85: \"data:0.174\" NUMERICAL mean:0.0291626 min:0 max:1 sd:0.146432\n",
            "\t86: \"data:0.175\" NUMERICAL mean:0.0558997 min:0 max:1 sd:0.202955\n",
            "\t87: \"data:0.176\" NUMERICAL mean:0.0946578 min:0 max:1 sd:0.260524\n",
            "\t88: \"data:0.177\" NUMERICAL mean:0.146229 min:0 max:1 sd:0.315775\n",
            "\t89: \"data:0.178\" NUMERICAL mean:0.208296 min:0 max:1 sd:0.362351\n",
            "\t90: \"data:0.179\" NUMERICAL mean:0.278089 min:0 max:1 sd:0.397951\n",
            "\t91: \"data:0.18\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t92: \"data:0.180\" NUMERICAL mean:0.350112 min:0 max:1 sd:0.422445\n",
            "\t93: \"data:0.181\" NUMERICAL mean:0.4166 min:0 max:1 sd:0.435368\n",
            "\t94: \"data:0.182\" NUMERICAL mean:0.46473 min:0 max:1 sd:0.439888\n",
            "\t95: \"data:0.183\" NUMERICAL mean:0.486659 min:0 max:1 sd:0.440528\n",
            "\t96: \"data:0.184\" NUMERICAL mean:0.477299 min:0 max:1 sd:0.440513\n",
            "\t97: \"data:0.185\" NUMERICAL mean:0.439346 min:0 max:1 sd:0.439807\n",
            "\t98: \"data:0.186\" NUMERICAL mean:0.376895 min:0 max:1 sd:0.430861\n",
            "\t99: \"data:0.187\" NUMERICAL mean:0.294766 min:0 max:1 sd:0.406821\n",
            "\t100: \"data:0.188\" NUMERICAL mean:0.21191 min:0 max:1 sd:0.364981\n",
            "\t101: \"data:0.189\" NUMERICAL mean:0.13848 min:0 max:1 sd:0.306265\n",
            "\t102: \"data:0.19\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t103: \"data:0.190\" NUMERICAL mean:0.0823212 min:0 max:1 sd:0.242604\n",
            "\t104: \"data:0.191\" NUMERICAL mean:0.0448723 min:0 max:1 sd:0.18026\n",
            "\t105: \"data:0.192\" NUMERICAL mean:0.0211285 min:0 max:1 sd:0.122173\n",
            "\t106: \"data:0.193\" NUMERICAL mean:0.0072768 min:0 max:1 sd:0.0698991\n",
            "\t107: \"data:0.194\" NUMERICAL mean:0.00146157 min:0 max:0.996078 sd:0.0302492\n",
            "\t108: \"data:0.195\" NUMERICAL mean:0.000118824 min:0 max:0.992157 sd:0.00807883\n",
            "\t109: \"data:0.196\" NUMERICAL mean:3.0719e-06 min:0 max:0.184314 sd:0.000752451\n",
            "\t110: \"data:0.197\" NUMERICAL mean:7.73856e-05 min:0 max:0.74902 sd:0.00584881\n",
            "\t111: \"data:0.198\" NUMERICAL mean:0.000422222 min:0 max:1 sd:0.0160884\n",
            "\t112: \"data:0.199\" NUMERICAL mean:0.00233588 min:0 max:1 sd:0.0394851\n",
            "\t113: \"data:0.2\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t114: \"data:0.20\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t115: \"data:0.200\" NUMERICAL mean:0.00906824 min:0 max:1 sd:0.0802464\n",
            "\t116: \"data:0.201\" NUMERICAL mean:0.0232501 min:0 max:1 sd:0.130295\n",
            "\t117: \"data:0.202\" NUMERICAL mean:0.0487688 min:0 max:1 sd:0.189023\n",
            "\t118: \"data:0.203\" NUMERICAL mean:0.0880463 min:0 max:1 sd:0.250907\n",
            "\t119: \"data:0.204\" NUMERICAL mean:0.142332 min:0 max:1 sd:0.310026\n",
            "\t120: \"data:0.205\" NUMERICAL mean:0.211366 min:0 max:1 sd:0.361838\n",
            "\t121: \"data:0.206\" NUMERICAL mean:0.289273 min:0 max:1 sd:0.399023\n",
            "\t122: \"data:0.207\" NUMERICAL mean:0.369032 min:0 max:1 sd:0.421443\n",
            "\t123: \"data:0.208\" NUMERICAL mean:0.437567 min:0 max:1 sd:0.431184\n",
            "\t124: \"data:0.209\" NUMERICAL mean:0.490196 min:0 max:1 sd:0.432971\n",
            "\t125: \"data:0.21\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t126: \"data:0.210\" NUMERICAL mean:0.520624 min:0 max:1 sd:0.433064\n",
            "\t127: \"data:0.211\" NUMERICAL mean:0.530975 min:0 max:1 sd:0.43185\n",
            "\t128: \"data:0.212\" NUMERICAL mean:0.522897 min:0 max:1 sd:0.432254\n",
            "\t129: \"data:0.213\" NUMERICAL mean:0.496775 min:0 max:1 sd:0.434012\n",
            "\t130: \"data:0.214\" NUMERICAL mean:0.445281 min:0 max:1 sd:0.435216\n",
            "\t131: \"data:0.215\" NUMERICAL mean:0.367625 min:0 max:1 sd:0.426007\n",
            "\t132: \"data:0.216\" NUMERICAL mean:0.273639 min:0 max:1 sd:0.396302\n",
            "\t133: \"data:0.217\" NUMERICAL mean:0.183658 min:0 max:1 sd:0.344639\n",
            "\t134: \"data:0.218\" NUMERICAL mean:0.110368 min:0 max:1 sd:0.277623\n",
            "\t135: \"data:0.219\" NUMERICAL mean:0.059612 min:0 max:1 sd:0.207215\n",
            "\t136: \"data:0.22\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t137: \"data:0.220\" NUMERICAL mean:0.027583 min:0 max:1 sd:0.14001\n",
            "\t138: \"data:0.221\" NUMERICAL mean:0.0101295 min:0 max:1 sd:0.0835571\n",
            "\t139: \"data:0.222\" NUMERICAL mean:0.00201216 min:0 max:1 sd:0.0354199\n",
            "\t140: \"data:0.223\" NUMERICAL mean:0.000125033 min:0 max:0.992157 sd:0.00812393\n",
            "\t141: \"data:0.224\" NUMERICAL mean:1.59477e-05 min:0 max:0.74902 sd:0.00317336\n",
            "\t142: \"data:0.225\" NUMERICAL mean:0.000199281 min:0 max:0.988235 sd:0.0115055\n",
            "\t143: \"data:0.226\" NUMERICAL mean:0.00129163 min:0 max:1 sd:0.0299818\n",
            "\t144: \"data:0.227\" NUMERICAL mean:0.00516608 min:0 max:1 sd:0.0605999\n",
            "\t145: \"data:0.228\" NUMERICAL mean:0.0146986 min:0 max:1 sd:0.105397\n",
            "\t146: \"data:0.229\" NUMERICAL mean:0.0332685 min:0 max:1 sd:0.157758\n",
            "\t147: \"data:0.23\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t148: \"data:0.230\" NUMERICAL mean:0.0659537 min:0 max:1 sd:0.219832\n",
            "\t149: \"data:0.231\" NUMERICAL mean:0.116068 min:0 max:1 sd:0.284983\n",
            "\t150: \"data:0.232\" NUMERICAL mean:0.18404 min:0 max:1 sd:0.345363\n",
            "\t151: \"data:0.233\" NUMERICAL mean:0.267086 min:0 max:1 sd:0.392411\n",
            "\t152: \"data:0.234\" NUMERICAL mean:0.354084 min:0 max:1 sd:0.420533\n",
            "\t153: \"data:0.235\" NUMERICAL mean:0.425395 min:0 max:1 sd:0.432999\n",
            "\t154: \"data:0.236\" NUMERICAL mean:0.468374 min:0 max:1 sd:0.435721\n",
            "\t155: \"data:0.237\" NUMERICAL mean:0.483897 min:0 max:1 sd:0.436738\n",
            "\t156: \"data:0.238\" NUMERICAL mean:0.482502 min:0 max:1 sd:0.436026\n",
            "\t157: \"data:0.239\" NUMERICAL mean:0.479767 min:0 max:1 sd:0.434515\n",
            "\t158: \"data:0.24\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t159: \"data:0.240\" NUMERICAL mean:0.481294 min:0 max:1 sd:0.434371\n",
            "\t160: \"data:0.241\" NUMERICAL mean:0.478996 min:0 max:1 sd:0.43537\n",
            "\t161: \"data:0.242\" NUMERICAL mean:0.455925 min:0 max:1 sd:0.436799\n",
            "\t162: \"data:0.243\" NUMERICAL mean:0.394551 min:0 max:1 sd:0.432158\n",
            "\t163: \"data:0.244\" NUMERICAL mean:0.303208 min:0 max:1 sd:0.410189\n",
            "\t164: \"data:0.245\" NUMERICAL mean:0.207442 min:0 max:1 sd:0.363292\n",
            "\t165: \"data:0.246\" NUMERICAL mean:0.124748 min:0 max:1 sd:0.294444\n",
            "\t166: \"data:0.247\" NUMERICAL mean:0.0641477 min:0 max:1 sd:0.215119\n",
            "\t167: \"data:0.248\" NUMERICAL mean:0.0281791 min:0 max:1 sd:0.142545\n",
            "\t168: \"data:0.249\" NUMERICAL mean:0.010222 min:0 max:1 sd:0.0847009\n",
            "\t169: \"data:0.25\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t170: \"data:0.250\" NUMERICAL mean:0.00188856 min:0 max:0.996078 sd:0.0350151\n",
            "\t171: \"data:0.251\" NUMERICAL mean:0.000106601 min:0 max:0.866667 sd:0.00789315\n",
            "\t172: \"data:0.252\" NUMERICAL mean:1.9085e-05 min:0 max:0.721569 sd:0.00323161\n",
            "\t173: \"data:0.253\" NUMERICAL mean:0.000311634 min:0 max:0.996078 sd:0.0147626\n",
            "\t174: \"data:0.254\" NUMERICAL mean:0.00200791 min:0 max:1 sd:0.0378929\n",
            "\t175: \"data:0.255\" NUMERICAL mean:0.00674268 min:0 max:1 sd:0.0724408\n",
            "\t176: \"data:0.256\" NUMERICAL mean:0.0174346 min:0 max:1 sd:0.115922\n",
            "\t177: \"data:0.257\" NUMERICAL mean:0.0384574 min:0 max:1 sd:0.170022\n",
            "\t178: \"data:0.258\" NUMERICAL mean:0.0765744 min:0 max:1 sd:0.2366\n",
            "\t179: \"data:0.259\" NUMERICAL mean:0.135313 min:0 max:1 sd:0.306047\n",
            "\t180: \"data:0.26\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t181: \"data:0.260\" NUMERICAL mean:0.214513 min:0 max:1 sd:0.367162\n",
            "\t182: \"data:0.261\" NUMERICAL mean:0.306424 min:0 max:1 sd:0.409342\n",
            "\t183: \"data:0.262\" NUMERICAL mean:0.388387 min:0 max:1 sd:0.431326\n",
            "\t184: \"data:0.263\" NUMERICAL mean:0.433727 min:0 max:1 sd:0.437054\n",
            "\t185: \"data:0.264\" NUMERICAL mean:0.434461 min:0 max:1 sd:0.436605\n",
            "\t186: \"data:0.265\" NUMERICAL mean:0.410014 min:0 max:1 sd:0.431795\n",
            "\t187: \"data:0.266\" NUMERICAL mean:0.38842 min:0 max:1 sd:0.42735\n",
            "\t188: \"data:0.267\" NUMERICAL mean:0.389758 min:0 max:1 sd:0.426461\n",
            "\t189: \"data:0.268\" NUMERICAL mean:0.40915 min:0 max:1 sd:0.428741\n",
            "\t190: \"data:0.269\" NUMERICAL mean:0.434832 min:0 max:1 sd:0.433493\n",
            "\t191: \"data:0.27\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t192: \"data:0.270\" NUMERICAL mean:0.435601 min:0 max:1 sd:0.435825\n",
            "\t193: \"data:0.271\" NUMERICAL mean:0.388811 min:0 max:1 sd:0.43129\n",
            "\t194: \"data:0.272\" NUMERICAL mean:0.30212 min:0 max:1 sd:0.410109\n",
            "\t195: \"data:0.273\" NUMERICAL mean:0.206689 min:0 max:1 sd:0.364153\n",
            "\t196: \"data:0.274\" NUMERICAL mean:0.123327 min:0 max:1 sd:0.293516\n",
            "\t197: \"data:0.275\" NUMERICAL mean:0.0603636 min:0 max:1 sd:0.208025\n",
            "\t198: \"data:0.276\" NUMERICAL mean:0.023377 min:0 max:1 sd:0.128811\n",
            "\t199: \"data:0.277\" NUMERICAL mean:0.00744301 min:0 max:1 sd:0.0709265\n",
            "\t200: \"data:0.278\" NUMERICAL mean:0.00137974 min:0 max:1 sd:0.0292236\n",
            "\t201: \"data:0.279\" NUMERICAL mean:0.000110654 min:0 max:0.862745 sd:0.00783063\n",
            "\t202: \"data:0.28\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t203: \"data:0.280\" NUMERICAL mean:2.61438e-05 min:0 max:0.839216 sd:0.00452878\n",
            "\t204: \"data:0.281\" NUMERICAL mean:0.000386536 min:0 max:1 sd:0.017079\n",
            "\t205: \"data:0.282\" NUMERICAL mean:0.00205111 min:0 max:1 sd:0.0388445\n",
            "\t206: \"data:0.283\" NUMERICAL mean:0.00656699 min:0 max:1 sd:0.071221\n",
            "\t207: \"data:0.284\" NUMERICAL mean:0.0168199 min:0 max:1 sd:0.114071\n",
            "\t208: \"data:0.285\" NUMERICAL mean:0.0387311 min:0 max:1 sd:0.170408\n",
            "\t209: \"data:0.286\" NUMERICAL mean:0.0805463 min:0 max:1 sd:0.242297\n",
            "\t210: \"data:0.287\" NUMERICAL mean:0.145839 min:0 max:1 sd:0.315195\n",
            "\t211: \"data:0.288\" NUMERICAL mean:0.234177 min:0 max:1 sd:0.378294\n",
            "\t212: \"data:0.289\" NUMERICAL mean:0.327054 min:0 max:1 sd:0.41701\n",
            "\t213: \"data:0.29\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t214: \"data:0.290\" NUMERICAL mean:0.393043 min:0 max:1 sd:0.432766\n",
            "\t215: \"data:0.291\" NUMERICAL mean:0.404584 min:0 max:1 sd:0.434395\n",
            "\t216: \"data:0.292\" NUMERICAL mean:0.368204 min:0 max:1 sd:0.423429\n",
            "\t217: \"data:0.293\" NUMERICAL mean:0.325305 min:0 max:1 sd:0.408132\n",
            "\t218: \"data:0.294\" NUMERICAL mean:0.311462 min:0 max:1 sd:0.403756\n",
            "\t219: \"data:0.295\" NUMERICAL mean:0.331471 min:0 max:1 sd:0.412503\n",
            "\t220: \"data:0.296\" NUMERICAL mean:0.368112 min:0 max:1 sd:0.42121\n",
            "\t221: \"data:0.297\" NUMERICAL mean:0.40952 min:0 max:1 sd:0.43036\n",
            "\t222: \"data:0.298\" NUMERICAL mean:0.416789 min:0 max:1 sd:0.433194\n",
            "\t223: \"data:0.299\" NUMERICAL mean:0.369498 min:0 max:1 sd:0.42792\n",
            "\t224: \"data:0.3\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t225: \"data:0.30\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t226: \"data:0.300\" NUMERICAL mean:0.281761 min:0 max:1 sd:0.401756\n",
            "\t227: \"data:0.301\" NUMERICAL mean:0.189479 min:0 max:1 sd:0.352588\n",
            "\t228: \"data:0.302\" NUMERICAL mean:0.111679 min:0 max:1 sd:0.28147\n",
            "\t229: \"data:0.303\" NUMERICAL mean:0.052934 min:0 max:1 sd:0.195168\n",
            "\t230: \"data:0.304\" NUMERICAL mean:0.0180412 min:0 max:1 sd:0.113235\n",
            "\t231: \"data:0.305\" NUMERICAL mean:0.0045102 min:0 max:1 sd:0.0555044\n",
            "\t232: \"data:0.306\" NUMERICAL mean:0.000869935 min:0 max:0.996078 sd:0.023543\n",
            "\t233: \"data:0.307\" NUMERICAL mean:7.34641e-05 min:0 max:0.796078 sd:0.00618728\n",
            "\t234: \"data:0.308\" NUMERICAL mean:2.3268e-05 min:0 max:0.588235 sd:0.003298\n",
            "\t235: \"data:0.309\" NUMERICAL mean:0.000299608 min:0 max:1 sd:0.0144242\n",
            "\t236: \"data:0.31\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t237: \"data:0.310\" NUMERICAL mean:0.00165052 min:0 max:1 sd:0.0349661\n",
            "\t238: \"data:0.311\" NUMERICAL mean:0.00502105 min:0 max:1 sd:0.0612294\n",
            "\t239: \"data:0.312\" NUMERICAL mean:0.0142984 min:0 max:1 sd:0.10402\n",
            "\t240: \"data:0.313\" NUMERICAL mean:0.0374663 min:0 max:1 sd:0.166382\n",
            "\t241: \"data:0.314\" NUMERICAL mean:0.0828754 min:0 max:1 sd:0.244837\n",
            "\t242: \"data:0.315\" NUMERICAL mean:0.156292 min:0 max:1 sd:0.32363\n",
            "\t243: \"data:0.316\" NUMERICAL mean:0.25133 min:0 max:1 sd:0.387683\n",
            "\t244: \"data:0.317\" NUMERICAL mean:0.341999 min:0 max:1 sd:0.422322\n",
            "\t245: \"data:0.318\" NUMERICAL mean:0.387375 min:0 max:1 sd:0.432116\n",
            "\t246: \"data:0.319\" NUMERICAL mean:0.372027 min:0 max:1 sd:0.426741\n",
            "\t247: \"data:0.32\" NUMERICAL mean:1.04575e-06 min:0 max:0.0627451 sd:0.000256154\n",
            "\t248: \"data:0.320\" NUMERICAL mean:0.320328 min:0 max:1 sd:0.408073\n",
            "\t249: \"data:0.321\" NUMERICAL mean:0.287619 min:0 max:1 sd:0.392631\n",
            "\t250: \"data:0.322\" NUMERICAL mean:0.298608 min:0 max:1 sd:0.403007\n",
            "\t251: \"data:0.323\" NUMERICAL mean:0.335002 min:0 max:1 sd:0.417599\n",
            "\t252: \"data:0.324\" NUMERICAL mean:0.38154 min:0 max:1 sd:0.42334\n",
            "\t253: \"data:0.325\" NUMERICAL mean:0.4215 min:0 max:1 sd:0.431104\n",
            "\t254: \"data:0.326\" NUMERICAL mean:0.413762 min:0 max:1 sd:0.433011\n",
            "\t255: \"data:0.327\" NUMERICAL mean:0.349135 min:0 max:1 sd:0.423244\n",
            "\t256: \"data:0.328\" NUMERICAL mean:0.254684 min:0 max:1 sd:0.388245\n",
            "\t257: \"data:0.329\" NUMERICAL mean:0.166654 min:0 max:1 sd:0.333733\n",
            "\t258: \"data:0.33\" NUMERICAL mean:3.59477e-06 min:0 max:0.184314 sd:0.000763272\n",
            "\t259: \"data:0.330\" NUMERICAL mean:0.0993769 min:0 max:1 sd:0.268896\n",
            "\t260: \"data:0.331\" NUMERICAL mean:0.0493342 min:0 max:1 sd:0.190874\n",
            "\t261: \"data:0.332\" NUMERICAL mean:0.0156466 min:0 max:1 sd:0.104523\n",
            "\t262: \"data:0.333\" NUMERICAL mean:0.00237072 min:0 max:1 sd:0.0387934\n",
            "\t263: \"data:0.334\" NUMERICAL mean:0.000488235 min:0 max:0.992157 sd:0.0174298\n",
            "\t264: \"data:0.335\" NUMERICAL mean:3.20261e-05 min:0 max:0.513726 sd:0.00350968\n",
            "\t265: \"data:0.336\" NUMERICAL mean:1.4902e-05 min:0 max:0.639216 sd:0.00280938\n",
            "\t266: \"data:0.337\" NUMERICAL mean:0.000171307 min:0 max:1 sd:0.0105495\n",
            "\t267: \"data:0.338\" NUMERICAL mean:0.00094915 min:0 max:1 sd:0.0260909\n",
            "\t268: \"data:0.339\" NUMERICAL mean:0.00344634 min:0 max:1 sd:0.0502514\n",
            "\t269: \"data:0.34\" NUMERICAL mean:3.64052e-05 min:0 max:0.615686 sd:0.00413727\n",
            "\t270: \"data:0.340\" NUMERICAL mean:0.0120346 min:0 max:1 sd:0.0944868\n",
            "\t271: \"data:0.341\" NUMERICAL mean:0.0376763 min:0 max:1 sd:0.166603\n",
            "\t272: \"data:0.342\" NUMERICAL mean:0.0893254 min:0 max:1 sd:0.253619\n",
            "\t273: \"data:0.343\" NUMERICAL mean:0.170882 min:0 max:1 sd:0.336659\n",
            "\t274: \"data:0.344\" NUMERICAL mean:0.270476 min:0 max:1 sd:0.398081\n",
            "\t275: \"data:0.345\" NUMERICAL mean:0.353948 min:0 max:1 sd:0.427344\n",
            "\t276: \"data:0.346\" NUMERICAL mean:0.383897 min:0 max:1 sd:0.431913\n",
            "\t277: \"data:0.347\" NUMERICAL mean:0.357187 min:0 max:1 sd:0.424263\n",
            "\t278: \"data:0.348\" NUMERICAL mean:0.312575 min:0 max:1 sd:0.407777\n",
            "\t279: \"data:0.349\" NUMERICAL mean:0.311251 min:0 max:1 sd:0.404115\n",
            "\t280: \"data:0.35\" NUMERICAL mean:9.52288e-05 min:0 max:0.996078 sd:0.00821606\n",
            "\t281: \"data:0.350\" NUMERICAL mean:0.350348 min:0 max:1 sd:0.427074\n",
            "\t282: \"data:0.351\" NUMERICAL mean:0.39888 min:0 max:1 sd:0.43466\n",
            "\t283: \"data:0.352\" NUMERICAL mean:0.443286 min:0 max:1 sd:0.430753\n",
            "\t284: \"data:0.353\" NUMERICAL mean:0.461102 min:0 max:1 sd:0.43571\n",
            "\t285: \"data:0.354\" NUMERICAL mean:0.421281 min:0 max:1 sd:0.436256\n",
            "\t286: \"data:0.355\" NUMERICAL mean:0.331447 min:0 max:1 sd:0.417189\n",
            "\t287: \"data:0.356\" NUMERICAL mean:0.229754 min:0 max:1 sd:0.372523\n",
            "\t288: \"data:0.357\" NUMERICAL mean:0.150053 min:0 max:1 sd:0.319212\n",
            "\t289: \"data:0.358\" NUMERICAL mean:0.093095 min:0 max:1 sd:0.262148\n",
            "\t290: \"data:0.359\" NUMERICAL mean:0.0498514 min:0 max:1 sd:0.195184\n",
            "\t291: \"data:0.36\" NUMERICAL mean:0.000171438 min:0 max:1 sd:0.0116158\n",
            "\t292: \"data:0.360\" NUMERICAL mean:0.016842 min:0 max:1 sd:0.109489\n",
            "\t293: \"data:0.361\" NUMERICAL mean:0.00173824 min:0 max:0.996078 sd:0.0331381\n",
            "\t294: \"data:0.362\" NUMERICAL mean:0.000312876 min:0 max:0.988235 sd:0.0145484\n",
            "\t295: \"data:0.363\" NUMERICAL mean:3.98693e-05 min:0 max:0.596078 sd:0.00401828\n",
            "\t296: \"data:0.364\" NUMERICAL mean:2.0915e-06 min:0 max:0.12549 sd:0.000512307\n",
            "\t297: \"data:0.365\" NUMERICAL mean:7.15686e-05 min:0 max:0.992157 sd:0.00654528\n",
            "\t298: \"data:0.366\" NUMERICAL mean:0.00048085 min:0 max:1 sd:0.0188238\n",
            "\t299: \"data:0.367\" NUMERICAL mean:0.0023817 min:0 max:1 sd:0.0417307\n",
            "\t300: \"data:0.368\" NUMERICAL mean:0.0114425 min:0 max:1 sd:0.0917881\n",
            "\t301: \"data:0.369\" NUMERICAL mean:0.0417026 min:0 max:1 sd:0.174855\n",
            "\t302: \"data:0.37\" NUMERICAL mean:0.000251373 min:0 max:0.996078 sd:0.0130347\n",
            "\t303: \"data:0.370\" NUMERICAL mean:0.100211 min:0 max:1 sd:0.268476\n",
            "\t304: \"data:0.371\" NUMERICAL mean:0.186603 min:0 max:1 sd:0.35001\n",
            "\t305: \"data:0.372\" NUMERICAL mean:0.284832 min:0 max:1 sd:0.40569\n",
            "\t306: \"data:0.373\" NUMERICAL mean:0.359505 min:0 max:1 sd:0.429285\n",
            "\t307: \"data:0.374\" NUMERICAL mean:0.379955 min:0 max:1 sd:0.43173\n",
            "\t308: \"data:0.375\" NUMERICAL mean:0.357246 min:0 max:1 sd:0.42478\n",
            "\t309: \"data:0.376\" NUMERICAL mean:0.340656 min:0 max:1 sd:0.417066\n",
            "\t310: \"data:0.377\" NUMERICAL mean:0.380261 min:0 max:1 sd:0.426338\n",
            "\t311: \"data:0.378\" NUMERICAL mean:0.436752 min:0 max:1 sd:0.446326\n",
            "\t312: \"data:0.379\" NUMERICAL mean:0.486165 min:0 max:1 sd:0.43767\n",
            "\t313: \"data:0.38\" NUMERICAL mean:0.000471111 min:0 max:1 sd:0.0190951\n",
            "\t314: \"data:0.380\" NUMERICAL mean:0.509045 min:0 max:1 sd:0.431164\n",
            "\t315: \"data:0.381\" NUMERICAL mean:0.496469 min:0 max:1 sd:0.439798\n",
            "\t316: \"data:0.382\" NUMERICAL mean:0.426982 min:0 max:1 sd:0.43745\n",
            "\t317: \"data:0.383\" NUMERICAL mean:0.318265 min:0 max:1 sd:0.410561\n",
            "\t318: \"data:0.384\" NUMERICAL mean:0.216572 min:0 max:1 sd:0.364325\n",
            "\t319: \"data:0.385\" NUMERICAL mean:0.1459 min:0 max:1 sd:0.316548\n",
            "\t320: \"data:0.386\" NUMERICAL mean:0.094011 min:0 max:1 sd:0.264447\n",
            "\t321: \"data:0.387\" NUMERICAL mean:0.0535049 min:0 max:1 sd:0.203017\n",
            "\t322: \"data:0.388\" NUMERICAL mean:0.0200105 min:0 max:1 sd:0.121642\n",
            "\t323: \"data:0.389\" NUMERICAL mean:0.00229294 min:0 max:0.996078 sd:0.0385284\n",
            "\t324: \"data:0.39\" NUMERICAL mean:0.000630327 min:0 max:1 sd:0.0216823\n",
            "\t325: \"data:0.390\" NUMERICAL mean:0.000325425 min:0 max:0.988235 sd:0.0139257\n",
            "\t326: \"data:0.391\" NUMERICAL mean:4.26144e-05 min:0 max:0.968627 sd:0.00575534\n",
            "\t327: \"data:0.392\" NUMERICAL mean:7.38562e-06 min:0 max:0.443137 sd:0.00180909\n",
            "\t328: \"data:0.393\" NUMERICAL mean:3.23529e-05 min:0 max:0.737255 sd:0.00405002\n",
            "\t329: \"data:0.394\" NUMERICAL mean:0.000212418 min:0 max:0.996078 sd:0.0116098\n",
            "\t330: \"data:0.395\" NUMERICAL mean:0.00182817 min:0 max:1 sd:0.0356095\n",
            "\t331: \"data:0.396\" NUMERICAL mean:0.0120219 min:0 max:1 sd:0.0929434\n",
            "\t332: \"data:0.397\" NUMERICAL mean:0.0484363 min:0 max:1 sd:0.188087\n",
            "\t333: \"data:0.398\" NUMERICAL mean:0.111875 min:0 max:1 sd:0.283219\n",
            "\t334: \"data:0.399\" NUMERICAL mean:0.198072 min:0 max:1 sd:0.359855\n",
            "\t335: \"data:0.4\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t336: \"data:0.40\" NUMERICAL mean:0.000683072 min:0 max:1 sd:0.022328\n",
            "\t337: \"data:0.400\" NUMERICAL mean:0.289218 min:0 max:1 sd:0.408891\n",
            "\t338: \"data:0.401\" NUMERICAL mean:0.354389 min:0 max:1 sd:0.429016\n",
            "\t339: \"data:0.402\" NUMERICAL mean:0.372851 min:0 max:1 sd:0.429624\n",
            "\t340: \"data:0.403\" NUMERICAL mean:0.365837 min:0 max:1 sd:0.425025\n",
            "\t341: \"data:0.404\" NUMERICAL mean:0.383643 min:0 max:1 sd:0.424367\n",
            "\t342: \"data:0.405\" NUMERICAL mean:0.452633 min:0 max:1 sd:0.437452\n",
            "\t343: \"data:0.406\" NUMERICAL mean:0.510852 min:0 max:1 sd:0.445989\n",
            "\t344: \"data:0.407\" NUMERICAL mean:0.547269 min:0 max:1 sd:0.429497\n",
            "\t345: \"data:0.408\" NUMERICAL mean:0.53765 min:0 max:1 sd:0.430742\n",
            "\t346: \"data:0.409\" NUMERICAL mean:0.502297 min:0 max:1 sd:0.440698\n",
            "\t347: \"data:0.41\" NUMERICAL mean:0.000695817 min:0 max:1 sd:0.0223276\n",
            "\t348: \"data:0.410\" NUMERICAL mean:0.419586 min:0 max:1 sd:0.435579\n",
            "\t349: \"data:0.411\" NUMERICAL mean:0.311976 min:0 max:1 sd:0.408875\n",
            "\t350: \"data:0.412\" NUMERICAL mean:0.219987 min:0 max:1 sd:0.36847\n",
            "\t351: \"data:0.413\" NUMERICAL mean:0.152718 min:0 max:1 sd:0.323541\n",
            "\t352: \"data:0.414\" NUMERICAL mean:0.100147 min:0 max:1 sd:0.271865\n",
            "\t353: \"data:0.415\" NUMERICAL mean:0.0573186 min:0 max:1 sd:0.209708\n",
            "\t354: \"data:0.416\" NUMERICAL mean:0.0224376 min:0 max:1 sd:0.129408\n",
            "\t355: \"data:0.417\" NUMERICAL mean:0.00321686 min:0 max:1 sd:0.0466599\n",
            "\t356: \"data:0.418\" NUMERICAL mean:0.000362549 min:0 max:0.996078 sd:0.0147111\n",
            "\t357: \"data:0.419\" NUMERICAL mean:8.69281e-06 min:0 max:0.203922 sd:0.00124451\n",
            "\t358: \"data:0.42\" NUMERICAL mean:0.000742418 min:0 max:1 sd:0.0232275\n",
            "\t359: \"data:0.420\" NUMERICAL mean:2.87582e-06 min:0 max:0.145098 sd:0.000602861\n",
            "\t360: \"data:0.421\" NUMERICAL mean:1.51634e-05 min:0 max:0.886275 sd:0.00361944\n",
            "\t361: \"data:0.422\" NUMERICAL mean:0.000176863 min:0 max:0.996078 sd:0.00948414\n",
            "\t362: \"data:0.423\" NUMERICAL mean:0.00198268 min:0 max:1 sd:0.037218\n",
            "\t363: \"data:0.424\" NUMERICAL mean:0.013963 min:0 max:1 sd:0.0994371\n",
            "\t364: \"data:0.425\" NUMERICAL mean:0.0565025 min:0 max:1 sd:0.203847\n",
            "\t365: \"data:0.426\" NUMERICAL mean:0.121523 min:0 max:1 sd:0.294809\n",
            "\t366: \"data:0.427\" NUMERICAL mean:0.200822 min:0 max:1 sd:0.362493\n",
            "\t367: \"data:0.428\" NUMERICAL mean:0.280159 min:0 max:1 sd:0.40485\n",
            "\t368: \"data:0.429\" NUMERICAL mean:0.336205 min:0 max:1 sd:0.424189\n",
            "\t369: \"data:0.43\" NUMERICAL mean:0.000682941 min:0 max:1 sd:0.022612\n",
            "\t370: \"data:0.430\" NUMERICAL mean:0.358357 min:0 max:1 sd:0.425632\n",
            "\t371: \"data:0.431\" NUMERICAL mean:0.369578 min:0 max:1 sd:0.424916\n",
            "\t372: \"data:0.432\" NUMERICAL mean:0.411949 min:0 max:1 sd:0.429712\n",
            "\t373: \"data:0.433\" NUMERICAL mean:0.483154 min:0 max:1 sd:0.441598\n",
            "\t374: \"data:0.434\" NUMERICAL mean:0.532115 min:0 max:1 sd:0.441628\n",
            "\t375: \"data:0.435\" NUMERICAL mean:0.54553 min:0 max:1 sd:0.428732\n",
            "\t376: \"data:0.436\" NUMERICAL mean:0.51688 min:0 max:1 sd:0.436689\n",
            "\t377: \"data:0.437\" NUMERICAL mean:0.476222 min:0 max:1 sd:0.44162\n",
            "\t378: \"data:0.438\" NUMERICAL mean:0.397413 min:0 max:1 sd:0.43076\n",
            "\t379: \"data:0.439\" NUMERICAL mean:0.30737 min:0 max:1 sd:0.408475\n",
            "\t380: \"data:0.44\" NUMERICAL mean:0.000733072 min:0 max:1 sd:0.0234132\n",
            "\t381: \"data:0.440\" NUMERICAL mean:0.22856 min:0 max:1 sd:0.37482\n",
            "\t382: \"data:0.441\" NUMERICAL mean:0.161768 min:0 max:1 sd:0.332341\n",
            "\t383: \"data:0.442\" NUMERICAL mean:0.105804 min:0 max:1 sd:0.277777\n",
            "\t384: \"data:0.443\" NUMERICAL mean:0.0583945 min:0 max:1 sd:0.209827\n",
            "\t385: \"data:0.444\" NUMERICAL mean:0.022856 min:0 max:1 sd:0.13024\n",
            "\t386: \"data:0.445\" NUMERICAL mean:0.00423359 min:0 max:1 sd:0.0549631\n",
            "\t387: \"data:0.446\" NUMERICAL mean:0.000581242 min:0 max:1 sd:0.0196191\n",
            "\t388: \"data:0.447\" NUMERICAL mean:4.24837e-05 min:0 max:0.745098 sd:0.00466329\n",
            "\t389: \"data:0.448\" NUMERICAL mean:2.61438e-06 min:0 max:0.156863 sd:0.000640384\n",
            "\t390: \"data:0.449\" NUMERICAL mean:1.55556e-05 min:0 max:0.419608 sd:0.00231921\n",
            "\t391: \"data:0.45\" NUMERICAL mean:0.000602549 min:0 max:1 sd:0.0212289\n",
            "\t392: \"data:0.450\" NUMERICAL mean:0.000291503 min:0 max:0.996078 sd:0.0134946\n",
            "\t393: \"data:0.451\" NUMERICAL mean:0.00244301 min:0 max:1 sd:0.0402421\n",
            "\t394: \"data:0.452\" NUMERICAL mean:0.0175293 min:0 max:1 sd:0.111636\n",
            "\t395: \"data:0.453\" NUMERICAL mean:0.0648195 min:0 max:1 sd:0.218128\n",
            "\t396: \"data:0.454\" NUMERICAL mean:0.127666 min:0 max:1 sd:0.302307\n",
            "\t397: \"data:0.455\" NUMERICAL mean:0.195862 min:0 max:1 sd:0.358901\n",
            "\t398: \"data:0.456\" NUMERICAL mean:0.260046 min:0 max:1 sd:0.394547\n",
            "\t399: \"data:0.457\" NUMERICAL mean:0.305436 min:0 max:1 sd:0.412055\n",
            "\t400: \"data:0.458\" NUMERICAL mean:0.328263 min:0 max:1 sd:0.416377\n",
            "\t401: \"data:0.459\" NUMERICAL mean:0.350778 min:0 max:1 sd:0.420614\n",
            "\t402: \"data:0.46\" NUMERICAL mean:0.000392614 min:0 max:1 sd:0.0169822\n",
            "\t403: \"data:0.460\" NUMERICAL mean:0.396612 min:0 max:1 sd:0.431375\n",
            "\t404: \"data:0.461\" NUMERICAL mean:0.454343 min:0 max:1 sd:0.442848\n",
            "\t405: \"data:0.462\" NUMERICAL mean:0.495974 min:0 max:1 sd:0.441739\n",
            "\t406: \"data:0.463\" NUMERICAL mean:0.499712 min:0 max:1 sd:0.436406\n",
            "\t407: \"data:0.464\" NUMERICAL mean:0.474733 min:0 max:1 sd:0.439787\n",
            "\t408: \"data:0.465\" NUMERICAL mean:0.436149 min:0 max:1 sd:0.436199\n",
            "\t409: \"data:0.466\" NUMERICAL mean:0.374009 min:0 max:1 sd:0.425534\n",
            "\t410: \"data:0.467\" NUMERICAL mean:0.303352 min:0 max:1 sd:0.40796\n",
            "\t411: \"data:0.468\" NUMERICAL mean:0.233754 min:0 max:1 sd:0.379704\n",
            "\t412: \"data:0.469\" NUMERICAL mean:0.164864 min:0 max:1 sd:0.334356\n",
            "\t413: \"data:0.47\" NUMERICAL mean:0.000279346 min:0 max:1 sd:0.0145746\n",
            "\t414: \"data:0.470\" NUMERICAL mean:0.104819 min:0 max:1 sd:0.27593\n",
            "\t415: \"data:0.471\" NUMERICAL mean:0.0558554 min:0 max:1 sd:0.204211\n",
            "\t416: \"data:0.472\" NUMERICAL mean:0.0220218 min:0 max:1 sd:0.126898\n",
            "\t417: \"data:0.473\" NUMERICAL mean:0.00504745 min:0 max:1 sd:0.0600529\n",
            "\t418: \"data:0.474\" NUMERICAL mean:0.00075098 min:0 max:0.996078 sd:0.0219826\n",
            "\t419: \"data:0.475\" NUMERICAL mean:4.82353e-05 min:0 max:0.87451 sd:0.00539566\n",
            "\t420: \"data:0.476\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t421: \"data:0.477\" NUMERICAL mean:2.85621e-05 min:0 max:0.521569 sd:0.00319769\n",
            "\t422: \"data:0.478\" NUMERICAL mean:0.00044 min:0 max:0.996078 sd:0.0173244\n",
            "\t423: \"data:0.479\" NUMERICAL mean:0.00373863 min:0 max:1 sd:0.0505902\n",
            "\t424: \"data:0.48\" NUMERICAL mean:0.000211046 min:0 max:0.956863 sd:0.012583\n",
            "\t425: \"data:0.480\" NUMERICAL mean:0.0233421 min:0 max:1 sd:0.131239\n",
            "\t426: \"data:0.481\" NUMERICAL mean:0.0726447 min:0 max:1 sd:0.231808\n",
            "\t427: \"data:0.482\" NUMERICAL mean:0.131181 min:0 max:1 sd:0.305774\n",
            "\t428: \"data:0.483\" NUMERICAL mean:0.188927 min:0 max:1 sd:0.353076\n",
            "\t429: \"data:0.484\" NUMERICAL mean:0.2371 min:0 max:1 sd:0.381938\n",
            "\t430: \"data:0.485\" NUMERICAL mean:0.271443 min:0 max:1 sd:0.397609\n",
            "\t431: \"data:0.486\" NUMERICAL mean:0.292868 min:0 max:1 sd:0.40481\n",
            "\t432: \"data:0.487\" NUMERICAL mean:0.316615 min:0 max:1 sd:0.413573\n",
            "\t433: \"data:0.488\" NUMERICAL mean:0.35132 min:0 max:1 sd:0.425806\n",
            "\t434: \"data:0.489\" NUMERICAL mean:0.399806 min:0 max:1 sd:0.434859\n",
            "\t435: \"data:0.49\" NUMERICAL mean:8.37909e-05 min:0 max:1 sd:0.00761987\n",
            "\t436: \"data:0.490\" NUMERICAL mean:0.441633 min:0 max:1 sd:0.438886\n",
            "\t437: \"data:0.491\" NUMERICAL mean:0.452694 min:0 max:1 sd:0.438311\n",
            "\t438: \"data:0.492\" NUMERICAL mean:0.440176 min:0 max:1 sd:0.435528\n",
            "\t439: \"data:0.493\" NUMERICAL mean:0.409899 min:0 max:1 sd:0.430788\n",
            "\t440: \"data:0.494\" NUMERICAL mean:0.363242 min:0 max:1 sd:0.424613\n",
            "\t441: \"data:0.495\" NUMERICAL mean:0.302986 min:0 max:1 sd:0.409263\n",
            "\t442: \"data:0.496\" NUMERICAL mean:0.232661 min:0 max:1 sd:0.37938\n",
            "\t443: \"data:0.497\" NUMERICAL mean:0.160033 min:0 max:1 sd:0.329858\n",
            "\t444: \"data:0.498\" NUMERICAL mean:0.0978147 min:0 max:1 sd:0.265771\n",
            "\t445: \"data:0.499\" NUMERICAL mean:0.0503325 min:0 max:1 sd:0.193006\n",
            "\t446: \"data:0.5\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t447: \"data:0.50\" NUMERICAL mean:3.95425e-05 min:0 max:0.721569 sd:0.00474993\n",
            "\t448: \"data:0.500\" NUMERICAL mean:0.0202222 min:0 max:1 sd:0.120131\n",
            "\t449: \"data:0.501\" NUMERICAL mean:0.00555556 min:0 max:1 sd:0.0627444\n",
            "\t450: \"data:0.502\" NUMERICAL mean:0.00082366 min:0 max:0.992157 sd:0.02292\n",
            "\t451: \"data:0.503\" NUMERICAL mean:3.48366e-05 min:0 max:0.407843 sd:0.00325247\n",
            "\t452: \"data:0.504\" NUMERICAL mean:7.45098e-06 min:0 max:0.235294 sd:0.0012616\n",
            "\t453: \"data:0.505\" NUMERICAL mean:2.08497e-05 min:0 max:0.772549 sd:0.00328232\n",
            "\t454: \"data:0.506\" NUMERICAL mean:0.000707843 min:0 max:1 sd:0.0212437\n",
            "\t455: \"data:0.507\" NUMERICAL mean:0.00596137 min:0 max:1 sd:0.0652909\n",
            "\t456: \"data:0.508\" NUMERICAL mean:0.029888 min:0 max:1 sd:0.15011\n",
            "\t457: \"data:0.509\" NUMERICAL mean:0.0800701 min:0 max:1 sd:0.24414\n",
            "\t458: \"data:0.51\" NUMERICAL mean:1.38562e-05 min:0 max:0.772549 sd:0.00316302\n",
            "\t459: \"data:0.510\" NUMERICAL mean:0.136905 min:0 max:1 sd:0.31186\n",
            "\t460: \"data:0.511\" NUMERICAL mean:0.188951 min:0 max:1 sd:0.353541\n",
            "\t461: \"data:0.512\" NUMERICAL mean:0.228537 min:0 max:1 sd:0.377156\n",
            "\t462: \"data:0.513\" NUMERICAL mean:0.258802 min:0 max:1 sd:0.392478\n",
            "\t463: \"data:0.514\" NUMERICAL mean:0.281359 min:0 max:1 sd:0.403181\n",
            "\t464: \"data:0.515\" NUMERICAL mean:0.300327 min:0 max:1 sd:0.411168\n",
            "\t465: \"data:0.516\" NUMERICAL mean:0.325969 min:0 max:1 sd:0.417307\n",
            "\t466: \"data:0.517\" NUMERICAL mean:0.373059 min:0 max:1 sd:0.427972\n",
            "\t467: \"data:0.518\" NUMERICAL mean:0.417871 min:0 max:1 sd:0.435985\n",
            "\t468: \"data:0.519\" NUMERICAL mean:0.440005 min:0 max:1 sd:0.435112\n",
            "\t469: \"data:0.52\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t470: \"data:0.520\" NUMERICAL mean:0.436659 min:0 max:1 sd:0.432143\n",
            "\t471: \"data:0.521\" NUMERICAL mean:0.411836 min:0 max:1 sd:0.432172\n",
            "\t472: \"data:0.522\" NUMERICAL mean:0.367132 min:0 max:1 sd:0.427531\n",
            "\t473: \"data:0.523\" NUMERICAL mean:0.3005 min:0 max:1 sd:0.410344\n",
            "\t474: \"data:0.524\" NUMERICAL mean:0.222357 min:0 max:1 sd:0.373766\n",
            "\t475: \"data:0.525\" NUMERICAL mean:0.148088 min:0 max:1 sd:0.319549\n",
            "\t476: \"data:0.526\" NUMERICAL mean:0.0884185 min:0 max:1 sd:0.253514\n",
            "\t477: \"data:0.527\" NUMERICAL mean:0.0446366 min:0 max:1 sd:0.181535\n",
            "\t478: \"data:0.528\" NUMERICAL mean:0.0179571 min:0 max:1 sd:0.113508\n",
            "\t479: \"data:0.529\" NUMERICAL mean:0.00509235 min:0 max:1 sd:0.0596029\n",
            "\t480: \"data:0.53\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t481: \"data:0.530\" NUMERICAL mean:0.00060366 min:0 max:1 sd:0.0191286\n",
            "\t482: \"data:0.531\" NUMERICAL mean:4.77778e-05 min:0 max:0.6 sd:0.00489506\n",
            "\t483: \"data:0.532\" NUMERICAL mean:9.80392e-07 min:0 max:0.0588235 sd:0.000240144\n",
            "\t484: \"data:0.533\" NUMERICAL mean:4.77778e-05 min:0 max:0.65098 sd:0.00423499\n",
            "\t485: \"data:0.534\" NUMERICAL mean:0.00112281 min:0 max:1 sd:0.0282418\n",
            "\t486: \"data:0.535\" NUMERICAL mean:0.00801497 min:0 max:1 sd:0.0771766\n",
            "\t487: \"data:0.536\" NUMERICAL mean:0.0342099 min:0 max:1 sd:0.161382\n",
            "\t488: \"data:0.537\" NUMERICAL mean:0.0852332 min:0 max:1 sd:0.252559\n",
            "\t489: \"data:0.538\" NUMERICAL mean:0.144444 min:0 max:1 sd:0.319777\n",
            "\t490: \"data:0.539\" NUMERICAL mean:0.199918 min:0 max:1 sd:0.362084\n",
            "\t491: \"data:0.54\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t492: \"data:0.540\" NUMERICAL mean:0.24451 min:0 max:1 sd:0.386953\n",
            "\t493: \"data:0.541\" NUMERICAL mean:0.279496 min:0 max:1 sd:0.403183\n",
            "\t494: \"data:0.542\" NUMERICAL mean:0.305413 min:0 max:1 sd:0.413623\n",
            "\t495: \"data:0.543\" NUMERICAL mean:0.324058 min:0 max:1 sd:0.420455\n",
            "\t496: \"data:0.544\" NUMERICAL mean:0.352813 min:0 max:1 sd:0.425708\n",
            "\t497: \"data:0.545\" NUMERICAL mean:0.397672 min:0 max:1 sd:0.432594\n",
            "\t498: \"data:0.546\" NUMERICAL mean:0.440963 min:0 max:1 sd:0.437113\n",
            "\t499: \"data:0.547\" NUMERICAL mean:0.461974 min:0 max:1 sd:0.435485\n",
            "\t500: \"data:0.548\" NUMERICAL mean:0.454606 min:0 max:1 sd:0.433733\n",
            "\t501: \"data:0.549\" NUMERICAL mean:0.421304 min:0 max:1 sd:0.435657\n",
            "\t502: \"data:0.55\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t503: \"data:0.550\" NUMERICAL mean:0.361872 min:0 max:1 sd:0.427491\n",
            "\t504: \"data:0.551\" NUMERICAL mean:0.281895 min:0 max:1 sd:0.402005\n",
            "\t505: \"data:0.552\" NUMERICAL mean:0.199217 min:0 max:1 sd:0.3587\n",
            "\t506: \"data:0.553\" NUMERICAL mean:0.128212 min:0 max:1 sd:0.300209\n",
            "\t507: \"data:0.554\" NUMERICAL mean:0.0736195 min:0 max:1 sd:0.232377\n",
            "\t508: \"data:0.555\" NUMERICAL mean:0.0359073 min:0 max:1 sd:0.162708\n",
            "\t509: \"data:0.556\" NUMERICAL mean:0.0142747 min:0 max:1 sd:0.101198\n",
            "\t510: \"data:0.557\" NUMERICAL mean:0.0041902 min:0 max:1 sd:0.0536029\n",
            "\t511: \"data:0.558\" NUMERICAL mean:0.000575294 min:0 max:0.992157 sd:0.0197136\n",
            "\t512: \"data:0.559\" NUMERICAL mean:2.67974e-05 min:0 max:0.501961 sd:0.00333891\n",
            "\t513: \"data:0.56\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t514: \"data:0.560\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t515: \"data:0.561\" NUMERICAL mean:5.98693e-05 min:0 max:0.72549 sd:0.00578889\n",
            "\t516: \"data:0.562\" NUMERICAL mean:0.00130196 min:0 max:1 sd:0.0300867\n",
            "\t517: \"data:0.563\" NUMERICAL mean:0.00884575 min:0 max:1 sd:0.0810295\n",
            "\t518: \"data:0.564\" NUMERICAL mean:0.0333845 min:0 max:1 sd:0.15971\n",
            "\t519: \"data:0.565\" NUMERICAL mean:0.0811533 min:0 max:1 sd:0.245752\n",
            "\t520: \"data:0.566\" NUMERICAL mean:0.145432 min:0 max:1 sd:0.319719\n",
            "\t521: \"data:0.567\" NUMERICAL mean:0.210957 min:0 max:1 sd:0.370622\n",
            "\t522: \"data:0.568\" NUMERICAL mean:0.270076 min:0 max:1 sd:0.401336\n",
            "\t523: \"data:0.569\" NUMERICAL mean:0.318273 min:0 max:1 sd:0.418449\n",
            "\t524: \"data:0.57\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t525: \"data:0.570\" NUMERICAL mean:0.354533 min:0 max:1 sd:0.427789\n",
            "\t526: \"data:0.571\" NUMERICAL mean:0.383868 min:0 max:1 sd:0.433011\n",
            "\t527: \"data:0.572\" NUMERICAL mean:0.418567 min:0 max:1 sd:0.43608\n",
            "\t528: \"data:0.573\" NUMERICAL mean:0.460155 min:0 max:1 sd:0.437666\n",
            "\t529: \"data:0.574\" NUMERICAL mean:0.490009 min:0 max:1 sd:0.437155\n",
            "\t530: \"data:0.575\" NUMERICAL mean:0.492375 min:0 max:1 sd:0.436138\n",
            "\t531: \"data:0.576\" NUMERICAL mean:0.463593 min:0 max:1 sd:0.436225\n",
            "\t532: \"data:0.577\" NUMERICAL mean:0.407082 min:0 max:1 sd:0.433373\n",
            "\t533: \"data:0.578\" NUMERICAL mean:0.328927 min:0 max:1 sd:0.417766\n",
            "\t534: \"data:0.579\" NUMERICAL mean:0.24014 min:0 max:1 sd:0.383004\n",
            "\t535: \"data:0.58\" NUMERICAL mean:4.18301e-06 min:0 max:0.25098 sd:0.00102461\n",
            "\t536: \"data:0.580\" NUMERICAL mean:0.160598 min:0 max:1 sd:0.329052\n",
            "\t537: \"data:0.581\" NUMERICAL mean:0.0978197 min:0 max:1 sd:0.265129\n",
            "\t538: \"data:0.582\" NUMERICAL mean:0.0534456 min:0 max:1 sd:0.198467\n",
            "\t539: \"data:0.583\" NUMERICAL mean:0.0256373 min:0 max:1 sd:0.136942\n",
            "\t540: \"data:0.584\" NUMERICAL mean:0.0106427 min:0 max:1 sd:0.0875023\n",
            "\t541: \"data:0.585\" NUMERICAL mean:0.00293791 min:0 max:1 sd:0.0441832\n",
            "\t542: \"data:0.586\" NUMERICAL mean:0.000437974 min:0 max:1 sd:0.0168238\n",
            "\t543: \"data:0.587\" NUMERICAL mean:6.60131e-06 min:0 max:0.2 sd:0.00114342\n",
            "\t544: \"data:0.588\" NUMERICAL mean:2.0915e-06 min:0 max:0.12549 sd:0.000512307\n",
            "\t545: \"data:0.589\" NUMERICAL mean:4.98039e-05 min:0 max:0.72549 sd:0.00497566\n",
            "\t546: \"data:0.59\" NUMERICAL mean:2.7451e-06 min:0 max:0.113725 sd:0.00050879\n",
            "\t547: \"data:0.590\" NUMERICAL mean:0.00111464 min:0 max:1 sd:0.0275229\n",
            "\t548: \"data:0.591\" NUMERICAL mean:0.00721255 min:0 max:1 sd:0.0721365\n",
            "\t549: \"data:0.592\" NUMERICAL mean:0.0260101 min:0 max:1 sd:0.138203\n",
            "\t550: \"data:0.593\" NUMERICAL mean:0.0662764 min:0 max:1 sd:0.221193\n",
            "\t551: \"data:0.594\" NUMERICAL mean:0.128665 min:0 max:1 sd:0.301147\n",
            "\t552: \"data:0.595\" NUMERICAL mean:0.202239 min:0 max:1 sd:0.364229\n",
            "\t553: \"data:0.596\" NUMERICAL mean:0.276172 min:0 max:1 sd:0.405076\n",
            "\t554: \"data:0.597\" NUMERICAL mean:0.342165 min:0 max:1 sd:0.426859\n",
            "\t555: \"data:0.598\" NUMERICAL mean:0.39602 min:0 max:1 sd:0.43583\n",
            "\t556: \"data:0.599\" NUMERICAL mean:0.441003 min:0 max:1 sd:0.437093\n",
            "\t557: \"data:0.6\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t558: \"data:0.60\" NUMERICAL mean:2.72549e-05 min:0 max:0.52549 sd:0.00319803\n",
            "\t559: \"data:0.600\" NUMERICAL mean:0.480761 min:0 max:1 sd:0.435621\n",
            "\t560: \"data:0.601\" NUMERICAL mean:0.511264 min:0 max:1 sd:0.432786\n",
            "\t561: \"data:0.602\" NUMERICAL mean:0.517039 min:0 max:1 sd:0.43369\n",
            "\t562: \"data:0.603\" NUMERICAL mean:0.489679 min:0 max:1 sd:0.435152\n",
            "\t563: \"data:0.604\" NUMERICAL mean:0.431474 min:0 max:1 sd:0.433769\n",
            "\t564: \"data:0.605\" NUMERICAL mean:0.350847 min:0 max:1 sd:0.421573\n",
            "\t565: \"data:0.606\" NUMERICAL mean:0.261142 min:0 max:1 sd:0.391444\n",
            "\t566: \"data:0.607\" NUMERICAL mean:0.178813 min:0 max:1 sd:0.342099\n",
            "\t567: \"data:0.608\" NUMERICAL mean:0.111987 min:0 max:1 sd:0.280623\n",
            "\t568: \"data:0.609\" NUMERICAL mean:0.0639052 min:0 max:1 sd:0.215386\n",
            "\t569: \"data:0.61\" NUMERICAL mean:2.15033e-05 min:0 max:0.243137 sd:0.00179418\n",
            "\t570: \"data:0.610\" NUMERICAL mean:0.0333784 min:0 max:1 sd:0.156981\n",
            "\t571: \"data:0.611\" NUMERICAL mean:0.0161141 min:0 max:1 sd:0.108371\n",
            "\t572: \"data:0.612\" NUMERICAL mean:0.00667837 min:0 max:1 sd:0.0689232\n",
            "\t573: \"data:0.613\" NUMERICAL mean:0.00174046 min:0 max:1 sd:0.0341728\n",
            "\t574: \"data:0.614\" NUMERICAL mean:0.000231569 min:0 max:0.988235 sd:0.0114556\n",
            "\t575: \"data:0.615\" NUMERICAL mean:2.54902e-06 min:0 max:0.152941 sd:0.000624375\n",
            "\t576: \"data:0.616\" NUMERICAL mean:2.02614e-06 min:0 max:0.121569 sd:0.000496298\n",
            "\t577: \"data:0.617\" NUMERICAL mean:3.85621e-06 min:0 max:0.14902 sd:0.000642176\n",
            "\t578: \"data:0.618\" NUMERICAL mean:0.00073366 min:0 max:1 sd:0.0217662\n",
            "\t579: \"data:0.619\" NUMERICAL mean:0.00426654 min:0 max:1 sd:0.0540256\n",
            "\t580: \"data:0.62\" NUMERICAL mean:0.000184706 min:0 max:0.917647 sd:0.0104629\n",
            "\t581: \"data:0.620\" NUMERICAL mean:0.0154684 min:0 max:1 sd:0.104699\n",
            "\t582: \"data:0.621\" NUMERICAL mean:0.0425309 min:0 max:1 sd:0.174844\n",
            "\t583: \"data:0.622\" NUMERICAL mean:0.091728 min:0 max:1 sd:0.254555\n",
            "\t584: \"data:0.623\" NUMERICAL mean:0.159367 min:0 max:1 sd:0.327616\n",
            "\t585: \"data:0.624\" NUMERICAL mean:0.239095 min:0 max:1 sd:0.384144\n",
            "\t586: \"data:0.625\" NUMERICAL mean:0.317668 min:0 max:1 sd:0.419805\n",
            "\t587: \"data:0.626\" NUMERICAL mean:0.388672 min:0 max:1 sd:0.437331\n",
            "\t588: \"data:0.627\" NUMERICAL mean:0.443531 min:0 max:1 sd:0.442571\n",
            "\t589: \"data:0.628\" NUMERICAL mean:0.480488 min:0 max:1 sd:0.440979\n",
            "\t590: \"data:0.629\" NUMERICAL mean:0.491381 min:0 max:1 sd:0.439739\n",
            "\t591: \"data:0.63\" NUMERICAL mean:0.000542745 min:0 max:1 sd:0.019586\n",
            "\t592: \"data:0.630\" NUMERICAL mean:0.472994 min:0 max:1 sd:0.44006\n",
            "\t593: \"data:0.631\" NUMERICAL mean:0.420337 min:0 max:1 sd:0.436454\n",
            "\t594: \"data:0.632\" NUMERICAL mean:0.343947 min:0 max:1 sd:0.420643\n",
            "\t595: \"data:0.633\" NUMERICAL mean:0.258718 min:0 max:1 sd:0.389251\n",
            "\t596: \"data:0.634\" NUMERICAL mean:0.177779 min:0 max:1 sd:0.339536\n",
            "\t597: \"data:0.635\" NUMERICAL mean:0.11267 min:0 max:1 sd:0.280174\n",
            "\t598: \"data:0.636\" NUMERICAL mean:0.066288 min:0 max:1 sd:0.218722\n",
            "\t599: \"data:0.637\" NUMERICAL mean:0.0359273 min:0 max:1 sd:0.162067\n",
            "\t600: \"data:0.638\" NUMERICAL mean:0.0184665 min:0 max:1 sd:0.115875\n",
            "\t601: \"data:0.639\" NUMERICAL mean:0.00872556 min:0 max:1 sd:0.0792795\n",
            "\t602: \"data:0.64\" NUMERICAL mean:0.00103601 min:0 max:1 sd:0.0279852\n",
            "\t603: \"data:0.640\" NUMERICAL mean:0.00327503 min:0 max:1 sd:0.0467596\n",
            "\t604: \"data:0.641\" NUMERICAL mean:0.000741634 min:0 max:0.996078 sd:0.019971\n",
            "\t605: \"data:0.642\" NUMERICAL mean:6.99346e-05 min:0 max:0.882353 sd:0.00573169\n",
            "\t606: \"data:0.643\" NUMERICAL mean:4.70588e-06 min:0 max:0.282353 sd:0.00115269\n",
            "\t607: \"data:0.644\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t608: \"data:0.645\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t609: \"data:0.646\" NUMERICAL mean:0.000251634 min:0 max:0.85098 sd:0.0110663\n",
            "\t610: \"data:0.647\" NUMERICAL mean:0.00164222 min:0 max:1 sd:0.0316388\n",
            "\t611: \"data:0.648\" NUMERICAL mean:0.0067949 min:0 max:1 sd:0.0679572\n",
            "\t612: \"data:0.649\" NUMERICAL mean:0.0196656 min:0 max:1 sd:0.116757\n",
            "\t613: \"data:0.65\" NUMERICAL mean:0.00198673 min:0 max:1 sd:0.0380956\n",
            "\t614: \"data:0.650\" NUMERICAL mean:0.0471801 min:0 max:1 sd:0.181245\n",
            "\t615: \"data:0.651\" NUMERICAL mean:0.0938829 min:0 max:1 sd:0.253849\n",
            "\t616: \"data:0.652\" NUMERICAL mean:0.157869 min:0 max:1 sd:0.322117\n",
            "\t617: \"data:0.653\" NUMERICAL mean:0.230951 min:0 max:1 sd:0.375304\n",
            "\t618: \"data:0.654\" NUMERICAL mean:0.303015 min:0 max:1 sd:0.410046\n",
            "\t619: \"data:0.655\" NUMERICAL mean:0.360911 min:0 max:1 sd:0.428037\n",
            "\t620: \"data:0.656\" NUMERICAL mean:0.390998 min:0 max:1 sd:0.433502\n",
            "\t621: \"data:0.657\" NUMERICAL mean:0.388881 min:0 max:1 sd:0.432183\n",
            "\t622: \"data:0.658\" NUMERICAL mean:0.355263 min:0 max:1 sd:0.423059\n",
            "\t623: \"data:0.659\" NUMERICAL mean:0.296406 min:0 max:1 sd:0.403462\n",
            "\t624: \"data:0.66\" NUMERICAL mean:0.00339922 min:0 max:1 sd:0.0507072\n",
            "\t625: \"data:0.660\" NUMERICAL mean:0.225828 min:0 max:1 sd:0.368653\n",
            "\t626: \"data:0.661\" NUMERICAL mean:0.157623 min:0 max:1 sd:0.320325\n",
            "\t627: \"data:0.662\" NUMERICAL mean:0.0999892 min:0 max:1 sd:0.263179\n",
            "\t628: \"data:0.663\" NUMERICAL mean:0.0597641 min:0 max:1 sd:0.206927\n",
            "\t629: \"data:0.664\" NUMERICAL mean:0.0334262 min:0 max:1 sd:0.156606\n",
            "\t630: \"data:0.665\" NUMERICAL mean:0.0173303 min:0 max:1 sd:0.112778\n",
            "\t631: \"data:0.666\" NUMERICAL mean:0.00864732 min:0 max:1 sd:0.0792416\n",
            "\t632: \"data:0.667\" NUMERICAL mean:0.00384961 min:0 max:1 sd:0.0519524\n",
            "\t633: \"data:0.668\" NUMERICAL mean:0.00121712 min:0 max:1 sd:0.028098\n",
            "\t634: \"data:0.669\" NUMERICAL mean:0.00022732 min:0 max:0.996078 sd:0.0117516\n",
            "\t635: \"data:0.67\" NUMERICAL mean:0.00505915 min:0 max:1 sd:0.0609411\n",
            "\t636: \"data:0.670\" NUMERICAL mean:3.77124e-05 min:0 max:0.588235 sd:0.00362533\n",
            "\t637: \"data:0.671\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t638: \"data:0.672\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t639: \"data:0.673\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t640: \"data:0.674\" NUMERICAL mean:6.21569e-05 min:0 max:0.992157 sd:0.00600393\n",
            "\t641: \"data:0.675\" NUMERICAL mean:0.000479216 min:0 max:0.992157 sd:0.0166683\n",
            "\t642: \"data:0.676\" NUMERICAL mean:0.0021319 min:0 max:1 sd:0.0370324\n",
            "\t643: \"data:0.677\" NUMERICAL mean:0.00627784 min:0 max:1 sd:0.0658673\n",
            "\t644: \"data:0.678\" NUMERICAL mean:0.0164836 min:0 max:1 sd:0.107308\n",
            "\t645: \"data:0.679\" NUMERICAL mean:0.0358572 min:0 max:1 sd:0.160489\n",
            "\t646: \"data:0.68\" NUMERICAL mean:0.00733471 min:0 max:1 sd:0.0738052\n",
            "\t647: \"data:0.680\" NUMERICAL mean:0.0659907 min:0 max:1 sd:0.217376\n",
            "\t648: \"data:0.681\" NUMERICAL mean:0.106184 min:0 max:1 sd:0.273331\n",
            "\t649: \"data:0.682\" NUMERICAL mean:0.149425 min:0 max:1 sd:0.317793\n",
            "\t650: \"data:0.683\" NUMERICAL mean:0.184485 min:0 max:1 sd:0.346046\n",
            "\t651: \"data:0.684\" NUMERICAL mean:0.202387 min:0 max:1 sd:0.357255\n",
            "\t652: \"data:0.685\" NUMERICAL mean:0.199852 min:0 max:1 sd:0.355113\n",
            "\t653: \"data:0.686\" NUMERICAL mean:0.178187 min:0 max:1 sd:0.338009\n",
            "\t654: \"data:0.687\" NUMERICAL mean:0.144096 min:0 max:1 sd:0.30786\n",
            "\t655: \"data:0.688\" NUMERICAL mean:0.107615 min:0 max:1 sd:0.271888\n",
            "\t656: \"data:0.689\" NUMERICAL mean:0.0749356 min:0 max:1 sd:0.230721\n",
            "\t657: \"data:0.69\" NUMERICAL mean:0.00992137 min:0 max:1 sd:0.0861349\n",
            "\t658: \"data:0.690\" NUMERICAL mean:0.0475065 min:0 max:1 sd:0.185786\n",
            "\t659: \"data:0.691\" NUMERICAL mean:0.0282937 min:0 max:1 sd:0.145386\n",
            "\t660: \"data:0.692\" NUMERICAL mean:0.0155268 min:0 max:1 sd:0.107397\n",
            "\t661: \"data:0.693\" NUMERICAL mean:0.00781641 min:0 max:1 sd:0.0768019\n",
            "\t662: \"data:0.694\" NUMERICAL mean:0.00373033 min:0 max:1 sd:0.052227\n",
            "\t663: \"data:0.695\" NUMERICAL mean:0.00156719 min:0 max:1 sd:0.0328017\n",
            "\t664: \"data:0.696\" NUMERICAL mean:0.000399281 min:0 max:0.996078 sd:0.0155046\n",
            "\t665: \"data:0.697\" NUMERICAL mean:8.69935e-05 min:0 max:0.988235 sd:0.0076448\n",
            "\t666: \"data:0.698\" NUMERICAL mean:7.5817e-06 min:0 max:0.384314 sd:0.00159518\n",
            "\t667: \"data:0.699\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t668: \"data:0.7\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t669: \"data:0.70\" NUMERICAL mean:0.0125554 min:0 max:1 sd:0.0972279\n",
            "\t670: \"data:0.700\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t671: \"data:0.701\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t672: \"data:0.702\" NUMERICAL mean:6.14379e-06 min:0 max:0.164706 sd:0.000921896\n",
            "\t673: \"data:0.703\" NUMERICAL mean:6.97386e-05 min:0 max:0.996078 sd:0.00636056\n",
            "\t674: \"data:0.704\" NUMERICAL mean:0.000501111 min:0 max:1 sd:0.0181533\n",
            "\t675: \"data:0.705\" NUMERICAL mean:0.00186078 min:0 max:1 sd:0.0360942\n",
            "\t676: \"data:0.706\" NUMERICAL mean:0.00551176 min:0 max:1 sd:0.0635202\n",
            "\t677: \"data:0.707\" NUMERICAL mean:0.0124737 min:0 max:1 sd:0.0971529\n",
            "\t678: \"data:0.708\" NUMERICAL mean:0.0240918 min:0 max:1 sd:0.13706\n",
            "\t679: \"data:0.709\" NUMERICAL mean:0.0385439 min:0 max:1 sd:0.172801\n",
            "\t680: \"data:0.71\" NUMERICAL mean:0.0142178 min:0 max:1 sd:0.102734\n",
            "\t681: \"data:0.710\" NUMERICAL mean:0.0543895 min:0 max:1 sd:0.203981\n",
            "\t682: \"data:0.711\" NUMERICAL mean:0.0655621 min:0 max:1 sd:0.222362\n",
            "\t683: \"data:0.712\" NUMERICAL mean:0.0709805 min:0 max:1 sd:0.230827\n",
            "\t684: \"data:0.713\" NUMERICAL mean:0.0697075 min:0 max:1 sd:0.228414\n",
            "\t685: \"data:0.714\" NUMERICAL mean:0.0619909 min:0 max:1 sd:0.214329\n",
            "\t686: \"data:0.715\" NUMERICAL mean:0.0514649 min:0 max:1 sd:0.195512\n",
            "\t687: \"data:0.716\" NUMERICAL mean:0.0411688 min:0 max:1 sd:0.176143\n",
            "\t688: \"data:0.717\" NUMERICAL mean:0.0305536 min:0 max:1 sd:0.151987\n",
            "\t689: \"data:0.718\" NUMERICAL mean:0.0204782 min:0 max:1 sd:0.125103\n",
            "\t690: \"data:0.719\" NUMERICAL mean:0.0124005 min:0 max:1 sd:0.0971325\n",
            "\t691: \"data:0.72\" NUMERICAL mean:0.014596 min:0 max:1 sd:0.105095\n",
            "\t692: \"data:0.720\" NUMERICAL mean:0.00663268 min:0 max:1 sd:0.0705866\n",
            "\t693: \"data:0.721\" NUMERICAL mean:0.0032368 min:0 max:1 sd:0.0492789\n",
            "\t694: \"data:0.722\" NUMERICAL mean:0.00145327 min:0 max:1 sd:0.0316433\n",
            "\t695: \"data:0.723\" NUMERICAL mean:0.000548301 min:0 max:1 sd:0.019092\n",
            "\t696: \"data:0.724\" NUMERICAL mean:0.000122614 min:0 max:0.992157 sd:0.0078133\n",
            "\t697: \"data:0.725\" NUMERICAL mean:1.39869e-05 min:0 max:0.498039 sd:0.00246452\n",
            "\t698: \"data:0.726\" NUMERICAL mean:6.79739e-06 min:0 max:0.407843 sd:0.001665\n",
            "\t699: \"data:0.727\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t700: \"data:0.728\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t701: \"data:0.729\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t702: \"data:0.73\" NUMERICAL mean:0.0133041 min:0 max:1 sd:0.100908\n",
            "\t703: \"data:0.730\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t704: \"data:0.731\" NUMERICAL mean:2.48366e-06 min:0 max:0.14902 sd:0.000608365\n",
            "\t705: \"data:0.732\" NUMERICAL mean:0.00013902 min:0 max:1 sd:0.00919357\n",
            "\t706: \"data:0.733\" NUMERICAL mean:0.000639542 min:0 max:1 sd:0.0203874\n",
            "\t707: \"data:0.734\" NUMERICAL mean:0.00211092 min:0 max:1 sd:0.039582\n",
            "\t708: \"data:0.735\" NUMERICAL mean:0.00470333 min:0 max:1 sd:0.0593643\n",
            "\t709: \"data:0.736\" NUMERICAL mean:0.00908268 min:0 max:1 sd:0.0838066\n",
            "\t710: \"data:0.737\" NUMERICAL mean:0.0137703 min:0 max:1 sd:0.10278\n",
            "\t711: \"data:0.738\" NUMERICAL mean:0.0190205 min:0 max:1 sd:0.120755\n",
            "\t712: \"data:0.739\" NUMERICAL mean:0.0234519 min:0 max:1 sd:0.13393\n",
            "\t713: \"data:0.74\" NUMERICAL mean:0.0109919 min:0 max:1 sd:0.0912724\n",
            "\t714: \"data:0.740\" NUMERICAL mean:0.0252738 min:0 max:1 sd:0.13839\n",
            "\t715: \"data:0.741\" NUMERICAL mean:0.024546 min:0 max:1 sd:0.135962\n",
            "\t716: \"data:0.742\" NUMERICAL mean:0.0218452 min:0 max:1 sd:0.128594\n",
            "\t717: \"data:0.743\" NUMERICAL mean:0.017454 min:0 max:1 sd:0.113961\n",
            "\t718: \"data:0.744\" NUMERICAL mean:0.0138625 min:0 max:1 sd:0.102357\n",
            "\t719: \"data:0.745\" NUMERICAL mean:0.010164 min:0 max:1 sd:0.0872593\n",
            "\t720: \"data:0.746\" NUMERICAL mean:0.00667124 min:0 max:1 sd:0.0710075\n",
            "\t721: \"data:0.747\" NUMERICAL mean:0.00395529 min:0 max:1 sd:0.054498\n",
            "\t722: \"data:0.748\" NUMERICAL mean:0.00211876 min:0 max:1 sd:0.0404618\n",
            "\t723: \"data:0.749\" NUMERICAL mean:0.000934902 min:0 max:1 sd:0.0256961\n",
            "\t724: \"data:0.75\" NUMERICAL mean:0.00801719 min:0 max:1 sd:0.0786841\n",
            "\t725: \"data:0.750\" NUMERICAL mean:0.000295163 min:0 max:1 sd:0.0137266\n",
            "\t726: \"data:0.751\" NUMERICAL mean:6.33987e-05 min:0 max:0.537255 sd:0.0048696\n",
            "\t727: \"data:0.752\" NUMERICAL mean:2.02614e-06 min:0 max:0.109804 sd:0.000450834\n",
            "\t728: \"data:0.753\" NUMERICAL mean:3.85621e-06 min:0 max:0.231373 sd:0.000944567\n",
            "\t729: \"data:0.754\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t730: \"data:0.755\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t731: \"data:0.756\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t732: \"data:0.757\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t733: \"data:0.758\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t734: \"data:0.759\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t735: \"data:0.76\" NUMERICAL mean:0.00471418 min:0 max:1 sd:0.0599731\n",
            "\t736: \"data:0.760\" NUMERICAL mean:9.93464e-06 min:0 max:0.368627 sd:0.00171578\n",
            "\t737: \"data:0.761\" NUMERICAL mean:6.11111e-05 min:0 max:0.988235 sd:0.00674974\n",
            "\t738: \"data:0.762\" NUMERICAL mean:0.000163268 min:0 max:0.960784 sd:0.0102008\n",
            "\t739: \"data:0.763\" NUMERICAL mean:0.000349804 min:0 max:0.996078 sd:0.0158141\n",
            "\t740: \"data:0.764\" NUMERICAL mean:0.00050281 min:0 max:0.996078 sd:0.0187294\n",
            "\t741: \"data:0.765\" NUMERICAL mean:0.000771503 min:0 max:1 sd:0.0242268\n",
            "\t742: \"data:0.766\" NUMERICAL mean:0.00131771 min:0 max:1 sd:0.0301202\n",
            "\t743: \"data:0.767\" NUMERICAL mean:0.00168614 min:0 max:1 sd:0.0356607\n",
            "\t744: \"data:0.768\" NUMERICAL mean:0.00206268 min:0 max:1 sd:0.0388168\n",
            "\t745: \"data:0.769\" NUMERICAL mean:0.00231641 min:0 max:1 sd:0.0409094\n",
            "\t746: \"data:0.77\" NUMERICAL mean:0.00248412 min:0 max:1 sd:0.0435844\n",
            "\t747: \"data:0.770\" NUMERICAL mean:0.00269817 min:0 max:1 sd:0.0447173\n",
            "\t748: \"data:0.771\" NUMERICAL mean:0.00232183 min:0 max:1 sd:0.041244\n",
            "\t749: \"data:0.772\" NUMERICAL mean:0.00189307 min:0 max:1 sd:0.0368542\n",
            "\t750: \"data:0.773\" NUMERICAL mean:0.00134712 min:0 max:1 sd:0.0315987\n",
            "\t751: \"data:0.774\" NUMERICAL mean:0.000786013 min:0 max:0.996078 sd:0.0236958\n",
            "\t752: \"data:0.775\" NUMERICAL mean:0.000348497 min:0 max:0.996078 sd:0.0155143\n",
            "\t753: \"data:0.776\" NUMERICAL mean:0.000178954 min:0 max:0.992157 sd:0.0111366\n",
            "\t754: \"data:0.777\" NUMERICAL mean:7.56209e-05 min:0 max:0.992157 sd:0.00661473\n",
            "\t755: \"data:0.778\" NUMERICAL mean:5.9281e-05 min:0 max:0.996078 sd:0.00658145\n",
            "\t756: \"data:0.779\" NUMERICAL mean:7.84314e-06 min:0 max:0.243137 sd:0.0013592\n",
            "\t757: \"data:0.78\" NUMERICAL mean:0.00116144 min:0 max:1 sd:0.0292866\n",
            "\t758: \"data:0.780\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t759: \"data:0.781\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t760: \"data:0.782\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t761: \"data:0.783\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t762: \"data:0.79\" NUMERICAL mean:0.000368562 min:0 max:1 sd:0.0155325\n",
            "\t763: \"data:0.8\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t764: \"data:0.80\" NUMERICAL mean:0.000138105 min:0 max:1 sd:0.00980275\n",
            "\t765: \"data:0.81\" NUMERICAL mean:3.38562e-05 min:0 max:0.647059 sd:0.00432345\n",
            "\t766: \"data:0.82\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t767: \"data:0.83\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t768: \"data:0.84\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t769: \"data:0.85\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t770: \"data:0.86\" NUMERICAL mean:1.26797e-05 min:0 max:0.552941 sd:0.00236193\n",
            "\t771: \"data:0.87\" NUMERICAL mean:2.29412e-05 min:0 max:0.396078 sd:0.0025862\n",
            "\t772: \"data:0.88\" NUMERICAL mean:4.71242e-05 min:0 max:0.376471 sd:0.00334907\n",
            "\t773: \"data:0.89\" NUMERICAL mean:0.000273595 min:0 max:1 sd:0.0123537\n",
            "\t774: \"data:0.9\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t775: \"data:0.90\" NUMERICAL mean:0.000831699 min:0 max:1 sd:0.0236412\n",
            "\t776: \"data:0.91\" NUMERICAL mean:0.00214157 min:0 max:1 sd:0.0389209\n",
            "\t777: \"data:0.92\" NUMERICAL mean:0.00452712 min:0 max:1 sd:0.0572357\n",
            "\t778: \"data:0.93\" NUMERICAL mean:0.0086898 min:0 max:1 sd:0.0807235\n",
            "\t779: \"data:0.94\" NUMERICAL mean:0.0142731 min:0 max:1 sd:0.104054\n",
            "\t780: \"data:0.95\" NUMERICAL mean:0.0213255 min:0 max:1 sd:0.127617\n",
            "\t781: \"data:0.96\" NUMERICAL mean:0.0290473 min:0 max:1 sd:0.148194\n",
            "\t782: \"data:0.97\" NUMERICAL mean:0.0380264 min:0 max:1 sd:0.169389\n",
            "\t783: \"data:0.98\" NUMERICAL mean:0.0466003 min:0 max:1 sd:0.187409\n",
            "\t784: \"data:0.99\" NUMERICAL mean:0.0519112 min:0 max:1 sd:0.198045\n",
            "\n",
            "CATEGORICAL: 1 (0.127389%)\n",
            "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:11 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 23-05-27 16:47:49.1275 UTC kernel.cc:810] Configure learner\n",
            "[INFO 23-05-27 16:47:49.1280 UTC kernel.cc:824] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"^data:0\\\\.0$\"\n",
            "features: \"^data:0\\\\.1$\"\n",
            "features: \"^data:0\\\\.10$\"\n",
            "features: \"^data:0\\\\.100$\"\n",
            "features: \"^data:0\\\\.101$\"\n",
            "features: \"^data:0\\\\.102$\"\n",
            "features: \"^data:0\\\\.103$\"\n",
            "features: \"^data:0\\\\.104$\"\n",
            "features: \"^data:0\\\\.105$\"\n",
            "features: \"^data:0\\\\.106$\"\n",
            "features: \"^data:0\\\\.107$\"\n",
            "features: \"^data:0\\\\.108$\"\n",
            "features: \"^data:0\\\\.109$\"\n",
            "features: \"^data:0\\\\.11$\"\n",
            "features: \"^data:0\\\\.110$\"\n",
            "features: \"^data:0\\\\.111$\"\n",
            "features: \"^data:0\\\\.112$\"\n",
            "features: \"^data:0\\\\.113$\"\n",
            "features: \"^data:0\\\\.114$\"\n",
            "features: \"^data:0\\\\.115$\"\n",
            "features: \"^data:0\\\\.116$\"\n",
            "features: \"^data:0\\\\.117$\"\n",
            "features: \"^data:0\\\\.118$\"\n",
            "features: \"^data:0\\\\.119$\"\n",
            "features: \"^data:0\\\\.12$\"\n",
            "features: \"^data:0\\\\.120$\"\n",
            "features: \"^data:0\\\\.121$\"\n",
            "features: \"^data:0\\\\.122$\"\n",
            "features: \"^data:0\\\\.123$\"\n",
            "features: \"^data:0\\\\.124$\"\n",
            "features: \"^data:0\\\\.125$\"\n",
            "features: \"^data:0\\\\.126$\"\n",
            "features: \"^data:0\\\\.127$\"\n",
            "features: \"^data:0\\\\.128$\"\n",
            "features: \"^data:0\\\\.129$\"\n",
            "features: \"^data:0\\\\.13$\"\n",
            "features: \"^data:0\\\\.130$\"\n",
            "features: \"^data:0\\\\.131$\"\n",
            "features: \"^data:0\\\\.132$\"\n",
            "features: \"^data:0\\\\.133$\"\n",
            "features: \"^data:0\\\\.134$\"\n",
            "features: \"^data:0\\\\.135$\"\n",
            "features: \"^data:0\\\\.136$\"\n",
            "features: \"^data:0\\\\.137$\"\n",
            "features: \"^data:0\\\\.138$\"\n",
            "features: \"^data:0\\\\.139$\"\n",
            "features: \"^data:0\\\\.14$\"\n",
            "features: \"^data:0\\\\.140$\"\n",
            "features: \"^data:0\\\\.141$\"\n",
            "features: \"^data:0\\\\.142$\"\n",
            "features: \"^data:0\\\\.143$\"\n",
            "features: \"^data:0\\\\.144$\"\n",
            "features: \"^data:0\\\\.145$\"\n",
            "features: \"^data:0\\\\.146$\"\n",
            "features: \"^data:0\\\\.147$\"\n",
            "features: \"^data:0\\\\.148$\"\n",
            "features: \"^data:0\\\\.149$\"\n",
            "features: \"^data:0\\\\.15$\"\n",
            "features: \"^data:0\\\\.150$\"\n",
            "features: \"^data:0\\\\.151$\"\n",
            "features: \"^data:0\\\\.152$\"\n",
            "features: \"^data:0\\\\.153$\"\n",
            "features: \"^data:0\\\\.154$\"\n",
            "features: \"^data:0\\\\.155$\"\n",
            "features: \"^data:0\\\\.156$\"\n",
            "features: \"^data:0\\\\.157$\"\n",
            "features: \"^data:0\\\\.158$\"\n",
            "features: \"^data:0\\\\.159$\"\n",
            "features: \"^data:0\\\\.16$\"\n",
            "features: \"^data:0\\\\.160$\"\n",
            "features: \"^data:0\\\\.161$\"\n",
            "features: \"^data:0\\\\.162$\"\n",
            "features: \"^data:0\\\\.163$\"\n",
            "features: \"^data:0\\\\.164$\"\n",
            "features: \"^data:0\\\\.165$\"\n",
            "features: \"^data:0\\\\.166$\"\n",
            "features: \"^data:0\\\\.167$\"\n",
            "features: \"^data:0\\\\.168$\"\n",
            "features: \"^data:0\\\\.169$\"\n",
            "features: \"^data:0\\\\.17$\"\n",
            "features: \"^data:0\\\\.170$\"\n",
            "features: \"^data:0\\\\.171$\"\n",
            "features: \"^data:0\\\\.172$\"\n",
            "features: \"^data:0\\\\.173$\"\n",
            "features: \"^data:0\\\\.174$\"\n",
            "features: \"^data:0\\\\.175$\"\n",
            "features: \"^data:0\\\\.176$\"\n",
            "features: \"^data:0\\\\.177$\"\n",
            "features: \"^data:0\\\\.178$\"\n",
            "features: \"^data:0\\\\.179$\"\n",
            "features: \"^data:0\\\\.18$\"\n",
            "features: \"^data:0\\\\.180$\"\n",
            "features: \"^data:0\\\\.181$\"\n",
            "features: \"^data:0\\\\.182$\"\n",
            "features: \"^data:0\\\\.183$\"\n",
            "features: \"^data:0\\\\.184$\"\n",
            "features: \"^data:0\\\\.185$\"\n",
            "features: \"^data:0\\\\.186$\"\n",
            "features: \"^data:0\\\\.187$\"\n",
            "features: \"^data:0\\\\.188$\"\n",
            "features: \"^data:0\\\\.189$\"\n",
            "features: \"^data:0\\\\.19$\"\n",
            "features: \"^data:0\\\\.190$\"\n",
            "features: \"^data:0\\\\.191$\"\n",
            "features: \"^data:0\\\\.192$\"\n",
            "features: \"^data:0\\\\.193$\"\n",
            "features: \"^data:0\\\\.194$\"\n",
            "features: \"^data:0\\\\.195$\"\n",
            "features: \"^data:0\\\\.196$\"\n",
            "features: \"^data:0\\\\.197$\"\n",
            "features: \"^data:0\\\\.198$\"\n",
            "features: \"^data:0\\\\.199$\"\n",
            "features: \"^data:0\\\\.2$\"\n",
            "features: \"^data:0\\\\.20$\"\n",
            "features: \"^data:0\\\\.200$\"\n",
            "features: \"^data:0\\\\.201$\"\n",
            "features: \"^data:0\\\\.202$\"\n",
            "features: \"^data:0\\\\.203$\"\n",
            "features: \"^data:0\\\\.204$\"\n",
            "features: \"^data:0\\\\.205$\"\n",
            "features: \"^data:0\\\\.206$\"\n",
            "features: \"^data:0\\\\.207$\"\n",
            "features: \"^data:0\\\\.208$\"\n",
            "features: \"^data:0\\\\.209$\"\n",
            "features: \"^data:0\\\\.21$\"\n",
            "features: \"^data:0\\\\.210$\"\n",
            "features: \"^data:0\\\\.211$\"\n",
            "features: \"^data:0\\\\.212$\"\n",
            "features: \"^data:0\\\\.213$\"\n",
            "features: \"^data:0\\\\.214$\"\n",
            "features: \"^data:0\\\\.215$\"\n",
            "features: \"^data:0\\\\.216$\"\n",
            "features: \"^data:0\\\\.217$\"\n",
            "features: \"^data:0\\\\.218$\"\n",
            "features: \"^data:0\\\\.219$\"\n",
            "features: \"^data:0\\\\.22$\"\n",
            "features: \"^data:0\\\\.220$\"\n",
            "features: \"^data:0\\\\.221$\"\n",
            "features: \"^data:0\\\\.222$\"\n",
            "features: \"^data:0\\\\.223$\"\n",
            "features: \"^data:0\\\\.224$\"\n",
            "features: \"^data:0\\\\.225$\"\n",
            "features: \"^data:0\\\\.226$\"\n",
            "features: \"^data:0\\\\.227$\"\n",
            "features: \"^data:0\\\\.228$\"\n",
            "features: \"^data:0\\\\.229$\"\n",
            "features: \"^data:0\\\\.23$\"\n",
            "features: \"^data:0\\\\.230$\"\n",
            "features: \"^data:0\\\\.231$\"\n",
            "features: \"^data:0\\\\.232$\"\n",
            "features: \"^data:0\\\\.233$\"\n",
            "features: \"^data:0\\\\.234$\"\n",
            "features: \"^data:0\\\\.235$\"\n",
            "features: \"^data:0\\\\.236$\"\n",
            "features: \"^data:0\\\\.237$\"\n",
            "features: \"^data:0\\\\.238$\"\n",
            "features: \"^data:0\\\\.239$\"\n",
            "features: \"^data:0\\\\.24$\"\n",
            "features: \"^data:0\\\\.240$\"\n",
            "features: \"^data:0\\\\.241$\"\n",
            "features: \"^data:0\\\\.242$\"\n",
            "features: \"^data:0\\\\.243$\"\n",
            "features: \"^data:0\\\\.244$\"\n",
            "features: \"^data:0\\\\.245$\"\n",
            "features: \"^data:0\\\\.246$\"\n",
            "features: \"^data:0\\\\.247$\"\n",
            "features: \"^data:0\\\\.248$\"\n",
            "features: \"^data:0\\\\.249$\"\n",
            "features: \"^data:0\\\\.25$\"\n",
            "features: \"^data:0\\\\.250$\"\n",
            "features: \"^data:0\\\\.251$\"\n",
            "features: \"^data:0\\\\.252$\"\n",
            "features: \"^data:0\\\\.253$\"\n",
            "features: \"^data:0\\\\.254$\"\n",
            "features: \"^data:0\\\\.255$\"\n",
            "features: \"^data:0\\\\.256$\"\n",
            "features: \"^data:0\\\\.257$\"\n",
            "features: \"^data:0\\\\.258$\"\n",
            "features: \"^data:0\\\\.259$\"\n",
            "features: \"^data:0\\\\.26$\"\n",
            "features: \"^data:0\\\\.260$\"\n",
            "features: \"^data:0\\\\.261$\"\n",
            "features: \"^data:0\\\\.262$\"\n",
            "features: \"^data:0\\\\.263$\"\n",
            "features: \"^data:0\\\\.264$\"\n",
            "features: \"^data:0\\\\.265$\"\n",
            "features: \"^data:0\\\\.266$\"\n",
            "features: \"^data:0\\\\.267$\"\n",
            "features: \"^data:0\\\\.268$\"\n",
            "features: \"^data:0\\\\.269$\"\n",
            "features: \"^data:0\\\\.27$\"\n",
            "features: \"^data:0\\\\.270$\"\n",
            "features: \"^data:0\\\\.271$\"\n",
            "features: \"^data:0\\\\.272$\"\n",
            "features: \"^data:0\\\\.273$\"\n",
            "features: \"^data:0\\\\.274$\"\n",
            "features: \"^data:0\\\\.275$\"\n",
            "features: \"^data:0\\\\.276$\"\n",
            "features: \"^data:0\\\\.277$\"\n",
            "features: \"^data:0\\\\.278$\"\n",
            "features: \"^data:0\\\\.279$\"\n",
            "features: \"^data:0\\\\.28$\"\n",
            "features: \"^data:0\\\\.280$\"\n",
            "features: \"^data:0\\\\.281$\"\n",
            "features: \"^data:0\\\\.282$\"\n",
            "features: \"^data:0\\\\.283$\"\n",
            "features: \"^data:0\\\\.284$\"\n",
            "features: \"^data:0\\\\.285$\"\n",
            "features: \"^data:0\\\\.286$\"\n",
            "features: \"^data:0\\\\.287$\"\n",
            "features: \"^data:0\\\\.288$\"\n",
            "features: \"^data:0\\\\.289$\"\n",
            "features: \"^data:0\\\\.29$\"\n",
            "features: \"^data:0\\\\.290$\"\n",
            "features: \"^data:0\\\\.291$\"\n",
            "features: \"^data:0\\\\.292$\"\n",
            "features: \"^data:0\\\\.293$\"\n",
            "features: \"^data:0\\\\.294$\"\n",
            "features: \"^data:0\\\\.295$\"\n",
            "features: \"^data:0\\\\.296$\"\n",
            "features: \"^data:0\\\\.297$\"\n",
            "features: \"^data:0\\\\.298$\"\n",
            "features: \"^data:0\\\\.299$\"\n",
            "features: \"^data:0\\\\.3$\"\n",
            "features: \"^data:0\\\\.30$\"\n",
            "features: \"^data:0\\\\.300$\"\n",
            "features: \"^data:0\\\\.301$\"\n",
            "features: \"^data:0\\\\.302$\"\n",
            "features: \"^data:0\\\\.303$\"\n",
            "features: \"^data:0\\\\.304$\"\n",
            "features: \"^data:0\\\\.305$\"\n",
            "features: \"^data:0\\\\.306$\"\n",
            "features: \"^data:0\\\\.307$\"\n",
            "features: \"^data:0\\\\.308$\"\n",
            "features: \"^data:0\\\\.309$\"\n",
            "features: \"^data:0\\\\.31$\"\n",
            "features: \"^data:0\\\\.310$\"\n",
            "features: \"^data:0\\\\.311$\"\n",
            "features: \"^data:0\\\\.312$\"\n",
            "features: \"^data:0\\\\.313$\"\n",
            "features: \"^data:0\\\\.314$\"\n",
            "features: \"^data:0\\\\.315$\"\n",
            "features: \"^data:0\\\\.316$\"\n",
            "features: \"^data:0\\\\.317$\"\n",
            "features: \"^data:0\\\\.318$\"\n",
            "features: \"^data:0\\\\.319$\"\n",
            "features: \"^data:0\\\\.32$\"\n",
            "features: \"^data:0\\\\.320$\"\n",
            "features: \"^data:0\\\\.321$\"\n",
            "features: \"^data:0\\\\.322$\"\n",
            "features: \"^data:0\\\\.323$\"\n",
            "features: \"^data:0\\\\.324$\"\n",
            "features: \"^data:0\\\\.325$\"\n",
            "features: \"^data:0\\\\.326$\"\n",
            "features: \"^data:0\\\\.327$\"\n",
            "features: \"^data:0\\\\.328$\"\n",
            "features: \"^data:0\\\\.329$\"\n",
            "features: \"^data:0\\\\.33$\"\n",
            "features: \"^data:0\\\\.330$\"\n",
            "features: \"^data:0\\\\.331$\"\n",
            "features: \"^data:0\\\\.332$\"\n",
            "features: \"^data:0\\\\.333$\"\n",
            "features: \"^data:0\\\\.334$\"\n",
            "features: \"^data:0\\\\.335$\"\n",
            "features: \"^data:0\\\\.336$\"\n",
            "features: \"^data:0\\\\.337$\"\n",
            "features: \"^data:0\\\\.338$\"\n",
            "features: \"^data:0\\\\.339$\"\n",
            "features: \"^data:0\\\\.34$\"\n",
            "features: \"^data:0\\\\.340$\"\n",
            "features: \"^data:0\\\\.341$\"\n",
            "features: \"^data:0\\\\.342$\"\n",
            "features: \"^data:0\\\\.343$\"\n",
            "features: \"^data:0\\\\.344$\"\n",
            "features: \"^data:0\\\\.345$\"\n",
            "features: \"^data:0\\\\.346$\"\n",
            "features: \"^data:0\\\\.347$\"\n",
            "features: \"^data:0\\\\.348$\"\n",
            "features: \"^data:0\\\\.349$\"\n",
            "features: \"^data:0\\\\.35$\"\n",
            "features: \"^data:0\\\\.350$\"\n",
            "features: \"^data:0\\\\.351$\"\n",
            "features: \"^data:0\\\\.352$\"\n",
            "features: \"^data:0\\\\.353$\"\n",
            "features: \"^data:0\\\\.354$\"\n",
            "features: \"^data:0\\\\.355$\"\n",
            "features: \"^data:0\\\\.356$\"\n",
            "features: \"^data:0\\\\.357$\"\n",
            "features: \"^data:0\\\\.358$\"\n",
            "features: \"^data:0\\\\.359$\"\n",
            "features: \"^data:0\\\\.36$\"\n",
            "features: \"^data:0\\\\.360$\"\n",
            "features: \"^data:0\\\\.361$\"\n",
            "features: \"^data:0\\\\.362$\"\n",
            "features: \"^data:0\\\\.363$\"\n",
            "features: \"^data:0\\\\.364$\"\n",
            "features: \"^data:0\\\\.365$\"\n",
            "features: \"^data:0\\\\.366$\"\n",
            "features: \"^data:0\\\\.367$\"\n",
            "features: \"^data:0\\\\.368$\"\n",
            "features: \"^data:0\\\\.369$\"\n",
            "features: \"^data:0\\\\.37$\"\n",
            "features: \"^data:0\\\\.370$\"\n",
            "features: \"^data:0\\\\.371$\"\n",
            "features: \"^data:0\\\\.372$\"\n",
            "features: \"^data:0\\\\.373$\"\n",
            "features: \"^data:0\\\\.374$\"\n",
            "features: \"^data:0\\\\.375$\"\n",
            "features: \"^data:0\\\\.376$\"\n",
            "features: \"^data:0\\\\.377$\"\n",
            "features: \"^data:0\\\\.378$\"\n",
            "features: \"^data:0\\\\.379$\"\n",
            "features: \"^data:0\\\\.38$\"\n",
            "features: \"^data:0\\\\.380$\"\n",
            "features: \"^data:0\\\\.381$\"\n",
            "features: \"^data:0\\\\.382$\"\n",
            "features: \"^data:0\\\\.383$\"\n",
            "features: \"^data:0\\\\.384$\"\n",
            "features: \"^data:0\\\\.385$\"\n",
            "features: \"^data:0\\\\.386$\"\n",
            "features: \"^data:0\\\\.387$\"\n",
            "features: \"^data:0\\\\.388$\"\n",
            "features: \"^data:0\\\\.389$\"\n",
            "features: \"^data:0\\\\.39$\"\n",
            "features: \"^data:0\\\\.390$\"\n",
            "features: \"^data:0\\\\.391$\"\n",
            "features: \"^data:0\\\\.392$\"\n",
            "features: \"^data:0\\\\.393$\"\n",
            "features: \"^data:0\\\\.394$\"\n",
            "features: \"^data:0\\\\.395$\"\n",
            "features: \"^data:0\\\\.396$\"\n",
            "features: \"^data:0\\\\.397$\"\n",
            "features: \"^data:0\\\\.398$\"\n",
            "features: \"^data:0\\\\.399$\"\n",
            "features: \"^data:0\\\\.4$\"\n",
            "features: \"^data:0\\\\.40$\"\n",
            "features: \"^data:0\\\\.400$\"\n",
            "features: \"^data:0\\\\.401$\"\n",
            "features: \"^data:0\\\\.402$\"\n",
            "features: \"^data:0\\\\.403$\"\n",
            "features: \"^data:0\\\\.404$\"\n",
            "features: \"^data:0\\\\.405$\"\n",
            "features: \"^data:0\\\\.406$\"\n",
            "features: \"^data:0\\\\.407$\"\n",
            "features: \"^data:0\\\\.408$\"\n",
            "features: \"^data:0\\\\.409$\"\n",
            "features: \"^data:0\\\\.41$\"\n",
            "features: \"^data:0\\\\.410$\"\n",
            "features: \"^data:0\\\\.411$\"\n",
            "features: \"^data:0\\\\.412$\"\n",
            "features: \"^data:0\\\\.413$\"\n",
            "features: \"^data:0\\\\.414$\"\n",
            "features: \"^data:0\\\\.415$\"\n",
            "features: \"^data:0\\\\.416$\"\n",
            "features: \"^data:0\\\\.417$\"\n",
            "features: \"^data:0\\\\.418$\"\n",
            "features: \"^data:0\\\\.419$\"\n",
            "features: \"^data:0\\\\.42$\"\n",
            "features: \"^data:0\\\\.420$\"\n",
            "features: \"^data:0\\\\.421$\"\n",
            "features: \"^data:0\\\\.422$\"\n",
            "features: \"^data:0\\\\.423$\"\n",
            "features: \"^data:0\\\\.424$\"\n",
            "features: \"^data:0\\\\.425$\"\n",
            "features: \"^data:0\\\\.426$\"\n",
            "features: \"^data:0\\\\.427$\"\n",
            "features: \"^data:0\\\\.428$\"\n",
            "features: \"^data:0\\\\.429$\"\n",
            "features: \"^data:0\\\\.43$\"\n",
            "features: \"^data:0\\\\.430$\"\n",
            "features: \"^data:0\\\\.431$\"\n",
            "features: \"^data:0\\\\.432$\"\n",
            "features: \"^data:0\\\\.433$\"\n",
            "features: \"^data:0\\\\.434$\"\n",
            "features: \"^data:0\\\\.435$\"\n",
            "features: \"^data:0\\\\.436$\"\n",
            "features: \"^data:0\\\\.437$\"\n",
            "features: \"^data:0\\\\.438$\"\n",
            "features: \"^data:0\\\\.439$\"\n",
            "features: \"^data:0\\\\.44$\"\n",
            "features: \"^data:0\\\\.440$\"\n",
            "features: \"^data:0\\\\.441$\"\n",
            "features: \"^data:0\\\\.442$\"\n",
            "features: \"^data:0\\\\.443$\"\n",
            "features: \"^data:0\\\\.444$\"\n",
            "features: \"^data:0\\\\.445$\"\n",
            "features: \"^data:0\\\\.446$\"\n",
            "features: \"^data:0\\\\.447$\"\n",
            "features: \"^data:0\\\\.448$\"\n",
            "features: \"^data:0\\\\.449$\"\n",
            "features: \"^data:0\\\\.45$\"\n",
            "features: \"^data:0\\\\.450$\"\n",
            "features: \"^data:0\\\\.451$\"\n",
            "features: \"^data:0\\\\.452$\"\n",
            "features: \"^data:0\\\\.453$\"\n",
            "features: \"^data:0\\\\.454$\"\n",
            "features: \"^data:0\\\\.455$\"\n",
            "features: \"^data:0\\\\.456$\"\n",
            "features: \"^data:0\\\\.457$\"\n",
            "features: \"^data:0\\\\.458$\"\n",
            "features: \"^data:0\\\\.459$\"\n",
            "features: \"^data:0\\\\.46$\"\n",
            "features: \"^data:0\\\\.460$\"\n",
            "features: \"^data:0\\\\.461$\"\n",
            "features: \"^data:0\\\\.462$\"\n",
            "features: \"^data:0\\\\.463$\"\n",
            "features: \"^data:0\\\\.464$\"\n",
            "features: \"^data:0\\\\.465$\"\n",
            "features: \"^data:0\\\\.466$\"\n",
            "features: \"^data:0\\\\.467$\"\n",
            "features: \"^data:0\\\\.468$\"\n",
            "features: \"^data:0\\\\.469$\"\n",
            "features: \"^data:0\\\\.47$\"\n",
            "features: \"^data:0\\\\.470$\"\n",
            "features: \"^data:0\\\\.471$\"\n",
            "features: \"^data:0\\\\.472$\"\n",
            "features: \"^data:0\\\\.473$\"\n",
            "features: \"^data:0\\\\.474$\"\n",
            "features: \"^data:0\\\\.475$\"\n",
            "features: \"^data:0\\\\.476$\"\n",
            "features: \"^data:0\\\\.477$\"\n",
            "features: \"^data:0\\\\.478$\"\n",
            "features: \"^data:0\\\\.479$\"\n",
            "features: \"^data:0\\\\.48$\"\n",
            "features: \"^data:0\\\\.480$\"\n",
            "features: \"^data:0\\\\.481$\"\n",
            "features: \"^data:0\\\\.482$\"\n",
            "features: \"^data:0\\\\.483$\"\n",
            "features: \"^data:0\\\\.484$\"\n",
            "features: \"^data:0\\\\.485$\"\n",
            "features: \"^data:0\\\\.486$\"\n",
            "features: \"^data:0\\\\.487$\"\n",
            "features: \"^data:0\\\\.488$\"\n",
            "features: \"^data:0\\\\.489$\"\n",
            "features: \"^data:0\\\\.49$\"\n",
            "features: \"^data:0\\\\.490$\"\n",
            "features: \"^data:0\\\\.491$\"\n",
            "features: \"^data:0\\\\.492$\"\n",
            "features: \"^data:0\\\\.493$\"\n",
            "features: \"^data:0\\\\.494$\"\n",
            "features: \"^data:0\\\\.495$\"\n",
            "features: \"^data:0\\\\.496$\"\n",
            "features: \"^data:0\\\\.497$\"\n",
            "features: \"^data:0\\\\.498$\"\n",
            "features: \"^data:0\\\\.499$\"\n",
            "features: \"^data:0\\\\.5$\"\n",
            "features: \"^data:0\\\\.50$\"\n",
            "features: \"^data:0\\\\.500$\"\n",
            "features: \"^data:0\\\\.501$\"\n",
            "features: \"^data:0\\\\.502$\"\n",
            "features: \"^data:0\\\\.503$\"\n",
            "features: \"^data:0\\\\.504$\"\n",
            "features: \"^data:0\\\\.505$\"\n",
            "features: \"^data:0\\\\.506$\"\n",
            "features: \"^data:0\\\\.507$\"\n",
            "features: \"^data:0\\\\.508$\"\n",
            "features: \"^data:0\\\\.509$\"\n",
            "features: \"^data:0\\\\.51$\"\n",
            "features: \"^data:0\\\\.510$\"\n",
            "features: \"^data:0\\\\.511$\"\n",
            "features: \"^data:0\\\\.512$\"\n",
            "features: \"^data:0\\\\.513$\"\n",
            "features: \"^data:0\\\\.514$\"\n",
            "features: \"^data:0\\\\.515$\"\n",
            "features: \"^data:0\\\\.516$\"\n",
            "features: \"^data:0\\\\.517$\"\n",
            "features: \"^data:0\\\\.518$\"\n",
            "features: \"^data:0\\\\.519$\"\n",
            "features: \"^data:0\\\\.52$\"\n",
            "features: \"^data:0\\\\.520$\"\n",
            "features: \"^data:0\\\\.521$\"\n",
            "features: \"^data:0\\\\.522$\"\n",
            "features: \"^data:0\\\\.523$\"\n",
            "features: \"^data:0\\\\.524$\"\n",
            "features: \"^data:0\\\\.525$\"\n",
            "features: \"^data:0\\\\.526$\"\n",
            "features: \"^data:0\\\\.527$\"\n",
            "features: \"^data:0\\\\.528$\"\n",
            "features: \"^data:0\\\\.529$\"\n",
            "features: \"^data:0\\\\.53$\"\n",
            "features: \"^data:0\\\\.530$\"\n",
            "features: \"^data:0\\\\.531$\"\n",
            "features: \"^data:0\\\\.532$\"\n",
            "features: \"^data:0\\\\.533$\"\n",
            "features: \"^data:0\\\\.534$\"\n",
            "features: \"^data:0\\\\.535$\"\n",
            "features: \"^data:0\\\\.536$\"\n",
            "features: \"^data:0\\\\.537$\"\n",
            "features: \"^data:0\\\\.538$\"\n",
            "features: \"^data:0\\\\.539$\"\n",
            "features: \"^data:0\\\\.54$\"\n",
            "features: \"^data:0\\\\.540$\"\n",
            "features: \"^data:0\\\\.541$\"\n",
            "features: \"^data:0\\\\.542$\"\n",
            "features: \"^data:0\\\\.543$\"\n",
            "features: \"^data:0\\\\.544$\"\n",
            "features: \"^data:0\\\\.545$\"\n",
            "features: \"^data:0\\\\.546$\"\n",
            "features: \"^data:0\\\\.547$\"\n",
            "features: \"^data:0\\\\.548$\"\n",
            "features: \"^data:0\\\\.549$\"\n",
            "features: \"^data:0\\\\.55$\"\n",
            "features: \"^data:0\\\\.550$\"\n",
            "features: \"^data:0\\\\.551$\"\n",
            "features: \"^data:0\\\\.552$\"\n",
            "features: \"^data:0\\\\.553$\"\n",
            "features: \"^data:0\\\\.554$\"\n",
            "features: \"^data:0\\\\.555$\"\n",
            "features: \"^data:0\\\\.556$\"\n",
            "features: \"^data:0\\\\.557$\"\n",
            "features: \"^data:0\\\\.558$\"\n",
            "features: \"^data:0\\\\.559$\"\n",
            "features: \"^data:0\\\\.56$\"\n",
            "features: \"^data:0\\\\.560$\"\n",
            "features: \"^data:0\\\\.561$\"\n",
            "features: \"^data:0\\\\.562$\"\n",
            "features: \"^data:0\\\\.563$\"\n",
            "features: \"^data:0\\\\.564$\"\n",
            "features: \"^data:0\\\\.565$\"\n",
            "features: \"^data:0\\\\.566$\"\n",
            "features: \"^data:0\\\\.567$\"\n",
            "features: \"^data:0\\\\.568$\"\n",
            "features: \"^data:0\\\\.569$\"\n",
            "features: \"^data:0\\\\.57$\"\n",
            "features: \"^data:0\\\\.570$\"\n",
            "features: \"^data:0\\\\.571$\"\n",
            "features: \"^data:0\\\\.572$\"\n",
            "features: \"^data:0\\\\.573$\"\n",
            "features: \"^data:0\\\\.574$\"\n",
            "features: \"^data:0\\\\.575$\"\n",
            "features: \"^data:0\\\\.576$\"\n",
            "features: \"^data:0\\\\.577$\"\n",
            "features: \"^data:0\\\\.578$\"\n",
            "features: \"^data:0\\\\.579$\"\n",
            "features: \"^data:0\\\\.58$\"\n",
            "features: \"^data:0\\\\.580$\"\n",
            "features: \"^data:0\\\\.581$\"\n",
            "features: \"^data:0\\\\.582$\"\n",
            "features: \"^data:0\\\\.583$\"\n",
            "features: \"^data:0\\\\.584$\"\n",
            "features: \"^data:0\\\\.585$\"\n",
            "features: \"^data:0\\\\.586$\"\n",
            "features: \"^data:0\\\\.587$\"\n",
            "features: \"^data:0\\\\.588$\"\n",
            "features: \"^data:0\\\\.589$\"\n",
            "features: \"^data:0\\\\.59$\"\n",
            "features: \"^data:0\\\\.590$\"\n",
            "features: \"^data:0\\\\.591$\"\n",
            "features: \"^data:0\\\\.592$\"\n",
            "features: \"^data:0\\\\.593$\"\n",
            "features: \"^data:0\\\\.594$\"\n",
            "features: \"^data:0\\\\.595$\"\n",
            "features: \"^data:0\\\\.596$\"\n",
            "features: \"^data:0\\\\.597$\"\n",
            "features: \"^data:0\\\\.598$\"\n",
            "features: \"^data:0\\\\.599$\"\n",
            "features: \"^data:0\\\\.6$\"\n",
            "features: \"^data:0\\\\.60$\"\n",
            "features: \"^data:0\\\\.600$\"\n",
            "features: \"^data:0\\\\.601$\"\n",
            "features: \"^data:0\\\\.602$\"\n",
            "features: \"^data:0\\\\.603$\"\n",
            "features: \"^data:0\\\\.604$\"\n",
            "features: \"^data:0\\\\.605$\"\n",
            "features: \"^data:0\\\\.606$\"\n",
            "features: \"^data:0\\\\.607$\"\n",
            "features: \"^data:0\\\\.608$\"\n",
            "features: \"^data:0\\\\.609$\"\n",
            "features: \"^data:0\\\\.61$\"\n",
            "features: \"^data:0\\\\.610$\"\n",
            "features: \"^data:0\\\\.611$\"\n",
            "features: \"^data:0\\\\.612$\"\n",
            "features: \"^data:0\\\\.613$\"\n",
            "features: \"^data:0\\\\.614$\"\n",
            "features: \"^data:0\\\\.615$\"\n",
            "features: \"^data:0\\\\.616$\"\n",
            "features: \"^data:0\\\\.617$\"\n",
            "features: \"^data:0\\\\.618$\"\n",
            "features: \"^data:0\\\\.619$\"\n",
            "features: \"^data:0\\\\.62$\"\n",
            "features: \"^data:0\\\\.620$\"\n",
            "features: \"^data:0\\\\.621$\"\n",
            "features: \"^data:0\\\\.622$\"\n",
            "features: \"^data:0\\\\.623$\"\n",
            "features: \"^data:0\\\\.624$\"\n",
            "features: \"^data:0\\\\.625$\"\n",
            "features: \"^data:0\\\\.626$\"\n",
            "features: \"^data:0\\\\.627$\"\n",
            "features: \"^data:0\\\\.628$\"\n",
            "features: \"^data:0\\\\.629$\"\n",
            "features: \"^data:0\\\\.63$\"\n",
            "features: \"^data:0\\\\.630$\"\n",
            "features: \"^data:0\\\\.631$\"\n",
            "features: \"^data:0\\\\.632$\"\n",
            "features: \"^data:0\\\\.633$\"\n",
            "features: \"^data:0\\\\.634$\"\n",
            "features: \"^data:0\\\\.635$\"\n",
            "features: \"^data:0\\\\.636$\"\n",
            "features: \"^data:0\\\\.637$\"\n",
            "features: \"^data:0\\\\.638$\"\n",
            "features: \"^data:0\\\\.639$\"\n",
            "features: \"^data:0\\\\.64$\"\n",
            "features: \"^data:0\\\\.640$\"\n",
            "features: \"^data:0\\\\.641$\"\n",
            "features: \"^data:0\\\\.642$\"\n",
            "features: \"^data:0\\\\.643$\"\n",
            "features: \"^data:0\\\\.644$\"\n",
            "features: \"^data:0\\\\.645$\"\n",
            "features: \"^data:0\\\\.646$\"\n",
            "features: \"^data:0\\\\.647$\"\n",
            "features: \"^data:0\\\\.648$\"\n",
            "features: \"^data:0\\\\.649$\"\n",
            "features: \"^data:0\\\\.65$\"\n",
            "features: \"^data:0\\\\.650$\"\n",
            "features: \"^data:0\\\\.651$\"\n",
            "features: \"^data:0\\\\.652$\"\n",
            "features: \"^data:0\\\\.653$\"\n",
            "features: \"^data:0\\\\.654$\"\n",
            "features: \"^data:0\\\\.655$\"\n",
            "features: \"^data:0\\\\.656$\"\n",
            "features: \"^data:0\\\\.657$\"\n",
            "features: \"^data:0\\\\.658$\"\n",
            "features: \"^data:0\\\\.659$\"\n",
            "features: \"^data:0\\\\.66$\"\n",
            "features: \"^data:0\\\\.660$\"\n",
            "features: \"^data:0\\\\.661$\"\n",
            "features: \"^data:0\\\\.662$\"\n",
            "features: \"^data:0\\\\.663$\"\n",
            "features: \"^data:0\\\\.664$\"\n",
            "features: \"^data:0\\\\.665$\"\n",
            "features: \"^data:0\\\\.666$\"\n",
            "features: \"^data:0\\\\.667$\"\n",
            "features: \"^data:0\\\\.668$\"\n",
            "features: \"^data:0\\\\.669$\"\n",
            "features: \"^data:0\\\\.67$\"\n",
            "features: \"^data:0\\\\.670$\"\n",
            "features: \"^data:0\\\\.671$\"\n",
            "features: \"^data:0\\\\.672$\"\n",
            "features: \"^data:0\\\\.673$\"\n",
            "features: \"^data:0\\\\.674$\"\n",
            "features: \"^data:0\\\\.675$\"\n",
            "features: \"^data:0\\\\.676$\"\n",
            "features: \"^data:0\\\\.677$\"\n",
            "features: \"^data:0\\\\.678$\"\n",
            "features: \"^data:0\\\\.679$\"\n",
            "features: \"^data:0\\\\.68$\"\n",
            "features: \"^data:0\\\\.680$\"\n",
            "features: \"^data:0\\\\.681$\"\n",
            "features: \"^data:0\\\\.682$\"\n",
            "features: \"^data:0\\\\.683$\"\n",
            "features: \"^data:0\\\\.684$\"\n",
            "features: \"^data:0\\\\.685$\"\n",
            "features: \"^data:0\\\\.686$\"\n",
            "features: \"^data:0\\\\.687$\"\n",
            "features: \"^data:0\\\\.688$\"\n",
            "features: \"^data:0\\\\.689$\"\n",
            "features: \"^data:0\\\\.69$\"\n",
            "features: \"^data:0\\\\.690$\"\n",
            "features: \"^data:0\\\\.691$\"\n",
            "features: \"^data:0\\\\.692$\"\n",
            "features: \"^data:0\\\\.693$\"\n",
            "features: \"^data:0\\\\.694$\"\n",
            "features: \"^data:0\\\\.695$\"\n",
            "features: \"^data:0\\\\.696$\"\n",
            "features: \"^data:0\\\\.697$\"\n",
            "features: \"^data:0\\\\.698$\"\n",
            "features: \"^data:0\\\\.699$\"\n",
            "features: \"^data:0\\\\.7$\"\n",
            "features: \"^data:0\\\\.70$\"\n",
            "features: \"^data:0\\\\.700$\"\n",
            "features: \"^data:0\\\\.701$\"\n",
            "features: \"^data:0\\\\.702$\"\n",
            "features: \"^data:0\\\\.703$\"\n",
            "features: \"^data:0\\\\.704$\"\n",
            "features: \"^data:0\\\\.705$\"\n",
            "features: \"^data:0\\\\.706$\"\n",
            "features: \"^data:0\\\\.707$\"\n",
            "features: \"^data:0\\\\.708$\"\n",
            "features: \"^data:0\\\\.709$\"\n",
            "features: \"^data:0\\\\.71$\"\n",
            "features: \"^data:0\\\\.710$\"\n",
            "features: \"^data:0\\\\.711$\"\n",
            "features: \"^data:0\\\\.712$\"\n",
            "features: \"^data:0\\\\.713$\"\n",
            "features: \"^data:0\\\\.714$\"\n",
            "features: \"^data:0\\\\.715$\"\n",
            "features: \"^data:0\\\\.716$\"\n",
            "features: \"^data:0\\\\.717$\"\n",
            "features: \"^data:0\\\\.718$\"\n",
            "features: \"^data:0\\\\.719$\"\n",
            "features: \"^data:0\\\\.72$\"\n",
            "features: \"^data:0\\\\.720$\"\n",
            "features: \"^data:0\\\\.721$\"\n",
            "features: \"^data:0\\\\.722$\"\n",
            "features: \"^data:0\\\\.723$\"\n",
            "features: \"^data:0\\\\.724$\"\n",
            "features: \"^data:0\\\\.725$\"\n",
            "features: \"^data:0\\\\.726$\"\n",
            "features: \"^data:0\\\\.727$\"\n",
            "features: \"^data:0\\\\.728$\"\n",
            "features: \"^data:0\\\\.729$\"\n",
            "features: \"^data:0\\\\.73$\"\n",
            "features: \"^data:0\\\\.730$\"\n",
            "features: \"^data:0\\\\.731$\"\n",
            "features: \"^data:0\\\\.732$\"\n",
            "features: \"^data:0\\\\.733$\"\n",
            "features: \"^data:0\\\\.734$\"\n",
            "features: \"^data:0\\\\.735$\"\n",
            "features: \"^data:0\\\\.736$\"\n",
            "features: \"^data:0\\\\.737$\"\n",
            "features: \"^data:0\\\\.738$\"\n",
            "features: \"^data:0\\\\.739$\"\n",
            "features: \"^data:0\\\\.74$\"\n",
            "features: \"^data:0\\\\.740$\"\n",
            "features: \"^data:0\\\\.741$\"\n",
            "features: \"^data:0\\\\.742$\"\n",
            "features: \"^data:0\\\\.743$\"\n",
            "features: \"^data:0\\\\.744$\"\n",
            "features: \"^data:0\\\\.745$\"\n",
            "features: \"^data:0\\\\.746$\"\n",
            "features: \"^data:0\\\\.747$\"\n",
            "features: \"^data:0\\\\.748$\"\n",
            "features: \"^data:0\\\\.749$\"\n",
            "features: \"^data:0\\\\.75$\"\n",
            "features: \"^data:0\\\\.750$\"\n",
            "features: \"^data:0\\\\.751$\"\n",
            "features: \"^data:0\\\\.752$\"\n",
            "features: \"^data:0\\\\.753$\"\n",
            "features: \"^data:0\\\\.754$\"\n",
            "features: \"^data:0\\\\.755$\"\n",
            "features: \"^data:0\\\\.756$\"\n",
            "features: \"^data:0\\\\.757$\"\n",
            "features: \"^data:0\\\\.758$\"\n",
            "features: \"^data:0\\\\.759$\"\n",
            "features: \"^data:0\\\\.76$\"\n",
            "features: \"^data:0\\\\.760$\"\n",
            "features: \"^data:0\\\\.761$\"\n",
            "features: \"^data:0\\\\.762$\"\n",
            "features: \"^data:0\\\\.763$\"\n",
            "features: \"^data:0\\\\.764$\"\n",
            "features: \"^data:0\\\\.765$\"\n",
            "features: \"^data:0\\\\.766$\"\n",
            "features: \"^data:0\\\\.767$\"\n",
            "features: \"^data:0\\\\.768$\"\n",
            "features: \"^data:0\\\\.769$\"\n",
            "features: \"^data:0\\\\.77$\"\n",
            "features: \"^data:0\\\\.770$\"\n",
            "features: \"^data:0\\\\.771$\"\n",
            "features: \"^data:0\\\\.772$\"\n",
            "features: \"^data:0\\\\.773$\"\n",
            "features: \"^data:0\\\\.774$\"\n",
            "features: \"^data:0\\\\.775$\"\n",
            "features: \"^data:0\\\\.776$\"\n",
            "features: \"^data:0\\\\.777$\"\n",
            "features: \"^data:0\\\\.778$\"\n",
            "features: \"^data:0\\\\.779$\"\n",
            "features: \"^data:0\\\\.78$\"\n",
            "features: \"^data:0\\\\.780$\"\n",
            "features: \"^data:0\\\\.781$\"\n",
            "features: \"^data:0\\\\.782$\"\n",
            "features: \"^data:0\\\\.783$\"\n",
            "features: \"^data:0\\\\.79$\"\n",
            "features: \"^data:0\\\\.8$\"\n",
            "features: \"^data:0\\\\.80$\"\n",
            "features: \"^data:0\\\\.81$\"\n",
            "features: \"^data:0\\\\.82$\"\n",
            "features: \"^data:0\\\\.83$\"\n",
            "features: \"^data:0\\\\.84$\"\n",
            "features: \"^data:0\\\\.85$\"\n",
            "features: \"^data:0\\\\.86$\"\n",
            "features: \"^data:0\\\\.87$\"\n",
            "features: \"^data:0\\\\.88$\"\n",
            "features: \"^data:0\\\\.89$\"\n",
            "features: \"^data:0\\\\.9$\"\n",
            "features: \"^data:0\\\\.90$\"\n",
            "features: \"^data:0\\\\.91$\"\n",
            "features: \"^data:0\\\\.92$\"\n",
            "features: \"^data:0\\\\.93$\"\n",
            "features: \"^data:0\\\\.94$\"\n",
            "features: \"^data:0\\\\.95$\"\n",
            "features: \"^data:0\\\\.96$\"\n",
            "features: \"^data:0\\\\.97$\"\n",
            "features: \"^data:0\\\\.98$\"\n",
            "features: \"^data:0\\\\.99$\"\n",
            "label: \"^__LABEL$\"\n",
            "task: CLASSIFICATION\n",
            "random_seed: 123456\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "pure_serving_model: false\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 500\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    keep_non_leaf_label_distribution: true\n",
            "    num_candidate_attributes: 0\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "    uplift {\n",
            "      min_examples_in_treatment: 5\n",
            "      split_score: KULLBACK_LEIBLER\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  num_oob_variable_importances_permutations: 1\n",
            "  bootstrap_training_dataset: true\n",
            "  bootstrap_size_ratio: 1\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "  sampling_with_replacement: true\n",
            "}\n",
            "\n",
            "[INFO 23-05-27 16:47:49.1283 UTC kernel.cc:827] Deployment config:\n",
            "cache_path: \"/tmp/tmp6puxm1wr/working_cache\"\n",
            "num_threads: 2\n",
            "try_resume_training: true\n",
            "\n",
            "[INFO 23-05-27 16:47:49.1370 UTC kernel.cc:889] Train model\n",
            "[INFO 23-05-27 16:47:49.2742 UTC random_forest.cc:416] Training random forest on 60000 example(s) and 784 feature(s).\n",
            "[INFO 23-05-27 16:47:54.8063 UTC random_forest.cc:805] Training of tree  1/500 (tree index:0) done accuracy:0.830498 logloss:6.10945\n",
            "[INFO 23-05-27 16:48:05.2922 UTC random_forest.cc:805] Training of tree  11/500 (tree index:10) done accuracy:0.90397 logloss:1.33512\n",
            "[INFO 23-05-27 16:48:15.7467 UTC random_forest.cc:805] Training of tree  21/500 (tree index:20) done accuracy:0.938795 logloss:0.568085\n",
            "[INFO 23-05-27 16:48:26.3941 UTC random_forest.cc:805] Training of tree  31/500 (tree index:30) done accuracy:0.950167 logloss:0.393499\n",
            "[INFO 23-05-27 16:48:37.0460 UTC random_forest.cc:805] Training of tree  41/500 (tree index:40) done accuracy:0.954833 logloss:0.323543\n",
            "[INFO 23-05-27 16:48:47.6603 UTC random_forest.cc:805] Training of tree  51/500 (tree index:50) done accuracy:0.957533 logloss:0.293047\n",
            "[INFO 23-05-27 16:48:57.6425 UTC random_forest.cc:805] Training of tree  61/500 (tree index:60) done accuracy:0.9596 logloss:0.273547\n",
            "[INFO 23-05-27 16:49:08.1625 UTC random_forest.cc:805] Training of tree  71/500 (tree index:70) done accuracy:0.960867 logloss:0.263795\n",
            "[INFO 23-05-27 16:49:18.6590 UTC random_forest.cc:805] Training of tree  81/500 (tree index:80) done accuracy:0.961533 logloss:0.255504\n",
            "[INFO 23-05-27 16:49:29.1368 UTC random_forest.cc:805] Training of tree  91/500 (tree index:90) done accuracy:0.962517 logloss:0.250962\n",
            "[INFO 23-05-27 16:49:39.6309 UTC random_forest.cc:805] Training of tree  101/500 (tree index:100) done accuracy:0.963167 logloss:0.245924\n",
            "[INFO 23-05-27 16:49:50.0039 UTC random_forest.cc:805] Training of tree  111/500 (tree index:110) done accuracy:0.9634 logloss:0.242079\n",
            "[INFO 23-05-27 16:50:00.5969 UTC random_forest.cc:805] Training of tree  121/500 (tree index:120) done accuracy:0.964 logloss:0.240756\n",
            "[INFO 23-05-27 16:50:10.8455 UTC random_forest.cc:805] Training of tree  131/500 (tree index:130) done accuracy:0.96425 logloss:0.238417\n",
            "[INFO 23-05-27 16:50:21.1739 UTC random_forest.cc:805] Training of tree  141/500 (tree index:140) done accuracy:0.964533 logloss:0.236996\n",
            "[INFO 23-05-27 16:50:31.4404 UTC random_forest.cc:805] Training of tree  151/500 (tree index:150) done accuracy:0.96485 logloss:0.234643\n",
            "[INFO 23-05-27 16:50:41.8566 UTC random_forest.cc:805] Training of tree  161/500 (tree index:160) done accuracy:0.964983 logloss:0.232777\n",
            "[INFO 23-05-27 16:50:52.3714 UTC random_forest.cc:805] Training of tree  171/500 (tree index:170) done accuracy:0.964933 logloss:0.231719\n",
            "[INFO 23-05-27 16:51:03.0066 UTC random_forest.cc:805] Training of tree  181/500 (tree index:180) done accuracy:0.964983 logloss:0.231038\n",
            "[INFO 23-05-27 16:51:13.3712 UTC random_forest.cc:805] Training of tree  191/500 (tree index:190) done accuracy:0.965133 logloss:0.230806\n",
            "[INFO 23-05-27 16:51:23.9429 UTC random_forest.cc:805] Training of tree  201/500 (tree index:201) done accuracy:0.965267 logloss:0.229063\n",
            "[INFO 23-05-27 16:51:34.4078 UTC random_forest.cc:805] Training of tree  211/500 (tree index:210) done accuracy:0.965233 logloss:0.228445\n",
            "[INFO 23-05-27 16:51:44.0647 UTC random_forest.cc:805] Training of tree  221/500 (tree index:220) done accuracy:0.965717 logloss:0.22814\n",
            "[INFO 23-05-27 16:51:54.4968 UTC random_forest.cc:805] Training of tree  231/500 (tree index:230) done accuracy:0.96555 logloss:0.227411\n",
            "[INFO 23-05-27 16:52:05.0910 UTC random_forest.cc:805] Training of tree  241/500 (tree index:240) done accuracy:0.965733 logloss:0.227197\n",
            "[INFO 23-05-27 16:52:15.5329 UTC random_forest.cc:805] Training of tree  251/500 (tree index:250) done accuracy:0.9659 logloss:0.227128\n",
            "[INFO 23-05-27 16:52:26.2418 UTC random_forest.cc:805] Training of tree  261/500 (tree index:260) done accuracy:0.966067 logloss:0.227147\n",
            "[INFO 23-05-27 16:52:36.8557 UTC random_forest.cc:805] Training of tree  271/500 (tree index:270) done accuracy:0.966 logloss:0.227069\n",
            "[INFO 23-05-27 16:52:47.4751 UTC random_forest.cc:805] Training of tree  281/500 (tree index:280) done accuracy:0.965883 logloss:0.226611\n",
            "[INFO 23-05-27 16:52:58.0323 UTC random_forest.cc:805] Training of tree  291/500 (tree index:291) done accuracy:0.965917 logloss:0.226496\n",
            "[INFO 23-05-27 16:53:07.6624 UTC random_forest.cc:805] Training of tree  301/500 (tree index:300) done accuracy:0.9659 logloss:0.226489\n",
            "[INFO 23-05-27 16:53:18.0009 UTC random_forest.cc:805] Training of tree  311/500 (tree index:310) done accuracy:0.966133 logloss:0.226479\n",
            "[INFO 23-05-27 16:53:28.4333 UTC random_forest.cc:805] Training of tree  321/500 (tree index:320) done accuracy:0.966217 logloss:0.22645\n",
            "[INFO 23-05-27 16:53:39.0380 UTC random_forest.cc:805] Training of tree  331/500 (tree index:330) done accuracy:0.96625 logloss:0.226421\n",
            "[INFO 23-05-27 16:53:49.5530 UTC random_forest.cc:805] Training of tree  341/500 (tree index:341) done accuracy:0.96605 logloss:0.225929\n",
            "[INFO 23-05-27 16:54:00.1602 UTC random_forest.cc:805] Training of tree  351/500 (tree index:350) done accuracy:0.966233 logloss:0.22578\n",
            "[INFO 23-05-27 16:54:10.6533 UTC random_forest.cc:805] Training of tree  361/500 (tree index:360) done accuracy:0.966367 logloss:0.225249\n",
            "[INFO 23-05-27 16:54:21.3339 UTC random_forest.cc:805] Training of tree  371/500 (tree index:370) done accuracy:0.966533 logloss:0.224674\n",
            "[INFO 23-05-27 16:54:30.8711 UTC random_forest.cc:805] Training of tree  381/500 (tree index:380) done accuracy:0.966567 logloss:0.224576\n",
            "[INFO 23-05-27 16:54:41.3714 UTC random_forest.cc:805] Training of tree  391/500 (tree index:390) done accuracy:0.966783 logloss:0.224497\n",
            "[INFO 23-05-27 16:54:51.9152 UTC random_forest.cc:805] Training of tree  401/500 (tree index:400) done accuracy:0.966667 logloss:0.224493\n",
            "[INFO 23-05-27 16:55:02.4940 UTC random_forest.cc:805] Training of tree  411/500 (tree index:410) done accuracy:0.966767 logloss:0.224461\n",
            "[INFO 23-05-27 16:55:12.8253 UTC random_forest.cc:805] Training of tree  421/500 (tree index:420) done accuracy:0.966583 logloss:0.224394\n",
            "[INFO 23-05-27 16:55:23.2234 UTC random_forest.cc:805] Training of tree  431/500 (tree index:430) done accuracy:0.966717 logloss:0.22435\n",
            "[INFO 23-05-27 16:55:33.5822 UTC random_forest.cc:805] Training of tree  441/500 (tree index:440) done accuracy:0.966717 logloss:0.224336\n",
            "[INFO 23-05-27 16:55:43.4958 UTC random_forest.cc:805] Training of tree  451/500 (tree index:450) done accuracy:0.966717 logloss:0.22425\n",
            "[INFO 23-05-27 16:55:53.6626 UTC random_forest.cc:805] Training of tree  461/500 (tree index:461) done accuracy:0.966817 logloss:0.224198\n",
            "[INFO 23-05-27 16:56:04.1434 UTC random_forest.cc:805] Training of tree  471/500 (tree index:470) done accuracy:0.96685 logloss:0.224122\n",
            "[INFO 23-05-27 16:56:14.6871 UTC random_forest.cc:805] Training of tree  481/500 (tree index:480) done accuracy:0.966833 logloss:0.224085\n",
            "[INFO 23-05-27 16:56:25.1682 UTC random_forest.cc:805] Training of tree  491/500 (tree index:490) done accuracy:0.966817 logloss:0.22406\n",
            "[INFO 23-05-27 16:56:33.7730 UTC random_forest.cc:805] Training of tree  500/500 (tree index:499) done accuracy:0.966867 logloss:0.224047\n",
            "[INFO 23-05-27 16:56:33.7732 UTC random_forest.cc:885] Final OOB metrics: accuracy:0.966867 logloss:0.224047\n",
            "[INFO 23-05-27 16:56:39.9013 UTC kernel.cc:926] Export model in log directory: /tmp/tmp6puxm1wr with prefix ed850ff665384cee\n",
            "[INFO 23-05-27 16:56:45.2744 UTC kernel.cc:944] Save model in resources\n",
            "[INFO 23-05-27 16:56:45.2949 UTC abstract_model.cc:849] Model self evaluation:\n",
            "Number of predictions (without weights): 60000\n",
            "Number of predictions (with weights): 60000\n",
            "Task: CLASSIFICATION\n",
            "Label: __LABEL\n",
            "\n",
            "Accuracy: 0.966867  CI95[W][0.96564 0.96806]\n",
            "LogLoss: : 0.224047\n",
            "ErrorRate: : 0.0331333\n",
            "\n",
            "Default Accuracy: : 0.112367\n",
            "Default LogLoss: : 2.30116\n",
            "Default ErrorRate: : 0.887633\n",
            "\n",
            "Confusion Table:\n",
            "truth\\prediction\n",
            "    0     1     2     3     4     5     6     7     8     9    10\n",
            " 0  0     0     0     0     0     0     0     0     0     0     0\n",
            " 1  0  5846     1     7     2     5     8    12     2    37     3\n",
            " 2  0     1  6646    31    14    11     2     6    14    11     6\n",
            " 3  0    23    10  5770    26    24     4    21    40    32     8\n",
            " 4  0     7     7    93  5826     3    63     9    48    50    25\n",
            " 5  0    12     9     9     1  5660     0    21    10    14   106\n",
            " 6  0    21     8    11    57    11  5212    40     6    36    19\n",
            " 7  0    29    11     4     0    12    29  5816     0    17     0\n",
            " 8  0     4    22    65     6    38     1     0  6043    15    71\n",
            " 9  0    12    34    42    32    25    39    29     6  5563    69\n",
            "10  0    22    10    17    82    79    18     5    48    38  5630\n",
            "Total: 60000\n",
            "\n",
            "One vs other classes:\n",
            "\n",
            "[INFO 23-05-27 16:56:46.5159 UTC kernel.cc:1242] Loading model from path /tmp/tmp6puxm1wr/model/ with prefix ed850ff665384cee\n",
            "[INFO 23-05-27 16:56:57.7118 UTC decision_forest.cc:660] Model loaded with 500 root(s), 2333144 node(s), and 583 input feature(s).\n",
            "[INFO 23-05-27 16:56:57.7118 UTC abstract_model.cc:1311] Engine \"RandomForestGeneric\" built\n",
            "[INFO 23-05-27 16:56:57.7124 UTC kernel.cc:1074] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:09:09.765030\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "Model: \"random_forest_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (784):\n",
            "\tdata:0.0\n",
            "\tdata:0.1\n",
            "\tdata:0.10\n",
            "\tdata:0.100\n",
            "\tdata:0.101\n",
            "\tdata:0.102\n",
            "\tdata:0.103\n",
            "\tdata:0.104\n",
            "\tdata:0.105\n",
            "\tdata:0.106\n",
            "\tdata:0.107\n",
            "\tdata:0.108\n",
            "\tdata:0.109\n",
            "\tdata:0.11\n",
            "\tdata:0.110\n",
            "\tdata:0.111\n",
            "\tdata:0.112\n",
            "\tdata:0.113\n",
            "\tdata:0.114\n",
            "\tdata:0.115\n",
            "\tdata:0.116\n",
            "\tdata:0.117\n",
            "\tdata:0.118\n",
            "\tdata:0.119\n",
            "\tdata:0.12\n",
            "\tdata:0.120\n",
            "\tdata:0.121\n",
            "\tdata:0.122\n",
            "\tdata:0.123\n",
            "\tdata:0.124\n",
            "\tdata:0.125\n",
            "\tdata:0.126\n",
            "\tdata:0.127\n",
            "\tdata:0.128\n",
            "\tdata:0.129\n",
            "\tdata:0.13\n",
            "\tdata:0.130\n",
            "\tdata:0.131\n",
            "\tdata:0.132\n",
            "\tdata:0.133\n",
            "\tdata:0.134\n",
            "\tdata:0.135\n",
            "\tdata:0.136\n",
            "\tdata:0.137\n",
            "\tdata:0.138\n",
            "\tdata:0.139\n",
            "\tdata:0.14\n",
            "\tdata:0.140\n",
            "\tdata:0.141\n",
            "\tdata:0.142\n",
            "\tdata:0.143\n",
            "\tdata:0.144\n",
            "\tdata:0.145\n",
            "\tdata:0.146\n",
            "\tdata:0.147\n",
            "\tdata:0.148\n",
            "\tdata:0.149\n",
            "\tdata:0.15\n",
            "\tdata:0.150\n",
            "\tdata:0.151\n",
            "\tdata:0.152\n",
            "\tdata:0.153\n",
            "\tdata:0.154\n",
            "\tdata:0.155\n",
            "\tdata:0.156\n",
            "\tdata:0.157\n",
            "\tdata:0.158\n",
            "\tdata:0.159\n",
            "\tdata:0.16\n",
            "\tdata:0.160\n",
            "\tdata:0.161\n",
            "\tdata:0.162\n",
            "\tdata:0.163\n",
            "\tdata:0.164\n",
            "\tdata:0.165\n",
            "\tdata:0.166\n",
            "\tdata:0.167\n",
            "\tdata:0.168\n",
            "\tdata:0.169\n",
            "\tdata:0.17\n",
            "\tdata:0.170\n",
            "\tdata:0.171\n",
            "\tdata:0.172\n",
            "\tdata:0.173\n",
            "\tdata:0.174\n",
            "\tdata:0.175\n",
            "\tdata:0.176\n",
            "\tdata:0.177\n",
            "\tdata:0.178\n",
            "\tdata:0.179\n",
            "\tdata:0.18\n",
            "\tdata:0.180\n",
            "\tdata:0.181\n",
            "\tdata:0.182\n",
            "\tdata:0.183\n",
            "\tdata:0.184\n",
            "\tdata:0.185\n",
            "\tdata:0.186\n",
            "\tdata:0.187\n",
            "\tdata:0.188\n",
            "\tdata:0.189\n",
            "\tdata:0.19\n",
            "\tdata:0.190\n",
            "\tdata:0.191\n",
            "\tdata:0.192\n",
            "\tdata:0.193\n",
            "\tdata:0.194\n",
            "\tdata:0.195\n",
            "\tdata:0.196\n",
            "\tdata:0.197\n",
            "\tdata:0.198\n",
            "\tdata:0.199\n",
            "\tdata:0.2\n",
            "\tdata:0.20\n",
            "\tdata:0.200\n",
            "\tdata:0.201\n",
            "\tdata:0.202\n",
            "\tdata:0.203\n",
            "\tdata:0.204\n",
            "\tdata:0.205\n",
            "\tdata:0.206\n",
            "\tdata:0.207\n",
            "\tdata:0.208\n",
            "\tdata:0.209\n",
            "\tdata:0.21\n",
            "\tdata:0.210\n",
            "\tdata:0.211\n",
            "\tdata:0.212\n",
            "\tdata:0.213\n",
            "\tdata:0.214\n",
            "\tdata:0.215\n",
            "\tdata:0.216\n",
            "\tdata:0.217\n",
            "\tdata:0.218\n",
            "\tdata:0.219\n",
            "\tdata:0.22\n",
            "\tdata:0.220\n",
            "\tdata:0.221\n",
            "\tdata:0.222\n",
            "\tdata:0.223\n",
            "\tdata:0.224\n",
            "\tdata:0.225\n",
            "\tdata:0.226\n",
            "\tdata:0.227\n",
            "\tdata:0.228\n",
            "\tdata:0.229\n",
            "\tdata:0.23\n",
            "\tdata:0.230\n",
            "\tdata:0.231\n",
            "\tdata:0.232\n",
            "\tdata:0.233\n",
            "\tdata:0.234\n",
            "\tdata:0.235\n",
            "\tdata:0.236\n",
            "\tdata:0.237\n",
            "\tdata:0.238\n",
            "\tdata:0.239\n",
            "\tdata:0.24\n",
            "\tdata:0.240\n",
            "\tdata:0.241\n",
            "\tdata:0.242\n",
            "\tdata:0.243\n",
            "\tdata:0.244\n",
            "\tdata:0.245\n",
            "\tdata:0.246\n",
            "\tdata:0.247\n",
            "\tdata:0.248\n",
            "\tdata:0.249\n",
            "\tdata:0.25\n",
            "\tdata:0.250\n",
            "\tdata:0.251\n",
            "\tdata:0.252\n",
            "\tdata:0.253\n",
            "\tdata:0.254\n",
            "\tdata:0.255\n",
            "\tdata:0.256\n",
            "\tdata:0.257\n",
            "\tdata:0.258\n",
            "\tdata:0.259\n",
            "\tdata:0.26\n",
            "\tdata:0.260\n",
            "\tdata:0.261\n",
            "\tdata:0.262\n",
            "\tdata:0.263\n",
            "\tdata:0.264\n",
            "\tdata:0.265\n",
            "\tdata:0.266\n",
            "\tdata:0.267\n",
            "\tdata:0.268\n",
            "\tdata:0.269\n",
            "\tdata:0.27\n",
            "\tdata:0.270\n",
            "\tdata:0.271\n",
            "\tdata:0.272\n",
            "\tdata:0.273\n",
            "\tdata:0.274\n",
            "\tdata:0.275\n",
            "\tdata:0.276\n",
            "\tdata:0.277\n",
            "\tdata:0.278\n",
            "\tdata:0.279\n",
            "\tdata:0.28\n",
            "\tdata:0.280\n",
            "\tdata:0.281\n",
            "\tdata:0.282\n",
            "\tdata:0.283\n",
            "\tdata:0.284\n",
            "\tdata:0.285\n",
            "\tdata:0.286\n",
            "\tdata:0.287\n",
            "\tdata:0.288\n",
            "\tdata:0.289\n",
            "\tdata:0.29\n",
            "\tdata:0.290\n",
            "\tdata:0.291\n",
            "\tdata:0.292\n",
            "\tdata:0.293\n",
            "\tdata:0.294\n",
            "\tdata:0.295\n",
            "\tdata:0.296\n",
            "\tdata:0.297\n",
            "\tdata:0.298\n",
            "\tdata:0.299\n",
            "\tdata:0.3\n",
            "\tdata:0.30\n",
            "\tdata:0.300\n",
            "\tdata:0.301\n",
            "\tdata:0.302\n",
            "\tdata:0.303\n",
            "\tdata:0.304\n",
            "\tdata:0.305\n",
            "\tdata:0.306\n",
            "\tdata:0.307\n",
            "\tdata:0.308\n",
            "\tdata:0.309\n",
            "\tdata:0.31\n",
            "\tdata:0.310\n",
            "\tdata:0.311\n",
            "\tdata:0.312\n",
            "\tdata:0.313\n",
            "\tdata:0.314\n",
            "\tdata:0.315\n",
            "\tdata:0.316\n",
            "\tdata:0.317\n",
            "\tdata:0.318\n",
            "\tdata:0.319\n",
            "\tdata:0.32\n",
            "\tdata:0.320\n",
            "\tdata:0.321\n",
            "\tdata:0.322\n",
            "\tdata:0.323\n",
            "\tdata:0.324\n",
            "\tdata:0.325\n",
            "\tdata:0.326\n",
            "\tdata:0.327\n",
            "\tdata:0.328\n",
            "\tdata:0.329\n",
            "\tdata:0.33\n",
            "\tdata:0.330\n",
            "\tdata:0.331\n",
            "\tdata:0.332\n",
            "\tdata:0.333\n",
            "\tdata:0.334\n",
            "\tdata:0.335\n",
            "\tdata:0.336\n",
            "\tdata:0.337\n",
            "\tdata:0.338\n",
            "\tdata:0.339\n",
            "\tdata:0.34\n",
            "\tdata:0.340\n",
            "\tdata:0.341\n",
            "\tdata:0.342\n",
            "\tdata:0.343\n",
            "\tdata:0.344\n",
            "\tdata:0.345\n",
            "\tdata:0.346\n",
            "\tdata:0.347\n",
            "\tdata:0.348\n",
            "\tdata:0.349\n",
            "\tdata:0.35\n",
            "\tdata:0.350\n",
            "\tdata:0.351\n",
            "\tdata:0.352\n",
            "\tdata:0.353\n",
            "\tdata:0.354\n",
            "\tdata:0.355\n",
            "\tdata:0.356\n",
            "\tdata:0.357\n",
            "\tdata:0.358\n",
            "\tdata:0.359\n",
            "\tdata:0.36\n",
            "\tdata:0.360\n",
            "\tdata:0.361\n",
            "\tdata:0.362\n",
            "\tdata:0.363\n",
            "\tdata:0.364\n",
            "\tdata:0.365\n",
            "\tdata:0.366\n",
            "\tdata:0.367\n",
            "\tdata:0.368\n",
            "\tdata:0.369\n",
            "\tdata:0.37\n",
            "\tdata:0.370\n",
            "\tdata:0.371\n",
            "\tdata:0.372\n",
            "\tdata:0.373\n",
            "\tdata:0.374\n",
            "\tdata:0.375\n",
            "\tdata:0.376\n",
            "\tdata:0.377\n",
            "\tdata:0.378\n",
            "\tdata:0.379\n",
            "\tdata:0.38\n",
            "\tdata:0.380\n",
            "\tdata:0.381\n",
            "\tdata:0.382\n",
            "\tdata:0.383\n",
            "\tdata:0.384\n",
            "\tdata:0.385\n",
            "\tdata:0.386\n",
            "\tdata:0.387\n",
            "\tdata:0.388\n",
            "\tdata:0.389\n",
            "\tdata:0.39\n",
            "\tdata:0.390\n",
            "\tdata:0.391\n",
            "\tdata:0.392\n",
            "\tdata:0.393\n",
            "\tdata:0.394\n",
            "\tdata:0.395\n",
            "\tdata:0.396\n",
            "\tdata:0.397\n",
            "\tdata:0.398\n",
            "\tdata:0.399\n",
            "\tdata:0.4\n",
            "\tdata:0.40\n",
            "\tdata:0.400\n",
            "\tdata:0.401\n",
            "\tdata:0.402\n",
            "\tdata:0.403\n",
            "\tdata:0.404\n",
            "\tdata:0.405\n",
            "\tdata:0.406\n",
            "\tdata:0.407\n",
            "\tdata:0.408\n",
            "\tdata:0.409\n",
            "\tdata:0.41\n",
            "\tdata:0.410\n",
            "\tdata:0.411\n",
            "\tdata:0.412\n",
            "\tdata:0.413\n",
            "\tdata:0.414\n",
            "\tdata:0.415\n",
            "\tdata:0.416\n",
            "\tdata:0.417\n",
            "\tdata:0.418\n",
            "\tdata:0.419\n",
            "\tdata:0.42\n",
            "\tdata:0.420\n",
            "\tdata:0.421\n",
            "\tdata:0.422\n",
            "\tdata:0.423\n",
            "\tdata:0.424\n",
            "\tdata:0.425\n",
            "\tdata:0.426\n",
            "\tdata:0.427\n",
            "\tdata:0.428\n",
            "\tdata:0.429\n",
            "\tdata:0.43\n",
            "\tdata:0.430\n",
            "\tdata:0.431\n",
            "\tdata:0.432\n",
            "\tdata:0.433\n",
            "\tdata:0.434\n",
            "\tdata:0.435\n",
            "\tdata:0.436\n",
            "\tdata:0.437\n",
            "\tdata:0.438\n",
            "\tdata:0.439\n",
            "\tdata:0.44\n",
            "\tdata:0.440\n",
            "\tdata:0.441\n",
            "\tdata:0.442\n",
            "\tdata:0.443\n",
            "\tdata:0.444\n",
            "\tdata:0.445\n",
            "\tdata:0.446\n",
            "\tdata:0.447\n",
            "\tdata:0.448\n",
            "\tdata:0.449\n",
            "\tdata:0.45\n",
            "\tdata:0.450\n",
            "\tdata:0.451\n",
            "\tdata:0.452\n",
            "\tdata:0.453\n",
            "\tdata:0.454\n",
            "\tdata:0.455\n",
            "\tdata:0.456\n",
            "\tdata:0.457\n",
            "\tdata:0.458\n",
            "\tdata:0.459\n",
            "\tdata:0.46\n",
            "\tdata:0.460\n",
            "\tdata:0.461\n",
            "\tdata:0.462\n",
            "\tdata:0.463\n",
            "\tdata:0.464\n",
            "\tdata:0.465\n",
            "\tdata:0.466\n",
            "\tdata:0.467\n",
            "\tdata:0.468\n",
            "\tdata:0.469\n",
            "\tdata:0.47\n",
            "\tdata:0.470\n",
            "\tdata:0.471\n",
            "\tdata:0.472\n",
            "\tdata:0.473\n",
            "\tdata:0.474\n",
            "\tdata:0.475\n",
            "\tdata:0.476\n",
            "\tdata:0.477\n",
            "\tdata:0.478\n",
            "\tdata:0.479\n",
            "\tdata:0.48\n",
            "\tdata:0.480\n",
            "\tdata:0.481\n",
            "\tdata:0.482\n",
            "\tdata:0.483\n",
            "\tdata:0.484\n",
            "\tdata:0.485\n",
            "\tdata:0.486\n",
            "\tdata:0.487\n",
            "\tdata:0.488\n",
            "\tdata:0.489\n",
            "\tdata:0.49\n",
            "\tdata:0.490\n",
            "\tdata:0.491\n",
            "\tdata:0.492\n",
            "\tdata:0.493\n",
            "\tdata:0.494\n",
            "\tdata:0.495\n",
            "\tdata:0.496\n",
            "\tdata:0.497\n",
            "\tdata:0.498\n",
            "\tdata:0.499\n",
            "\tdata:0.5\n",
            "\tdata:0.50\n",
            "\tdata:0.500\n",
            "\tdata:0.501\n",
            "\tdata:0.502\n",
            "\tdata:0.503\n",
            "\tdata:0.504\n",
            "\tdata:0.505\n",
            "\tdata:0.506\n",
            "\tdata:0.507\n",
            "\tdata:0.508\n",
            "\tdata:0.509\n",
            "\tdata:0.51\n",
            "\tdata:0.510\n",
            "\tdata:0.511\n",
            "\tdata:0.512\n",
            "\tdata:0.513\n",
            "\tdata:0.514\n",
            "\tdata:0.515\n",
            "\tdata:0.516\n",
            "\tdata:0.517\n",
            "\tdata:0.518\n",
            "\tdata:0.519\n",
            "\tdata:0.52\n",
            "\tdata:0.520\n",
            "\tdata:0.521\n",
            "\tdata:0.522\n",
            "\tdata:0.523\n",
            "\tdata:0.524\n",
            "\tdata:0.525\n",
            "\tdata:0.526\n",
            "\tdata:0.527\n",
            "\tdata:0.528\n",
            "\tdata:0.529\n",
            "\tdata:0.53\n",
            "\tdata:0.530\n",
            "\tdata:0.531\n",
            "\tdata:0.532\n",
            "\tdata:0.533\n",
            "\tdata:0.534\n",
            "\tdata:0.535\n",
            "\tdata:0.536\n",
            "\tdata:0.537\n",
            "\tdata:0.538\n",
            "\tdata:0.539\n",
            "\tdata:0.54\n",
            "\tdata:0.540\n",
            "\tdata:0.541\n",
            "\tdata:0.542\n",
            "\tdata:0.543\n",
            "\tdata:0.544\n",
            "\tdata:0.545\n",
            "\tdata:0.546\n",
            "\tdata:0.547\n",
            "\tdata:0.548\n",
            "\tdata:0.549\n",
            "\tdata:0.55\n",
            "\tdata:0.550\n",
            "\tdata:0.551\n",
            "\tdata:0.552\n",
            "\tdata:0.553\n",
            "\tdata:0.554\n",
            "\tdata:0.555\n",
            "\tdata:0.556\n",
            "\tdata:0.557\n",
            "\tdata:0.558\n",
            "\tdata:0.559\n",
            "\tdata:0.56\n",
            "\tdata:0.560\n",
            "\tdata:0.561\n",
            "\tdata:0.562\n",
            "\tdata:0.563\n",
            "\tdata:0.564\n",
            "\tdata:0.565\n",
            "\tdata:0.566\n",
            "\tdata:0.567\n",
            "\tdata:0.568\n",
            "\tdata:0.569\n",
            "\tdata:0.57\n",
            "\tdata:0.570\n",
            "\tdata:0.571\n",
            "\tdata:0.572\n",
            "\tdata:0.573\n",
            "\tdata:0.574\n",
            "\tdata:0.575\n",
            "\tdata:0.576\n",
            "\tdata:0.577\n",
            "\tdata:0.578\n",
            "\tdata:0.579\n",
            "\tdata:0.58\n",
            "\tdata:0.580\n",
            "\tdata:0.581\n",
            "\tdata:0.582\n",
            "\tdata:0.583\n",
            "\tdata:0.584\n",
            "\tdata:0.585\n",
            "\tdata:0.586\n",
            "\tdata:0.587\n",
            "\tdata:0.588\n",
            "\tdata:0.589\n",
            "\tdata:0.59\n",
            "\tdata:0.590\n",
            "\tdata:0.591\n",
            "\tdata:0.592\n",
            "\tdata:0.593\n",
            "\tdata:0.594\n",
            "\tdata:0.595\n",
            "\tdata:0.596\n",
            "\tdata:0.597\n",
            "\tdata:0.598\n",
            "\tdata:0.599\n",
            "\tdata:0.6\n",
            "\tdata:0.60\n",
            "\tdata:0.600\n",
            "\tdata:0.601\n",
            "\tdata:0.602\n",
            "\tdata:0.603\n",
            "\tdata:0.604\n",
            "\tdata:0.605\n",
            "\tdata:0.606\n",
            "\tdata:0.607\n",
            "\tdata:0.608\n",
            "\tdata:0.609\n",
            "\tdata:0.61\n",
            "\tdata:0.610\n",
            "\tdata:0.611\n",
            "\tdata:0.612\n",
            "\tdata:0.613\n",
            "\tdata:0.614\n",
            "\tdata:0.615\n",
            "\tdata:0.616\n",
            "\tdata:0.617\n",
            "\tdata:0.618\n",
            "\tdata:0.619\n",
            "\tdata:0.62\n",
            "\tdata:0.620\n",
            "\tdata:0.621\n",
            "\tdata:0.622\n",
            "\tdata:0.623\n",
            "\tdata:0.624\n",
            "\tdata:0.625\n",
            "\tdata:0.626\n",
            "\tdata:0.627\n",
            "\tdata:0.628\n",
            "\tdata:0.629\n",
            "\tdata:0.63\n",
            "\tdata:0.630\n",
            "\tdata:0.631\n",
            "\tdata:0.632\n",
            "\tdata:0.633\n",
            "\tdata:0.634\n",
            "\tdata:0.635\n",
            "\tdata:0.636\n",
            "\tdata:0.637\n",
            "\tdata:0.638\n",
            "\tdata:0.639\n",
            "\tdata:0.64\n",
            "\tdata:0.640\n",
            "\tdata:0.641\n",
            "\tdata:0.642\n",
            "\tdata:0.643\n",
            "\tdata:0.644\n",
            "\tdata:0.645\n",
            "\tdata:0.646\n",
            "\tdata:0.647\n",
            "\tdata:0.648\n",
            "\tdata:0.649\n",
            "\tdata:0.65\n",
            "\tdata:0.650\n",
            "\tdata:0.651\n",
            "\tdata:0.652\n",
            "\tdata:0.653\n",
            "\tdata:0.654\n",
            "\tdata:0.655\n",
            "\tdata:0.656\n",
            "\tdata:0.657\n",
            "\tdata:0.658\n",
            "\tdata:0.659\n",
            "\tdata:0.66\n",
            "\tdata:0.660\n",
            "\tdata:0.661\n",
            "\tdata:0.662\n",
            "\tdata:0.663\n",
            "\tdata:0.664\n",
            "\tdata:0.665\n",
            "\tdata:0.666\n",
            "\tdata:0.667\n",
            "\tdata:0.668\n",
            "\tdata:0.669\n",
            "\tdata:0.67\n",
            "\tdata:0.670\n",
            "\tdata:0.671\n",
            "\tdata:0.672\n",
            "\tdata:0.673\n",
            "\tdata:0.674\n",
            "\tdata:0.675\n",
            "\tdata:0.676\n",
            "\tdata:0.677\n",
            "\tdata:0.678\n",
            "\tdata:0.679\n",
            "\tdata:0.68\n",
            "\tdata:0.680\n",
            "\tdata:0.681\n",
            "\tdata:0.682\n",
            "\tdata:0.683\n",
            "\tdata:0.684\n",
            "\tdata:0.685\n",
            "\tdata:0.686\n",
            "\tdata:0.687\n",
            "\tdata:0.688\n",
            "\tdata:0.689\n",
            "\tdata:0.69\n",
            "\tdata:0.690\n",
            "\tdata:0.691\n",
            "\tdata:0.692\n",
            "\tdata:0.693\n",
            "\tdata:0.694\n",
            "\tdata:0.695\n",
            "\tdata:0.696\n",
            "\tdata:0.697\n",
            "\tdata:0.698\n",
            "\tdata:0.699\n",
            "\tdata:0.7\n",
            "\tdata:0.70\n",
            "\tdata:0.700\n",
            "\tdata:0.701\n",
            "\tdata:0.702\n",
            "\tdata:0.703\n",
            "\tdata:0.704\n",
            "\tdata:0.705\n",
            "\tdata:0.706\n",
            "\tdata:0.707\n",
            "\tdata:0.708\n",
            "\tdata:0.709\n",
            "\tdata:0.71\n",
            "\tdata:0.710\n",
            "\tdata:0.711\n",
            "\tdata:0.712\n",
            "\tdata:0.713\n",
            "\tdata:0.714\n",
            "\tdata:0.715\n",
            "\tdata:0.716\n",
            "\tdata:0.717\n",
            "\tdata:0.718\n",
            "\tdata:0.719\n",
            "\tdata:0.72\n",
            "\tdata:0.720\n",
            "\tdata:0.721\n",
            "\tdata:0.722\n",
            "\tdata:0.723\n",
            "\tdata:0.724\n",
            "\tdata:0.725\n",
            "\tdata:0.726\n",
            "\tdata:0.727\n",
            "\tdata:0.728\n",
            "\tdata:0.729\n",
            "\tdata:0.73\n",
            "\tdata:0.730\n",
            "\tdata:0.731\n",
            "\tdata:0.732\n",
            "\tdata:0.733\n",
            "\tdata:0.734\n",
            "\tdata:0.735\n",
            "\tdata:0.736\n",
            "\tdata:0.737\n",
            "\tdata:0.738\n",
            "\tdata:0.739\n",
            "\tdata:0.74\n",
            "\tdata:0.740\n",
            "\tdata:0.741\n",
            "\tdata:0.742\n",
            "\tdata:0.743\n",
            "\tdata:0.744\n",
            "\tdata:0.745\n",
            "\tdata:0.746\n",
            "\tdata:0.747\n",
            "\tdata:0.748\n",
            "\tdata:0.749\n",
            "\tdata:0.75\n",
            "\tdata:0.750\n",
            "\tdata:0.751\n",
            "\tdata:0.752\n",
            "\tdata:0.753\n",
            "\tdata:0.754\n",
            "\tdata:0.755\n",
            "\tdata:0.756\n",
            "\tdata:0.757\n",
            "\tdata:0.758\n",
            "\tdata:0.759\n",
            "\tdata:0.76\n",
            "\tdata:0.760\n",
            "\tdata:0.761\n",
            "\tdata:0.762\n",
            "\tdata:0.763\n",
            "\tdata:0.764\n",
            "\tdata:0.765\n",
            "\tdata:0.766\n",
            "\tdata:0.767\n",
            "\tdata:0.768\n",
            "\tdata:0.769\n",
            "\tdata:0.77\n",
            "\tdata:0.770\n",
            "\tdata:0.771\n",
            "\tdata:0.772\n",
            "\tdata:0.773\n",
            "\tdata:0.774\n",
            "\tdata:0.775\n",
            "\tdata:0.776\n",
            "\tdata:0.777\n",
            "\tdata:0.778\n",
            "\tdata:0.779\n",
            "\tdata:0.78\n",
            "\tdata:0.780\n",
            "\tdata:0.781\n",
            "\tdata:0.782\n",
            "\tdata:0.783\n",
            "\tdata:0.79\n",
            "\tdata:0.8\n",
            "\tdata:0.80\n",
            "\tdata:0.81\n",
            "\tdata:0.82\n",
            "\tdata:0.83\n",
            "\tdata:0.84\n",
            "\tdata:0.85\n",
            "\tdata:0.86\n",
            "\tdata:0.87\n",
            "\tdata:0.88\n",
            "\tdata:0.89\n",
            "\tdata:0.9\n",
            "\tdata:0.90\n",
            "\tdata:0.91\n",
            "\tdata:0.92\n",
            "\tdata:0.93\n",
            "\tdata:0.94\n",
            "\tdata:0.95\n",
            "\tdata:0.96\n",
            "\tdata:0.97\n",
            "\tdata:0.98\n",
            "\tdata:0.99\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1. \"data:0.378\"  0.084416 ################\n",
            "    2. \"data:0.569\"  0.083522 ##############\n",
            "    3. \"data:0.461\"  0.083468 ##############\n",
            "    4. \"data:0.377\"  0.083330 #############\n",
            "    5. \"data:0.155\"  0.083038 #############\n",
            "    6. \"data:0.406\"  0.082913 #############\n",
            "    7. \"data:0.350\"  0.082708 ############\n",
            "    8. \"data:0.405\"  0.082354 ###########\n",
            "    9. \"data:0.568\"  0.082124 ###########\n",
            "   10. \"data:0.515\"  0.082043 ###########\n",
            "   11. \"data:0.542\"  0.081771 ##########\n",
            "   12. \"data:0.373\"  0.081686 ##########\n",
            "   13. \"data:0.596\"  0.081535 ##########\n",
            "   14. \"data:0.409\"  0.081527 ##########\n",
            "   15. \"data:0.345\"  0.081515 ##########\n",
            "   16. \"data:0.489\"  0.081091 #########\n",
            "   17. \"data:0.154\"  0.080943 #########\n",
            "   18. \"data:0.597\"  0.080859 ########\n",
            "   19. \"data:0.433\"  0.080831 ########\n",
            "   20. \"data:0.401\"  0.080807 ########\n",
            "   21. \"data:0.462\"  0.080617 ########\n",
            "   22. \"data:0.434\"  0.080514 ########\n",
            "   23. \"data:0.514\"  0.080491 ########\n",
            "   24. \"data:0.488\"  0.080454 ########\n",
            "   25. \"data:0.346\"  0.080453 ########\n",
            "   26. \"data:0.318\"  0.080424 ########\n",
            "   27. \"data:0.460\"  0.080306 #######\n",
            "   28. \"data:0.374\"  0.080266 #######\n",
            "   29. \"data:0.156\"  0.080262 #######\n",
            "   30. \"data:0.541\"  0.080137 #######\n",
            "   31. \"data:0.428\"  0.080058 #######\n",
            "   32. \"data:0.437\"  0.079958 #######\n",
            "   33. \"data:0.487\"  0.079878 ######\n",
            "   34. \"data:0.543\"  0.079847 ######\n",
            "   35. \"data:0.567\"  0.079832 ######\n",
            "   36. \"data:0.347\"  0.079714 ######\n",
            "   37. \"data:0.290\"  0.079659 ######\n",
            "   38. \"data:0.400\"  0.079650 ######\n",
            "   39. \"data:0.656\"  0.079610 ######\n",
            "   40. \"data:0.429\"  0.079579 ######\n",
            "   41. \"data:0.317\"  0.079551 ######\n",
            "   42. \"data:0.570\"  0.079501 ######\n",
            "   43. \"data:0.153\"  0.079440 ######\n",
            "   44. \"data:0.625\"  0.079383 #####\n",
            "   45. \"data:0.486\"  0.079314 #####\n",
            "   46. \"data:0.402\"  0.079258 #####\n",
            "   47. \"data:0.657\"  0.079112 #####\n",
            "   48. \"data:0.375\"  0.079107 #####\n",
            "   49. \"data:0.291\"  0.079102 #####\n",
            "   50. \"data:0.516\"  0.079034 #####\n",
            "   51. \"data:0.354\"  0.078923 #####\n",
            "   52. \"data:0.457\"  0.078893 ####\n",
            "   53. \"data:0.351\"  0.078881 ####\n",
            "   54. \"data:0.211\"  0.078862 ####\n",
            "   55. \"data:0.319\"  0.078855 ####\n",
            "   56. \"data:0.490\"  0.078831 ####\n",
            "   57. \"data:0.430\"  0.078815 ####\n",
            "   58. \"data:0.458\"  0.078797 ####\n",
            "   59. \"data:0.655\"  0.078778 ####\n",
            "   60. \"data:0.456\"  0.078722 ####\n",
            "   61. \"data:0.407\"  0.078700 ####\n",
            "   62. \"data:0.326\"  0.078664 ####\n",
            "   63. \"data:0.432\"  0.078653 ####\n",
            "   64. \"data:0.654\"  0.078643 ####\n",
            "   65. \"data:0.376\"  0.078640 ####\n",
            "   66. \"data:0.403\"  0.078604 ####\n",
            "   67. \"data:0.210\"  0.078574 ####\n",
            "   68. \"data:0.459\"  0.078562 ####\n",
            "   69. \"data:0.349\"  0.078552 ####\n",
            "   70. \"data:0.550\"  0.078548 ####\n",
            "   71. \"data:0.658\"  0.078525 ####\n",
            "   72. \"data:0.381\"  0.078520 ####\n",
            "   73. \"data:0.348\"  0.078466 ####\n",
            "   74. \"data:0.263\"  0.078446 ####\n",
            "   75. \"data:0.540\"  0.078434 ####\n",
            "   76. \"data:0.157\"  0.078380 ###\n",
            "   77. \"data:0.595\"  0.078380 ###\n",
            "   78. \"data:0.372\"  0.078362 ###\n",
            "   79. \"data:0.571\"  0.078359 ###\n",
            "   80. \"data:0.238\"  0.078338 ###\n",
            "   81. \"data:0.298\"  0.078323 ###\n",
            "   82. \"data:0.513\"  0.078322 ###\n",
            "   83. \"data:0.517\"  0.078311 ###\n",
            "   84. \"data:0.484\"  0.078309 ###\n",
            "   85. \"data:0.624\"  0.078282 ###\n",
            "   86. \"data:0.212\"  0.078279 ###\n",
            "   87. \"data:0.239\"  0.078256 ###\n",
            "   88. \"data:0.551\"  0.078233 ###\n",
            "   89. \"data:0.152\"  0.078217 ###\n",
            "   90. \"data:0.380\"  0.078217 ###\n",
            "   91. \"data:0.485\"  0.078207 ###\n",
            "   92. \"data:0.436\"  0.078201 ###\n",
            "   93. \"data:0.408\"  0.078189 ###\n",
            "   94. \"data:0.270\"  0.078160 ###\n",
            "   95. \"data:0.382\"  0.078135 ###\n",
            "   96. \"data:0.183\"  0.078112 ###\n",
            "   97. \"data:0.598\"  0.078109 ###\n",
            "   98. \"data:0.322\"  0.078108 ###\n",
            "   99. \"data:0.435\"  0.078095 ###\n",
            "  100. \"data:0.240\"  0.078069 ###\n",
            "  101. \"data:0.353\"  0.078067 ###\n",
            "  102. \"data:0.626\"  0.078063 ###\n",
            "  103. \"data:0.262\"  0.078039 ###\n",
            "  104. \"data:0.320\"  0.078036 ###\n",
            "  105. \"data:0.299\"  0.078031 ###\n",
            "  106. \"data:0.431\"  0.078013 ###\n",
            "  107. \"data:0.427\"  0.077993 ###\n",
            "  108. \"data:0.455\"  0.077976 ###\n",
            "  109. \"data:0.523\"  0.077967 ###\n",
            "  110. \"data:0.463\"  0.077967 ###\n",
            "  111. \"data:0.522\"  0.077964 ###\n",
            "  112. \"data:0.297\"  0.077952 ###\n",
            "  113. \"data:0.544\"  0.077946 ###\n",
            "  114. \"data:0.182\"  0.077925 ###\n",
            "  115. \"data:0.323\"  0.077921 ###\n",
            "  116. \"data:0.271\"  0.077919 ###\n",
            "  117. \"data:0.379\"  0.077914 ###\n",
            "  118. \"data:0.352\"  0.077912 ###\n",
            "  119. \"data:0.327\"  0.077891 ##\n",
            "  120. \"data:0.267\"  0.077884 ##\n",
            "  121. \"data:0.438\"  0.077838 ##\n",
            "  122. \"data:0.410\"  0.077813 ##\n",
            "  123. \"data:0.404\"  0.077803 ##\n",
            "  124. \"data:0.539\"  0.077794 ##\n",
            "  125. \"data:0.292\"  0.077769 ##\n",
            "  126. \"data:0.325\"  0.077763 ##\n",
            "  127. \"data:0.269\"  0.077762 ##\n",
            "  128. \"data:0.465\"  0.077762 ##\n",
            "  129. \"data:0.572\"  0.077761 ##\n",
            "  130. \"data:0.483\"  0.077728 ##\n",
            "  131. \"data:0.295\"  0.077720 ##\n",
            "  132. \"data:0.242\"  0.077719 ##\n",
            "  133. \"data:0.289\"  0.077709 ##\n",
            "  134. \"data:0.241\"  0.077685 ##\n",
            "  135. \"data:0.296\"  0.077657 ##\n",
            "  136. \"data:0.659\"  0.077655 ##\n",
            "  137. \"data:0.184\"  0.077639 ##\n",
            "  138. \"data:0.268\"  0.077610 ##\n",
            "  139. \"data:0.243\"  0.077597 ##\n",
            "  140. \"data:0.266\"  0.077597 ##\n",
            "  141. \"data:0.344\"  0.077553 ##\n",
            "  142. \"data:0.237\"  0.077549 ##\n",
            "  143. \"data:0.151\"  0.077542 ##\n",
            "  144. \"data:0.324\"  0.077528 ##\n",
            "  145. \"data:0.294\"  0.077521 ##\n",
            "  146. \"data:0.321\"  0.077518 ##\n",
            "  147. \"data:0.209\"  0.077515 ##\n",
            "  148. \"data:0.491\"  0.077509 ##\n",
            "  149. \"data:0.236\"  0.077490 ##\n",
            "  150. \"data:0.464\"  0.077456 ##\n",
            "  151. \"data:0.518\"  0.077424 ##\n",
            "  152. \"data:0.181\"  0.077413 ##\n",
            "  153. \"data:0.179\"  0.077377 #\n",
            "  154. \"data:0.653\"  0.077365 #\n",
            "  155. \"data:0.185\"  0.077335 #\n",
            "  156. \"data:0.272\"  0.077327 #\n",
            "  157. \"data:0.178\"  0.077325 #\n",
            "  158. \"data:0.623\"  0.077320 #\n",
            "  159. \"data:0.235\"  0.077319 #\n",
            "  160. \"data:0.578\"  0.077312 #\n",
            "  161. \"data:0.512\"  0.077298 #\n",
            "  162. \"data:0.158\"  0.077294 #\n",
            "  163. \"data:0.627\"  0.077292 #\n",
            "  164. \"data:0.265\"  0.077288 #\n",
            "  165. \"data:0.511\"  0.077285 #\n",
            "  166. \"data:0.206\"  0.077283 #\n",
            "  167. \"data:0.213\"  0.077276 #\n",
            "  168. \"data:0.264\"  0.077272 #\n",
            "  169. \"data:0.399\"  0.077271 #\n",
            "  170. \"data:0.524\"  0.077252 #\n",
            "  171. \"data:0.293\"  0.077245 #\n",
            "  172. \"data:0.316\"  0.077237 #\n",
            "  173. \"data:0.467\"  0.077223 #\n",
            "  174. \"data:0.300\"  0.077223 #\n",
            "  175. \"data:0.496\"  0.077220 #\n",
            "  176. \"data:0.355\"  0.077208 #\n",
            "  177. \"data:0.549\"  0.077206 #\n",
            "  178. \"data:0.495\"  0.077204 #\n",
            "  179. \"data:0.126\"  0.077203 #\n",
            "  180. \"data:0.545\"  0.077201 #\n",
            "  181. \"data:0.180\"  0.077199 #\n",
            "  182. \"data:0.599\"  0.077191 #\n",
            "  183. \"data:0.329\"  0.077189 #\n",
            "  184. \"data:0.207\"  0.077173 #\n",
            "  185. \"data:0.208\"  0.077171 #\n",
            "  186. \"data:0.234\"  0.077169 #\n",
            "  187. \"data:0.244\"  0.077157 #\n",
            "  188. \"data:0.573\"  0.077156 #\n",
            "  189. \"data:0.466\"  0.077155 #\n",
            "  190. \"data:0.127\"  0.077151 #\n",
            "  191. \"data:0.261\"  0.077149 #\n",
            "  192. \"data:0.328\"  0.077137 #\n",
            "  193. \"data:0.594\"  0.077129 #\n",
            "  194. \"data:0.494\"  0.077126 #\n",
            "  195. \"data:0.100\"  0.077108 #\n",
            "  196. \"data:0.214\"  0.077099 #\n",
            "  197. \"data:0.652\"  0.077089 #\n",
            "  198. \"data:0.358\"  0.077084 #\n",
            "  199. \"data:0.125\"  0.077079 #\n",
            "  200. \"data:0.577\"  0.077060 #\n",
            "  201. \"data:0.301\"  0.077057 #\n",
            "  202. \"data:0.343\"  0.077048 #\n",
            "  203. \"data:0.371\"  0.077047 #\n",
            "  204. \"data:0.205\"  0.077031 #\n",
            "  205. \"data:0.150\"  0.077031 #\n",
            "  206. \"data:0.521\"  0.077024 #\n",
            "  207. \"data:0.630\"  0.077024 #\n",
            "  208. \"data:0.684\"  0.077016 #\n",
            "  209. \"data:0.215\"  0.077012 #\n",
            "  210. \"data:0.546\"  0.077002 #\n",
            "  211. \"data:0.439\"  0.076997 #\n",
            "  212. \"data:0.579\"  0.076993 #\n",
            "  213. \"data:0.538\"  0.076988 #\n",
            "  214. \"data:0.552\"  0.076983 #\n",
            "  215. \"data:0.385\"  0.076981 #\n",
            "  216. \"data:0.493\"  0.076968 #\n",
            "  217. \"data:0.566\"  0.076968 #\n",
            "  218. \"data:0.600\"  0.076955 #\n",
            "  219. \"data:0.357\"  0.076954 #\n",
            "  220. \"data:0.468\"  0.076946 #\n",
            "  221. \"data:0.685\"  0.076945 #\n",
            "  222. \"data:0.660\"  0.076940 #\n",
            "  223. \"data:0.628\"  0.076938 #\n",
            "  224. \"data:0.128\"  0.076930 #\n",
            "  225. \"data:0.492\"  0.076928 #\n",
            "  226. \"data:0.177\"  0.076925 #\n",
            "  227. \"data:0.273\"  0.076923 #\n",
            "  228. \"data:0.519\"  0.076917 #\n",
            "  229.  \"data:0.99\"  0.076907 #\n",
            "  230. \"data:0.245\"  0.076902 #\n",
            "  231. \"data:0.315\"  0.076901 #\n",
            "  232. \"data:0.101\"  0.076897 \n",
            "  233. \"data:0.683\"  0.076894 \n",
            "  234. \"data:0.574\"  0.076893 \n",
            "  235. \"data:0.233\"  0.076889 \n",
            "  236. \"data:0.441\"  0.076885 \n",
            "  237. \"data:0.216\"  0.076884 \n",
            "  238. \"data:0.383\"  0.076879 \n",
            "  239. \"data:0.260\"  0.076876 \n",
            "  240. \"data:0.218\"  0.076874 \n",
            "  241. \"data:0.580\"  0.076869 \n",
            "  242. \"data:0.330\"  0.076865 \n",
            "  243. \"data:0.288\"  0.076864 \n",
            "  244. \"data:0.631\"  0.076862 \n",
            "  245. \"data:0.601\"  0.076850 \n",
            "  246. \"data:0.217\"  0.076829 \n",
            "  247. \"data:0.186\"  0.076827 \n",
            "  248. \"data:0.356\"  0.076826 \n",
            "  249. \"data:0.606\"  0.076823 \n",
            "  250. \"data:0.440\"  0.076823 \n",
            "  251. \"data:0.575\"  0.076819 \n",
            "  252. \"data:0.124\"  0.076813 \n",
            "  253. \"data:0.686\"  0.076813 \n",
            "  254. \"data:0.651\"  0.076812 \n",
            "  255. \"data:0.576\"  0.076809 \n",
            "  256. \"data:0.629\"  0.076802 \n",
            "  257. \"data:0.454\"  0.076800 \n",
            "  258. \"data:0.386\"  0.076796 \n",
            "  259. \"data:0.482\"  0.076790 \n",
            "  260. \"data:0.632\"  0.076784 \n",
            "  261. \"data:0.426\"  0.076781 \n",
            "  262. \"data:0.510\"  0.076773 \n",
            "  263. \"data:0.682\"  0.076769 \n",
            "  264. \"data:0.187\"  0.076768 \n",
            "  265. \"data:0.219\"  0.076764 \n",
            "  266. \"data:0.602\"  0.076760 \n",
            "  267. \"data:0.411\"  0.076755 \n",
            "  268. \"data:0.413\"  0.076748 \n",
            "  269. \"data:0.370\"  0.076744 \n",
            "  270. \"data:0.129\"  0.076740 \n",
            "  271. \"data:0.603\"  0.076739 \n",
            "  272. \"data:0.188\"  0.076735 \n",
            "  273. \"data:0.398\"  0.076730 \n",
            "  274. \"data:0.547\"  0.076727 \n",
            "  275. \"data:0.661\"  0.076726 \n",
            "  276. \"data:0.159\"  0.076722 \n",
            "  277. \"data:0.605\"  0.076722 \n",
            "  278. \"data:0.246\"  0.076718 \n",
            "  279. \"data:0.414\"  0.076718 \n",
            "  280. \"data:0.520\"  0.076715 \n",
            "  281. \"data:0.548\"  0.076713 \n",
            "  282. \"data:0.681\"  0.076708 \n",
            "  283. \"data:0.604\"  0.076707 \n",
            "  284. \"data:0.711\"  0.076700 \n",
            "  285. \"data:0.149\"  0.076694 \n",
            "  286. \"data:0.247\"  0.076688 \n",
            "  287. \"data:0.102\"  0.076684 \n",
            "  288. \"data:0.274\"  0.076679 \n",
            "  289. \"data:0.232\"  0.076676 \n",
            "  290. \"data:0.442\"  0.076676 \n",
            "  291. \"data:0.607\"  0.076667 \n",
            "  292. \"data:0.581\"  0.076666 \n",
            "  293. \"data:0.384\"  0.076665 \n",
            "  294. \"data:0.189\"  0.076662 \n",
            "  295. \"data:0.190\"  0.076660 \n",
            "  296. \"data:0.712\"  0.076656 \n",
            "  297.  \"data:0.97\"  0.076655 \n",
            "  298. \"data:0.553\"  0.076655 \n",
            "  299. \"data:0.412\"  0.076646 \n",
            "  300.  \"data:0.98\"  0.076640 \n",
            "  301. \"data:0.525\"  0.076639 \n",
            "  302. \"data:0.342\"  0.076637 \n",
            "  303. \"data:0.123\"  0.076634 \n",
            "  304. \"data:0.248\"  0.076630 \n",
            "  305. \"data:0.633\"  0.076630 \n",
            "  306. \"data:0.497\"  0.076629 \n",
            "  307. \"data:0.302\"  0.076628 \n",
            "  308. \"data:0.469\"  0.076624 \n",
            "  309. \"data:0.176\"  0.076624 \n",
            "  310. \"data:0.608\"  0.076615 \n",
            "  311. \"data:0.680\"  0.076615 \n",
            "  312. \"data:0.204\"  0.076609 \n",
            "  313. \"data:0.359\"  0.076607 \n",
            "  314. \"data:0.622\"  0.076605 \n",
            "  315. \"data:0.713\"  0.076598 \n",
            "  316. \"data:0.634\"  0.076589 \n",
            "  317. \"data:0.710\"  0.076586 \n",
            "  318. \"data:0.275\"  0.076584 \n",
            "  319. \"data:0.415\"  0.076581 \n",
            "  320. \"data:0.287\"  0.076578 \n",
            "  321. \"data:0.708\"  0.076576 \n",
            "  322. \"data:0.387\"  0.076570 \n",
            "  323. \"data:0.191\"  0.076569 \n",
            "  324. \"data:0.470\"  0.076568 \n",
            "  325. \"data:0.160\"  0.076567 \n",
            "  326. \"data:0.526\"  0.076566 \n",
            "  327. \"data:0.709\"  0.076563 \n",
            "  328. \"data:0.130\"  0.076560 \n",
            "  329. \"data:0.687\"  0.076558 \n",
            "  330. \"data:0.161\"  0.076552 \n",
            "  331. \"data:0.662\"  0.076544 \n",
            "  332. \"data:0.220\"  0.076539 \n",
            "  333. \"data:0.609\"  0.076539 \n",
            "  334. \"data:0.103\"  0.076536 \n",
            "  335. \"data:0.314\"  0.076535 \n",
            "  336. \"data:0.425\"  0.076535 \n",
            "  337. \"data:0.565\"  0.076528 \n",
            "  338. \"data:0.554\"  0.076527 \n",
            "  339. \"data:0.537\"  0.076524 \n",
            "  340. \"data:0.122\"  0.076524 \n",
            "  341. \"data:0.635\"  0.076518 \n",
            "  342. \"data:0.453\"  0.076518 \n",
            "  343.  \"data:0.96\"  0.076513 \n",
            "  344. \"data:0.498\"  0.076513 \n",
            "  345. \"data:0.231\"  0.076513 \n",
            "  346. \"data:0.131\"  0.076513 \n",
            "  347. \"data:0.714\"  0.076512 \n",
            "  348. \"data:0.397\"  0.076512 \n",
            "  349. \"data:0.259\"  0.076512 \n",
            "  350. \"data:0.582\"  0.076509 \n",
            "  351. \"data:0.331\"  0.076507 \n",
            "  352. \"data:0.481\"  0.076506 \n",
            "  353. \"data:0.276\"  0.076503 \n",
            "  354. \"data:0.509\"  0.076503 \n",
            "  355. \"data:0.203\"  0.076500 \n",
            "  356. \"data:0.369\"  0.076490 \n",
            "  357. \"data:0.679\"  0.076489 \n",
            "  358. \"data:0.303\"  0.076489 \n",
            "  359. \"data:0.443\"  0.076480 \n",
            "  360. \"data:0.688\"  0.076480 \n",
            "  361. \"data:0.286\"  0.076478 \n",
            "  362. \"data:0.716\"  0.076475 \n",
            "  363. \"data:0.593\"  0.076475 \n",
            "  364. \"data:0.162\"  0.076474 \n",
            "  365. \"data:0.341\"  0.076474 \n",
            "  366. \"data:0.715\"  0.076473 \n",
            "  367. \"data:0.650\"  0.076471 \n",
            "  368. \"data:0.527\"  0.076469 \n",
            "  369. \"data:0.707\"  0.076468 \n",
            "  370. \"data:0.175\"  0.076466 \n",
            "  371. \"data:0.717\"  0.076465 \n",
            "  372. \"data:0.148\"  0.076464 \n",
            "  373. \"data:0.555\"  0.076461 \n",
            "  374. \"data:0.663\"  0.076461 \n",
            "  375. \"data:0.689\"  0.076459 \n",
            "  376. \"data:0.471\"  0.076457 \n",
            "  377. \"data:0.132\"  0.076456 \n",
            "  378.  \"data:0.95\"  0.076453 \n",
            "  379. \"data:0.258\"  0.076452 \n",
            "  380. \"data:0.499\"  0.076452 \n",
            "  381. \"data:0.718\"  0.076452 \n",
            "  382. \"data:0.192\"  0.076450 \n",
            "  383. \"data:0.636\"  0.076449 \n",
            "  384. \"data:0.121\"  0.076447 \n",
            "  385. \"data:0.230\"  0.076444 \n",
            "  386. \"data:0.690\"  0.076444 \n",
            "  387. \"data:0.104\"  0.076441 \n",
            "  388. \"data:0.313\"  0.076436 \n",
            "  389. \"data:0.528\"  0.076433 \n",
            "  390. \"data:0.610\"  0.076432 \n",
            "  391. \"data:0.163\"  0.076431 \n",
            "  392. \"data:0.202\"  0.076429 \n",
            "  393. \"data:0.583\"  0.076428 \n",
            "  394.  \"data:0.94\"  0.076427 \n",
            "  395. \"data:0.678\"  0.076426 \n",
            "  396.  \"data:0.70\"  0.076426 \n",
            "  397. \"data:0.304\"  0.076426 \n",
            "  398. \"data:0.637\"  0.076426 \n",
            "  399. \"data:0.664\"  0.076424 \n",
            "  400. \"data:0.147\"  0.076424 \n",
            "  401.  \"data:0.68\"  0.076423 \n",
            "  402. \"data:0.691\"  0.076423 \n",
            "  403. \"data:0.285\"  0.076421 \n",
            "  404. \"data:0.740\"  0.076421 \n",
            "  405. \"data:0.621\"  0.076421 \n",
            "  406. \"data:0.174\"  0.076420 \n",
            "  407. \"data:0.742\"  0.076420 \n",
            "  408. \"data:0.133\"  0.076420 \n",
            "  409. \"data:0.741\"  0.076420 \n",
            "  410. \"data:0.564\"  0.076420 \n",
            "  411. \"data:0.719\"  0.076420 \n",
            "  412. \"data:0.739\"  0.076419 \n",
            "  413. \"data:0.444\"  0.076418 \n",
            "  414.  \"data:0.69\"  0.076417 \n",
            "  415. \"data:0.472\"  0.076417 \n",
            "  416. \"data:0.500\"  0.076417 \n",
            "  417. \"data:0.592\"  0.076415 \n",
            "  418.  \"data:0.71\"  0.076415 \n",
            "  419. \"data:0.706\"  0.076415 \n",
            "  420.  \"data:0.67\"  0.076414 \n",
            "  421. \"data:0.536\"  0.076414 \n",
            "  422. \"data:0.257\"  0.076414 \n",
            "  423. \"data:0.508\"  0.076413 \n",
            "  424. \"data:0.229\"  0.076413 \n",
            "  425. \"data:0.105\"  0.076413 \n",
            "  426. \"data:0.556\"  0.076412 \n",
            "  427. \"data:0.388\"  0.076410 \n",
            "  428. \"data:0.452\"  0.076410 \n",
            "  429. \"data:0.744\"  0.076410 \n",
            "  430. \"data:0.201\"  0.076409 \n",
            "  431.  \"data:0.73\"  0.076409 \n",
            "  432. \"data:0.277\"  0.076408 \n",
            "  433.  \"data:0.93\"  0.076408 \n",
            "  434. \"data:0.120\"  0.076408 \n",
            "  435. \"data:0.692\"  0.076408 \n",
            "  436. \"data:0.416\"  0.076408 \n",
            "  437. \"data:0.360\"  0.076408 \n",
            "  438. \"data:0.480\"  0.076408 \n",
            "  439. \"data:0.134\"  0.076408 \n",
            "  440. \"data:0.611\"  0.076407 \n",
            "  441. \"data:0.146\"  0.076407 \n",
            "  442. \"data:0.743\"  0.076406 \n",
            "  443. \"data:0.396\"  0.076406 \n",
            "  444. \"data:0.424\"  0.076406 \n",
            "  445. \"data:0.665\"  0.076406 \n",
            "  446. \"data:0.720\"  0.076406 \n",
            "  447. \"data:0.649\"  0.076406 \n",
            "  448. \"data:0.340\"  0.076406 \n",
            "  449. \"data:0.638\"  0.076406 \n",
            "  450. \"data:0.249\"  0.076405 \n",
            "  451. \"data:0.745\"  0.076405 \n",
            "  452. \"data:0.677\"  0.076404 \n",
            "  453. \"data:0.221\"  0.076404 \n",
            "  454. \"data:0.332\"  0.076403 \n",
            "  455. \"data:0.368\"  0.076403 \n",
            "  456. \"data:0.737\"  0.076403 \n",
            "  457. \"data:0.312\"  0.076403 \n",
            "  458. \"data:0.584\"  0.076403 \n",
            "  459. \"data:0.284\"  0.076403 \n",
            "  460. \"data:0.705\"  0.076402 \n",
            "  461. \"data:0.173\"  0.076402 \n",
            "  462. \"data:0.135\"  0.076402 \n",
            "  463. \"data:0.738\"  0.076402 \n",
            "  464. \"data:0.746\"  0.076402 \n",
            "  465. \"data:0.473\"  0.076402 \n",
            "  466. \"data:0.620\"  0.076402 \n",
            "  467.  \"data:0.66\"  0.076402 \n",
            "  468. \"data:0.164\"  0.076402 \n",
            "  469.  \"data:0.92\"  0.076401 \n",
            "  470. \"data:0.119\"  0.076401 \n",
            "  471. \"data:0.228\"  0.076401 \n",
            "  472. \"data:0.256\"  0.076401 \n",
            "  473. \"data:0.501\"  0.076400 \n",
            "  474. \"data:0.563\"  0.076400 \n",
            "  475. \"data:0.676\"  0.076400 \n",
            "  476. \"data:0.693\"  0.076400 \n",
            "  477. \"data:0.200\"  0.076400 \n",
            "  478. \"data:0.529\"  0.076400 \n",
            "  479.  \"data:0.72\"  0.076400 \n",
            "  480. \"data:0.747\"  0.076400 \n",
            "  481. \"data:0.535\"  0.076400 \n",
            "  482. \"data:0.507\"  0.076400 \n",
            "  483. \"data:0.106\"  0.076399 \n",
            "  484. \"data:0.193\"  0.076399 \n",
            "  485. \"data:0.639\"  0.076399 \n",
            "  486. \"data:0.612\"  0.076399 \n",
            "  487. \"data:0.648\"  0.076399 \n",
            "  488. \"data:0.305\"  0.076399 \n",
            "  489.  \"data:0.74\"  0.076399 \n",
            "  490. \"data:0.445\"  0.076399 \n",
            "  491. \"data:0.666\"  0.076399 \n",
            "  492.  \"data:0.63\"  0.076399 \n",
            "  493. \"data:0.311\"  0.076399 \n",
            "  494.  \"data:0.91\"  0.076399 \n",
            "  495. \"data:0.417\"  0.076399 \n",
            "  496. \"data:0.694\"  0.076398 \n",
            "  497. \"data:0.736\"  0.076398 \n",
            "  498. \"data:0.721\"  0.076398 \n",
            "  499.  \"data:0.75\"  0.076398 \n",
            "  500. \"data:0.145\"  0.076398 \n",
            "  501. \"data:0.479\"  0.076398 \n",
            "  502. \"data:0.136\"  0.076398 \n",
            "  503. \"data:0.107\"  0.076398 \n",
            "  504. \"data:0.283\"  0.076398 \n",
            "  505. \"data:0.474\"  0.076398 \n",
            "  506. \"data:0.361\"  0.076398 \n",
            "  507. \"data:0.748\"  0.076398 \n",
            "  508. \"data:0.118\"  0.076398 \n",
            "  509.  \"data:0.65\"  0.076398 \n",
            "  510.  \"data:0.64\"  0.076398 \n",
            "  511. \"data:0.172\"  0.076398 \n",
            "  512.  \"data:0.76\"  0.076398 \n",
            "  513. \"data:0.165\"  0.076398 \n",
            "  514. \"data:0.222\"  0.076398 \n",
            "  515. \"data:0.451\"  0.076398 \n",
            "  516. \"data:0.557\"  0.076398 \n",
            "  517. \"data:0.339\"  0.076398 \n",
            "  518. \"data:0.733\"  0.076398 \n",
            "  519. \"data:0.619\"  0.076398 \n",
            "  520. \"data:0.367\"  0.076398 \n",
            "  521. \"data:0.278\"  0.076398 \n",
            "  522. \"data:0.591\"  0.076398 \n",
            "  523. \"data:0.704\"  0.076398 \n",
            "  524. \"data:0.333\"  0.076398 \n",
            "  525. \"data:0.534\"  0.076398 \n",
            "  526. \"data:0.423\"  0.076398 \n",
            "  527. \"data:0.734\"  0.076398 \n",
            "  528. \"data:0.640\"  0.076398 \n",
            "  529. \"data:0.722\"  0.076398 \n",
            "  530. \"data:0.199\"  0.076398 \n",
            "  531. \"data:0.306\"  0.076398 \n",
            "  532. \"data:0.667\"  0.076398 \n",
            "  533. \"data:0.418\"  0.076398 \n",
            "  534. \"data:0.530\"  0.076398 \n",
            "  535. \"data:0.108\"  0.076397 \n",
            "  536. \"data:0.389\"  0.076397 \n",
            "  537. \"data:0.647\"  0.076397 \n",
            "  538. \"data:0.668\"  0.076397 \n",
            "  539. \"data:0.227\"  0.076397 \n",
            "  540.  \"data:0.78\"  0.076397 \n",
            "  541. \"data:0.735\"  0.076397 \n",
            "  542. \"data:0.732\"  0.076397 \n",
            "  543. \"data:0.338\"  0.076397 \n",
            "  544. \"data:0.675\"  0.076397 \n",
            "  545. \"data:0.446\"  0.076397 \n",
            "  546. \"data:0.695\"  0.076397 \n",
            "  547. \"data:0.723\"  0.076397 \n",
            "  548. \"data:0.703\"  0.076397 \n",
            "  549. \"data:0.137\"  0.076397 \n",
            "  550. \"data:0.613\"  0.076397 \n",
            "  551. \"data:0.255\"  0.076397 \n",
            "  552. \"data:0.395\"  0.076397 \n",
            "  553. \"data:0.585\"  0.076397 \n",
            "  554.  \"data:0.90\"  0.076397 \n",
            "  555. \"data:0.562\"  0.076397 \n",
            "  556. \"data:0.749\"  0.076397 \n",
            "  557. \"data:0.117\"  0.076397 \n",
            "  558. \"data:0.478\"  0.076397 \n",
            "  559. \"data:0.590\"  0.076397 \n",
            "  560. \"data:0.310\"  0.076397 \n",
            "  561. \"data:0.254\"  0.076397 \n",
            "  562. \"data:0.696\"  0.076397 \n",
            "  563. \"data:0.143\"  0.076397 \n",
            "  564. \"data:0.614\"  0.076397 \n",
            "  565. \"data:0.362\"  0.076397 \n",
            "  566. \"data:0.775\"  0.076397 \n",
            "  567. \"data:0.194\"  0.076397 \n",
            "  568.  \"data:0.77\"  0.076397 \n",
            "  569. \"data:0.773\"  0.076397 \n",
            "  570. \"data:0.250\"  0.076397 \n",
            "  571. \"data:0.506\"  0.076397 \n",
            "  572. \"data:0.282\"  0.076397 \n",
            "  573. \"data:0.772\"  0.076397 \n",
            "  574. \"data:0.390\"  0.076397 \n",
            "  575. \"data:0.771\"  0.076397 \n",
            "  576. \"data:0.768\"  0.076397 \n",
            "  577. \"data:0.144\"  0.076397 \n",
            "  578. \"data:0.171\"  0.076397 \n",
            "  579.  \"data:0.42\"  0.076397 \n",
            "  580. \"data:0.770\"  0.076397 \n",
            "  581.  \"data:0.48\"  0.076397 \n",
            "  582. \"data:0.558\"  0.076397 \n",
            "  583.  \"data:0.89\"  0.076397 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"data:0.569\" 25.000000 ################\n",
            "    2. \"data:0.378\" 24.000000 ###############\n",
            "    3. \"data:0.461\" 19.000000 ############\n",
            "    4. \"data:0.350\" 18.000000 ###########\n",
            "    5. \"data:0.373\" 18.000000 ###########\n",
            "    6. \"data:0.377\" 18.000000 ###########\n",
            "    7. \"data:0.155\" 17.000000 ##########\n",
            "    8. \"data:0.406\" 17.000000 ##########\n",
            "    9. \"data:0.568\" 17.000000 ##########\n",
            "   10. \"data:0.596\" 17.000000 ##########\n",
            "   11. \"data:0.345\" 15.000000 #########\n",
            "   12. \"data:0.405\" 14.000000 ########\n",
            "   13. \"data:0.409\" 13.000000 ########\n",
            "   14. \"data:0.433\" 13.000000 ########\n",
            "   15. \"data:0.489\" 13.000000 ########\n",
            "   16. \"data:0.597\" 13.000000 ########\n",
            "   17. \"data:0.428\" 12.000000 #######\n",
            "   18. \"data:0.462\" 12.000000 #######\n",
            "   19. \"data:0.400\" 10.000000 ######\n",
            "   20. \"data:0.346\"  9.000000 #####\n",
            "   21. \"data:0.401\"  9.000000 #####\n",
            "   22. \"data:0.567\"  9.000000 #####\n",
            "   23. \"data:0.154\"  8.000000 ####\n",
            "   24. \"data:0.434\"  8.000000 ####\n",
            "   25. \"data:0.460\"  8.000000 ####\n",
            "   26. \"data:0.515\"  8.000000 ####\n",
            "   27. \"data:0.541\"  8.000000 ####\n",
            "   28. \"data:0.290\"  7.000000 ####\n",
            "   29. \"data:0.156\"  6.000000 ###\n",
            "   30. \"data:0.318\"  6.000000 ###\n",
            "   31. \"data:0.488\"  6.000000 ###\n",
            "   32. \"data:0.542\"  6.000000 ###\n",
            "   33. \"data:0.317\"  5.000000 ##\n",
            "   34. \"data:0.374\"  5.000000 ##\n",
            "   35. \"data:0.625\"  5.000000 ##\n",
            "   36. \"data:0.372\"  4.000000 ##\n",
            "   37. \"data:0.437\"  4.000000 ##\n",
            "   38. \"data:0.523\"  4.000000 ##\n",
            "   39. \"data:0.157\"  3.000000 #\n",
            "   40. \"data:0.351\"  3.000000 #\n",
            "   41. \"data:0.429\"  3.000000 #\n",
            "   42. \"data:0.484\"  3.000000 #\n",
            "   43. \"data:0.550\"  3.000000 #\n",
            "   44. \"data:0.595\"  3.000000 #\n",
            "   45. \"data:0.153\"  2.000000 \n",
            "   46. \"data:0.262\"  2.000000 \n",
            "   47. \"data:0.407\"  2.000000 \n",
            "   48. \"data:0.427\"  2.000000 \n",
            "   49. \"data:0.436\"  2.000000 \n",
            "   50. \"data:0.456\"  2.000000 \n",
            "   51. \"data:0.457\"  2.000000 \n",
            "   52. \"data:0.487\"  2.000000 \n",
            "   53. \"data:0.514\"  2.000000 \n",
            "   54. \"data:0.516\"  2.000000 \n",
            "   55. \"data:0.540\"  2.000000 \n",
            "   56. \"data:0.551\"  2.000000 \n",
            "   57. \"data:0.263\"  1.000000 \n",
            "   58. \"data:0.291\"  1.000000 \n",
            "   59. \"data:0.319\"  1.000000 \n",
            "   60. \"data:0.327\"  1.000000 \n",
            "   61. \"data:0.344\"  1.000000 \n",
            "   62. \"data:0.349\"  1.000000 \n",
            "   63. \"data:0.402\"  1.000000 \n",
            "   64. \"data:0.403\"  1.000000 \n",
            "   65. \"data:0.432\"  1.000000 \n",
            "   66. \"data:0.455\"  1.000000 \n",
            "   67. \"data:0.458\"  1.000000 \n",
            "   68. \"data:0.459\"  1.000000 \n",
            "   69. \"data:0.463\"  1.000000 \n",
            "   70. \"data:0.483\"  1.000000 \n",
            "   71. \"data:0.490\"  1.000000 \n",
            "   72. \"data:0.495\"  1.000000 \n",
            "   73. \"data:0.496\"  1.000000 \n",
            "   74. \"data:0.511\"  1.000000 \n",
            "   75. \"data:0.513\"  1.000000 \n",
            "   76. \"data:0.517\"  1.000000 \n",
            "   77. \"data:0.524\"  1.000000 \n",
            "   78. \"data:0.539\"  1.000000 \n",
            "   79. \"data:0.543\"  1.000000 \n",
            "   80. \"data:0.594\"  1.000000 \n",
            "   81. \"data:0.598\"  1.000000 \n",
            "   82. \"data:0.624\"  1.000000 \n",
            "   83. \"data:0.626\"  1.000000 \n",
            "   84. \"data:0.655\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"data:0.267\" 6503.000000 ################\n",
            "    2. \"data:0.296\" 6467.000000 ###############\n",
            "    3. \"data:0.295\" 6439.000000 ###############\n",
            "    4. \"data:0.211\" 6407.000000 ###############\n",
            "    5. \"data:0.294\" 6337.000000 ###############\n",
            "    6. \"data:0.378\" 6210.000000 ###############\n",
            "    7. \"data:0.322\" 6198.000000 ###############\n",
            "    8. \"data:0.266\" 6153.000000 ###############\n",
            "    9. \"data:0.297\" 6121.000000 ###############\n",
            "   10. \"data:0.268\" 6114.000000 ###############\n",
            "   11. \"data:0.239\" 6110.000000 ###############\n",
            "   12. \"data:0.324\" 6076.000000 ##############\n",
            "   13. \"data:0.323\" 6048.000000 ##############\n",
            "   14. \"data:0.210\" 6044.000000 ##############\n",
            "   15. \"data:0.321\" 6043.000000 ##############\n",
            "   16. \"data:0.293\" 6035.000000 ##############\n",
            "   17. \"data:0.350\" 6031.000000 ##############\n",
            "   18. \"data:0.351\" 6017.000000 ##############\n",
            "   19. \"data:0.320\" 5996.000000 ##############\n",
            "   20. \"data:0.212\" 5943.000000 ##############\n",
            "   21. \"data:0.269\" 5926.000000 ##############\n",
            "   22. \"data:0.347\" 5859.000000 ##############\n",
            "   23. \"data:0.352\" 5857.000000 ##############\n",
            "   24. \"data:0.292\" 5820.000000 ##############\n",
            "   25. \"data:0.325\" 5803.000000 ##############\n",
            "   26. \"data:0.487\" 5787.000000 ##############\n",
            "   27. \"data:0.319\" 5786.000000 ##############\n",
            "   28. \"data:0.238\" 5744.000000 ##############\n",
            "   29. \"data:0.348\" 5735.000000 ##############\n",
            "   30. \"data:0.515\" 5699.000000 ##############\n",
            "   31. \"data:0.377\" 5697.000000 ##############\n",
            "   32. \"data:0.240\" 5684.000000 #############\n",
            "   33. \"data:0.405\" 5572.000000 #############\n",
            "   34. \"data:0.375\" 5566.000000 #############\n",
            "   35. \"data:0.349\" 5554.000000 #############\n",
            "   36. \"data:0.353\" 5514.000000 #############\n",
            "   37. \"data:0.406\" 5503.000000 #############\n",
            "   38. \"data:0.488\" 5500.000000 #############\n",
            "   39. \"data:0.265\" 5473.000000 #############\n",
            "   40. \"data:0.376\" 5472.000000 #############\n",
            "   41. \"data:0.291\" 5460.000000 #############\n",
            "   42. \"data:0.486\" 5460.000000 #############\n",
            "   43. \"data:0.543\" 5457.000000 #############\n",
            "   44. \"data:0.516\" 5453.000000 #############\n",
            "   45. \"data:0.379\" 5423.000000 #############\n",
            "   46. \"data:0.380\" 5415.000000 #############\n",
            "   47. \"data:0.514\" 5371.000000 #############\n",
            "   48. \"data:0.209\" 5280.000000 ############\n",
            "   49. \"data:0.241\" 5264.000000 ############\n",
            "   50. \"data:0.237\" 5247.000000 ############\n",
            "   51. \"data:0.213\" 5243.000000 ############\n",
            "   52. \"data:0.544\" 5238.000000 ############\n",
            "   53. \"data:0.490\" 5232.000000 ############\n",
            "   54. \"data:0.326\" 5231.000000 ############\n",
            "   55. \"data:0.433\" 5220.000000 ############\n",
            "   56. \"data:0.264\" 5212.000000 ############\n",
            "   57. \"data:0.381\" 5205.000000 ############\n",
            "   58. \"data:0.461\" 5174.000000 ############\n",
            "   59. \"data:0.459\" 5162.000000 ############\n",
            "   60. \"data:0.318\" 5143.000000 ############\n",
            "   61. \"data:0.298\" 5141.000000 ############\n",
            "   62. \"data:0.346\" 5125.000000 ############\n",
            "   63. \"data:0.183\" 5071.000000 ############\n",
            "   64. \"data:0.374\" 5063.000000 ############\n",
            "   65. \"data:0.404\" 5058.000000 ############\n",
            "   66. \"data:0.270\" 5047.000000 ############\n",
            "   67. \"data:0.458\" 5009.000000 ############\n",
            "   68. \"data:0.354\" 5006.000000 ############\n",
            "   69. \"data:0.407\" 5005.000000 ############\n",
            "   70. \"data:0.460\" 5002.000000 ############\n",
            "   71. \"data:0.517\" 4998.000000 ############\n",
            "   72. \"data:0.437\" 4992.000000 ############\n",
            "   73. \"data:0.434\" 4991.000000 ############\n",
            "   74. \"data:0.409\" 4988.000000 ############\n",
            "   75. \"data:0.489\" 4980.000000 ############\n",
            "   76. \"data:0.462\" 4954.000000 ############\n",
            "   77. \"data:0.572\" 4904.000000 ############\n",
            "   78. \"data:0.464\" 4896.000000 ############\n",
            "   79. \"data:0.408\" 4867.000000 ###########\n",
            "   80. \"data:0.436\" 4863.000000 ###########\n",
            "   81. \"data:0.403\" 4848.000000 ###########\n",
            "   82. \"data:0.457\" 4837.000000 ###########\n",
            "   83. \"data:0.485\" 4812.000000 ###########\n",
            "   84. \"data:0.518\" 4810.000000 ###########\n",
            "   85. \"data:0.491\" 4807.000000 ###########\n",
            "   86. \"data:0.236\" 4802.000000 ###########\n",
            "   87. \"data:0.432\" 4801.000000 ###########\n",
            "   88. \"data:0.542\" 4789.000000 ###########\n",
            "   89. \"data:0.290\" 4788.000000 ###########\n",
            "   90. \"data:0.184\" 4786.000000 ###########\n",
            "   91. \"data:0.430\" 4775.000000 ###########\n",
            "   92. \"data:0.463\" 4740.000000 ###########\n",
            "   93. \"data:0.571\" 4722.000000 ###########\n",
            "   94. \"data:0.182\" 4707.000000 ###########\n",
            "   95. \"data:0.263\" 4701.000000 ###########\n",
            "   96. \"data:0.402\" 4657.000000 ###########\n",
            "   97. \"data:0.545\" 4640.000000 ###########\n",
            "   98. \"data:0.431\" 4634.000000 ###########\n",
            "   99. \"data:0.573\" 4616.000000 ###########\n",
            "  100. \"data:0.656\" 4581.000000 ###########\n",
            "  101. \"data:0.242\" 4546.000000 ###########\n",
            "  102. \"data:0.214\" 4539.000000 ###########\n",
            "  103. \"data:0.429\" 4535.000000 ###########\n",
            "  104. \"data:0.208\" 4499.000000 ###########\n",
            "  105. \"data:0.435\" 4490.000000 ###########\n",
            "  106. \"data:0.345\" 4450.000000 ##########\n",
            "  107. \"data:0.657\" 4442.000000 ##########\n",
            "  108. \"data:0.299\" 4416.000000 ##########\n",
            "  109. \"data:0.185\" 4389.000000 ##########\n",
            "  110. \"data:0.465\" 4329.000000 ##########\n",
            "  111. \"data:0.546\" 4325.000000 ##########\n",
            "  112. \"data:0.317\" 4321.000000 ##########\n",
            "  113. \"data:0.181\" 4318.000000 ##########\n",
            "  114. \"data:0.382\" 4297.000000 ##########\n",
            "  115. \"data:0.574\" 4294.000000 ##########\n",
            "  116. \"data:0.401\" 4273.000000 ##########\n",
            "  117. \"data:0.155\" 4253.000000 ##########\n",
            "  118. \"data:0.235\" 4243.000000 ##########\n",
            "  119. \"data:0.492\" 4239.000000 ##########\n",
            "  120. \"data:0.271\" 4232.000000 ##########\n",
            "  121. \"data:0.373\" 4221.000000 ##########\n",
            "  122. \"data:0.513\" 4219.000000 ##########\n",
            "  123. \"data:0.438\" 4200.000000 ##########\n",
            "  124. \"data:0.327\" 4145.000000 ##########\n",
            "  125. \"data:0.410\" 4142.000000 ##########\n",
            "  126. \"data:0.519\" 4129.000000 ##########\n",
            "  127. \"data:0.154\" 4124.000000 ##########\n",
            "  128. \"data:0.655\" 4082.000000 ##########\n",
            "  129. \"data:0.456\" 4054.000000 #########\n",
            "  130. \"data:0.658\" 4012.000000 #########\n",
            "  131. \"data:0.570\" 4005.000000 #########\n",
            "  132. \"data:0.262\" 3993.000000 #########\n",
            "  133. \"data:0.428\" 3991.000000 #########\n",
            "  134. \"data:0.156\" 3933.000000 #########\n",
            "  135. \"data:0.575\" 3918.000000 #########\n",
            "  136. \"data:0.289\" 3914.000000 #########\n",
            "  137. \"data:0.541\" 3887.000000 #########\n",
            "  138. \"data:0.243\" 3858.000000 #########\n",
            "  139. \"data:0.355\" 3848.000000 #########\n",
            "  140. \"data:0.601\" 3830.000000 #########\n",
            "  141. \"data:0.153\" 3785.000000 #########\n",
            "  142. \"data:0.180\" 3767.000000 #########\n",
            "  143. \"data:0.484\" 3765.000000 #########\n",
            "  144. \"data:0.207\" 3743.000000 #########\n",
            "  145. \"data:0.600\" 3736.000000 #########\n",
            "  146. \"data:0.547\" 3725.000000 #########\n",
            "  147. \"data:0.186\" 3709.000000 #########\n",
            "  148. \"data:0.602\" 3695.000000 #########\n",
            "  149. \"data:0.466\" 3668.000000 #########\n",
            "  150. \"data:0.493\" 3655.000000 ########\n",
            "  151. \"data:0.520\" 3646.000000 ########\n",
            "  152. \"data:0.576\" 3585.000000 ########\n",
            "  153. \"data:0.599\" 3577.000000 ########\n",
            "  154. \"data:0.629\" 3539.000000 ########\n",
            "  155. \"data:0.215\" 3518.000000 ########\n",
            "  156. \"data:0.157\" 3502.000000 ########\n",
            "  157. \"data:0.603\" 3494.000000 ########\n",
            "  158. \"data:0.628\" 3454.000000 ########\n",
            "  159. \"data:0.400\" 3451.000000 ########\n",
            "  160. \"data:0.627\" 3388.000000 ########\n",
            "  161. \"data:0.439\" 3384.000000 ########\n",
            "  162. \"data:0.630\" 3377.000000 ########\n",
            "  163. \"data:0.659\" 3365.000000 ########\n",
            "  164. \"data:0.344\" 3364.000000 ########\n",
            "  165. \"data:0.548\" 3361.000000 ########\n",
            "  166. \"data:0.234\" 3356.000000 ########\n",
            "  167. \"data:0.372\" 3335.000000 ########\n",
            "  168. \"data:0.512\" 3317.000000 ########\n",
            "  169. \"data:0.179\" 3316.000000 ########\n",
            "  170. \"data:0.569\" 3298.000000 ########\n",
            "  171. \"data:0.467\" 3290.000000 ########\n",
            "  172. \"data:0.521\" 3289.000000 ########\n",
            "  173. \"data:0.152\" 3275.000000 ########\n",
            "  174. \"data:0.654\" 3273.000000 ########\n",
            "  175. \"data:0.383\" 3261.000000 ########\n",
            "  176. \"data:0.631\" 3243.000000 #######\n",
            "  177. \"data:0.316\" 3220.000000 #######\n",
            "  178. \"data:0.411\" 3184.000000 #######\n",
            "  179. \"data:0.626\" 3179.000000 #######\n",
            "  180. \"data:0.328\" 3169.000000 #######\n",
            "  181. \"data:0.577\" 3136.000000 #######\n",
            "  182. \"data:0.272\" 3130.000000 #######\n",
            "  183. \"data:0.549\" 3130.000000 #######\n",
            "  184. \"data:0.300\" 3121.000000 #######\n",
            "  185. \"data:0.206\" 3118.000000 #######\n",
            "  186. \"data:0.604\" 3118.000000 #######\n",
            "  187. \"data:0.261\" 3090.000000 #######\n",
            "  188. \"data:0.494\" 3010.000000 #######\n",
            "  189. \"data:0.598\" 3010.000000 #######\n",
            "  190. \"data:0.550\" 3005.000000 #######\n",
            "  191. \"data:0.455\" 2990.000000 #######\n",
            "  192. \"data:0.540\" 2980.000000 #######\n",
            "  193. \"data:0.187\" 2923.000000 #######\n",
            "  194. \"data:0.244\" 2884.000000 #######\n",
            "  195. \"data:0.522\" 2884.000000 #######\n",
            "  196. \"data:0.625\" 2835.000000 ######\n",
            "  197. \"data:0.483\" 2816.000000 ######\n",
            "  198. \"data:0.178\" 2814.000000 ######\n",
            "  199. \"data:0.356\" 2804.000000 ######\n",
            "  200. \"data:0.427\" 2799.000000 ######\n",
            "  201. \"data:0.158\" 2791.000000 ######\n",
            "  202. \"data:0.632\" 2754.000000 ######\n",
            "  203. \"data:0.578\" 2753.000000 ######\n",
            "  204. \"data:0.568\" 2749.000000 ######\n",
            "  205. \"data:0.597\" 2744.000000 ######\n",
            "  206. \"data:0.151\" 2734.000000 ######\n",
            "  207. \"data:0.288\" 2700.000000 ######\n",
            "  208. \"data:0.495\" 2699.000000 ######\n",
            "  209. \"data:0.216\" 2694.000000 ######\n",
            "  210. \"data:0.605\" 2693.000000 ######\n",
            "  211. \"data:0.233\" 2600.000000 ######\n",
            "  212. \"data:0.523\" 2557.000000 ######\n",
            "  213. \"data:0.596\" 2544.000000 ######\n",
            "  214. \"data:0.660\" 2526.000000 ######\n",
            "  215. \"data:0.399\" 2491.000000 ######\n",
            "  216. \"data:0.633\" 2445.000000 ######\n",
            "  217. \"data:0.511\" 2442.000000 ######\n",
            "  218. \"data:0.551\" 2426.000000 #####\n",
            "  219. \"data:0.606\" 2422.000000 #####\n",
            "  220. \"data:0.440\" 2363.000000 #####\n",
            "  221. \"data:0.539\" 2337.000000 #####\n",
            "  222. \"data:0.468\" 2333.000000 #####\n",
            "  223. \"data:0.205\" 2328.000000 #####\n",
            "  224. \"data:0.653\" 2321.000000 #####\n",
            "  225. \"data:0.371\" 2309.000000 #####\n",
            "  226. \"data:0.245\" 2289.000000 #####\n",
            "  227. \"data:0.188\" 2266.000000 #####\n",
            "  228. \"data:0.343\" 2260.000000 #####\n",
            "  229. \"data:0.384\" 2259.000000 #####\n",
            "  230. \"data:0.567\" 2236.000000 #####\n",
            "  231. \"data:0.260\" 2227.000000 #####\n",
            "  232. \"data:0.273\" 2179.000000 #####\n",
            "  233. \"data:0.579\" 2147.000000 #####\n",
            "  234. \"data:0.624\" 2136.000000 #####\n",
            "  235. \"data:0.412\" 2131.000000 #####\n",
            "  236. \"data:0.301\" 2127.000000 #####\n",
            "  237. \"data:0.496\" 2109.000000 #####\n",
            "  238. \"data:0.315\" 2062.000000 #####\n",
            "  239. \"data:0.177\" 2055.000000 #####\n",
            "  240. \"data:0.329\" 2055.000000 #####\n",
            "  241. \"data:0.217\" 2001.000000 ####\n",
            "  242. \"data:0.159\" 1998.000000 ####\n",
            "  243. \"data:0.634\" 1918.000000 ####\n",
            "  244. \"data:0.150\" 1910.000000 ####\n",
            "  245. \"data:0.595\" 1897.000000 ####\n",
            "  246. \"data:0.524\" 1895.000000 ####\n",
            "  247. \"data:0.685\" 1866.000000 ####\n",
            "  248. \"data:0.607\" 1864.000000 ####\n",
            "  249. \"data:0.684\" 1841.000000 ####\n",
            "  250. \"data:0.661\" 1838.000000 ####\n",
            "  251. \"data:0.126\" 1799.000000 ####\n",
            "  252. \"data:0.232\" 1788.000000 ####\n",
            "  253. \"data:0.357\" 1780.000000 ####\n",
            "  254. \"data:0.552\" 1764.000000 ####\n",
            "  255. \"data:0.125\" 1728.000000 ####\n",
            "  256. \"data:0.683\" 1718.000000 ####\n",
            "  257. \"data:0.127\" 1712.000000 ####\n",
            "  258. \"data:0.189\" 1693.000000 ####\n",
            "  259. \"data:0.454\" 1691.000000 ####\n",
            "  260. \"data:0.580\" 1657.000000 ####\n",
            "  261. \"data:0.128\" 1652.000000 ####\n",
            "  262. \"data:0.510\" 1651.000000 ####\n",
            "  263. \"data:0.204\" 1625.000000 ###\n",
            "  264. \"data:0.246\" 1624.000000 ###\n",
            "  265. \"data:0.426\" 1606.000000 ###\n",
            "  266. \"data:0.441\" 1606.000000 ###\n",
            "  267. \"data:0.218\" 1571.000000 ###\n",
            "  268. \"data:0.686\" 1568.000000 ###\n",
            "  269. \"data:0.287\" 1564.000000 ###\n",
            "  270. \"data:0.652\" 1561.000000 ###\n",
            "  271. \"data:0.482\" 1558.000000 ###\n",
            "  272. \"data:0.385\" 1533.000000 ###\n",
            "  273. \"data:0.538\" 1529.000000 ###\n",
            "  274. \"data:0.623\" 1512.000000 ###\n",
            "  275. \"data:0.469\" 1505.000000 ###\n",
            "  276. \"data:0.413\" 1493.000000 ###\n",
            "  277. \"data:0.274\" 1488.000000 ###\n",
            "  278. \"data:0.398\" 1470.000000 ###\n",
            "  279. \"data:0.566\" 1457.000000 ###\n",
            "  280. \"data:0.682\" 1452.000000 ###\n",
            "  281. \"data:0.129\" 1442.000000 ###\n",
            "  282. \"data:0.124\" 1413.000000 ###\n",
            "  283. \"data:0.687\" 1395.000000 ###\n",
            "  284. \"data:0.525\" 1388.000000 ###\n",
            "  285. \"data:0.370\" 1367.000000 ###\n",
            "  286. \"data:0.497\" 1361.000000 ###\n",
            "  287. \"data:0.302\" 1335.000000 ###\n",
            "  288. \"data:0.330\" 1329.000000 ###\n",
            "  289. \"data:0.553\" 1326.000000 ###\n",
            "  290. \"data:0.176\" 1313.000000 ###\n",
            "  291. \"data:0.635\" 1281.000000 ###\n",
            "  292. \"data:0.608\" 1272.000000 ###\n",
            "  293. \"data:0.160\" 1268.000000 ###\n",
            "  294. \"data:0.358\" 1259.000000 ###\n",
            "  295. \"data:0.149\" 1258.000000 ###\n",
            "  296. \"data:0.259\" 1240.000000 ###\n",
            "  297. \"data:0.681\" 1235.000000 ###\n",
            "  298. \"data:0.130\" 1213.000000 ##\n",
            "  299. \"data:0.231\" 1211.000000 ##\n",
            "  300. \"data:0.342\" 1211.000000 ##\n",
            "  301. \"data:0.662\" 1198.000000 ##\n",
            "  302. \"data:0.581\" 1153.000000 ##\n",
            "  303. \"data:0.190\" 1130.000000 ##\n",
            "  304. \"data:0.594\" 1110.000000 ##\n",
            "  305. \"data:0.247\" 1090.000000 ##\n",
            "  306. \"data:0.219\" 1080.000000 ##\n",
            "  307. \"data:0.386\" 1067.000000 ##\n",
            "  308. \"data:0.123\" 1066.000000 ##\n",
            "  309. \"data:0.688\" 1052.000000 ##\n",
            "  310. \"data:0.498\" 1036.000000 ##\n",
            "  311. \"data:0.414\" 1031.000000 ##\n",
            "  312. \"data:0.442\" 1013.000000 ##\n",
            "  313. \"data:0.470\" 1009.000000 ##\n",
            "  314. \"data:0.131\" 1000.000000 ##\n",
            "  315. \"data:0.651\" 993.000000 ##\n",
            "  316. \"data:0.314\" 982.000000 ##\n",
            "  317. \"data:0.203\" 979.000000 ##\n",
            "  318. \"data:0.275\" 947.000000 ##\n",
            "  319. \"data:0.526\" 935.000000 ##\n",
            "  320. \"data:0.161\" 902.000000 ##\n",
            "  321. \"data:0.680\" 885.000000 ##\n",
            "  322. \"data:0.286\" 846.000000 ##\n",
            "  323. \"data:0.554\" 832.000000 ##\n",
            "  324. \"data:0.622\" 830.000000 ##\n",
            "  325. \"data:0.689\" 775.000000 #\n",
            "  326. \"data:0.609\" 772.000000 #\n",
            "  327. \"data:0.636\" 764.000000 #\n",
            "  328. \"data:0.509\" 753.000000 #\n",
            "  329. \"data:0.481\" 731.000000 #\n",
            "  330. \"data:0.537\" 731.000000 #\n",
            "  331. \"data:0.663\" 710.000000 #\n",
            "  332. \"data:0.711\" 701.000000 #\n",
            "  333. \"data:0.258\" 697.000000 #\n",
            "  334. \"data:0.101\" 678.000000 #\n",
            "  335. \"data:0.453\" 676.000000 #\n",
            "  336. \"data:0.122\" 673.000000 #\n",
            "  337. \"data:0.303\" 670.000000 #\n",
            "  338. \"data:0.191\" 665.000000 #\n",
            "  339. \"data:0.712\" 663.000000 #\n",
            "  340. \"data:0.132\" 649.000000 #\n",
            "  341. \"data:0.175\" 641.000000 #\n",
            "  342. \"data:0.425\" 639.000000 #\n",
            "  343. \"data:0.710\" 630.000000 #\n",
            "  344. \"data:0.582\" 629.000000 #\n",
            "  345. \"data:0.565\" 627.000000 #\n",
            "  346. \"data:0.100\" 625.000000 #\n",
            "  347. \"data:0.415\" 623.000000 #\n",
            "  348. \"data:0.331\" 622.000000 #\n",
            "  349. \"data:0.679\" 614.000000 #\n",
            "  350. \"data:0.230\" 613.000000 #\n",
            "  351. \"data:0.397\" 613.000000 #\n",
            "  352. \"data:0.148\" 609.000000 #\n",
            "  353. \"data:0.359\" 605.000000 #\n",
            "  354. \"data:0.713\" 597.000000 #\n",
            "  355. \"data:0.387\" 584.000000 #\n",
            "  356. \"data:0.102\" 574.000000 #\n",
            "  357. \"data:0.714\" 566.000000 #\n",
            "  358.  \"data:0.99\" 566.000000 #\n",
            "  359. \"data:0.443\" 565.000000 #\n",
            "  360. \"data:0.690\" 549.000000 #\n",
            "  361. \"data:0.709\" 543.000000 #\n",
            "  362. \"data:0.248\" 538.000000 #\n",
            "  363. \"data:0.162\" 535.000000 #\n",
            "  364. \"data:0.527\" 529.000000 #\n",
            "  365. \"data:0.369\" 524.000000 #\n",
            "  366. \"data:0.471\" 516.000000 #\n",
            "  367.  \"data:0.98\" 513.000000 #\n",
            "  368. \"data:0.593\" 504.000000 #\n",
            "  369. \"data:0.715\" 499.000000 #\n",
            "  370. \"data:0.499\" 493.000000 #\n",
            "  371. \"data:0.650\" 488.000000 #\n",
            "  372. \"data:0.341\" 485.000000 #\n",
            "  373. \"data:0.202\" 477.000000 #\n",
            "  374. \"data:0.220\" 477.000000 #\n",
            "  375. \"data:0.708\" 456.000000 #\n",
            "  376. \"data:0.716\" 455.000000 #\n",
            "  377. \"data:0.276\" 446.000000 #\n",
            "  378. \"data:0.555\" 422.000000 #\n",
            "  379.  \"data:0.97\" 420.000000 #\n",
            "  380. \"data:0.103\" 419.000000 #\n",
            "  381. \"data:0.637\" 410.000000 #\n",
            "  382. \"data:0.664\" 392.000000 \n",
            "  383. \"data:0.121\" 389.000000 \n",
            "  384. \"data:0.313\" 380.000000 \n",
            "  385. \"data:0.717\" 377.000000 \n",
            "  386. \"data:0.610\" 372.000000 \n",
            "  387. \"data:0.691\" 360.000000 \n",
            "  388.  \"data:0.96\" 346.000000 \n",
            "  389. \"data:0.133\" 344.000000 \n",
            "  390. \"data:0.621\" 335.000000 \n",
            "  391. \"data:0.285\" 317.000000 \n",
            "  392. \"data:0.678\" 303.000000 \n",
            "  393. \"data:0.174\" 298.000000 \n",
            "  394. \"data:0.147\" 277.000000 \n",
            "  395. \"data:0.707\" 258.000000 \n",
            "  396. \"data:0.257\" 254.000000 \n",
            "  397. \"data:0.718\" 254.000000 \n",
            "  398. \"data:0.536\" 252.000000 \n",
            "  399. \"data:0.229\" 249.000000 \n",
            "  400. \"data:0.583\" 243.000000 \n",
            "  401. \"data:0.163\" 238.000000 \n",
            "  402. \"data:0.304\" 236.000000 \n",
            "  403. \"data:0.564\" 213.000000 \n",
            "  404.  \"data:0.95\" 211.000000 \n",
            "  405. \"data:0.104\" 208.000000 \n",
            "  406. \"data:0.500\" 205.000000 \n",
            "  407. \"data:0.692\" 205.000000 \n",
            "  408. \"data:0.192\" 197.000000 \n",
            "  409. \"data:0.472\" 195.000000 \n",
            "  410. \"data:0.508\" 193.000000 \n",
            "  411. \"data:0.201\" 191.000000 \n",
            "  412. \"data:0.444\" 188.000000 \n",
            "  413. \"data:0.649\" 187.000000 \n",
            "  414. \"data:0.528\" 180.000000 \n",
            "  415. \"data:0.134\" 178.000000 \n",
            "  416. \"data:0.120\" 174.000000 \n",
            "  417. \"data:0.480\" 169.000000 \n",
            "  418. \"data:0.719\" 168.000000 \n",
            "  419. \"data:0.592\" 162.000000 \n",
            "  420.  \"data:0.94\" 152.000000 \n",
            "  421. \"data:0.665\" 151.000000 \n",
            "  422. \"data:0.416\" 149.000000 \n",
            "  423. \"data:0.638\" 145.000000 \n",
            "  424. \"data:0.340\" 143.000000 \n",
            "  425. \"data:0.388\" 130.000000 \n",
            "  426. \"data:0.452\" 130.000000 \n",
            "  427. \"data:0.556\" 126.000000 \n",
            "  428. \"data:0.396\" 124.000000 \n",
            "  429. \"data:0.424\" 116.000000 \n",
            "  430. \"data:0.360\" 113.000000 \n",
            "  431. \"data:0.677\" 113.000000 \n",
            "  432. \"data:0.105\" 112.000000 \n",
            "  433. \"data:0.611\" 112.000000 \n",
            "  434. \"data:0.332\" 109.000000 \n",
            "  435. \"data:0.368\" 108.000000 \n",
            "  436. \"data:0.146\" 106.000000 \n",
            "  437. \"data:0.312\" 100.000000 \n",
            "  438. \"data:0.173\" 98.000000 \n",
            "  439. \"data:0.720\" 95.000000 \n",
            "  440. \"data:0.706\" 92.000000 \n",
            "  441. \"data:0.742\" 92.000000 \n",
            "  442. \"data:0.743\" 90.000000 \n",
            "  443. \"data:0.164\" 89.000000 \n",
            "  444. \"data:0.256\" 89.000000 \n",
            "  445. \"data:0.620\" 84.000000 \n",
            "  446. \"data:0.135\" 82.000000 \n",
            "  447. \"data:0.741\" 81.000000 \n",
            "  448. \"data:0.739\" 79.000000 \n",
            "  449. \"data:0.284\" 78.000000 \n",
            "  450. \"data:0.228\" 75.000000 \n",
            "  451. \"data:0.744\" 72.000000 \n",
            "  452.  \"data:0.93\" 72.000000 \n",
            "  453. \"data:0.249\" 68.000000 \n",
            "  454. \"data:0.740\" 66.000000 \n",
            "  455. \"data:0.221\" 64.000000 \n",
            "  456. \"data:0.693\" 64.000000 \n",
            "  457. \"data:0.277\" 61.000000 \n",
            "  458. \"data:0.648\" 60.000000 \n",
            "  459. \"data:0.666\" 56.000000 \n",
            "  460. \"data:0.119\" 55.000000 \n",
            "  461. \"data:0.584\" 54.000000 \n",
            "  462. \"data:0.738\" 53.000000 \n",
            "  463.  \"data:0.69\" 52.000000 \n",
            "  464.  \"data:0.71\" 51.000000 \n",
            "  465. \"data:0.200\" 50.000000 \n",
            "  466.  \"data:0.70\" 47.000000 \n",
            "  467. \"data:0.737\" 47.000000 \n",
            "  468. \"data:0.745\" 45.000000 \n",
            "  469.  \"data:0.92\" 45.000000 \n",
            "  470. \"data:0.501\" 42.000000 \n",
            "  471.  \"data:0.67\" 41.000000 \n",
            "  472. \"data:0.473\" 38.000000 \n",
            "  473. \"data:0.529\" 37.000000 \n",
            "  474. \"data:0.507\" 36.000000 \n",
            "  475. \"data:0.535\" 36.000000 \n",
            "  476. \"data:0.563\" 36.000000 \n",
            "  477. \"data:0.705\" 36.000000 \n",
            "  478. \"data:0.106\" 35.000000 \n",
            "  479. \"data:0.639\" 35.000000 \n",
            "  480. \"data:0.145\" 33.000000 \n",
            "  481. \"data:0.193\" 33.000000 \n",
            "  482.  \"data:0.68\" 33.000000 \n",
            "  483.  \"data:0.73\" 33.000000 \n",
            "  484. \"data:0.746\" 32.000000 \n",
            "  485. \"data:0.445\" 31.000000 \n",
            "  486. \"data:0.305\" 30.000000 \n",
            "  487.  \"data:0.72\" 30.000000 \n",
            "  488. \"data:0.694\" 24.000000 \n",
            "  489.  \"data:0.74\" 24.000000 \n",
            "  490. \"data:0.721\" 22.000000 \n",
            "  491. \"data:0.136\" 21.000000 \n",
            "  492.  \"data:0.66\" 21.000000 \n",
            "  493. \"data:0.747\" 20.000000 \n",
            "  494. \"data:0.676\" 19.000000 \n",
            "  495. \"data:0.733\" 19.000000 \n",
            "  496. \"data:0.736\" 19.000000 \n",
            "  497. \"data:0.479\" 18.000000 \n",
            "  498.  \"data:0.75\" 18.000000 \n",
            "  499. \"data:0.591\" 17.000000 \n",
            "  500. \"data:0.118\" 16.000000 \n",
            "  501. \"data:0.165\" 16.000000 \n",
            "  502. \"data:0.172\" 16.000000 \n",
            "  503. \"data:0.417\" 16.000000 \n",
            "  504. \"data:0.333\" 15.000000 \n",
            "  505. \"data:0.612\" 15.000000 \n",
            "  506. \"data:0.619\" 15.000000 \n",
            "  507. \"data:0.451\" 14.000000 \n",
            "  508. \"data:0.734\" 14.000000 \n",
            "  509. \"data:0.748\" 14.000000 \n",
            "  510. \"data:0.107\" 13.000000 \n",
            "  511. \"data:0.361\" 13.000000 \n",
            "  512. \"data:0.557\" 13.000000 \n",
            "  513.  \"data:0.91\" 13.000000 \n",
            "  514. \"data:0.311\" 12.000000 \n",
            "  515. \"data:0.339\" 10.000000 \n",
            "  516. \"data:0.283\"  9.000000 \n",
            "  517. \"data:0.389\"  9.000000 \n",
            "  518. \"data:0.640\"  9.000000 \n",
            "  519. \"data:0.704\"  9.000000 \n",
            "  520. \"data:0.722\"  9.000000 \n",
            "  521. \"data:0.732\"  9.000000 \n",
            "  522. \"data:0.735\"  9.000000 \n",
            "  523. \"data:0.227\"  8.000000 \n",
            "  524. \"data:0.367\"  8.000000 \n",
            "  525. \"data:0.474\"  8.000000 \n",
            "  526.  \"data:0.65\"  8.000000 \n",
            "  527. \"data:0.667\"  8.000000 \n",
            "  528.  \"data:0.76\"  8.000000 \n",
            "  529. \"data:0.423\"  7.000000 \n",
            "  530.  \"data:0.63\"  7.000000 \n",
            "  531. \"data:0.222\"  6.000000 \n",
            "  532. \"data:0.255\"  6.000000 \n",
            "  533. \"data:0.199\"  5.000000 \n",
            "  534. \"data:0.278\"  5.000000 \n",
            "  535.  \"data:0.64\"  5.000000 \n",
            "  536. \"data:0.668\"  5.000000 \n",
            "  537. \"data:0.695\"  5.000000 \n",
            "  538. \"data:0.338\"  4.000000 \n",
            "  539. \"data:0.395\"  4.000000 \n",
            "  540. \"data:0.534\"  4.000000 \n",
            "  541. \"data:0.585\"  4.000000 \n",
            "  542. \"data:0.647\"  4.000000 \n",
            "  543.  \"data:0.78\"  4.000000 \n",
            "  544. \"data:0.108\"  3.000000 \n",
            "  545. \"data:0.117\"  3.000000 \n",
            "  546. \"data:0.137\"  2.000000 \n",
            "  547. \"data:0.194\"  2.000000 \n",
            "  548. \"data:0.254\"  2.000000 \n",
            "  549. \"data:0.306\"  2.000000 \n",
            "  550. \"data:0.310\"  2.000000 \n",
            "  551. \"data:0.418\"  2.000000 \n",
            "  552. \"data:0.446\"  2.000000 \n",
            "  553. \"data:0.590\"  2.000000 \n",
            "  554. \"data:0.613\"  2.000000 \n",
            "  555. \"data:0.723\"  2.000000 \n",
            "  556.  \"data:0.77\"  2.000000 \n",
            "  557.  \"data:0.90\"  2.000000 \n",
            "  558. \"data:0.143\"  1.000000 \n",
            "  559. \"data:0.144\"  1.000000 \n",
            "  560. \"data:0.171\"  1.000000 \n",
            "  561. \"data:0.250\"  1.000000 \n",
            "  562. \"data:0.282\"  1.000000 \n",
            "  563. \"data:0.362\"  1.000000 \n",
            "  564. \"data:0.390\"  1.000000 \n",
            "  565.  \"data:0.42\"  1.000000 \n",
            "  566. \"data:0.478\"  1.000000 \n",
            "  567.  \"data:0.48\"  1.000000 \n",
            "  568. \"data:0.506\"  1.000000 \n",
            "  569. \"data:0.530\"  1.000000 \n",
            "  570. \"data:0.558\"  1.000000 \n",
            "  571. \"data:0.562\"  1.000000 \n",
            "  572. \"data:0.614\"  1.000000 \n",
            "  573. \"data:0.675\"  1.000000 \n",
            "  574. \"data:0.696\"  1.000000 \n",
            "  575. \"data:0.703\"  1.000000 \n",
            "  576. \"data:0.749\"  1.000000 \n",
            "  577. \"data:0.768\"  1.000000 \n",
            "  578. \"data:0.770\"  1.000000 \n",
            "  579. \"data:0.771\"  1.000000 \n",
            "  580. \"data:0.772\"  1.000000 \n",
            "  581. \"data:0.773\"  1.000000 \n",
            "  582. \"data:0.775\"  1.000000 \n",
            "  583.  \"data:0.89\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1. \"data:0.378\" 934616.751698 ################\n",
            "    2. \"data:0.461\" 793274.737655 #############\n",
            "    3. \"data:0.377\" 769435.969394 #############\n",
            "    4. \"data:0.406\" 736132.099443 ############\n",
            "    5. \"data:0.350\" 718352.464731 ############\n",
            "    6. \"data:0.155\" 717587.731593 ############\n",
            "    7. \"data:0.569\" 708722.570443 ############\n",
            "    8. \"data:0.405\" 685719.782391 ###########\n",
            "    9. \"data:0.515\" 634445.406082 ##########\n",
            "   10. \"data:0.568\" 618867.227056 ##########\n",
            "   11. \"data:0.542\" 614812.803728 ##########\n",
            "   12. \"data:0.596\" 551029.826166 #########\n",
            "   13. \"data:0.373\" 544148.530879 #########\n",
            "   14. \"data:0.409\" 542536.011103 #########\n",
            "   15. \"data:0.154\" 539580.516765 #########\n",
            "   16. \"data:0.489\" 539116.563423 #########\n",
            "   17. \"data:0.345\" 530886.011442 #########\n",
            "   18. \"data:0.433\" 530067.498995 #########\n",
            "   19. \"data:0.514\" 519685.713043 ########\n",
            "   20. \"data:0.462\" 513441.594887 ########\n",
            "   21. \"data:0.434\" 507331.235154 ########\n",
            "   22. \"data:0.488\" 496983.455871 ########\n",
            "   23. \"data:0.347\" 493741.777367 ########\n",
            "   24. \"data:0.401\" 477645.009836 ########\n",
            "   25. \"data:0.346\" 475860.603577 ########\n",
            "   26. \"data:0.487\" 474948.673238 ########\n",
            "   27. \"data:0.460\" 471699.210762 ########\n",
            "   28. \"data:0.597\" 471399.537401 ########\n",
            "   29. \"data:0.318\" 463737.767192 #######\n",
            "   30. \"data:0.374\" 463198.696993 #######\n",
            "   31. \"data:0.543\" 444626.231805 #######\n",
            "   32. \"data:0.656\" 438320.080719 #######\n",
            "   33. \"data:0.156\" 437549.358270 #######\n",
            "   34. \"data:0.437\" 429438.840796 #######\n",
            "   35. \"data:0.211\" 422292.245300 #######\n",
            "   36. \"data:0.375\" 414131.049225 #######\n",
            "   37. \"data:0.541\" 404474.389414 ######\n",
            "   38. \"data:0.486\" 395984.531242 ######\n",
            "   39. \"data:0.570\" 394409.502544 ######\n",
            "   40. \"data:0.657\" 391159.644129 ######\n",
            "   41. \"data:0.428\" 385500.536992 ######\n",
            "   42. \"data:0.429\" 381397.628417 ######\n",
            "   43. \"data:0.210\" 377868.122537 ######\n",
            "   44. \"data:0.153\" 371621.556719 ######\n",
            "   45. \"data:0.290\" 371240.010491 ######\n",
            "   46. \"data:0.402\" 370308.152250 ######\n",
            "   47. \"data:0.567\" 364074.340411 ######\n",
            "   48. \"data:0.291\" 357695.098711 ######\n",
            "   49. \"data:0.319\" 357553.026211 ######\n",
            "   50. \"data:0.351\" 354309.509191 ######\n",
            "   51. \"data:0.317\" 350239.027185 #####\n",
            "   52. \"data:0.516\" 346437.581295 #####\n",
            "   53. \"data:0.490\" 346166.555369 #####\n",
            "   54. \"data:0.400\" 340351.334117 #####\n",
            "   55. \"data:0.376\" 335392.528833 #####\n",
            "   56. \"data:0.407\" 333468.505227 #####\n",
            "   57. \"data:0.430\" 332878.364723 #####\n",
            "   58. \"data:0.354\" 330834.726877 #####\n",
            "   59. \"data:0.458\" 330627.149067 #####\n",
            "   60. \"data:0.432\" 328105.455594 #####\n",
            "   61. \"data:0.238\" 324130.787950 #####\n",
            "   62. \"data:0.403\" 323774.883078 #####\n",
            "   63. \"data:0.625\" 319372.504485 #####\n",
            "   64. \"data:0.655\" 318446.577920 #####\n",
            "   65. \"data:0.457\" 317345.929764 #####\n",
            "   66. \"data:0.239\" 317092.361574 #####\n",
            "   67. \"data:0.348\" 314237.930336 #####\n",
            "   68. \"data:0.349\" 313903.607547 #####\n",
            "   69. \"data:0.381\" 309083.244992 #####\n",
            "   70. \"data:0.459\" 307828.020905 #####\n",
            "   71. \"data:0.212\" 301368.972806 #####\n",
            "   72. \"data:0.658\" 298758.986114 #####\n",
            "   73. \"data:0.326\" 293092.099485 #####\n",
            "   74. \"data:0.456\" 288374.029914 ####\n",
            "   75. \"data:0.654\" 284440.207409 ####\n",
            "   76. \"data:0.322\" 281609.348074 ####\n",
            "   77. \"data:0.571\" 276602.877100 ####\n",
            "   78. \"data:0.320\" 275980.933320 ####\n",
            "   79. \"data:0.380\" 275261.366503 ####\n",
            "   80. \"data:0.517\" 275174.560384 ####\n",
            "   81. \"data:0.485\" 274718.299304 ####\n",
            "   82. \"data:0.408\" 268451.927439 ####\n",
            "   83. \"data:0.298\" 268090.628342 ####\n",
            "   84. \"data:0.379\" 263137.708676 ####\n",
            "   85. \"data:0.263\" 262158.503020 ####\n",
            "   86. \"data:0.270\" 262066.966835 ####\n",
            "   87. \"data:0.435\" 261914.038638 ####\n",
            "   88. \"data:0.240\" 255786.153151 ####\n",
            "   89. \"data:0.513\" 255534.886699 ####\n",
            "   90. \"data:0.431\" 254557.704628 ####\n",
            "   91. \"data:0.183\" 254533.201184 ####\n",
            "   92. \"data:0.297\" 252353.489586 ####\n",
            "   93. \"data:0.353\" 249746.456518 ####\n",
            "   94. \"data:0.550\" 248962.612730 ####\n",
            "   95. \"data:0.352\" 247707.284706 ####\n",
            "   96. \"data:0.323\" 247672.574317 ####\n",
            "   97. \"data:0.436\" 245666.856801 ####\n",
            "   98. \"data:0.157\" 245361.390576 ####\n",
            "   99. \"data:0.382\" 243472.072333 ####\n",
            "  100. \"data:0.484\" 243384.526586 ####\n",
            "  101. \"data:0.267\" 243290.946631 ####\n",
            "  102. \"data:0.372\" 242994.411536 ####\n",
            "  103. \"data:0.544\" 241791.052465 ####\n",
            "  104. \"data:0.404\" 239605.326733 ####\n",
            "  105. \"data:0.463\" 239304.842731 ####\n",
            "  106. \"data:0.271\" 235511.817375 ####\n",
            "  107. \"data:0.296\" 234727.857554 ####\n",
            "  108. \"data:0.540\" 233897.712223 ####\n",
            "  109. \"data:0.295\" 231533.910889 ###\n",
            "  110. \"data:0.292\" 230364.132628 ###\n",
            "  111. \"data:0.152\" 230029.545843 ###\n",
            "  112. \"data:0.299\" 225802.265364 ###\n",
            "  113. \"data:0.624\" 225638.043578 ###\n",
            "  114. \"data:0.595\" 225493.667809 ###\n",
            "  115. \"data:0.269\" 222338.978429 ###\n",
            "  116. \"data:0.262\" 217489.836982 ###\n",
            "  117. \"data:0.182\" 217393.327350 ###\n",
            "  118. \"data:0.598\" 216580.436931 ###\n",
            "  119. \"data:0.294\" 216510.201912 ###\n",
            "  120. \"data:0.455\" 213996.737735 ###\n",
            "  121. \"data:0.325\" 213735.324350 ###\n",
            "  122. \"data:0.266\" 213244.883023 ###\n",
            "  123. \"data:0.572\" 208850.713193 ###\n",
            "  124. \"data:0.209\" 208374.052744 ###\n",
            "  125. \"data:0.268\" 207331.738562 ###\n",
            "  126. \"data:0.324\" 207132.635217 ###\n",
            "  127. \"data:0.427\" 206554.749571 ###\n",
            "  128. \"data:0.327\" 206345.574362 ###\n",
            "  129. \"data:0.626\" 206030.619377 ###\n",
            "  130. \"data:0.465\" 204793.288752 ###\n",
            "  131. \"data:0.242\" 204762.836801 ###\n",
            "  132. \"data:0.321\" 204354.559247 ###\n",
            "  133. \"data:0.237\" 202559.050898 ###\n",
            "  134. \"data:0.522\" 201031.512197 ###\n",
            "  135. \"data:0.410\" 199277.988807 ###\n",
            "  136. \"data:0.184\" 196037.507325 ###\n",
            "  137. \"data:0.438\" 195843.158944 ###\n",
            "  138. \"data:0.551\" 194893.228954 ###\n",
            "  139. \"data:0.243\" 194537.427322 ###\n",
            "  140. \"data:0.241\" 192369.117028 ###\n",
            "  141. \"data:0.483\" 191538.528034 ###\n",
            "  142. \"data:0.659\" 182957.630710 ###\n",
            "  143. \"data:0.539\" 182490.020123 ###\n",
            "  144. \"data:0.518\" 179928.811676 ###\n",
            "  145. \"data:0.491\" 175520.729728 ###\n",
            "  146. \"data:0.289\" 175476.002410 ###\n",
            "  147. \"data:0.344\" 174848.958718 ##\n",
            "  148. \"data:0.293\" 173611.363543 ##\n",
            "  149. \"data:0.236\" 171130.361615 ##\n",
            "  150. \"data:0.265\" 168382.048667 ##\n",
            "  151. \"data:0.464\" 167250.183056 ##\n",
            "  152. \"data:0.151\" 161077.835624 ##\n",
            "  153. \"data:0.181\" 159732.452432 ##\n",
            "  154. \"data:0.213\" 159713.673109 ##\n",
            "  155. \"data:0.272\" 158167.842236 ##\n",
            "  156. \"data:0.523\" 156134.507057 ##\n",
            "  157. \"data:0.179\" 153995.810104 ##\n",
            "  158. \"data:0.264\" 150839.012265 ##\n",
            "  159. \"data:0.235\" 150525.757769 ##\n",
            "  160. \"data:0.206\" 146788.189559 ##\n",
            "  161. \"data:0.178\" 146424.580382 ##\n",
            "  162. \"data:0.185\" 144505.971166 ##\n",
            "  163. \"data:0.355\" 141691.575668 ##\n",
            "  164. \"data:0.578\" 139383.708382 ##\n",
            "  165. \"data:0.466\" 136888.224408 ##\n",
            "  166. \"data:0.512\" 136464.549121 ##\n",
            "  167. \"data:0.399\" 136069.250825 ##\n",
            "  168. \"data:0.545\" 135496.280168 ##\n",
            "  169. \"data:0.316\" 134888.037527 ##\n",
            "  170. \"data:0.573\" 134236.005084 ##\n",
            "  171. \"data:0.207\" 133922.024432 ##\n",
            "  172. \"data:0.208\" 132822.828190 ##\n",
            "  173. \"data:0.180\" 132481.393035 ##\n",
            "  174. \"data:0.234\" 131932.339778 ##\n",
            "  175. \"data:0.214\" 131806.695984 ##\n",
            "  176. \"data:0.300\" 131024.375032 ##\n",
            "  177. \"data:0.653\" 130653.810290 ##\n",
            "  178. \"data:0.329\" 130282.608060 ##\n",
            "  179. \"data:0.511\" 127269.733441 ##\n",
            "  180. \"data:0.549\" 126604.164427 ##\n",
            "  181. \"data:0.328\" 126201.663282 ##\n",
            "  182. \"data:0.244\" 125724.936161 ##\n",
            "  183. \"data:0.627\" 124852.605817 ##\n",
            "  184. \"data:0.158\" 121772.622133 ##\n",
            "  185. \"data:0.599\" 118171.090152 ##\n",
            "  186. \"data:0.494\" 117774.811609 ##\n",
            "  187. \"data:0.371\" 117323.171794 ##\n",
            "  188. \"data:0.343\" 116114.487719 #\n",
            "  189. \"data:0.493\" 113275.403043 #\n",
            "  190. \"data:0.521\" 113208.228053 #\n",
            "  191. \"data:0.623\" 111656.821415 #\n",
            "  192. \"data:0.261\" 110914.566295 #\n",
            "  193. \"data:0.546\" 110483.226932 #\n",
            "  194. \"data:0.467\" 109867.282679 #\n",
            "  195. \"data:0.301\" 109544.479947 #\n",
            "  196. \"data:0.205\" 109398.957403 #\n",
            "  197. \"data:0.358\" 106866.164368 #\n",
            "  198. \"data:0.215\" 106610.518023 #\n",
            "  199. \"data:0.577\" 103472.993189 #\n",
            "  200. \"data:0.126\" 100822.027773 #\n",
            "  201. \"data:0.495\" 97001.194198 #\n",
            "  202. \"data:0.574\" 96257.482628 #\n",
            "  203. \"data:0.492\" 94683.740876 #\n",
            "  204. \"data:0.519\" 94479.078141 #\n",
            "  205. \"data:0.600\" 94367.214206 #\n",
            "  206. \"data:0.357\" 93461.818049 #\n",
            "  207. \"data:0.127\" 91457.469517 #\n",
            "  208. \"data:0.439\" 91296.944363 #\n",
            "  209. \"data:0.125\" 90945.679785 #\n",
            "  210. \"data:0.524\" 90296.325402 #\n",
            "  211. \"data:0.579\" 90092.059512 #\n",
            "  212. \"data:0.652\" 89871.852803 #\n",
            "  213. \"data:0.233\" 89557.899794 #\n",
            "  214. \"data:0.630\" 89268.042213 #\n",
            "  215. \"data:0.273\" 88922.804207 #\n",
            "  216. \"data:0.496\" 88779.718094 #\n",
            "  217. \"data:0.575\" 87669.419485 #\n",
            "  218. \"data:0.660\" 86660.756788 #\n",
            "  219. \"data:0.150\" 86511.162257 #\n",
            "  220. \"data:0.186\" 86452.618482 #\n",
            "  221. \"data:0.628\" 86344.464501 #\n",
            "  222. \"data:0.356\" 86326.216220 #\n",
            "  223. \"data:0.245\" 86209.134995 #\n",
            "  224. \"data:0.538\" 85898.199481 #\n",
            "  225. \"data:0.216\" 85747.061860 #\n",
            "  226. \"data:0.315\" 84644.485763 #\n",
            "  227. \"data:0.594\" 84156.221356 #\n",
            "  228. \"data:0.383\" 83296.319207 #\n",
            "  229. \"data:0.100\" 82725.731058 #\n",
            "  230. \"data:0.177\" 81548.328168 #\n",
            "  231. \"data:0.330\" 80723.878845 #\n",
            "  232. \"data:0.385\" 80166.818807 #\n",
            "  233. \"data:0.552\" 79805.500741 #\n",
            "  234. \"data:0.260\" 79600.367984 #\n",
            "  235. \"data:0.601\" 79409.013368 #\n",
            "  236. \"data:0.288\" 78761.498108 #\n",
            "  237. \"data:0.576\" 77333.283543 #\n",
            "  238. \"data:0.468\" 76604.437771 #\n",
            "  239. \"data:0.566\" 76078.812760 #\n",
            "  240. \"data:0.606\" 75298.200442 #\n",
            "  241. \"data:0.631\" 73798.430229 #\n",
            "  242. \"data:0.684\" 72884.206362 #\n",
            "  243. \"data:0.580\" 72649.423842 #\n",
            "  244. \"data:0.520\" 72326.079770 #\n",
            "  245. \"data:0.411\" 71783.878880 #\n",
            "  246. \"data:0.548\" 71615.728312 #\n",
            "  247. \"data:0.128\" 71484.470041 #\n",
            "  248. \"data:0.602\" 71431.088323 #\n",
            "  249. \"data:0.629\" 70982.179563 #\n",
            "  250. \"data:0.454\" 70458.708613 #\n",
            "  251. \"data:0.685\" 70317.949476 #\n",
            "  252. \"data:0.547\" 69399.359399 #\n",
            "  253. \"data:0.187\" 68780.883042 #\n",
            "  254. \"data:0.217\" 68665.584150 #\n",
            "  255. \"data:0.603\" 68455.316861 #\n",
            "  256. \"data:0.441\" 68446.912791 #\n",
            "  257. \"data:0.386\" 66539.019272 #\n",
            "  258. \"data:0.426\" 66182.490740 #\n",
            "  259. \"data:0.482\" 66007.912418 #\n",
            "  260. \"data:0.101\" 64627.096112 #\n",
            "  261. \"data:0.398\" 64591.442287 #\n",
            "  262. \"data:0.370\" 64053.424175 #\n",
            "  263. \"data:0.440\" 63501.376067 #\n",
            "  264. \"data:0.218\" 62503.969981 #\n",
            "  265. \"data:0.632\" 62451.529614 #\n",
            "  266. \"data:0.683\" 62435.360888 #\n",
            "  267. \"data:0.124\" 62255.012908 #\n",
            "  268. \"data:0.510\" 62020.500272 #\n",
            "  269. \"data:0.188\" 59619.824152 #\n",
            "  270. \"data:0.605\" 59456.756557 #\n",
            "  271. \"data:0.604\" 59404.642055 #\n",
            "  272. \"data:0.413\" 57634.372477 \n",
            "  273.  \"data:0.99\" 57533.195599 \n",
            "  274. \"data:0.159\" 56476.848202 \n",
            "  275. \"data:0.384\" 55236.152707 \n",
            "  276. \"data:0.246\" 54684.787584 \n",
            "  277. \"data:0.661\" 54026.610007 \n",
            "  278. \"data:0.682\" 53186.199030 \n",
            "  279. \"data:0.686\" 52508.666354 \n",
            "  280. \"data:0.607\" 52113.040792 \n",
            "  281. \"data:0.129\" 51660.813095 \n",
            "  282. \"data:0.219\" 51139.815220 \n",
            "  283. \"data:0.414\" 50027.932295 \n",
            "  284. \"data:0.651\" 49060.420668 \n",
            "  285. \"data:0.274\" 48978.306443 \n",
            "  286. \"data:0.412\" 48185.908484 \n",
            "  287. \"data:0.232\" 46119.353372 \n",
            "  288. \"data:0.342\" 45482.541247 \n",
            "  289. \"data:0.681\" 45402.096898 \n",
            "  290. \"data:0.633\" 45325.721119 \n",
            "  291. \"data:0.247\" 45098.471322 \n",
            "  292. \"data:0.149\" 44896.867278 \n",
            "  293. \"data:0.189\" 44569.848268 \n",
            "  294. \"data:0.553\" 42447.771332 \n",
            "  295. \"data:0.442\" 42207.460471 \n",
            "  296. \"data:0.302\" 42188.136707 \n",
            "  297. \"data:0.581\" 40891.206328 \n",
            "  298. \"data:0.123\" 39269.031761 \n",
            "  299. \"data:0.190\" 38861.320047 \n",
            "  300. \"data:0.608\" 38115.565329 \n",
            "  301. \"data:0.634\" 38057.772104 \n",
            "  302. \"data:0.102\" 37805.135055 \n",
            "  303. \"data:0.204\" 37661.959793 \n",
            "  304. \"data:0.497\" 37256.026825 \n",
            "  305. \"data:0.525\" 36682.503505 \n",
            "  306. \"data:0.711\" 36518.836585 \n",
            "  307. \"data:0.469\" 36136.068717 \n",
            "  308. \"data:0.176\" 35110.553730 \n",
            "  309. \"data:0.287\" 34410.111894 \n",
            "  310.  \"data:0.98\" 34300.025442 \n",
            "  311. \"data:0.359\" 33189.806586 \n",
            "  312. \"data:0.680\" 33056.085115 \n",
            "  313.  \"data:0.97\" 32734.781446 \n",
            "  314. \"data:0.275\" 32549.607758 \n",
            "  315. \"data:0.708\" 31023.594517 \n",
            "  316. \"data:0.709\" 30823.191412 \n",
            "  317. \"data:0.160\" 30511.851820 \n",
            "  318. \"data:0.248\" 30107.692374 \n",
            "  319. \"data:0.710\" 29883.572011 \n",
            "  320. \"data:0.415\" 29628.559410 \n",
            "  321. \"data:0.622\" 29101.182719 \n",
            "  322. \"data:0.387\" 28793.708526 \n",
            "  323. \"data:0.130\" 28466.213311 \n",
            "  324. \"data:0.470\" 28362.491694 \n",
            "  325. \"data:0.712\" 28269.054047 \n",
            "  326. \"data:0.314\" 28150.409761 \n",
            "  327. \"data:0.687\" 27035.228440 \n",
            "  328. \"data:0.526\" 26219.643139 \n",
            "  329. \"data:0.662\" 26167.441922 \n",
            "  330. \"data:0.635\" 25670.933387 \n",
            "  331. \"data:0.425\" 24607.642992 \n",
            "  332. \"data:0.191\" 24262.609889 \n",
            "  333. \"data:0.231\" 23413.752200 \n",
            "  334. \"data:0.131\" 23357.181111 \n",
            "  335. \"data:0.453\" 22853.783812 \n",
            "  336. \"data:0.554\" 22659.879272 \n",
            "  337. \"data:0.609\" 22381.075379 \n",
            "  338. \"data:0.161\" 21884.131284 \n",
            "  339. \"data:0.103\" 21785.796480 \n",
            "  340. \"data:0.397\" 21775.067404 \n",
            "  341. \"data:0.259\" 21624.996583 \n",
            "  342. \"data:0.537\" 21425.639440 \n",
            "  343. \"data:0.565\" 20980.285174 \n",
            "  344. \"data:0.481\" 20910.462147 \n",
            "  345. \"data:0.498\" 20801.181307 \n",
            "  346. \"data:0.122\" 20293.321700 \n",
            "  347. \"data:0.713\" 20240.136457 \n",
            "  348. \"data:0.331\" 20043.185390 \n",
            "  349. \"data:0.509\" 19756.869048 \n",
            "  350. \"data:0.220\" 18404.870033 \n",
            "  351. \"data:0.203\" 18302.160711 \n",
            "  352.  \"data:0.96\" 17740.902178 \n",
            "  353. \"data:0.582\" 17397.526074 \n",
            "  354. \"data:0.369\" 17356.100056 \n",
            "  355. \"data:0.303\" 17234.888298 \n",
            "  356. \"data:0.443\" 17162.827929 \n",
            "  357. \"data:0.679\" 16584.679751 \n",
            "  358. \"data:0.276\" 15644.074565 \n",
            "  359. \"data:0.688\" 15582.985917 \n",
            "  360. \"data:0.286\" 14668.787618 \n",
            "  361. \"data:0.714\" 14404.575876 \n",
            "  362. \"data:0.341\" 14008.567084 \n",
            "  363. \"data:0.593\" 12718.781781 \n",
            "  364. \"data:0.527\" 12480.724599 \n",
            "  365. \"data:0.663\" 12447.033649 \n",
            "  366. \"data:0.148\" 12257.594867 \n",
            "  367. \"data:0.689\" 12228.211738 \n",
            "  368. \"data:0.132\" 12188.850064 \n",
            "  369. \"data:0.175\" 12045.504426 \n",
            "  370. \"data:0.636\" 11745.531767 \n",
            "  371. \"data:0.707\" 11380.882274 \n",
            "  372. \"data:0.162\" 10954.870910 \n",
            "  373. \"data:0.471\" 10889.254354 \n",
            "  374. \"data:0.715\" 10623.049783 \n",
            "  375. \"data:0.716\" 10443.201552 \n",
            "  376. \"data:0.258\" 10326.604539 \n",
            "  377. \"data:0.650\" 10194.834072 \n",
            "  378. \"data:0.555\" 9984.671434 \n",
            "  379.  \"data:0.95\" 9827.839019 \n",
            "  380. \"data:0.499\" 9525.517302 \n",
            "  381. \"data:0.717\" 9090.959624 \n",
            "  382. \"data:0.230\" 9080.763944 \n",
            "  383. \"data:0.121\" 8519.685670 \n",
            "  384. \"data:0.690\" 8461.718230 \n",
            "  385. \"data:0.104\" 7562.994418 \n",
            "  386. \"data:0.313\" 7060.286224 \n",
            "  387. \"data:0.718\" 6532.645076 \n",
            "  388. \"data:0.192\" 6531.657613 \n",
            "  389. \"data:0.202\" 6457.800460 \n",
            "  390. \"data:0.610\" 6333.912375 \n",
            "  391. \"data:0.678\" 6204.525182 \n",
            "  392.  \"data:0.94\" 6148.126457 \n",
            "  393. \"data:0.637\" 5646.593436 \n",
            "  394. \"data:0.691\" 5570.408352 \n",
            "  395. \"data:0.304\" 5497.443465 \n",
            "  396. \"data:0.664\" 5453.676056 \n",
            "  397. \"data:0.163\" 5310.567389 \n",
            "  398. \"data:0.285\" 5108.418646 \n",
            "  399. \"data:0.133\" 5006.364769 \n",
            "  400. \"data:0.621\" 4976.010808 \n",
            "  401. \"data:0.528\" 4738.584215 \n",
            "  402. \"data:0.583\" 4731.011861 \n",
            "  403. \"data:0.147\" 4572.915225 \n",
            "  404. \"data:0.174\" 4325.054533 \n",
            "  405.  \"data:0.68\" 3995.782322 \n",
            "  406. \"data:0.500\" 3922.958280 \n",
            "  407. \"data:0.564\" 3855.331976 \n",
            "  408. \"data:0.472\" 3701.700198 \n",
            "  409. \"data:0.444\" 3676.656949 \n",
            "  410.  \"data:0.70\" 3570.830688 \n",
            "  411. \"data:0.719\" 3570.811464 \n",
            "  412. \"data:0.536\" 3547.553223 \n",
            "  413. \"data:0.706\" 3333.150778 \n",
            "  414. \"data:0.257\" 3288.439357 \n",
            "  415. \"data:0.592\" 3134.113024 \n",
            "  416. \"data:0.508\" 3064.192776 \n",
            "  417. \"data:0.229\" 3043.383062 \n",
            "  418. \"data:0.105\" 2893.762171 \n",
            "  419. \"data:0.739\" 2845.557809 \n",
            "  420. \"data:0.741\" 2757.615487 \n",
            "  421. \"data:0.388\" 2755.341969 \n",
            "  422. \"data:0.742\" 2712.162940 \n",
            "  423.  \"data:0.67\" 2680.848391 \n",
            "  424.  \"data:0.69\" 2561.218221 \n",
            "  425. \"data:0.692\" 2546.487376 \n",
            "  426.  \"data:0.93\" 2530.563819 \n",
            "  427. \"data:0.740\" 2521.009634 \n",
            "  428. \"data:0.416\" 2497.476224 \n",
            "  429. \"data:0.201\" 2486.108004 \n",
            "  430. \"data:0.120\" 2472.584775 \n",
            "  431.  \"data:0.71\" 2467.586370 \n",
            "  432. \"data:0.556\" 2451.853834 \n",
            "  433. \"data:0.360\" 2337.827276 \n",
            "  434. \"data:0.480\" 2334.179102 \n",
            "  435. \"data:0.744\" 2224.594949 \n",
            "  436. \"data:0.134\" 2171.301765 \n",
            "  437. \"data:0.649\" 2135.593755 \n",
            "  438. \"data:0.452\" 2051.991311 \n",
            "  439. \"data:0.396\" 1983.759826 \n",
            "  440. \"data:0.638\" 1919.679040 \n",
            "  441. \"data:0.665\" 1823.093975 \n",
            "  442. \"data:0.677\" 1783.251215 \n",
            "  443. \"data:0.340\" 1774.286395 \n",
            "  444. \"data:0.424\" 1759.076871 \n",
            "  445. \"data:0.611\" 1744.175707 \n",
            "  446. \"data:0.743\" 1637.683086 \n",
            "  447. \"data:0.720\" 1587.969515 \n",
            "  448. \"data:0.277\" 1546.551425 \n",
            "  449. \"data:0.332\" 1518.427147 \n",
            "  450. \"data:0.368\" 1509.967928 \n",
            "  451. \"data:0.745\" 1453.276454 \n",
            "  452. \"data:0.249\" 1432.199150 \n",
            "  453. \"data:0.146\" 1431.217374 \n",
            "  454. \"data:0.312\" 1202.259615 \n",
            "  455. \"data:0.173\" 1186.578950 \n",
            "  456. \"data:0.737\" 1161.655066 \n",
            "  457. \"data:0.164\" 1108.274753 \n",
            "  458. \"data:0.221\" 1107.268864 \n",
            "  459. \"data:0.620\" 1060.732616 \n",
            "  460. \"data:0.284\" 1039.160318 \n",
            "  461.  \"data:0.73\" 1013.361987 \n",
            "  462. \"data:0.584\" 984.330783 \n",
            "  463. \"data:0.135\" 962.581418 \n",
            "  464. \"data:0.738\" 921.641419 \n",
            "  465.  \"data:0.92\" 909.115440 \n",
            "  466. \"data:0.705\" 902.021074 \n",
            "  467. \"data:0.228\" 849.067062 \n",
            "  468. \"data:0.256\" 844.281445 \n",
            "  469.  \"data:0.66\" 828.668083 \n",
            "  470. \"data:0.119\" 749.172127 \n",
            "  471. \"data:0.693\" 737.618794 \n",
            "  472. \"data:0.473\" 735.783501 \n",
            "  473. \"data:0.501\" 730.190907 \n",
            "  474. \"data:0.746\" 717.599893 \n",
            "  475. \"data:0.200\" 625.305405 \n",
            "  476. \"data:0.648\" 602.910969 \n",
            "  477. \"data:0.563\" 579.031150 \n",
            "  478. \"data:0.529\" 548.981665 \n",
            "  479.  \"data:0.72\" 543.092953 \n",
            "  480. \"data:0.507\" 541.890459 \n",
            "  481. \"data:0.106\" 523.197145 \n",
            "  482. \"data:0.305\" 478.127557 \n",
            "  483. \"data:0.666\" 473.474954 \n",
            "  484. \"data:0.445\" 463.991521 \n",
            "  485. \"data:0.639\" 455.746051 \n",
            "  486. \"data:0.535\" 438.689988 \n",
            "  487. \"data:0.193\" 405.158445 \n",
            "  488.  \"data:0.91\" 381.507816 \n",
            "  489.  \"data:0.74\" 375.983496 \n",
            "  490. \"data:0.747\" 375.174581 \n",
            "  491. \"data:0.736\" 365.360945 \n",
            "  492. \"data:0.676\" 353.138881 \n",
            "  493. \"data:0.694\" 310.035634 \n",
            "  494. \"data:0.145\" 293.780555 \n",
            "  495. \"data:0.721\" 274.158376 \n",
            "  496.  \"data:0.63\" 253.945866 \n",
            "  497.  \"data:0.75\" 240.886316 \n",
            "  498. \"data:0.612\" 236.192174 \n",
            "  499. \"data:0.748\" 201.430831 \n",
            "  500. \"data:0.417\" 201.149899 \n",
            "  501. \"data:0.311\" 193.220650 \n",
            "  502. \"data:0.136\" 181.901302 \n",
            "  503. \"data:0.479\" 173.108676 \n",
            "  504. \"data:0.107\" 165.485925 \n",
            "  505. \"data:0.118\" 163.610336 \n",
            "  506.  \"data:0.64\" 162.138581 \n",
            "  507. \"data:0.361\" 160.791744 \n",
            "  508.  \"data:0.65\" 160.145339 \n",
            "  509. \"data:0.165\" 149.010386 \n",
            "  510. \"data:0.339\" 142.619876 \n",
            "  511. \"data:0.557\" 131.571550 \n",
            "  512. \"data:0.333\" 129.017903 \n",
            "  513. \"data:0.619\" 127.971210 \n",
            "  514. \"data:0.172\" 123.571357 \n",
            "  515. \"data:0.451\" 121.252715 \n",
            "  516. \"data:0.591\" 119.978947 \n",
            "  517. \"data:0.474\" 118.650810 \n",
            "  518. \"data:0.733\" 117.157155 \n",
            "  519. \"data:0.734\" 110.315912 \n",
            "  520. \"data:0.283\" 102.734578 \n",
            "  521.  \"data:0.76\" 102.722989 \n",
            "  522. \"data:0.278\" 101.397955 \n",
            "  523. \"data:0.722\" 99.050530 \n",
            "  524. \"data:0.423\" 97.318718 \n",
            "  525. \"data:0.222\" 95.537655 \n",
            "  526. \"data:0.199\" 90.963873 \n",
            "  527. \"data:0.367\" 88.832033 \n",
            "  528. \"data:0.389\" 83.362061 \n",
            "  529. \"data:0.704\" 80.307500 \n",
            "  530. \"data:0.735\" 78.210490 \n",
            "  531. \"data:0.732\" 76.568675 \n",
            "  532. \"data:0.640\" 73.012925 \n",
            "  533. \"data:0.227\" 71.159892 \n",
            "  534. \"data:0.306\" 61.658560 \n",
            "  535. \"data:0.667\" 59.474778 \n",
            "  536. \"data:0.418\" 55.680426 \n",
            "  537.  \"data:0.78\" 52.753303 \n",
            "  538. \"data:0.585\" 52.277192 \n",
            "  539. \"data:0.338\" 44.097637 \n",
            "  540. \"data:0.695\" 42.917231 \n",
            "  541. \"data:0.255\" 41.019461 \n",
            "  542. \"data:0.446\" 40.052230 \n",
            "  543. \"data:0.534\" 39.319992 \n",
            "  544. \"data:0.117\" 38.603263 \n",
            "  545. \"data:0.108\" 38.470051 \n",
            "  546. \"data:0.668\" 34.487597 \n",
            "  547. \"data:0.647\" 33.761990 \n",
            "  548. \"data:0.530\" 31.798481 \n",
            "  549. \"data:0.395\" 31.018949 \n",
            "  550.  \"data:0.90\" 25.815629 \n",
            "  551. \"data:0.362\" 24.705570 \n",
            "  552.  \"data:0.77\" 24.487465 \n",
            "  553. \"data:0.562\" 24.432385 \n",
            "  554. \"data:0.675\" 23.806231 \n",
            "  555. \"data:0.310\" 22.257103 \n",
            "  556. \"data:0.506\" 22.185824 \n",
            "  557. \"data:0.749\" 21.220965 \n",
            "  558. \"data:0.703\" 19.671769 \n",
            "  559. \"data:0.137\" 18.980210 \n",
            "  560. \"data:0.723\" 18.177557 \n",
            "  561. \"data:0.171\" 17.861846 \n",
            "  562. \"data:0.613\" 17.441620 \n",
            "  563. \"data:0.478\" 16.491313 \n",
            "  564. \"data:0.143\" 15.202583 \n",
            "  565. \"data:0.254\" 14.409727 \n",
            "  566. \"data:0.614\" 13.171670 \n",
            "  567. \"data:0.775\" 12.937472 \n",
            "  568. \"data:0.250\" 10.950348 \n",
            "  569. \"data:0.282\" 10.236112 \n",
            "  570. \"data:0.194\"  9.787043 \n",
            "  571. \"data:0.590\"  7.052012 \n",
            "  572. \"data:0.696\"  6.900814 \n",
            "  573. \"data:0.770\"  4.228105 \n",
            "  574. \"data:0.144\"  3.726418 \n",
            "  575. \"data:0.771\"  3.629153 \n",
            "  576. \"data:0.772\"  3.530150 \n",
            "  577.  \"data:0.48\"  3.382963 \n",
            "  578. \"data:0.773\"  3.149592 \n",
            "  579. \"data:0.768\"  2.743585 \n",
            "  580.  \"data:0.42\"  2.659725 \n",
            "  581. \"data:0.558\"  2.041676 \n",
            "  582. \"data:0.390\"  1.638966 \n",
            "  583.  \"data:0.89\"  0.748818 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: true\n",
            "Out-of-bag evaluation: accuracy:0.966867 logloss:0.224047\n",
            "Number of trees: 500\n",
            "Total number of nodes: 2333144\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 500 Average: 4666.29 StdDev: 106.476\n",
            "Min: 4361 Max: 4935 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 4361, 4389)  2   0.40%   0.40%\n",
            "[ 4389, 4418)  4   0.80%   1.20% #\n",
            "[ 4418, 4447)  6   1.20%   2.40% #\n",
            "[ 4447, 4476)  8   1.60%   4.00% #\n",
            "[ 4476, 4504) 15   3.00%   7.00% ##\n",
            "[ 4504, 4533) 21   4.20%  11.20% ###\n",
            "[ 4533, 4562) 23   4.60%  15.80% ####\n",
            "[ 4562, 4591) 30   6.00%  21.80% #####\n",
            "[ 4591, 4619) 50  10.00%  31.80% ########\n",
            "[ 4619, 4648) 61  12.20%  44.00% ##########\n",
            "[ 4648, 4677) 55  11.00%  55.00% #########\n",
            "[ 4677, 4706) 48   9.60%  64.60% ########\n",
            "[ 4706, 4734) 49   9.80%  74.40% ########\n",
            "[ 4734, 4763) 33   6.60%  81.00% #####\n",
            "[ 4763, 4792) 30   6.00%  87.00% #####\n",
            "[ 4792, 4821) 23   4.60%  91.60% ####\n",
            "[ 4821, 4849) 19   3.80%  95.40% ###\n",
            "[ 4849, 4878) 10   2.00%  97.40% ##\n",
            "[ 4878, 4907) 11   2.20%  99.60% ##\n",
            "[ 4907, 4935]  2   0.40% 100.00%\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 1.16682e+06 Average: 12.0896 StdDev: 1.63601\n",
            "Min: 5 Max: 15 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  5,  6)      4   0.00%   0.00%\n",
            "[  6,  7)     95   0.01%   0.01%\n",
            "[  7,  8)   1184   0.10%   0.11%\n",
            "[  8,  9)   9999   0.86%   0.97%\n",
            "[  9, 10)  49380   4.23%   5.20% ##\n",
            "[ 10, 11) 137084  11.75%  16.95% #####\n",
            "[ 11, 12) 236304  20.25%  37.20% #########\n",
            "[ 12, 13) 269752  23.12%  60.32% ##########\n",
            "[ 13, 14) 219978  18.85%  79.17% ########\n",
            "[ 14, 15) 139446  11.95%  91.12% #####\n",
            "[ 15, 15] 103596   8.88% 100.00% ####\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 1.16682e+06 Average: 25.7109 StdDev: 118.813\n",
            "Min: 5 Max: 4992 Ignored: 0\n",
            "----------------------------------------------\n",
            "[    5,  254) 1.15e+06  98.56%  98.56% ##########\n",
            "[  254,  503)     9483   0.81%  99.37%\n",
            "[  503,  753)     2940   0.25%  99.62%\n",
            "[  753, 1002)     1454   0.12%  99.75%\n",
            "[ 1002, 1252)      791   0.07%  99.81%\n",
            "[ 1252, 1501)      516   0.04%  99.86%\n",
            "[ 1501, 1750)      327   0.03%  99.89%\n",
            "[ 1750, 2000)      321   0.03%  99.91%\n",
            "[ 2000, 2249)      268   0.02%  99.94%\n",
            "[ 2249, 2499)      187   0.02%  99.95%\n",
            "[ 2499, 2748)      117   0.01%  99.96%\n",
            "[ 2748, 2997)       78   0.01%  99.97%\n",
            "[ 2997, 3247)       64   0.01%  99.98%\n",
            "[ 3247, 3496)       54   0.00%  99.98%\n",
            "[ 3496, 3746)       64   0.01%  99.99%\n",
            "[ 3746, 3995)       39   0.00%  99.99%\n",
            "[ 3995, 4244)       48   0.00%  99.99%\n",
            "[ 4244, 4494)       35   0.00% 100.00%\n",
            "[ 4494, 4743)       26   0.00% 100.00%\n",
            "[ 4743, 4992]       15   0.00% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t6503 : data:0.267 [NUMERICAL]\n",
            "\t6467 : data:0.296 [NUMERICAL]\n",
            "\t6439 : data:0.295 [NUMERICAL]\n",
            "\t6407 : data:0.211 [NUMERICAL]\n",
            "\t6337 : data:0.294 [NUMERICAL]\n",
            "\t6210 : data:0.378 [NUMERICAL]\n",
            "\t6198 : data:0.322 [NUMERICAL]\n",
            "\t6153 : data:0.266 [NUMERICAL]\n",
            "\t6121 : data:0.297 [NUMERICAL]\n",
            "\t6114 : data:0.268 [NUMERICAL]\n",
            "\t6110 : data:0.239 [NUMERICAL]\n",
            "\t6076 : data:0.324 [NUMERICAL]\n",
            "\t6048 : data:0.323 [NUMERICAL]\n",
            "\t6044 : data:0.210 [NUMERICAL]\n",
            "\t6043 : data:0.321 [NUMERICAL]\n",
            "\t6035 : data:0.293 [NUMERICAL]\n",
            "\t6031 : data:0.350 [NUMERICAL]\n",
            "\t6017 : data:0.351 [NUMERICAL]\n",
            "\t5996 : data:0.320 [NUMERICAL]\n",
            "\t5943 : data:0.212 [NUMERICAL]\n",
            "\t5926 : data:0.269 [NUMERICAL]\n",
            "\t5859 : data:0.347 [NUMERICAL]\n",
            "\t5857 : data:0.352 [NUMERICAL]\n",
            "\t5820 : data:0.292 [NUMERICAL]\n",
            "\t5803 : data:0.325 [NUMERICAL]\n",
            "\t5787 : data:0.487 [NUMERICAL]\n",
            "\t5786 : data:0.319 [NUMERICAL]\n",
            "\t5744 : data:0.238 [NUMERICAL]\n",
            "\t5735 : data:0.348 [NUMERICAL]\n",
            "\t5699 : data:0.515 [NUMERICAL]\n",
            "\t5697 : data:0.377 [NUMERICAL]\n",
            "\t5684 : data:0.240 [NUMERICAL]\n",
            "\t5572 : data:0.405 [NUMERICAL]\n",
            "\t5566 : data:0.375 [NUMERICAL]\n",
            "\t5554 : data:0.349 [NUMERICAL]\n",
            "\t5514 : data:0.353 [NUMERICAL]\n",
            "\t5503 : data:0.406 [NUMERICAL]\n",
            "\t5500 : data:0.488 [NUMERICAL]\n",
            "\t5473 : data:0.265 [NUMERICAL]\n",
            "\t5472 : data:0.376 [NUMERICAL]\n",
            "\t5460 : data:0.486 [NUMERICAL]\n",
            "\t5460 : data:0.291 [NUMERICAL]\n",
            "\t5457 : data:0.543 [NUMERICAL]\n",
            "\t5453 : data:0.516 [NUMERICAL]\n",
            "\t5423 : data:0.379 [NUMERICAL]\n",
            "\t5415 : data:0.380 [NUMERICAL]\n",
            "\t5371 : data:0.514 [NUMERICAL]\n",
            "\t5280 : data:0.209 [NUMERICAL]\n",
            "\t5264 : data:0.241 [NUMERICAL]\n",
            "\t5247 : data:0.237 [NUMERICAL]\n",
            "\t5243 : data:0.213 [NUMERICAL]\n",
            "\t5238 : data:0.544 [NUMERICAL]\n",
            "\t5232 : data:0.490 [NUMERICAL]\n",
            "\t5231 : data:0.326 [NUMERICAL]\n",
            "\t5220 : data:0.433 [NUMERICAL]\n",
            "\t5212 : data:0.264 [NUMERICAL]\n",
            "\t5205 : data:0.381 [NUMERICAL]\n",
            "\t5174 : data:0.461 [NUMERICAL]\n",
            "\t5162 : data:0.459 [NUMERICAL]\n",
            "\t5143 : data:0.318 [NUMERICAL]\n",
            "\t5141 : data:0.298 [NUMERICAL]\n",
            "\t5125 : data:0.346 [NUMERICAL]\n",
            "\t5071 : data:0.183 [NUMERICAL]\n",
            "\t5063 : data:0.374 [NUMERICAL]\n",
            "\t5058 : data:0.404 [NUMERICAL]\n",
            "\t5047 : data:0.270 [NUMERICAL]\n",
            "\t5009 : data:0.458 [NUMERICAL]\n",
            "\t5006 : data:0.354 [NUMERICAL]\n",
            "\t5005 : data:0.407 [NUMERICAL]\n",
            "\t5002 : data:0.460 [NUMERICAL]\n",
            "\t4998 : data:0.517 [NUMERICAL]\n",
            "\t4992 : data:0.437 [NUMERICAL]\n",
            "\t4991 : data:0.434 [NUMERICAL]\n",
            "\t4988 : data:0.409 [NUMERICAL]\n",
            "\t4980 : data:0.489 [NUMERICAL]\n",
            "\t4954 : data:0.462 [NUMERICAL]\n",
            "\t4904 : data:0.572 [NUMERICAL]\n",
            "\t4896 : data:0.464 [NUMERICAL]\n",
            "\t4867 : data:0.408 [NUMERICAL]\n",
            "\t4863 : data:0.436 [NUMERICAL]\n",
            "\t4848 : data:0.403 [NUMERICAL]\n",
            "\t4837 : data:0.457 [NUMERICAL]\n",
            "\t4812 : data:0.485 [NUMERICAL]\n",
            "\t4810 : data:0.518 [NUMERICAL]\n",
            "\t4807 : data:0.491 [NUMERICAL]\n",
            "\t4802 : data:0.236 [NUMERICAL]\n",
            "\t4801 : data:0.432 [NUMERICAL]\n",
            "\t4789 : data:0.542 [NUMERICAL]\n",
            "\t4788 : data:0.290 [NUMERICAL]\n",
            "\t4786 : data:0.184 [NUMERICAL]\n",
            "\t4775 : data:0.430 [NUMERICAL]\n",
            "\t4740 : data:0.463 [NUMERICAL]\n",
            "\t4722 : data:0.571 [NUMERICAL]\n",
            "\t4707 : data:0.182 [NUMERICAL]\n",
            "\t4701 : data:0.263 [NUMERICAL]\n",
            "\t4657 : data:0.402 [NUMERICAL]\n",
            "\t4640 : data:0.545 [NUMERICAL]\n",
            "\t4634 : data:0.431 [NUMERICAL]\n",
            "\t4616 : data:0.573 [NUMERICAL]\n",
            "\t4581 : data:0.656 [NUMERICAL]\n",
            "\t4546 : data:0.242 [NUMERICAL]\n",
            "\t4539 : data:0.214 [NUMERICAL]\n",
            "\t4535 : data:0.429 [NUMERICAL]\n",
            "\t4499 : data:0.208 [NUMERICAL]\n",
            "\t4490 : data:0.435 [NUMERICAL]\n",
            "\t4450 : data:0.345 [NUMERICAL]\n",
            "\t4442 : data:0.657 [NUMERICAL]\n",
            "\t4416 : data:0.299 [NUMERICAL]\n",
            "\t4389 : data:0.185 [NUMERICAL]\n",
            "\t4329 : data:0.465 [NUMERICAL]\n",
            "\t4325 : data:0.546 [NUMERICAL]\n",
            "\t4321 : data:0.317 [NUMERICAL]\n",
            "\t4318 : data:0.181 [NUMERICAL]\n",
            "\t4297 : data:0.382 [NUMERICAL]\n",
            "\t4294 : data:0.574 [NUMERICAL]\n",
            "\t4273 : data:0.401 [NUMERICAL]\n",
            "\t4253 : data:0.155 [NUMERICAL]\n",
            "\t4243 : data:0.235 [NUMERICAL]\n",
            "\t4239 : data:0.492 [NUMERICAL]\n",
            "\t4232 : data:0.271 [NUMERICAL]\n",
            "\t4221 : data:0.373 [NUMERICAL]\n",
            "\t4219 : data:0.513 [NUMERICAL]\n",
            "\t4200 : data:0.438 [NUMERICAL]\n",
            "\t4145 : data:0.327 [NUMERICAL]\n",
            "\t4142 : data:0.410 [NUMERICAL]\n",
            "\t4129 : data:0.519 [NUMERICAL]\n",
            "\t4124 : data:0.154 [NUMERICAL]\n",
            "\t4082 : data:0.655 [NUMERICAL]\n",
            "\t4054 : data:0.456 [NUMERICAL]\n",
            "\t4012 : data:0.658 [NUMERICAL]\n",
            "\t4005 : data:0.570 [NUMERICAL]\n",
            "\t3993 : data:0.262 [NUMERICAL]\n",
            "\t3991 : data:0.428 [NUMERICAL]\n",
            "\t3933 : data:0.156 [NUMERICAL]\n",
            "\t3918 : data:0.575 [NUMERICAL]\n",
            "\t3914 : data:0.289 [NUMERICAL]\n",
            "\t3887 : data:0.541 [NUMERICAL]\n",
            "\t3858 : data:0.243 [NUMERICAL]\n",
            "\t3848 : data:0.355 [NUMERICAL]\n",
            "\t3830 : data:0.601 [NUMERICAL]\n",
            "\t3785 : data:0.153 [NUMERICAL]\n",
            "\t3767 : data:0.180 [NUMERICAL]\n",
            "\t3765 : data:0.484 [NUMERICAL]\n",
            "\t3743 : data:0.207 [NUMERICAL]\n",
            "\t3736 : data:0.600 [NUMERICAL]\n",
            "\t3725 : data:0.547 [NUMERICAL]\n",
            "\t3709 : data:0.186 [NUMERICAL]\n",
            "\t3695 : data:0.602 [NUMERICAL]\n",
            "\t3668 : data:0.466 [NUMERICAL]\n",
            "\t3655 : data:0.493 [NUMERICAL]\n",
            "\t3646 : data:0.520 [NUMERICAL]\n",
            "\t3585 : data:0.576 [NUMERICAL]\n",
            "\t3577 : data:0.599 [NUMERICAL]\n",
            "\t3539 : data:0.629 [NUMERICAL]\n",
            "\t3518 : data:0.215 [NUMERICAL]\n",
            "\t3502 : data:0.157 [NUMERICAL]\n",
            "\t3494 : data:0.603 [NUMERICAL]\n",
            "\t3454 : data:0.628 [NUMERICAL]\n",
            "\t3451 : data:0.400 [NUMERICAL]\n",
            "\t3388 : data:0.627 [NUMERICAL]\n",
            "\t3384 : data:0.439 [NUMERICAL]\n",
            "\t3377 : data:0.630 [NUMERICAL]\n",
            "\t3365 : data:0.659 [NUMERICAL]\n",
            "\t3364 : data:0.344 [NUMERICAL]\n",
            "\t3361 : data:0.548 [NUMERICAL]\n",
            "\t3356 : data:0.234 [NUMERICAL]\n",
            "\t3335 : data:0.372 [NUMERICAL]\n",
            "\t3317 : data:0.512 [NUMERICAL]\n",
            "\t3316 : data:0.179 [NUMERICAL]\n",
            "\t3298 : data:0.569 [NUMERICAL]\n",
            "\t3290 : data:0.467 [NUMERICAL]\n",
            "\t3289 : data:0.521 [NUMERICAL]\n",
            "\t3275 : data:0.152 [NUMERICAL]\n",
            "\t3273 : data:0.654 [NUMERICAL]\n",
            "\t3261 : data:0.383 [NUMERICAL]\n",
            "\t3243 : data:0.631 [NUMERICAL]\n",
            "\t3220 : data:0.316 [NUMERICAL]\n",
            "\t3184 : data:0.411 [NUMERICAL]\n",
            "\t3179 : data:0.626 [NUMERICAL]\n",
            "\t3169 : data:0.328 [NUMERICAL]\n",
            "\t3136 : data:0.577 [NUMERICAL]\n",
            "\t3130 : data:0.549 [NUMERICAL]\n",
            "\t3130 : data:0.272 [NUMERICAL]\n",
            "\t3121 : data:0.300 [NUMERICAL]\n",
            "\t3118 : data:0.604 [NUMERICAL]\n",
            "\t3118 : data:0.206 [NUMERICAL]\n",
            "\t3090 : data:0.261 [NUMERICAL]\n",
            "\t3010 : data:0.598 [NUMERICAL]\n",
            "\t3010 : data:0.494 [NUMERICAL]\n",
            "\t3005 : data:0.550 [NUMERICAL]\n",
            "\t2990 : data:0.455 [NUMERICAL]\n",
            "\t2980 : data:0.540 [NUMERICAL]\n",
            "\t2923 : data:0.187 [NUMERICAL]\n",
            "\t2884 : data:0.522 [NUMERICAL]\n",
            "\t2884 : data:0.244 [NUMERICAL]\n",
            "\t2835 : data:0.625 [NUMERICAL]\n",
            "\t2816 : data:0.483 [NUMERICAL]\n",
            "\t2814 : data:0.178 [NUMERICAL]\n",
            "\t2804 : data:0.356 [NUMERICAL]\n",
            "\t2799 : data:0.427 [NUMERICAL]\n",
            "\t2791 : data:0.158 [NUMERICAL]\n",
            "\t2754 : data:0.632 [NUMERICAL]\n",
            "\t2753 : data:0.578 [NUMERICAL]\n",
            "\t2749 : data:0.568 [NUMERICAL]\n",
            "\t2744 : data:0.597 [NUMERICAL]\n",
            "\t2734 : data:0.151 [NUMERICAL]\n",
            "\t2700 : data:0.288 [NUMERICAL]\n",
            "\t2699 : data:0.495 [NUMERICAL]\n",
            "\t2694 : data:0.216 [NUMERICAL]\n",
            "\t2693 : data:0.605 [NUMERICAL]\n",
            "\t2600 : data:0.233 [NUMERICAL]\n",
            "\t2557 : data:0.523 [NUMERICAL]\n",
            "\t2544 : data:0.596 [NUMERICAL]\n",
            "\t2526 : data:0.660 [NUMERICAL]\n",
            "\t2491 : data:0.399 [NUMERICAL]\n",
            "\t2445 : data:0.633 [NUMERICAL]\n",
            "\t2442 : data:0.511 [NUMERICAL]\n",
            "\t2426 : data:0.551 [NUMERICAL]\n",
            "\t2422 : data:0.606 [NUMERICAL]\n",
            "\t2363 : data:0.440 [NUMERICAL]\n",
            "\t2337 : data:0.539 [NUMERICAL]\n",
            "\t2333 : data:0.468 [NUMERICAL]\n",
            "\t2328 : data:0.205 [NUMERICAL]\n",
            "\t2321 : data:0.653 [NUMERICAL]\n",
            "\t2309 : data:0.371 [NUMERICAL]\n",
            "\t2289 : data:0.245 [NUMERICAL]\n",
            "\t2266 : data:0.188 [NUMERICAL]\n",
            "\t2260 : data:0.343 [NUMERICAL]\n",
            "\t2259 : data:0.384 [NUMERICAL]\n",
            "\t2236 : data:0.567 [NUMERICAL]\n",
            "\t2227 : data:0.260 [NUMERICAL]\n",
            "\t2179 : data:0.273 [NUMERICAL]\n",
            "\t2147 : data:0.579 [NUMERICAL]\n",
            "\t2136 : data:0.624 [NUMERICAL]\n",
            "\t2131 : data:0.412 [NUMERICAL]\n",
            "\t2127 : data:0.301 [NUMERICAL]\n",
            "\t2109 : data:0.496 [NUMERICAL]\n",
            "\t2062 : data:0.315 [NUMERICAL]\n",
            "\t2055 : data:0.329 [NUMERICAL]\n",
            "\t2055 : data:0.177 [NUMERICAL]\n",
            "\t2001 : data:0.217 [NUMERICAL]\n",
            "\t1998 : data:0.159 [NUMERICAL]\n",
            "\t1918 : data:0.634 [NUMERICAL]\n",
            "\t1910 : data:0.150 [NUMERICAL]\n",
            "\t1897 : data:0.595 [NUMERICAL]\n",
            "\t1895 : data:0.524 [NUMERICAL]\n",
            "\t1866 : data:0.685 [NUMERICAL]\n",
            "\t1864 : data:0.607 [NUMERICAL]\n",
            "\t1841 : data:0.684 [NUMERICAL]\n",
            "\t1838 : data:0.661 [NUMERICAL]\n",
            "\t1799 : data:0.126 [NUMERICAL]\n",
            "\t1788 : data:0.232 [NUMERICAL]\n",
            "\t1780 : data:0.357 [NUMERICAL]\n",
            "\t1764 : data:0.552 [NUMERICAL]\n",
            "\t1728 : data:0.125 [NUMERICAL]\n",
            "\t1718 : data:0.683 [NUMERICAL]\n",
            "\t1712 : data:0.127 [NUMERICAL]\n",
            "\t1693 : data:0.189 [NUMERICAL]\n",
            "\t1691 : data:0.454 [NUMERICAL]\n",
            "\t1657 : data:0.580 [NUMERICAL]\n",
            "\t1652 : data:0.128 [NUMERICAL]\n",
            "\t1651 : data:0.510 [NUMERICAL]\n",
            "\t1625 : data:0.204 [NUMERICAL]\n",
            "\t1624 : data:0.246 [NUMERICAL]\n",
            "\t1606 : data:0.441 [NUMERICAL]\n",
            "\t1606 : data:0.426 [NUMERICAL]\n",
            "\t1571 : data:0.218 [NUMERICAL]\n",
            "\t1568 : data:0.686 [NUMERICAL]\n",
            "\t1564 : data:0.287 [NUMERICAL]\n",
            "\t1561 : data:0.652 [NUMERICAL]\n",
            "\t1558 : data:0.482 [NUMERICAL]\n",
            "\t1533 : data:0.385 [NUMERICAL]\n",
            "\t1529 : data:0.538 [NUMERICAL]\n",
            "\t1512 : data:0.623 [NUMERICAL]\n",
            "\t1505 : data:0.469 [NUMERICAL]\n",
            "\t1493 : data:0.413 [NUMERICAL]\n",
            "\t1488 : data:0.274 [NUMERICAL]\n",
            "\t1470 : data:0.398 [NUMERICAL]\n",
            "\t1457 : data:0.566 [NUMERICAL]\n",
            "\t1452 : data:0.682 [NUMERICAL]\n",
            "\t1442 : data:0.129 [NUMERICAL]\n",
            "\t1413 : data:0.124 [NUMERICAL]\n",
            "\t1395 : data:0.687 [NUMERICAL]\n",
            "\t1388 : data:0.525 [NUMERICAL]\n",
            "\t1367 : data:0.370 [NUMERICAL]\n",
            "\t1361 : data:0.497 [NUMERICAL]\n",
            "\t1335 : data:0.302 [NUMERICAL]\n",
            "\t1329 : data:0.330 [NUMERICAL]\n",
            "\t1326 : data:0.553 [NUMERICAL]\n",
            "\t1313 : data:0.176 [NUMERICAL]\n",
            "\t1281 : data:0.635 [NUMERICAL]\n",
            "\t1272 : data:0.608 [NUMERICAL]\n",
            "\t1268 : data:0.160 [NUMERICAL]\n",
            "\t1259 : data:0.358 [NUMERICAL]\n",
            "\t1258 : data:0.149 [NUMERICAL]\n",
            "\t1240 : data:0.259 [NUMERICAL]\n",
            "\t1235 : data:0.681 [NUMERICAL]\n",
            "\t1213 : data:0.130 [NUMERICAL]\n",
            "\t1211 : data:0.342 [NUMERICAL]\n",
            "\t1211 : data:0.231 [NUMERICAL]\n",
            "\t1198 : data:0.662 [NUMERICAL]\n",
            "\t1153 : data:0.581 [NUMERICAL]\n",
            "\t1130 : data:0.190 [NUMERICAL]\n",
            "\t1110 : data:0.594 [NUMERICAL]\n",
            "\t1090 : data:0.247 [NUMERICAL]\n",
            "\t1080 : data:0.219 [NUMERICAL]\n",
            "\t1067 : data:0.386 [NUMERICAL]\n",
            "\t1066 : data:0.123 [NUMERICAL]\n",
            "\t1052 : data:0.688 [NUMERICAL]\n",
            "\t1036 : data:0.498 [NUMERICAL]\n",
            "\t1031 : data:0.414 [NUMERICAL]\n",
            "\t1013 : data:0.442 [NUMERICAL]\n",
            "\t1009 : data:0.470 [NUMERICAL]\n",
            "\t1000 : data:0.131 [NUMERICAL]\n",
            "\t993 : data:0.651 [NUMERICAL]\n",
            "\t982 : data:0.314 [NUMERICAL]\n",
            "\t979 : data:0.203 [NUMERICAL]\n",
            "\t947 : data:0.275 [NUMERICAL]\n",
            "\t935 : data:0.526 [NUMERICAL]\n",
            "\t902 : data:0.161 [NUMERICAL]\n",
            "\t885 : data:0.680 [NUMERICAL]\n",
            "\t846 : data:0.286 [NUMERICAL]\n",
            "\t832 : data:0.554 [NUMERICAL]\n",
            "\t830 : data:0.622 [NUMERICAL]\n",
            "\t775 : data:0.689 [NUMERICAL]\n",
            "\t772 : data:0.609 [NUMERICAL]\n",
            "\t764 : data:0.636 [NUMERICAL]\n",
            "\t753 : data:0.509 [NUMERICAL]\n",
            "\t731 : data:0.537 [NUMERICAL]\n",
            "\t731 : data:0.481 [NUMERICAL]\n",
            "\t710 : data:0.663 [NUMERICAL]\n",
            "\t701 : data:0.711 [NUMERICAL]\n",
            "\t697 : data:0.258 [NUMERICAL]\n",
            "\t678 : data:0.101 [NUMERICAL]\n",
            "\t676 : data:0.453 [NUMERICAL]\n",
            "\t673 : data:0.122 [NUMERICAL]\n",
            "\t670 : data:0.303 [NUMERICAL]\n",
            "\t665 : data:0.191 [NUMERICAL]\n",
            "\t663 : data:0.712 [NUMERICAL]\n",
            "\t649 : data:0.132 [NUMERICAL]\n",
            "\t641 : data:0.175 [NUMERICAL]\n",
            "\t639 : data:0.425 [NUMERICAL]\n",
            "\t630 : data:0.710 [NUMERICAL]\n",
            "\t629 : data:0.582 [NUMERICAL]\n",
            "\t627 : data:0.565 [NUMERICAL]\n",
            "\t625 : data:0.100 [NUMERICAL]\n",
            "\t623 : data:0.415 [NUMERICAL]\n",
            "\t622 : data:0.331 [NUMERICAL]\n",
            "\t614 : data:0.679 [NUMERICAL]\n",
            "\t613 : data:0.397 [NUMERICAL]\n",
            "\t613 : data:0.230 [NUMERICAL]\n",
            "\t609 : data:0.148 [NUMERICAL]\n",
            "\t605 : data:0.359 [NUMERICAL]\n",
            "\t597 : data:0.713 [NUMERICAL]\n",
            "\t584 : data:0.387 [NUMERICAL]\n",
            "\t574 : data:0.102 [NUMERICAL]\n",
            "\t566 : data:0.99 [NUMERICAL]\n",
            "\t566 : data:0.714 [NUMERICAL]\n",
            "\t565 : data:0.443 [NUMERICAL]\n",
            "\t549 : data:0.690 [NUMERICAL]\n",
            "\t543 : data:0.709 [NUMERICAL]\n",
            "\t538 : data:0.248 [NUMERICAL]\n",
            "\t535 : data:0.162 [NUMERICAL]\n",
            "\t529 : data:0.527 [NUMERICAL]\n",
            "\t524 : data:0.369 [NUMERICAL]\n",
            "\t516 : data:0.471 [NUMERICAL]\n",
            "\t513 : data:0.98 [NUMERICAL]\n",
            "\t504 : data:0.593 [NUMERICAL]\n",
            "\t499 : data:0.715 [NUMERICAL]\n",
            "\t493 : data:0.499 [NUMERICAL]\n",
            "\t488 : data:0.650 [NUMERICAL]\n",
            "\t485 : data:0.341 [NUMERICAL]\n",
            "\t477 : data:0.220 [NUMERICAL]\n",
            "\t477 : data:0.202 [NUMERICAL]\n",
            "\t456 : data:0.708 [NUMERICAL]\n",
            "\t455 : data:0.716 [NUMERICAL]\n",
            "\t446 : data:0.276 [NUMERICAL]\n",
            "\t422 : data:0.555 [NUMERICAL]\n",
            "\t420 : data:0.97 [NUMERICAL]\n",
            "\t419 : data:0.103 [NUMERICAL]\n",
            "\t410 : data:0.637 [NUMERICAL]\n",
            "\t392 : data:0.664 [NUMERICAL]\n",
            "\t389 : data:0.121 [NUMERICAL]\n",
            "\t380 : data:0.313 [NUMERICAL]\n",
            "\t377 : data:0.717 [NUMERICAL]\n",
            "\t372 : data:0.610 [NUMERICAL]\n",
            "\t360 : data:0.691 [NUMERICAL]\n",
            "\t346 : data:0.96 [NUMERICAL]\n",
            "\t344 : data:0.133 [NUMERICAL]\n",
            "\t335 : data:0.621 [NUMERICAL]\n",
            "\t317 : data:0.285 [NUMERICAL]\n",
            "\t303 : data:0.678 [NUMERICAL]\n",
            "\t298 : data:0.174 [NUMERICAL]\n",
            "\t277 : data:0.147 [NUMERICAL]\n",
            "\t258 : data:0.707 [NUMERICAL]\n",
            "\t254 : data:0.718 [NUMERICAL]\n",
            "\t254 : data:0.257 [NUMERICAL]\n",
            "\t252 : data:0.536 [NUMERICAL]\n",
            "\t249 : data:0.229 [NUMERICAL]\n",
            "\t243 : data:0.583 [NUMERICAL]\n",
            "\t238 : data:0.163 [NUMERICAL]\n",
            "\t236 : data:0.304 [NUMERICAL]\n",
            "\t213 : data:0.564 [NUMERICAL]\n",
            "\t211 : data:0.95 [NUMERICAL]\n",
            "\t208 : data:0.104 [NUMERICAL]\n",
            "\t205 : data:0.692 [NUMERICAL]\n",
            "\t205 : data:0.500 [NUMERICAL]\n",
            "\t197 : data:0.192 [NUMERICAL]\n",
            "\t195 : data:0.472 [NUMERICAL]\n",
            "\t193 : data:0.508 [NUMERICAL]\n",
            "\t191 : data:0.201 [NUMERICAL]\n",
            "\t188 : data:0.444 [NUMERICAL]\n",
            "\t187 : data:0.649 [NUMERICAL]\n",
            "\t180 : data:0.528 [NUMERICAL]\n",
            "\t178 : data:0.134 [NUMERICAL]\n",
            "\t174 : data:0.120 [NUMERICAL]\n",
            "\t169 : data:0.480 [NUMERICAL]\n",
            "\t168 : data:0.719 [NUMERICAL]\n",
            "\t162 : data:0.592 [NUMERICAL]\n",
            "\t152 : data:0.94 [NUMERICAL]\n",
            "\t151 : data:0.665 [NUMERICAL]\n",
            "\t149 : data:0.416 [NUMERICAL]\n",
            "\t145 : data:0.638 [NUMERICAL]\n",
            "\t143 : data:0.340 [NUMERICAL]\n",
            "\t130 : data:0.452 [NUMERICAL]\n",
            "\t130 : data:0.388 [NUMERICAL]\n",
            "\t126 : data:0.556 [NUMERICAL]\n",
            "\t124 : data:0.396 [NUMERICAL]\n",
            "\t116 : data:0.424 [NUMERICAL]\n",
            "\t113 : data:0.677 [NUMERICAL]\n",
            "\t113 : data:0.360 [NUMERICAL]\n",
            "\t112 : data:0.611 [NUMERICAL]\n",
            "\t112 : data:0.105 [NUMERICAL]\n",
            "\t109 : data:0.332 [NUMERICAL]\n",
            "\t108 : data:0.368 [NUMERICAL]\n",
            "\t106 : data:0.146 [NUMERICAL]\n",
            "\t100 : data:0.312 [NUMERICAL]\n",
            "\t98 : data:0.173 [NUMERICAL]\n",
            "\t95 : data:0.720 [NUMERICAL]\n",
            "\t92 : data:0.742 [NUMERICAL]\n",
            "\t92 : data:0.706 [NUMERICAL]\n",
            "\t90 : data:0.743 [NUMERICAL]\n",
            "\t89 : data:0.256 [NUMERICAL]\n",
            "\t89 : data:0.164 [NUMERICAL]\n",
            "\t84 : data:0.620 [NUMERICAL]\n",
            "\t82 : data:0.135 [NUMERICAL]\n",
            "\t81 : data:0.741 [NUMERICAL]\n",
            "\t79 : data:0.739 [NUMERICAL]\n",
            "\t78 : data:0.284 [NUMERICAL]\n",
            "\t75 : data:0.228 [NUMERICAL]\n",
            "\t72 : data:0.93 [NUMERICAL]\n",
            "\t72 : data:0.744 [NUMERICAL]\n",
            "\t68 : data:0.249 [NUMERICAL]\n",
            "\t66 : data:0.740 [NUMERICAL]\n",
            "\t64 : data:0.693 [NUMERICAL]\n",
            "\t64 : data:0.221 [NUMERICAL]\n",
            "\t61 : data:0.277 [NUMERICAL]\n",
            "\t60 : data:0.648 [NUMERICAL]\n",
            "\t56 : data:0.666 [NUMERICAL]\n",
            "\t55 : data:0.119 [NUMERICAL]\n",
            "\t54 : data:0.584 [NUMERICAL]\n",
            "\t53 : data:0.738 [NUMERICAL]\n",
            "\t52 : data:0.69 [NUMERICAL]\n",
            "\t51 : data:0.71 [NUMERICAL]\n",
            "\t50 : data:0.200 [NUMERICAL]\n",
            "\t47 : data:0.737 [NUMERICAL]\n",
            "\t47 : data:0.70 [NUMERICAL]\n",
            "\t45 : data:0.92 [NUMERICAL]\n",
            "\t45 : data:0.745 [NUMERICAL]\n",
            "\t42 : data:0.501 [NUMERICAL]\n",
            "\t41 : data:0.67 [NUMERICAL]\n",
            "\t38 : data:0.473 [NUMERICAL]\n",
            "\t37 : data:0.529 [NUMERICAL]\n",
            "\t36 : data:0.705 [NUMERICAL]\n",
            "\t36 : data:0.563 [NUMERICAL]\n",
            "\t36 : data:0.535 [NUMERICAL]\n",
            "\t36 : data:0.507 [NUMERICAL]\n",
            "\t35 : data:0.639 [NUMERICAL]\n",
            "\t35 : data:0.106 [NUMERICAL]\n",
            "\t33 : data:0.73 [NUMERICAL]\n",
            "\t33 : data:0.68 [NUMERICAL]\n",
            "\t33 : data:0.193 [NUMERICAL]\n",
            "\t33 : data:0.145 [NUMERICAL]\n",
            "\t32 : data:0.746 [NUMERICAL]\n",
            "\t31 : data:0.445 [NUMERICAL]\n",
            "\t30 : data:0.72 [NUMERICAL]\n",
            "\t30 : data:0.305 [NUMERICAL]\n",
            "\t24 : data:0.74 [NUMERICAL]\n",
            "\t24 : data:0.694 [NUMERICAL]\n",
            "\t22 : data:0.721 [NUMERICAL]\n",
            "\t21 : data:0.66 [NUMERICAL]\n",
            "\t21 : data:0.136 [NUMERICAL]\n",
            "\t20 : data:0.747 [NUMERICAL]\n",
            "\t19 : data:0.736 [NUMERICAL]\n",
            "\t19 : data:0.733 [NUMERICAL]\n",
            "\t19 : data:0.676 [NUMERICAL]\n",
            "\t18 : data:0.75 [NUMERICAL]\n",
            "\t18 : data:0.479 [NUMERICAL]\n",
            "\t17 : data:0.591 [NUMERICAL]\n",
            "\t16 : data:0.417 [NUMERICAL]\n",
            "\t16 : data:0.172 [NUMERICAL]\n",
            "\t16 : data:0.165 [NUMERICAL]\n",
            "\t16 : data:0.118 [NUMERICAL]\n",
            "\t15 : data:0.619 [NUMERICAL]\n",
            "\t15 : data:0.612 [NUMERICAL]\n",
            "\t15 : data:0.333 [NUMERICAL]\n",
            "\t14 : data:0.748 [NUMERICAL]\n",
            "\t14 : data:0.734 [NUMERICAL]\n",
            "\t14 : data:0.451 [NUMERICAL]\n",
            "\t13 : data:0.91 [NUMERICAL]\n",
            "\t13 : data:0.557 [NUMERICAL]\n",
            "\t13 : data:0.361 [NUMERICAL]\n",
            "\t13 : data:0.107 [NUMERICAL]\n",
            "\t12 : data:0.311 [NUMERICAL]\n",
            "\t10 : data:0.339 [NUMERICAL]\n",
            "\t9 : data:0.735 [NUMERICAL]\n",
            "\t9 : data:0.732 [NUMERICAL]\n",
            "\t9 : data:0.722 [NUMERICAL]\n",
            "\t9 : data:0.704 [NUMERICAL]\n",
            "\t9 : data:0.640 [NUMERICAL]\n",
            "\t9 : data:0.389 [NUMERICAL]\n",
            "\t9 : data:0.283 [NUMERICAL]\n",
            "\t8 : data:0.76 [NUMERICAL]\n",
            "\t8 : data:0.667 [NUMERICAL]\n",
            "\t8 : data:0.65 [NUMERICAL]\n",
            "\t8 : data:0.474 [NUMERICAL]\n",
            "\t8 : data:0.367 [NUMERICAL]\n",
            "\t8 : data:0.227 [NUMERICAL]\n",
            "\t7 : data:0.63 [NUMERICAL]\n",
            "\t7 : data:0.423 [NUMERICAL]\n",
            "\t6 : data:0.255 [NUMERICAL]\n",
            "\t6 : data:0.222 [NUMERICAL]\n",
            "\t5 : data:0.695 [NUMERICAL]\n",
            "\t5 : data:0.668 [NUMERICAL]\n",
            "\t5 : data:0.64 [NUMERICAL]\n",
            "\t5 : data:0.278 [NUMERICAL]\n",
            "\t5 : data:0.199 [NUMERICAL]\n",
            "\t4 : data:0.78 [NUMERICAL]\n",
            "\t4 : data:0.647 [NUMERICAL]\n",
            "\t4 : data:0.585 [NUMERICAL]\n",
            "\t4 : data:0.534 [NUMERICAL]\n",
            "\t4 : data:0.395 [NUMERICAL]\n",
            "\t4 : data:0.338 [NUMERICAL]\n",
            "\t3 : data:0.117 [NUMERICAL]\n",
            "\t3 : data:0.108 [NUMERICAL]\n",
            "\t2 : data:0.90 [NUMERICAL]\n",
            "\t2 : data:0.77 [NUMERICAL]\n",
            "\t2 : data:0.723 [NUMERICAL]\n",
            "\t2 : data:0.613 [NUMERICAL]\n",
            "\t2 : data:0.590 [NUMERICAL]\n",
            "\t2 : data:0.446 [NUMERICAL]\n",
            "\t2 : data:0.418 [NUMERICAL]\n",
            "\t2 : data:0.310 [NUMERICAL]\n",
            "\t2 : data:0.306 [NUMERICAL]\n",
            "\t2 : data:0.254 [NUMERICAL]\n",
            "\t2 : data:0.194 [NUMERICAL]\n",
            "\t2 : data:0.137 [NUMERICAL]\n",
            "\t1 : data:0.89 [NUMERICAL]\n",
            "\t1 : data:0.775 [NUMERICAL]\n",
            "\t1 : data:0.773 [NUMERICAL]\n",
            "\t1 : data:0.772 [NUMERICAL]\n",
            "\t1 : data:0.771 [NUMERICAL]\n",
            "\t1 : data:0.770 [NUMERICAL]\n",
            "\t1 : data:0.768 [NUMERICAL]\n",
            "\t1 : data:0.749 [NUMERICAL]\n",
            "\t1 : data:0.703 [NUMERICAL]\n",
            "\t1 : data:0.696 [NUMERICAL]\n",
            "\t1 : data:0.675 [NUMERICAL]\n",
            "\t1 : data:0.614 [NUMERICAL]\n",
            "\t1 : data:0.562 [NUMERICAL]\n",
            "\t1 : data:0.558 [NUMERICAL]\n",
            "\t1 : data:0.530 [NUMERICAL]\n",
            "\t1 : data:0.506 [NUMERICAL]\n",
            "\t1 : data:0.48 [NUMERICAL]\n",
            "\t1 : data:0.478 [NUMERICAL]\n",
            "\t1 : data:0.42 [NUMERICAL]\n",
            "\t1 : data:0.390 [NUMERICAL]\n",
            "\t1 : data:0.362 [NUMERICAL]\n",
            "\t1 : data:0.282 [NUMERICAL]\n",
            "\t1 : data:0.250 [NUMERICAL]\n",
            "\t1 : data:0.171 [NUMERICAL]\n",
            "\t1 : data:0.144 [NUMERICAL]\n",
            "\t1 : data:0.143 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t25 : data:0.569 [NUMERICAL]\n",
            "\t24 : data:0.378 [NUMERICAL]\n",
            "\t19 : data:0.461 [NUMERICAL]\n",
            "\t18 : data:0.377 [NUMERICAL]\n",
            "\t18 : data:0.373 [NUMERICAL]\n",
            "\t18 : data:0.350 [NUMERICAL]\n",
            "\t17 : data:0.596 [NUMERICAL]\n",
            "\t17 : data:0.568 [NUMERICAL]\n",
            "\t17 : data:0.406 [NUMERICAL]\n",
            "\t17 : data:0.155 [NUMERICAL]\n",
            "\t15 : data:0.345 [NUMERICAL]\n",
            "\t14 : data:0.405 [NUMERICAL]\n",
            "\t13 : data:0.597 [NUMERICAL]\n",
            "\t13 : data:0.489 [NUMERICAL]\n",
            "\t13 : data:0.433 [NUMERICAL]\n",
            "\t13 : data:0.409 [NUMERICAL]\n",
            "\t12 : data:0.462 [NUMERICAL]\n",
            "\t12 : data:0.428 [NUMERICAL]\n",
            "\t10 : data:0.400 [NUMERICAL]\n",
            "\t9 : data:0.567 [NUMERICAL]\n",
            "\t9 : data:0.401 [NUMERICAL]\n",
            "\t9 : data:0.346 [NUMERICAL]\n",
            "\t8 : data:0.541 [NUMERICAL]\n",
            "\t8 : data:0.515 [NUMERICAL]\n",
            "\t8 : data:0.460 [NUMERICAL]\n",
            "\t8 : data:0.434 [NUMERICAL]\n",
            "\t8 : data:0.154 [NUMERICAL]\n",
            "\t7 : data:0.290 [NUMERICAL]\n",
            "\t6 : data:0.542 [NUMERICAL]\n",
            "\t6 : data:0.488 [NUMERICAL]\n",
            "\t6 : data:0.318 [NUMERICAL]\n",
            "\t6 : data:0.156 [NUMERICAL]\n",
            "\t5 : data:0.625 [NUMERICAL]\n",
            "\t5 : data:0.374 [NUMERICAL]\n",
            "\t5 : data:0.317 [NUMERICAL]\n",
            "\t4 : data:0.523 [NUMERICAL]\n",
            "\t4 : data:0.437 [NUMERICAL]\n",
            "\t4 : data:0.372 [NUMERICAL]\n",
            "\t3 : data:0.595 [NUMERICAL]\n",
            "\t3 : data:0.550 [NUMERICAL]\n",
            "\t3 : data:0.484 [NUMERICAL]\n",
            "\t3 : data:0.429 [NUMERICAL]\n",
            "\t3 : data:0.351 [NUMERICAL]\n",
            "\t3 : data:0.157 [NUMERICAL]\n",
            "\t2 : data:0.551 [NUMERICAL]\n",
            "\t2 : data:0.540 [NUMERICAL]\n",
            "\t2 : data:0.516 [NUMERICAL]\n",
            "\t2 : data:0.514 [NUMERICAL]\n",
            "\t2 : data:0.487 [NUMERICAL]\n",
            "\t2 : data:0.457 [NUMERICAL]\n",
            "\t2 : data:0.456 [NUMERICAL]\n",
            "\t2 : data:0.436 [NUMERICAL]\n",
            "\t2 : data:0.427 [NUMERICAL]\n",
            "\t2 : data:0.407 [NUMERICAL]\n",
            "\t2 : data:0.262 [NUMERICAL]\n",
            "\t2 : data:0.153 [NUMERICAL]\n",
            "\t1 : data:0.655 [NUMERICAL]\n",
            "\t1 : data:0.626 [NUMERICAL]\n",
            "\t1 : data:0.624 [NUMERICAL]\n",
            "\t1 : data:0.598 [NUMERICAL]\n",
            "\t1 : data:0.594 [NUMERICAL]\n",
            "\t1 : data:0.543 [NUMERICAL]\n",
            "\t1 : data:0.539 [NUMERICAL]\n",
            "\t1 : data:0.524 [NUMERICAL]\n",
            "\t1 : data:0.517 [NUMERICAL]\n",
            "\t1 : data:0.513 [NUMERICAL]\n",
            "\t1 : data:0.511 [NUMERICAL]\n",
            "\t1 : data:0.496 [NUMERICAL]\n",
            "\t1 : data:0.495 [NUMERICAL]\n",
            "\t1 : data:0.490 [NUMERICAL]\n",
            "\t1 : data:0.483 [NUMERICAL]\n",
            "\t1 : data:0.463 [NUMERICAL]\n",
            "\t1 : data:0.459 [NUMERICAL]\n",
            "\t1 : data:0.458 [NUMERICAL]\n",
            "\t1 : data:0.455 [NUMERICAL]\n",
            "\t1 : data:0.432 [NUMERICAL]\n",
            "\t1 : data:0.403 [NUMERICAL]\n",
            "\t1 : data:0.402 [NUMERICAL]\n",
            "\t1 : data:0.349 [NUMERICAL]\n",
            "\t1 : data:0.344 [NUMERICAL]\n",
            "\t1 : data:0.327 [NUMERICAL]\n",
            "\t1 : data:0.319 [NUMERICAL]\n",
            "\t1 : data:0.291 [NUMERICAL]\n",
            "\t1 : data:0.263 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t48 : data:0.461 [NUMERICAL]\n",
            "\t41 : data:0.378 [NUMERICAL]\n",
            "\t40 : data:0.569 [NUMERICAL]\n",
            "\t39 : data:0.406 [NUMERICAL]\n",
            "\t36 : data:0.596 [NUMERICAL]\n",
            "\t36 : data:0.568 [NUMERICAL]\n",
            "\t35 : data:0.377 [NUMERICAL]\n",
            "\t34 : data:0.405 [NUMERICAL]\n",
            "\t33 : data:0.350 [NUMERICAL]\n",
            "\t31 : data:0.597 [NUMERICAL]\n",
            "\t30 : data:0.373 [NUMERICAL]\n",
            "\t29 : data:0.155 [NUMERICAL]\n",
            "\t28 : data:0.409 [NUMERICAL]\n",
            "\t28 : data:0.345 [NUMERICAL]\n",
            "\t25 : data:0.489 [NUMERICAL]\n",
            "\t24 : data:0.433 [NUMERICAL]\n",
            "\t22 : data:0.434 [NUMERICAL]\n",
            "\t22 : data:0.401 [NUMERICAL]\n",
            "\t22 : data:0.318 [NUMERICAL]\n",
            "\t21 : data:0.515 [NUMERICAL]\n",
            "\t21 : data:0.462 [NUMERICAL]\n",
            "\t21 : data:0.460 [NUMERICAL]\n",
            "\t21 : data:0.437 [NUMERICAL]\n",
            "\t20 : data:0.567 [NUMERICAL]\n",
            "\t20 : data:0.346 [NUMERICAL]\n",
            "\t19 : data:0.542 [NUMERICAL]\n",
            "\t18 : data:0.488 [NUMERICAL]\n",
            "\t18 : data:0.156 [NUMERICAL]\n",
            "\t17 : data:0.400 [NUMERICAL]\n",
            "\t17 : data:0.374 [NUMERICAL]\n",
            "\t17 : data:0.317 [NUMERICAL]\n",
            "\t16 : data:0.625 [NUMERICAL]\n",
            "\t16 : data:0.428 [NUMERICAL]\n",
            "\t16 : data:0.407 [NUMERICAL]\n",
            "\t16 : data:0.402 [NUMERICAL]\n",
            "\t15 : data:0.154 [NUMERICAL]\n",
            "\t14 : data:0.541 [NUMERICAL]\n",
            "\t14 : data:0.429 [NUMERICAL]\n",
            "\t14 : data:0.290 [NUMERICAL]\n",
            "\t13 : data:0.487 [NUMERICAL]\n",
            "\t11 : data:0.514 [NUMERICAL]\n",
            "\t11 : data:0.435 [NUMERICAL]\n",
            "\t11 : data:0.408 [NUMERICAL]\n",
            "\t11 : data:0.347 [NUMERICAL]\n",
            "\t10 : data:0.550 [NUMERICAL]\n",
            "\t10 : data:0.516 [NUMERICAL]\n",
            "\t10 : data:0.456 [NUMERICAL]\n",
            "\t9 : data:0.551 [NUMERICAL]\n",
            "\t9 : data:0.543 [NUMERICAL]\n",
            "\t9 : data:0.540 [NUMERICAL]\n",
            "\t9 : data:0.523 [NUMERICAL]\n",
            "\t9 : data:0.490 [NUMERICAL]\n",
            "\t9 : data:0.436 [NUMERICAL]\n",
            "\t9 : data:0.427 [NUMERICAL]\n",
            "\t9 : data:0.380 [NUMERICAL]\n",
            "\t9 : data:0.351 [NUMERICAL]\n",
            "\t8 : data:0.598 [NUMERICAL]\n",
            "\t8 : data:0.570 [NUMERICAL]\n",
            "\t8 : data:0.522 [NUMERICAL]\n",
            "\t8 : data:0.457 [NUMERICAL]\n",
            "\t8 : data:0.455 [NUMERICAL]\n",
            "\t8 : data:0.430 [NUMERICAL]\n",
            "\t8 : data:0.372 [NUMERICAL]\n",
            "\t8 : data:0.319 [NUMERICAL]\n",
            "\t8 : data:0.291 [NUMERICAL]\n",
            "\t8 : data:0.263 [NUMERICAL]\n",
            "\t7 : data:0.654 [NUMERICAL]\n",
            "\t7 : data:0.595 [NUMERICAL]\n",
            "\t7 : data:0.539 [NUMERICAL]\n",
            "\t7 : data:0.486 [NUMERICAL]\n",
            "\t7 : data:0.463 [NUMERICAL]\n",
            "\t6 : data:0.657 [NUMERICAL]\n",
            "\t6 : data:0.458 [NUMERICAL]\n",
            "\t6 : data:0.438 [NUMERICAL]\n",
            "\t6 : data:0.432 [NUMERICAL]\n",
            "\t6 : data:0.410 [NUMERICAL]\n",
            "\t6 : data:0.157 [NUMERICAL]\n",
            "\t6 : data:0.153 [NUMERICAL]\n",
            "\t5 : data:0.624 [NUMERICAL]\n",
            "\t5 : data:0.496 [NUMERICAL]\n",
            "\t5 : data:0.484 [NUMERICAL]\n",
            "\t5 : data:0.483 [NUMERICAL]\n",
            "\t5 : data:0.459 [NUMERICAL]\n",
            "\t5 : data:0.375 [NUMERICAL]\n",
            "\t5 : data:0.354 [NUMERICAL]\n",
            "\t5 : data:0.349 [NUMERICAL]\n",
            "\t5 : data:0.289 [NUMERICAL]\n",
            "\t4 : data:0.656 [NUMERICAL]\n",
            "\t4 : data:0.626 [NUMERICAL]\n",
            "\t4 : data:0.517 [NUMERICAL]\n",
            "\t4 : data:0.495 [NUMERICAL]\n",
            "\t4 : data:0.465 [NUMERICAL]\n",
            "\t4 : data:0.382 [NUMERICAL]\n",
            "\t4 : data:0.379 [NUMERICAL]\n",
            "\t4 : data:0.326 [NUMERICAL]\n",
            "\t3 : data:0.658 [NUMERICAL]\n",
            "\t3 : data:0.655 [NUMERICAL]\n",
            "\t3 : data:0.524 [NUMERICAL]\n",
            "\t3 : data:0.511 [NUMERICAL]\n",
            "\t3 : data:0.403 [NUMERICAL]\n",
            "\t3 : data:0.385 [NUMERICAL]\n",
            "\t3 : data:0.381 [NUMERICAL]\n",
            "\t3 : data:0.376 [NUMERICAL]\n",
            "\t3 : data:0.348 [NUMERICAL]\n",
            "\t3 : data:0.344 [NUMERICAL]\n",
            "\t3 : data:0.329 [NUMERICAL]\n",
            "\t3 : data:0.262 [NUMERICAL]\n",
            "\t3 : data:0.238 [NUMERICAL]\n",
            "\t3 : data:0.152 [NUMERICAL]\n",
            "\t2 : data:0.713 [NUMERICAL]\n",
            "\t2 : data:0.623 [NUMERICAL]\n",
            "\t2 : data:0.599 [NUMERICAL]\n",
            "\t2 : data:0.594 [NUMERICAL]\n",
            "\t2 : data:0.578 [NUMERICAL]\n",
            "\t2 : data:0.577 [NUMERICAL]\n",
            "\t2 : data:0.513 [NUMERICAL]\n",
            "\t2 : data:0.491 [NUMERICAL]\n",
            "\t2 : data:0.467 [NUMERICAL]\n",
            "\t2 : data:0.441 [NUMERICAL]\n",
            "\t2 : data:0.439 [NUMERICAL]\n",
            "\t2 : data:0.431 [NUMERICAL]\n",
            "\t2 : data:0.404 [NUMERICAL]\n",
            "\t2 : data:0.399 [NUMERICAL]\n",
            "\t2 : data:0.358 [NUMERICAL]\n",
            "\t2 : data:0.353 [NUMERICAL]\n",
            "\t2 : data:0.352 [NUMERICAL]\n",
            "\t2 : data:0.322 [NUMERICAL]\n",
            "\t2 : data:0.316 [NUMERICAL]\n",
            "\t2 : data:0.299 [NUMERICAL]\n",
            "\t2 : data:0.271 [NUMERICAL]\n",
            "\t2 : data:0.270 [NUMERICAL]\n",
            "\t2 : data:0.261 [NUMERICAL]\n",
            "\t2 : data:0.236 [NUMERICAL]\n",
            "\t2 : data:0.234 [NUMERICAL]\n",
            "\t2 : data:0.212 [NUMERICAL]\n",
            "\t2 : data:0.210 [NUMERICAL]\n",
            "\t2 : data:0.206 [NUMERICAL]\n",
            "\t2 : data:0.185 [NUMERICAL]\n",
            "\t2 : data:0.184 [NUMERICAL]\n",
            "\t2 : data:0.183 [NUMERICAL]\n",
            "\t2 : data:0.127 [NUMERICAL]\n",
            "\t1 : data:0.659 [NUMERICAL]\n",
            "\t1 : data:0.632 [NUMERICAL]\n",
            "\t1 : data:0.630 [NUMERICAL]\n",
            "\t1 : data:0.628 [NUMERICAL]\n",
            "\t1 : data:0.627 [NUMERICAL]\n",
            "\t1 : data:0.552 [NUMERICAL]\n",
            "\t1 : data:0.549 [NUMERICAL]\n",
            "\t1 : data:0.544 [NUMERICAL]\n",
            "\t1 : data:0.538 [NUMERICAL]\n",
            "\t1 : data:0.512 [NUMERICAL]\n",
            "\t1 : data:0.494 [NUMERICAL]\n",
            "\t1 : data:0.466 [NUMERICAL]\n",
            "\t1 : data:0.464 [NUMERICAL]\n",
            "\t1 : data:0.414 [NUMERICAL]\n",
            "\t1 : data:0.413 [NUMERICAL]\n",
            "\t1 : data:0.383 [NUMERICAL]\n",
            "\t1 : data:0.371 [NUMERICAL]\n",
            "\t1 : data:0.327 [NUMERICAL]\n",
            "\t1 : data:0.323 [NUMERICAL]\n",
            "\t1 : data:0.320 [NUMERICAL]\n",
            "\t1 : data:0.315 [NUMERICAL]\n",
            "\t1 : data:0.301 [NUMERICAL]\n",
            "\t1 : data:0.300 [NUMERICAL]\n",
            "\t1 : data:0.298 [NUMERICAL]\n",
            "\t1 : data:0.288 [NUMERICAL]\n",
            "\t1 : data:0.269 [NUMERICAL]\n",
            "\t1 : data:0.260 [NUMERICAL]\n",
            "\t1 : data:0.243 [NUMERICAL]\n",
            "\t1 : data:0.239 [NUMERICAL]\n",
            "\t1 : data:0.235 [NUMERICAL]\n",
            "\t1 : data:0.213 [NUMERICAL]\n",
            "\t1 : data:0.211 [NUMERICAL]\n",
            "\t1 : data:0.207 [NUMERICAL]\n",
            "\t1 : data:0.179 [NUMERICAL]\n",
            "\t1 : data:0.177 [NUMERICAL]\n",
            "\t1 : data:0.158 [NUMERICAL]\n",
            "\t1 : data:0.150 [NUMERICAL]\n",
            "\t1 : data:0.126 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t69 : data:0.461 [NUMERICAL]\n",
            "\t69 : data:0.378 [NUMERICAL]\n",
            "\t60 : data:0.569 [NUMERICAL]\n",
            "\t56 : data:0.406 [NUMERICAL]\n",
            "\t56 : data:0.377 [NUMERICAL]\n",
            "\t56 : data:0.350 [NUMERICAL]\n",
            "\t55 : data:0.568 [NUMERICAL]\n",
            "\t54 : data:0.155 [NUMERICAL]\n",
            "\t52 : data:0.405 [NUMERICAL]\n",
            "\t50 : data:0.542 [NUMERICAL]\n",
            "\t49 : data:0.434 [NUMERICAL]\n",
            "\t49 : data:0.409 [NUMERICAL]\n",
            "\t47 : data:0.596 [NUMERICAL]\n",
            "\t47 : data:0.515 [NUMERICAL]\n",
            "\t46 : data:0.462 [NUMERICAL]\n",
            "\t45 : data:0.373 [NUMERICAL]\n",
            "\t45 : data:0.345 [NUMERICAL]\n",
            "\t43 : data:0.597 [NUMERICAL]\n",
            "\t43 : data:0.489 [NUMERICAL]\n",
            "\t42 : data:0.401 [NUMERICAL]\n",
            "\t40 : data:0.460 [NUMERICAL]\n",
            "\t40 : data:0.437 [NUMERICAL]\n",
            "\t39 : data:0.488 [NUMERICAL]\n",
            "\t39 : data:0.433 [NUMERICAL]\n",
            "\t38 : data:0.154 [NUMERICAL]\n",
            "\t35 : data:0.570 [NUMERICAL]\n",
            "\t34 : data:0.407 [NUMERICAL]\n",
            "\t34 : data:0.346 [NUMERICAL]\n",
            "\t34 : data:0.318 [NUMERICAL]\n",
            "\t32 : data:0.374 [NUMERICAL]\n",
            "\t32 : data:0.156 [NUMERICAL]\n",
            "\t31 : data:0.541 [NUMERICAL]\n",
            "\t31 : data:0.514 [NUMERICAL]\n",
            "\t29 : data:0.543 [NUMERICAL]\n",
            "\t28 : data:0.625 [NUMERICAL]\n",
            "\t28 : data:0.428 [NUMERICAL]\n",
            "\t28 : data:0.290 [NUMERICAL]\n",
            "\t27 : data:0.567 [NUMERICAL]\n",
            "\t27 : data:0.400 [NUMERICAL]\n",
            "\t26 : data:0.487 [NUMERICAL]\n",
            "\t26 : data:0.429 [NUMERICAL]\n",
            "\t25 : data:0.550 [NUMERICAL]\n",
            "\t25 : data:0.435 [NUMERICAL]\n",
            "\t24 : data:0.540 [NUMERICAL]\n",
            "\t24 : data:0.486 [NUMERICAL]\n",
            "\t24 : data:0.375 [NUMERICAL]\n",
            "\t24 : data:0.317 [NUMERICAL]\n",
            "\t23 : data:0.595 [NUMERICAL]\n",
            "\t23 : data:0.402 [NUMERICAL]\n",
            "\t23 : data:0.349 [NUMERICAL]\n",
            "\t23 : data:0.347 [NUMERICAL]\n",
            "\t23 : data:0.291 [NUMERICAL]\n",
            "\t22 : data:0.490 [NUMERICAL]\n",
            "\t22 : data:0.408 [NUMERICAL]\n",
            "\t22 : data:0.380 [NUMERICAL]\n",
            "\t22 : data:0.153 [NUMERICAL]\n",
            "\t21 : data:0.656 [NUMERICAL]\n",
            "\t21 : data:0.598 [NUMERICAL]\n",
            "\t21 : data:0.463 [NUMERICAL]\n",
            "\t21 : data:0.432 [NUMERICAL]\n",
            "\t20 : data:0.657 [NUMERICAL]\n",
            "\t20 : data:0.654 [NUMERICAL]\n",
            "\t20 : data:0.624 [NUMERICAL]\n",
            "\t20 : data:0.456 [NUMERICAL]\n",
            "\t20 : data:0.436 [NUMERICAL]\n",
            "\t20 : data:0.430 [NUMERICAL]\n",
            "\t20 : data:0.319 [NUMERICAL]\n",
            "\t19 : data:0.626 [NUMERICAL]\n",
            "\t19 : data:0.522 [NUMERICAL]\n",
            "\t19 : data:0.516 [NUMERICAL]\n",
            "\t19 : data:0.438 [NUMERICAL]\n",
            "\t19 : data:0.381 [NUMERICAL]\n",
            "\t18 : data:0.372 [NUMERICAL]\n",
            "\t18 : data:0.263 [NUMERICAL]\n",
            "\t17 : data:0.571 [NUMERICAL]\n",
            "\t17 : data:0.551 [NUMERICAL]\n",
            "\t17 : data:0.455 [NUMERICAL]\n",
            "\t17 : data:0.358 [NUMERICAL]\n",
            "\t17 : data:0.354 [NUMERICAL]\n",
            "\t16 : data:0.483 [NUMERICAL]\n",
            "\t16 : data:0.465 [NUMERICAL]\n",
            "\t16 : data:0.427 [NUMERICAL]\n",
            "\t16 : data:0.351 [NUMERICAL]\n",
            "\t15 : data:0.539 [NUMERICAL]\n",
            "\t15 : data:0.517 [NUMERICAL]\n",
            "\t15 : data:0.376 [NUMERICAL]\n",
            "\t14 : data:0.655 [NUMERICAL]\n",
            "\t14 : data:0.484 [NUMERICAL]\n",
            "\t14 : data:0.458 [NUMERICAL]\n",
            "\t14 : data:0.403 [NUMERICAL]\n",
            "\t14 : data:0.262 [NUMERICAL]\n",
            "\t14 : data:0.157 [NUMERICAL]\n",
            "\t13 : data:0.658 [NUMERICAL]\n",
            "\t13 : data:0.523 [NUMERICAL]\n",
            "\t13 : data:0.459 [NUMERICAL]\n",
            "\t13 : data:0.410 [NUMERICAL]\n",
            "\t13 : data:0.352 [NUMERICAL]\n",
            "\t12 : data:0.457 [NUMERICAL]\n",
            "\t12 : data:0.382 [NUMERICAL]\n",
            "\t12 : data:0.379 [NUMERICAL]\n",
            "\t12 : data:0.348 [NUMERICAL]\n",
            "\t12 : data:0.211 [NUMERICAL]\n",
            "\t11 : data:0.513 [NUMERICAL]\n",
            "\t11 : data:0.485 [NUMERICAL]\n",
            "\t11 : data:0.385 [NUMERICAL]\n",
            "\t10 : data:0.464 [NUMERICAL]\n",
            "\t10 : data:0.431 [NUMERICAL]\n",
            "\t10 : data:0.326 [NUMERICAL]\n",
            "\t10 : data:0.212 [NUMERICAL]\n",
            "\t10 : data:0.185 [NUMERICAL]\n",
            "\t10 : data:0.184 [NUMERICAL]\n",
            "\t9 : data:0.659 [NUMERICAL]\n",
            "\t9 : data:0.623 [NUMERICAL]\n",
            "\t9 : data:0.496 [NUMERICAL]\n",
            "\t9 : data:0.399 [NUMERICAL]\n",
            "\t9 : data:0.298 [NUMERICAL]\n",
            "\t9 : data:0.242 [NUMERICAL]\n",
            "\t8 : data:0.578 [NUMERICAL]\n",
            "\t8 : data:0.511 [NUMERICAL]\n",
            "\t8 : data:0.329 [NUMERICAL]\n",
            "\t8 : data:0.270 [NUMERICAL]\n",
            "\t8 : data:0.240 [NUMERICAL]\n",
            "\t8 : data:0.182 [NUMERICAL]\n",
            "\t8 : data:0.152 [NUMERICAL]\n",
            "\t7 : data:0.467 [NUMERICAL]\n",
            "\t7 : data:0.404 [NUMERICAL]\n",
            "\t7 : data:0.330 [NUMERICAL]\n",
            "\t7 : data:0.322 [NUMERICAL]\n",
            "\t7 : data:0.320 [NUMERICAL]\n",
            "\t7 : data:0.261 [NUMERICAL]\n",
            "\t7 : data:0.238 [NUMERICAL]\n",
            "\t7 : data:0.183 [NUMERICAL]\n",
            "\t6 : data:0.627 [NUMERICAL]\n",
            "\t6 : data:0.599 [NUMERICAL]\n",
            "\t6 : data:0.549 [NUMERICAL]\n",
            "\t6 : data:0.538 [NUMERICAL]\n",
            "\t6 : data:0.494 [NUMERICAL]\n",
            "\t6 : data:0.441 [NUMERICAL]\n",
            "\t6 : data:0.344 [NUMERICAL]\n",
            "\t6 : data:0.323 [NUMERICAL]\n",
            "\t6 : data:0.299 [NUMERICAL]\n",
            "\t6 : data:0.289 [NUMERICAL]\n",
            "\t6 : data:0.271 [NUMERICAL]\n",
            "\t6 : data:0.239 [NUMERICAL]\n",
            "\t6 : data:0.235 [NUMERICAL]\n",
            "\t6 : data:0.234 [NUMERICAL]\n",
            "\t6 : data:0.206 [NUMERICAL]\n",
            "\t6 : data:0.179 [NUMERICAL]\n",
            "\t6 : data:0.127 [NUMERICAL]\n",
            "\t6 : data:0.126 [NUMERICAL]\n",
            "\t5 : data:0.628 [NUMERICAL]\n",
            "\t5 : data:0.552 [NUMERICAL]\n",
            "\t5 : data:0.524 [NUMERICAL]\n",
            "\t5 : data:0.521 [NUMERICAL]\n",
            "\t5 : data:0.518 [NUMERICAL]\n",
            "\t5 : data:0.512 [NUMERICAL]\n",
            "\t5 : data:0.495 [NUMERICAL]\n",
            "\t5 : data:0.386 [NUMERICAL]\n",
            "\t5 : data:0.267 [NUMERICAL]\n",
            "\t5 : data:0.260 [NUMERICAL]\n",
            "\t5 : data:0.210 [NUMERICAL]\n",
            "\t5 : data:0.207 [NUMERICAL]\n",
            "\t5 : data:0.100 [NUMERICAL]\n",
            "\t4 : data:0.99 [NUMERICAL]\n",
            "\t4 : data:0.630 [NUMERICAL]\n",
            "\t4 : data:0.594 [NUMERICAL]\n",
            "\t4 : data:0.577 [NUMERICAL]\n",
            "\t4 : data:0.572 [NUMERICAL]\n",
            "\t4 : data:0.566 [NUMERICAL]\n",
            "\t4 : data:0.491 [NUMERICAL]\n",
            "\t4 : data:0.482 [NUMERICAL]\n",
            "\t4 : data:0.466 [NUMERICAL]\n",
            "\t4 : data:0.439 [NUMERICAL]\n",
            "\t4 : data:0.414 [NUMERICAL]\n",
            "\t4 : data:0.357 [NUMERICAL]\n",
            "\t4 : data:0.301 [NUMERICAL]\n",
            "\t4 : data:0.300 [NUMERICAL]\n",
            "\t4 : data:0.273 [NUMERICAL]\n",
            "\t4 : data:0.269 [NUMERICAL]\n",
            "\t4 : data:0.244 [NUMERICAL]\n",
            "\t4 : data:0.243 [NUMERICAL]\n",
            "\t4 : data:0.205 [NUMERICAL]\n",
            "\t4 : data:0.180 [NUMERICAL]\n",
            "\t4 : data:0.178 [NUMERICAL]\n",
            "\t4 : data:0.158 [NUMERICAL]\n",
            "\t4 : data:0.128 [NUMERICAL]\n",
            "\t4 : data:0.125 [NUMERICAL]\n",
            "\t3 : data:0.686 [NUMERICAL]\n",
            "\t3 : data:0.684 [NUMERICAL]\n",
            "\t3 : data:0.653 [NUMERICAL]\n",
            "\t3 : data:0.651 [NUMERICAL]\n",
            "\t3 : data:0.580 [NUMERICAL]\n",
            "\t3 : data:0.426 [NUMERICAL]\n",
            "\t3 : data:0.371 [NUMERICAL]\n",
            "\t3 : data:0.355 [NUMERICAL]\n",
            "\t3 : data:0.353 [NUMERICAL]\n",
            "\t3 : data:0.343 [NUMERICAL]\n",
            "\t3 : data:0.327 [NUMERICAL]\n",
            "\t3 : data:0.316 [NUMERICAL]\n",
            "\t3 : data:0.315 [NUMERICAL]\n",
            "\t3 : data:0.297 [NUMERICAL]\n",
            "\t3 : data:0.295 [NUMERICAL]\n",
            "\t3 : data:0.268 [NUMERICAL]\n",
            "\t3 : data:0.266 [NUMERICAL]\n",
            "\t3 : data:0.241 [NUMERICAL]\n",
            "\t3 : data:0.236 [NUMERICAL]\n",
            "\t3 : data:0.233 [NUMERICAL]\n",
            "\t3 : data:0.214 [NUMERICAL]\n",
            "\t3 : data:0.181 [NUMERICAL]\n",
            "\t3 : data:0.151 [NUMERICAL]\n",
            "\t2 : data:0.713 [NUMERICAL]\n",
            "\t2 : data:0.685 [NUMERICAL]\n",
            "\t2 : data:0.682 [NUMERICAL]\n",
            "\t2 : data:0.632 [NUMERICAL]\n",
            "\t2 : data:0.631 [NUMERICAL]\n",
            "\t2 : data:0.603 [NUMERICAL]\n",
            "\t2 : data:0.579 [NUMERICAL]\n",
            "\t2 : data:0.576 [NUMERICAL]\n",
            "\t2 : data:0.544 [NUMERICAL]\n",
            "\t2 : data:0.510 [NUMERICAL]\n",
            "\t2 : data:0.413 [NUMERICAL]\n",
            "\t2 : data:0.328 [NUMERICAL]\n",
            "\t2 : data:0.325 [NUMERICAL]\n",
            "\t2 : data:0.292 [NUMERICAL]\n",
            "\t2 : data:0.288 [NUMERICAL]\n",
            "\t2 : data:0.232 [NUMERICAL]\n",
            "\t2 : data:0.218 [NUMERICAL]\n",
            "\t2 : data:0.213 [NUMERICAL]\n",
            "\t2 : data:0.208 [NUMERICAL]\n",
            "\t2 : data:0.150 [NUMERICAL]\n",
            "\t2 : data:0.129 [NUMERICAL]\n",
            "\t2 : data:0.124 [NUMERICAL]\n",
            "\t1 : data:0.98 [NUMERICAL]\n",
            "\t1 : data:0.97 [NUMERICAL]\n",
            "\t1 : data:0.711 [NUMERICAL]\n",
            "\t1 : data:0.708 [NUMERICAL]\n",
            "\t1 : data:0.683 [NUMERICAL]\n",
            "\t1 : data:0.681 [NUMERICAL]\n",
            "\t1 : data:0.662 [NUMERICAL]\n",
            "\t1 : data:0.652 [NUMERICAL]\n",
            "\t1 : data:0.622 [NUMERICAL]\n",
            "\t1 : data:0.606 [NUMERICAL]\n",
            "\t1 : data:0.605 [NUMERICAL]\n",
            "\t1 : data:0.601 [NUMERICAL]\n",
            "\t1 : data:0.600 [NUMERICAL]\n",
            "\t1 : data:0.581 [NUMERICAL]\n",
            "\t1 : data:0.575 [NUMERICAL]\n",
            "\t1 : data:0.545 [NUMERICAL]\n",
            "\t1 : data:0.526 [NUMERICAL]\n",
            "\t1 : data:0.497 [NUMERICAL]\n",
            "\t1 : data:0.493 [NUMERICAL]\n",
            "\t1 : data:0.492 [NUMERICAL]\n",
            "\t1 : data:0.470 [NUMERICAL]\n",
            "\t1 : data:0.468 [NUMERICAL]\n",
            "\t1 : data:0.442 [NUMERICAL]\n",
            "\t1 : data:0.425 [NUMERICAL]\n",
            "\t1 : data:0.383 [NUMERICAL]\n",
            "\t1 : data:0.359 [NUMERICAL]\n",
            "\t1 : data:0.331 [NUMERICAL]\n",
            "\t1 : data:0.324 [NUMERICAL]\n",
            "\t1 : data:0.321 [NUMERICAL]\n",
            "\t1 : data:0.302 [NUMERICAL]\n",
            "\t1 : data:0.294 [NUMERICAL]\n",
            "\t1 : data:0.272 [NUMERICAL]\n",
            "\t1 : data:0.264 [NUMERICAL]\n",
            "\t1 : data:0.245 [NUMERICAL]\n",
            "\t1 : data:0.237 [NUMERICAL]\n",
            "\t1 : data:0.215 [NUMERICAL]\n",
            "\t1 : data:0.209 [NUMERICAL]\n",
            "\t1 : data:0.186 [NUMERICAL]\n",
            "\t1 : data:0.177 [NUMERICAL]\n",
            "\t1 : data:0.102 [NUMERICAL]\n",
            "\t1 : data:0.101 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t114 : data:0.378 [NUMERICAL]\n",
            "\t107 : data:0.461 [NUMERICAL]\n",
            "\t98 : data:0.377 [NUMERICAL]\n",
            "\t92 : data:0.406 [NUMERICAL]\n",
            "\t92 : data:0.155 [NUMERICAL]\n",
            "\t87 : data:0.569 [NUMERICAL]\n",
            "\t87 : data:0.350 [NUMERICAL]\n",
            "\t85 : data:0.515 [NUMERICAL]\n",
            "\t83 : data:0.542 [NUMERICAL]\n",
            "\t83 : data:0.405 [NUMERICAL]\n",
            "\t81 : data:0.154 [NUMERICAL]\n",
            "\t79 : data:0.462 [NUMERICAL]\n",
            "\t79 : data:0.409 [NUMERICAL]\n",
            "\t78 : data:0.434 [NUMERICAL]\n",
            "\t77 : data:0.568 [NUMERICAL]\n",
            "\t75 : data:0.514 [NUMERICAL]\n",
            "\t75 : data:0.488 [NUMERICAL]\n",
            "\t73 : data:0.656 [NUMERICAL]\n",
            "\t70 : data:0.347 [NUMERICAL]\n",
            "\t69 : data:0.596 [NUMERICAL]\n",
            "\t69 : data:0.374 [NUMERICAL]\n",
            "\t65 : data:0.570 [NUMERICAL]\n",
            "\t65 : data:0.489 [NUMERICAL]\n",
            "\t65 : data:0.345 [NUMERICAL]\n",
            "\t64 : data:0.597 [NUMERICAL]\n",
            "\t64 : data:0.373 [NUMERICAL]\n",
            "\t62 : data:0.487 [NUMERICAL]\n",
            "\t62 : data:0.460 [NUMERICAL]\n",
            "\t62 : data:0.433 [NUMERICAL]\n",
            "\t62 : data:0.318 [NUMERICAL]\n",
            "\t61 : data:0.401 [NUMERICAL]\n",
            "\t60 : data:0.346 [NUMERICAL]\n",
            "\t57 : data:0.625 [NUMERICAL]\n",
            "\t57 : data:0.541 [NUMERICAL]\n",
            "\t57 : data:0.153 [NUMERICAL]\n",
            "\t55 : data:0.490 [NUMERICAL]\n",
            "\t53 : data:0.437 [NUMERICAL]\n",
            "\t53 : data:0.156 [NUMERICAL]\n",
            "\t52 : data:0.486 [NUMERICAL]\n",
            "\t51 : data:0.657 [NUMERICAL]\n",
            "\t50 : data:0.658 [NUMERICAL]\n",
            "\t50 : data:0.567 [NUMERICAL]\n",
            "\t50 : data:0.407 [NUMERICAL]\n",
            "\t49 : data:0.543 [NUMERICAL]\n",
            "\t49 : data:0.429 [NUMERICAL]\n",
            "\t47 : data:0.375 [NUMERICAL]\n",
            "\t47 : data:0.351 [NUMERICAL]\n",
            "\t45 : data:0.654 [NUMERICAL]\n",
            "\t45 : data:0.291 [NUMERICAL]\n",
            "\t44 : data:0.655 [NUMERICAL]\n",
            "\t44 : data:0.595 [NUMERICAL]\n",
            "\t43 : data:0.550 [NUMERICAL]\n",
            "\t42 : data:0.483 [NUMERICAL]\n",
            "\t42 : data:0.317 [NUMERICAL]\n",
            "\t41 : data:0.400 [NUMERICAL]\n",
            "\t40 : data:0.624 [NUMERICAL]\n",
            "\t40 : data:0.571 [NUMERICAL]\n",
            "\t40 : data:0.432 [NUMERICAL]\n",
            "\t40 : data:0.349 [NUMERICAL]\n",
            "\t39 : data:0.516 [NUMERICAL]\n",
            "\t39 : data:0.456 [NUMERICAL]\n",
            "\t39 : data:0.428 [NUMERICAL]\n",
            "\t39 : data:0.402 [NUMERICAL]\n",
            "\t39 : data:0.380 [NUMERICAL]\n",
            "\t39 : data:0.379 [NUMERICAL]\n",
            "\t39 : data:0.376 [NUMERICAL]\n",
            "\t39 : data:0.348 [NUMERICAL]\n",
            "\t39 : data:0.319 [NUMERICAL]\n",
            "\t38 : data:0.435 [NUMERICAL]\n",
            "\t38 : data:0.408 [NUMERICAL]\n",
            "\t38 : data:0.381 [NUMERICAL]\n",
            "\t38 : data:0.290 [NUMERICAL]\n",
            "\t37 : data:0.513 [NUMERICAL]\n",
            "\t37 : data:0.436 [NUMERICAL]\n",
            "\t36 : data:0.598 [NUMERICAL]\n",
            "\t36 : data:0.540 [NUMERICAL]\n",
            "\t36 : data:0.522 [NUMERICAL]\n",
            "\t36 : data:0.458 [NUMERICAL]\n",
            "\t36 : data:0.430 [NUMERICAL]\n",
            "\t36 : data:0.152 [NUMERICAL]\n",
            "\t35 : data:0.551 [NUMERICAL]\n",
            "\t35 : data:0.463 [NUMERICAL]\n",
            "\t35 : data:0.457 [NUMERICAL]\n",
            "\t35 : data:0.455 [NUMERICAL]\n",
            "\t35 : data:0.354 [NUMERICAL]\n",
            "\t34 : data:0.626 [NUMERICAL]\n",
            "\t34 : data:0.517 [NUMERICAL]\n",
            "\t34 : data:0.485 [NUMERICAL]\n",
            "\t34 : data:0.427 [NUMERICAL]\n",
            "\t33 : data:0.484 [NUMERICAL]\n",
            "\t33 : data:0.403 [NUMERICAL]\n",
            "\t33 : data:0.211 [NUMERICAL]\n",
            "\t32 : data:0.382 [NUMERICAL]\n",
            "\t31 : data:0.459 [NUMERICAL]\n",
            "\t31 : data:0.352 [NUMERICAL]\n",
            "\t30 : data:0.262 [NUMERICAL]\n",
            "\t30 : data:0.243 [NUMERICAL]\n",
            "\t29 : data:0.539 [NUMERICAL]\n",
            "\t29 : data:0.410 [NUMERICAL]\n",
            "\t28 : data:0.329 [NUMERICAL]\n",
            "\t28 : data:0.270 [NUMERICAL]\n",
            "\t28 : data:0.263 [NUMERICAL]\n",
            "\t27 : data:0.212 [NUMERICAL]\n",
            "\t26 : data:0.438 [NUMERICAL]\n",
            "\t26 : data:0.326 [NUMERICAL]\n",
            "\t26 : data:0.320 [NUMERICAL]\n",
            "\t25 : data:0.358 [NUMERICAL]\n",
            "\t25 : data:0.271 [NUMERICAL]\n",
            "\t25 : data:0.182 [NUMERICAL]\n",
            "\t24 : data:0.465 [NUMERICAL]\n",
            "\t24 : data:0.372 [NUMERICAL]\n",
            "\t24 : data:0.322 [NUMERICAL]\n",
            "\t24 : data:0.242 [NUMERICAL]\n",
            "\t23 : data:0.659 [NUMERICAL]\n",
            "\t23 : data:0.464 [NUMERICAL]\n",
            "\t23 : data:0.431 [NUMERICAL]\n",
            "\t23 : data:0.292 [NUMERICAL]\n",
            "\t23 : data:0.157 [NUMERICAL]\n",
            "\t22 : data:0.627 [NUMERICAL]\n",
            "\t22 : data:0.241 [NUMERICAL]\n",
            "\t22 : data:0.183 [NUMERICAL]\n",
            "\t21 : data:0.572 [NUMERICAL]\n",
            "\t21 : data:0.523 [NUMERICAL]\n",
            "\t21 : data:0.323 [NUMERICAL]\n",
            "\t21 : data:0.301 [NUMERICAL]\n",
            "\t21 : data:0.298 [NUMERICAL]\n",
            "\t21 : data:0.240 [NUMERICAL]\n",
            "\t21 : data:0.210 [NUMERICAL]\n",
            "\t21 : data:0.151 [NUMERICAL]\n",
            "\t20 : data:0.623 [NUMERICAL]\n",
            "\t20 : data:0.544 [NUMERICAL]\n",
            "\t20 : data:0.330 [NUMERICAL]\n",
            "\t20 : data:0.184 [NUMERICAL]\n",
            "\t19 : data:0.653 [NUMERICAL]\n",
            "\t19 : data:0.549 [NUMERICAL]\n",
            "\t19 : data:0.353 [NUMERICAL]\n",
            "\t19 : data:0.267 [NUMERICAL]\n",
            "\t19 : data:0.127 [NUMERICAL]\n",
            "\t18 : data:0.511 [NUMERICAL]\n",
            "\t18 : data:0.466 [NUMERICAL]\n",
            "\t18 : data:0.357 [NUMERICAL]\n",
            "\t18 : data:0.344 [NUMERICAL]\n",
            "\t18 : data:0.297 [NUMERICAL]\n",
            "\t18 : data:0.238 [NUMERICAL]\n",
            "\t17 : data:0.578 [NUMERICAL]\n",
            "\t17 : data:0.491 [NUMERICAL]\n",
            "\t17 : data:0.404 [NUMERICAL]\n",
            "\t17 : data:0.399 [NUMERICAL]\n",
            "\t17 : data:0.385 [NUMERICAL]\n",
            "\t17 : data:0.327 [NUMERICAL]\n",
            "\t17 : data:0.299 [NUMERICAL]\n",
            "\t17 : data:0.100 [NUMERICAL]\n",
            "\t16 : data:0.524 [NUMERICAL]\n",
            "\t16 : data:0.467 [NUMERICAL]\n",
            "\t16 : data:0.244 [NUMERICAL]\n",
            "\t16 : data:0.239 [NUMERICAL]\n",
            "\t16 : data:0.205 [NUMERICAL]\n",
            "\t16 : data:0.125 [NUMERICAL]\n",
            "\t15 : data:0.652 [NUMERICAL]\n",
            "\t15 : data:0.599 [NUMERICAL]\n",
            "\t15 : data:0.518 [NUMERICAL]\n",
            "\t15 : data:0.496 [NUMERICAL]\n",
            "\t15 : data:0.468 [NUMERICAL]\n",
            "\t15 : data:0.272 [NUMERICAL]\n",
            "\t14 : data:0.538 [NUMERICAL]\n",
            "\t14 : data:0.386 [NUMERICAL]\n",
            "\t14 : data:0.289 [NUMERICAL]\n",
            "\t14 : data:0.207 [NUMERICAL]\n",
            "\t14 : data:0.185 [NUMERICAL]\n",
            "\t13 : data:0.99 [NUMERICAL]\n",
            "\t13 : data:0.594 [NUMERICAL]\n",
            "\t13 : data:0.521 [NUMERICAL]\n",
            "\t13 : data:0.454 [NUMERICAL]\n",
            "\t13 : data:0.441 [NUMERICAL]\n",
            "\t13 : data:0.294 [NUMERICAL]\n",
            "\t13 : data:0.269 [NUMERICAL]\n",
            "\t13 : data:0.206 [NUMERICAL]\n",
            "\t13 : data:0.126 [NUMERICAL]\n",
            "\t12 : data:0.660 [NUMERICAL]\n",
            "\t12 : data:0.512 [NUMERICAL]\n",
            "\t12 : data:0.494 [NUMERICAL]\n",
            "\t12 : data:0.482 [NUMERICAL]\n",
            "\t12 : data:0.414 [NUMERICAL]\n",
            "\t12 : data:0.325 [NUMERICAL]\n",
            "\t12 : data:0.316 [NUMERICAL]\n",
            "\t12 : data:0.236 [NUMERICAL]\n",
            "\t12 : data:0.234 [NUMERICAL]\n",
            "\t12 : data:0.179 [NUMERICAL]\n",
            "\t11 : data:0.630 [NUMERICAL]\n",
            "\t11 : data:0.580 [NUMERICAL]\n",
            "\t11 : data:0.566 [NUMERICAL]\n",
            "\t11 : data:0.442 [NUMERICAL]\n",
            "\t11 : data:0.343 [NUMERICAL]\n",
            "\t11 : data:0.328 [NUMERICAL]\n",
            "\t11 : data:0.261 [NUMERICAL]\n",
            "\t11 : data:0.235 [NUMERICAL]\n",
            "\t11 : data:0.214 [NUMERICAL]\n",
            "\t11 : data:0.209 [NUMERICAL]\n",
            "\t11 : data:0.181 [NUMERICAL]\n",
            "\t11 : data:0.128 [NUMERICAL]\n",
            "\t10 : data:0.685 [NUMERICAL]\n",
            "\t10 : data:0.440 [NUMERICAL]\n",
            "\t10 : data:0.371 [NUMERICAL]\n",
            "\t10 : data:0.268 [NUMERICAL]\n",
            "\t10 : data:0.266 [NUMERICAL]\n",
            "\t10 : data:0.237 [NUMERICAL]\n",
            "\t10 : data:0.215 [NUMERICAL]\n",
            "\t10 : data:0.178 [NUMERICAL]\n",
            "\t9 : data:0.684 [NUMERICAL]\n",
            "\t9 : data:0.631 [NUMERICAL]\n",
            "\t9 : data:0.628 [NUMERICAL]\n",
            "\t9 : data:0.579 [NUMERICAL]\n",
            "\t9 : data:0.552 [NUMERICAL]\n",
            "\t9 : data:0.495 [NUMERICAL]\n",
            "\t9 : data:0.493 [NUMERICAL]\n",
            "\t9 : data:0.300 [NUMERICAL]\n",
            "\t9 : data:0.273 [NUMERICAL]\n",
            "\t9 : data:0.260 [NUMERICAL]\n",
            "\t9 : data:0.158 [NUMERICAL]\n",
            "\t9 : data:0.150 [NUMERICAL]\n",
            "\t9 : data:0.101 [NUMERICAL]\n",
            "\t8 : data:0.510 [NUMERICAL]\n",
            "\t8 : data:0.413 [NUMERICAL]\n",
            "\t8 : data:0.359 [NUMERICAL]\n",
            "\t8 : data:0.315 [NUMERICAL]\n",
            "\t8 : data:0.265 [NUMERICAL]\n",
            "\t8 : data:0.213 [NUMERICAL]\n",
            "\t8 : data:0.208 [NUMERICAL]\n",
            "\t8 : data:0.180 [NUMERICAL]\n",
            "\t8 : data:0.124 [NUMERICAL]\n",
            "\t7 : data:0.661 [NUMERICAL]\n",
            "\t7 : data:0.651 [NUMERICAL]\n",
            "\t7 : data:0.577 [NUMERICAL]\n",
            "\t7 : data:0.545 [NUMERICAL]\n",
            "\t7 : data:0.415 [NUMERICAL]\n",
            "\t7 : data:0.355 [NUMERICAL]\n",
            "\t7 : data:0.324 [NUMERICAL]\n",
            "\t7 : data:0.321 [NUMERICAL]\n",
            "\t7 : data:0.296 [NUMERICAL]\n",
            "\t7 : data:0.295 [NUMERICAL]\n",
            "\t7 : data:0.233 [NUMERICAL]\n",
            "\t6 : data:0.97 [NUMERICAL]\n",
            "\t6 : data:0.686 [NUMERICAL]\n",
            "\t6 : data:0.683 [NUMERICAL]\n",
            "\t6 : data:0.600 [NUMERICAL]\n",
            "\t6 : data:0.573 [NUMERICAL]\n",
            "\t6 : data:0.546 [NUMERICAL]\n",
            "\t6 : data:0.439 [NUMERICAL]\n",
            "\t6 : data:0.245 [NUMERICAL]\n",
            "\t5 : data:0.682 [NUMERICAL]\n",
            "\t5 : data:0.606 [NUMERICAL]\n",
            "\t5 : data:0.497 [NUMERICAL]\n",
            "\t5 : data:0.426 [NUMERICAL]\n",
            "\t5 : data:0.383 [NUMERICAL]\n",
            "\t5 : data:0.370 [NUMERICAL]\n",
            "\t5 : data:0.288 [NUMERICAL]\n",
            "\t5 : data:0.216 [NUMERICAL]\n",
            "\t4 : data:0.712 [NUMERICAL]\n",
            "\t4 : data:0.708 [NUMERICAL]\n",
            "\t4 : data:0.632 [NUMERICAL]\n",
            "\t4 : data:0.629 [NUMERICAL]\n",
            "\t4 : data:0.603 [NUMERICAL]\n",
            "\t4 : data:0.601 [NUMERICAL]\n",
            "\t4 : data:0.581 [NUMERICAL]\n",
            "\t4 : data:0.575 [NUMERICAL]\n",
            "\t4 : data:0.469 [NUMERICAL]\n",
            "\t4 : data:0.412 [NUMERICAL]\n",
            "\t4 : data:0.398 [NUMERICAL]\n",
            "\t4 : data:0.218 [NUMERICAL]\n",
            "\t4 : data:0.177 [NUMERICAL]\n",
            "\t4 : data:0.129 [NUMERICAL]\n",
            "\t4 : data:0.102 [NUMERICAL]\n",
            "\t3 : data:0.711 [NUMERICAL]\n",
            "\t3 : data:0.604 [NUMERICAL]\n",
            "\t3 : data:0.576 [NUMERICAL]\n",
            "\t3 : data:0.553 [NUMERICAL]\n",
            "\t3 : data:0.492 [NUMERICAL]\n",
            "\t3 : data:0.470 [NUMERICAL]\n",
            "\t3 : data:0.411 [NUMERICAL]\n",
            "\t3 : data:0.387 [NUMERICAL]\n",
            "\t3 : data:0.302 [NUMERICAL]\n",
            "\t3 : data:0.274 [NUMERICAL]\n",
            "\t3 : data:0.264 [NUMERICAL]\n",
            "\t3 : data:0.232 [NUMERICAL]\n",
            "\t3 : data:0.219 [NUMERICAL]\n",
            "\t3 : data:0.217 [NUMERICAL]\n",
            "\t3 : data:0.186 [NUMERICAL]\n",
            "\t2 : data:0.98 [NUMERICAL]\n",
            "\t2 : data:0.713 [NUMERICAL]\n",
            "\t2 : data:0.709 [NUMERICAL]\n",
            "\t2 : data:0.70 [NUMERICAL]\n",
            "\t2 : data:0.687 [NUMERICAL]\n",
            "\t2 : data:0.681 [NUMERICAL]\n",
            "\t2 : data:0.662 [NUMERICAL]\n",
            "\t2 : data:0.633 [NUMERICAL]\n",
            "\t2 : data:0.622 [NUMERICAL]\n",
            "\t2 : data:0.608 [NUMERICAL]\n",
            "\t2 : data:0.605 [NUMERICAL]\n",
            "\t2 : data:0.602 [NUMERICAL]\n",
            "\t2 : data:0.548 [NUMERICAL]\n",
            "\t2 : data:0.525 [NUMERICAL]\n",
            "\t2 : data:0.519 [NUMERICAL]\n",
            "\t2 : data:0.331 [NUMERICAL]\n",
            "\t2 : data:0.188 [NUMERICAL]\n",
            "\t2 : data:0.149 [NUMERICAL]\n",
            "\t2 : data:0.123 [NUMERICAL]\n",
            "\t1 : data:0.96 [NUMERICAL]\n",
            "\t1 : data:0.714 [NUMERICAL]\n",
            "\t1 : data:0.710 [NUMERICAL]\n",
            "\t1 : data:0.680 [NUMERICAL]\n",
            "\t1 : data:0.634 [NUMERICAL]\n",
            "\t1 : data:0.609 [NUMERICAL]\n",
            "\t1 : data:0.607 [NUMERICAL]\n",
            "\t1 : data:0.574 [NUMERICAL]\n",
            "\t1 : data:0.565 [NUMERICAL]\n",
            "\t1 : data:0.537 [NUMERICAL]\n",
            "\t1 : data:0.526 [NUMERICAL]\n",
            "\t1 : data:0.481 [NUMERICAL]\n",
            "\t1 : data:0.443 [NUMERICAL]\n",
            "\t1 : data:0.425 [NUMERICAL]\n",
            "\t1 : data:0.384 [NUMERICAL]\n",
            "\t1 : data:0.369 [NUMERICAL]\n",
            "\t1 : data:0.356 [NUMERICAL]\n",
            "\t1 : data:0.342 [NUMERICAL]\n",
            "\t1 : data:0.341 [NUMERICAL]\n",
            "\t1 : data:0.287 [NUMERICAL]\n",
            "\t1 : data:0.259 [NUMERICAL]\n",
            "\t1 : data:0.248 [NUMERICAL]\n",
            "\t1 : data:0.247 [NUMERICAL]\n",
            "\t1 : data:0.203 [NUMERICAL]\n",
            "\t1 : data:0.191 [NUMERICAL]\n",
            "\t1 : data:0.190 [NUMERICAL]\n",
            "\t1 : data:0.187 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t305 : data:0.656 [NUMERICAL]\n",
            "\t297 : data:0.515 [NUMERICAL]\n",
            "\t295 : data:0.378 [NUMERICAL]\n",
            "\t291 : data:0.514 [NUMERICAL]\n",
            "\t271 : data:0.542 [NUMERICAL]\n",
            "\t260 : data:0.377 [NUMERICAL]\n",
            "\t256 : data:0.657 [NUMERICAL]\n",
            "\t256 : data:0.461 [NUMERICAL]\n",
            "\t250 : data:0.155 [NUMERICAL]\n",
            "\t249 : data:0.350 [NUMERICAL]\n",
            "\t246 : data:0.487 [NUMERICAL]\n",
            "\t240 : data:0.406 [NUMERICAL]\n",
            "\t236 : data:0.543 [NUMERICAL]\n",
            "\t234 : data:0.488 [NUMERICAL]\n",
            "\t225 : data:0.655 [NUMERICAL]\n",
            "\t224 : data:0.347 [NUMERICAL]\n",
            "\t222 : data:0.434 [NUMERICAL]\n",
            "\t216 : data:0.405 [NUMERICAL]\n",
            "\t213 : data:0.486 [NUMERICAL]\n",
            "\t210 : data:0.154 [NUMERICAL]\n",
            "\t209 : data:0.658 [NUMERICAL]\n",
            "\t205 : data:0.489 [NUMERICAL]\n",
            "\t204 : data:0.462 [NUMERICAL]\n",
            "\t201 : data:0.153 [NUMERICAL]\n",
            "\t200 : data:0.569 [NUMERICAL]\n",
            "\t200 : data:0.460 [NUMERICAL]\n",
            "\t196 : data:0.490 [NUMERICAL]\n",
            "\t194 : data:0.459 [NUMERICAL]\n",
            "\t193 : data:0.351 [NUMERICAL]\n",
            "\t191 : data:0.374 [NUMERICAL]\n",
            "\t190 : data:0.654 [NUMERICAL]\n",
            "\t189 : data:0.570 [NUMERICAL]\n",
            "\t189 : data:0.457 [NUMERICAL]\n",
            "\t189 : data:0.433 [NUMERICAL]\n",
            "\t188 : data:0.318 [NUMERICAL]\n",
            "\t183 : data:0.409 [NUMERICAL]\n",
            "\t179 : data:0.458 [NUMERICAL]\n",
            "\t179 : data:0.375 [NUMERICAL]\n",
            "\t178 : data:0.516 [NUMERICAL]\n",
            "\t178 : data:0.456 [NUMERICAL]\n",
            "\t178 : data:0.346 [NUMERICAL]\n",
            "\t177 : data:0.291 [NUMERICAL]\n",
            "\t177 : data:0.156 [NUMERICAL]\n",
            "\t175 : data:0.568 [NUMERICAL]\n",
            "\t173 : data:0.345 [NUMERICAL]\n",
            "\t171 : data:0.319 [NUMERICAL]\n",
            "\t170 : data:0.376 [NUMERICAL]\n",
            "\t168 : data:0.271 [NUMERICAL]\n",
            "\t166 : data:0.541 [NUMERICAL]\n",
            "\t165 : data:0.596 [NUMERICAL]\n",
            "\t165 : data:0.381 [NUMERICAL]\n",
            "\t164 : data:0.485 [NUMERICAL]\n",
            "\t164 : data:0.270 [NUMERICAL]\n",
            "\t158 : data:0.380 [NUMERICAL]\n",
            "\t157 : data:0.625 [NUMERICAL]\n",
            "\t157 : data:0.571 [NUMERICAL]\n",
            "\t157 : data:0.353 [NUMERICAL]\n",
            "\t157 : data:0.298 [NUMERICAL]\n",
            "\t156 : data:0.513 [NUMERICAL]\n",
            "\t156 : data:0.428 [NUMERICAL]\n",
            "\t156 : data:0.299 [NUMERICAL]\n",
            "\t155 : data:0.597 [NUMERICAL]\n",
            "\t155 : data:0.379 [NUMERICAL]\n",
            "\t154 : data:0.352 [NUMERICAL]\n",
            "\t153 : data:0.349 [NUMERICAL]\n",
            "\t153 : data:0.348 [NUMERICAL]\n",
            "\t151 : data:0.326 [NUMERICAL]\n",
            "\t148 : data:0.429 [NUMERICAL]\n",
            "\t148 : data:0.354 [NUMERICAL]\n",
            "\t148 : data:0.320 [NUMERICAL]\n",
            "\t148 : data:0.290 [NUMERICAL]\n",
            "\t148 : data:0.243 [NUMERICAL]\n",
            "\t146 : data:0.544 [NUMERICAL]\n",
            "\t145 : data:0.517 [NUMERICAL]\n",
            "\t145 : data:0.484 [NUMERICAL]\n",
            "\t143 : data:0.242 [NUMERICAL]\n",
            "\t142 : data:0.437 [NUMERICAL]\n",
            "\t142 : data:0.403 [NUMERICAL]\n",
            "\t141 : data:0.402 [NUMERICAL]\n",
            "\t141 : data:0.373 [NUMERICAL]\n",
            "\t141 : data:0.269 [NUMERICAL]\n",
            "\t140 : data:0.463 [NUMERICAL]\n",
            "\t140 : data:0.401 [NUMERICAL]\n",
            "\t139 : data:0.567 [NUMERICAL]\n",
            "\t139 : data:0.407 [NUMERICAL]\n",
            "\t139 : data:0.210 [NUMERICAL]\n",
            "\t138 : data:0.455 [NUMERICAL]\n",
            "\t137 : data:0.211 [NUMERICAL]\n",
            "\t136 : data:0.626 [NUMERICAL]\n",
            "\t135 : data:0.430 [NUMERICAL]\n",
            "\t135 : data:0.400 [NUMERICAL]\n",
            "\t134 : data:0.325 [NUMERICAL]\n",
            "\t134 : data:0.272 [NUMERICAL]\n",
            "\t132 : data:0.297 [NUMERICAL]\n",
            "\t132 : data:0.152 [NUMERICAL]\n",
            "\t131 : data:0.624 [NUMERICAL]\n",
            "\t131 : data:0.317 [NUMERICAL]\n",
            "\t130 : data:0.327 [NUMERICAL]\n",
            "\t130 : data:0.322 [NUMERICAL]\n",
            "\t130 : data:0.241 [NUMERICAL]\n",
            "\t129 : data:0.292 [NUMERICAL]\n",
            "\t129 : data:0.239 [NUMERICAL]\n",
            "\t128 : data:0.408 [NUMERICAL]\n",
            "\t128 : data:0.238 [NUMERICAL]\n",
            "\t126 : data:0.436 [NUMERICAL]\n",
            "\t126 : data:0.432 [NUMERICAL]\n",
            "\t125 : data:0.323 [NUMERICAL]\n",
            "\t124 : data:0.372 [NUMERICAL]\n",
            "\t122 : data:0.212 [NUMERICAL]\n",
            "\t121 : data:0.659 [NUMERICAL]\n",
            "\t121 : data:0.572 [NUMERICAL]\n",
            "\t120 : data:0.427 [NUMERICAL]\n",
            "\t119 : data:0.483 [NUMERICAL]\n",
            "\t119 : data:0.183 [NUMERICAL]\n",
            "\t114 : data:0.491 [NUMERICAL]\n",
            "\t114 : data:0.296 [NUMERICAL]\n",
            "\t112 : data:0.598 [NUMERICAL]\n",
            "\t112 : data:0.240 [NUMERICAL]\n",
            "\t111 : data:0.404 [NUMERICAL]\n",
            "\t110 : data:0.344 [NUMERICAL]\n",
            "\t109 : data:0.382 [NUMERICAL]\n",
            "\t108 : data:0.595 [NUMERICAL]\n",
            "\t108 : data:0.435 [NUMERICAL]\n",
            "\t107 : data:0.295 [NUMERICAL]\n",
            "\t107 : data:0.182 [NUMERICAL]\n",
            "\t106 : data:0.328 [NUMERICAL]\n",
            "\t103 : data:0.431 [NUMERICAL]\n",
            "\t102 : data:0.540 [NUMERICAL]\n",
            "\t102 : data:0.324 [NUMERICAL]\n",
            "\t102 : data:0.244 [NUMERICAL]\n",
            "\t101 : data:0.329 [NUMERICAL]\n",
            "\t99 : data:0.539 [NUMERICAL]\n",
            "\t99 : data:0.157 [NUMERICAL]\n",
            "\t98 : data:0.653 [NUMERICAL]\n",
            "\t98 : data:0.550 [NUMERICAL]\n",
            "\t98 : data:0.263 [NUMERICAL]\n",
            "\t97 : data:0.300 [NUMERICAL]\n",
            "\t94 : data:0.464 [NUMERICAL]\n",
            "\t94 : data:0.268 [NUMERICAL]\n",
            "\t94 : data:0.184 [NUMERICAL]\n",
            "\t94 : data:0.151 [NUMERICAL]\n",
            "\t93 : data:0.627 [NUMERICAL]\n",
            "\t93 : data:0.267 [NUMERICAL]\n",
            "\t91 : data:0.399 [NUMERICAL]\n",
            "\t90 : data:0.518 [NUMERICAL]\n",
            "\t90 : data:0.371 [NUMERICAL]\n",
            "\t90 : data:0.289 [NUMERICAL]\n",
            "\t88 : data:0.301 [NUMERICAL]\n",
            "\t86 : data:0.465 [NUMERICAL]\n",
            "\t83 : data:0.321 [NUMERICAL]\n",
            "\t83 : data:0.266 [NUMERICAL]\n",
            "\t83 : data:0.181 [NUMERICAL]\n",
            "\t80 : data:0.265 [NUMERICAL]\n",
            "\t80 : data:0.209 [NUMERICAL]\n",
            "\t79 : data:0.551 [NUMERICAL]\n",
            "\t79 : data:0.511 [NUMERICAL]\n",
            "\t79 : data:0.343 [NUMERICAL]\n",
            "\t79 : data:0.245 [NUMERICAL]\n",
            "\t79 : data:0.213 [NUMERICAL]\n",
            "\t78 : data:0.573 [NUMERICAL]\n",
            "\t78 : data:0.125 [NUMERICAL]\n",
            "\t77 : data:0.438 [NUMERICAL]\n",
            "\t77 : data:0.410 [NUMERICAL]\n",
            "\t77 : data:0.358 [NUMERICAL]\n",
            "\t77 : data:0.294 [NUMERICAL]\n",
            "\t77 : data:0.262 [NUMERICAL]\n",
            "\t76 : data:0.330 [NUMERICAL]\n",
            "\t76 : data:0.316 [NUMERICAL]\n",
            "\t76 : data:0.273 [NUMERICAL]\n",
            "\t75 : data:0.355 [NUMERICAL]\n",
            "\t75 : data:0.264 [NUMERICAL]\n",
            "\t75 : data:0.179 [NUMERICAL]\n",
            "\t73 : data:0.357 [NUMERICAL]\n",
            "\t72 : data:0.522 [NUMERICAL]\n",
            "\t72 : data:0.214 [NUMERICAL]\n",
            "\t72 : data:0.180 [NUMERICAL]\n",
            "\t72 : data:0.178 [NUMERICAL]\n",
            "\t71 : data:0.545 [NUMERICAL]\n",
            "\t71 : data:0.237 [NUMERICAL]\n",
            "\t70 : data:0.185 [NUMERICAL]\n",
            "\t69 : data:0.623 [NUMERICAL]\n",
            "\t69 : data:0.386 [NUMERICAL]\n",
            "\t68 : data:0.652 [NUMERICAL]\n",
            "\t67 : data:0.512 [NUMERICAL]\n",
            "\t67 : data:0.215 [NUMERICAL]\n",
            "\t65 : data:0.466 [NUMERICAL]\n",
            "\t65 : data:0.126 [NUMERICAL]\n",
            "\t64 : data:0.454 [NUMERICAL]\n",
            "\t63 : data:0.467 [NUMERICAL]\n",
            "\t62 : data:0.578 [NUMERICAL]\n",
            "\t61 : data:0.599 [NUMERICAL]\n",
            "\t61 : data:0.100 [NUMERICAL]\n",
            "\t60 : data:0.385 [NUMERICAL]\n",
            "\t59 : data:0.566 [NUMERICAL]\n",
            "\t59 : data:0.538 [NUMERICAL]\n",
            "\t59 : data:0.356 [NUMERICAL]\n",
            "\t57 : data:0.293 [NUMERICAL]\n",
            "\t57 : data:0.101 [NUMERICAL]\n",
            "\t56 : data:0.660 [NUMERICAL]\n",
            "\t56 : data:0.413 [NUMERICAL]\n",
            "\t56 : data:0.236 [NUMERICAL]\n",
            "\t56 : data:0.235 [NUMERICAL]\n",
            "\t56 : data:0.216 [NUMERICAL]\n",
            "\t55 : data:0.684 [NUMERICAL]\n",
            "\t55 : data:0.482 [NUMERICAL]\n",
            "\t55 : data:0.127 [NUMERICAL]\n",
            "\t54 : data:0.594 [NUMERICAL]\n",
            "\t54 : data:0.523 [NUMERICAL]\n",
            "\t54 : data:0.206 [NUMERICAL]\n",
            "\t53 : data:0.630 [NUMERICAL]\n",
            "\t53 : data:0.468 [NUMERICAL]\n",
            "\t53 : data:0.414 [NUMERICAL]\n",
            "\t52 : data:0.549 [NUMERICAL]\n",
            "\t52 : data:0.492 [NUMERICAL]\n",
            "\t52 : data:0.158 [NUMERICAL]\n",
            "\t51 : data:0.683 [NUMERICAL]\n",
            "\t51 : data:0.150 [NUMERICAL]\n",
            "\t49 : data:0.600 [NUMERICAL]\n",
            "\t49 : data:0.128 [NUMERICAL]\n",
            "\t48 : data:0.574 [NUMERICAL]\n",
            "\t48 : data:0.546 [NUMERICAL]\n",
            "\t48 : data:0.494 [NUMERICAL]\n",
            "\t48 : data:0.398 [NUMERICAL]\n",
            "\t47 : data:0.579 [NUMERICAL]\n",
            "\t47 : data:0.370 [NUMERICAL]\n",
            "\t46 : data:0.99 [NUMERICAL]\n",
            "\t46 : data:0.577 [NUMERICAL]\n",
            "\t46 : data:0.493 [NUMERICAL]\n",
            "\t45 : data:0.685 [NUMERICAL]\n",
            "\t45 : data:0.208 [NUMERICAL]\n",
            "\t44 : data:0.521 [NUMERICAL]\n",
            "\t44 : data:0.510 [NUMERICAL]\n",
            "\t44 : data:0.495 [NUMERICAL]\n",
            "\t44 : data:0.426 [NUMERICAL]\n",
            "\t44 : data:0.315 [NUMERICAL]\n",
            "\t43 : data:0.628 [NUMERICAL]\n",
            "\t43 : data:0.383 [NUMERICAL]\n",
            "\t42 : data:0.441 [NUMERICAL]\n",
            "\t42 : data:0.439 [NUMERICAL]\n",
            "\t42 : data:0.411 [NUMERICAL]\n",
            "\t42 : data:0.384 [NUMERICAL]\n",
            "\t41 : data:0.219 [NUMERICAL]\n",
            "\t40 : data:0.218 [NUMERICAL]\n",
            "\t40 : data:0.207 [NUMERICAL]\n",
            "\t39 : data:0.686 [NUMERICAL]\n",
            "\t39 : data:0.524 [NUMERICAL]\n",
            "\t39 : data:0.217 [NUMERICAL]\n",
            "\t39 : data:0.186 [NUMERICAL]\n",
            "\t38 : data:0.519 [NUMERICAL]\n",
            "\t38 : data:0.442 [NUMERICAL]\n",
            "\t38 : data:0.302 [NUMERICAL]\n",
            "\t37 : data:0.234 [NUMERICAL]\n",
            "\t37 : data:0.177 [NUMERICAL]\n",
            "\t36 : data:0.631 [NUMERICAL]\n",
            "\t36 : data:0.552 [NUMERICAL]\n",
            "\t36 : data:0.496 [NUMERICAL]\n",
            "\t36 : data:0.440 [NUMERICAL]\n",
            "\t36 : data:0.288 [NUMERICAL]\n",
            "\t36 : data:0.205 [NUMERICAL]\n",
            "\t35 : data:0.606 [NUMERICAL]\n",
            "\t35 : data:0.575 [NUMERICAL]\n",
            "\t35 : data:0.415 [NUMERICAL]\n",
            "\t35 : data:0.359 [NUMERICAL]\n",
            "\t35 : data:0.187 [NUMERICAL]\n",
            "\t34 : data:0.682 [NUMERICAL]\n",
            "\t33 : data:0.629 [NUMERICAL]\n",
            "\t33 : data:0.601 [NUMERICAL]\n",
            "\t33 : data:0.580 [NUMERICAL]\n",
            "\t33 : data:0.387 [NUMERICAL]\n",
            "\t33 : data:0.124 [NUMERICAL]\n",
            "\t32 : data:0.651 [NUMERICAL]\n",
            "\t32 : data:0.261 [NUMERICAL]\n",
            "\t32 : data:0.129 [NUMERICAL]\n",
            "\t30 : data:0.681 [NUMERICAL]\n",
            "\t30 : data:0.661 [NUMERICAL]\n",
            "\t30 : data:0.342 [NUMERICAL]\n",
            "\t30 : data:0.233 [NUMERICAL]\n",
            "\t29 : data:0.98 [NUMERICAL]\n",
            "\t29 : data:0.602 [NUMERICAL]\n",
            "\t29 : data:0.497 [NUMERICAL]\n",
            "\t28 : data:0.274 [NUMERICAL]\n",
            "\t27 : data:0.576 [NUMERICAL]\n",
            "\t27 : data:0.260 [NUMERICAL]\n",
            "\t27 : data:0.248 [NUMERICAL]\n",
            "\t26 : data:0.188 [NUMERICAL]\n",
            "\t25 : data:0.97 [NUMERICAL]\n",
            "\t25 : data:0.412 [NUMERICAL]\n",
            "\t24 : data:0.581 [NUMERICAL]\n",
            "\t24 : data:0.548 [NUMERICAL]\n",
            "\t24 : data:0.537 [NUMERICAL]\n",
            "\t24 : data:0.247 [NUMERICAL]\n",
            "\t24 : data:0.246 [NUMERICAL]\n",
            "\t24 : data:0.149 [NUMERICAL]\n",
            "\t24 : data:0.102 [NUMERICAL]\n",
            "\t23 : data:0.604 [NUMERICAL]\n",
            "\t23 : data:0.603 [NUMERICAL]\n",
            "\t22 : data:0.633 [NUMERICAL]\n",
            "\t22 : data:0.553 [NUMERICAL]\n",
            "\t22 : data:0.525 [NUMERICAL]\n",
            "\t22 : data:0.123 [NUMERICAL]\n",
            "\t21 : data:0.469 [NUMERICAL]\n",
            "\t21 : data:0.453 [NUMERICAL]\n",
            "\t20 : data:0.632 [NUMERICAL]\n",
            "\t20 : data:0.622 [NUMERICAL]\n",
            "\t20 : data:0.608 [NUMERICAL]\n",
            "\t20 : data:0.607 [NUMERICAL]\n",
            "\t20 : data:0.605 [NUMERICAL]\n",
            "\t20 : data:0.481 [NUMERICAL]\n",
            "\t20 : data:0.470 [NUMERICAL]\n",
            "\t20 : data:0.159 [NUMERICAL]\n",
            "\t19 : data:0.680 [NUMERICAL]\n",
            "\t19 : data:0.275 [NUMERICAL]\n",
            "\t19 : data:0.190 [NUMERICAL]\n",
            "\t18 : data:0.711 [NUMERICAL]\n",
            "\t18 : data:0.710 [NUMERICAL]\n",
            "\t18 : data:0.425 [NUMERICAL]\n",
            "\t18 : data:0.397 [NUMERICAL]\n",
            "\t17 : data:0.709 [NUMERICAL]\n",
            "\t17 : data:0.520 [NUMERICAL]\n",
            "\t16 : data:0.712 [NUMERICAL]\n",
            "\t16 : data:0.708 [NUMERICAL]\n",
            "\t16 : data:0.547 [NUMERICAL]\n",
            "\t16 : data:0.314 [NUMERICAL]\n",
            "\t16 : data:0.220 [NUMERICAL]\n",
            "\t15 : data:0.634 [NUMERICAL]\n",
            "\t15 : data:0.509 [NUMERICAL]\n",
            "\t14 : data:0.687 [NUMERICAL]\n",
            "\t14 : data:0.554 [NUMERICAL]\n",
            "\t14 : data:0.287 [NUMERICAL]\n",
            "\t14 : data:0.189 [NUMERICAL]\n",
            "\t13 : data:0.96 [NUMERICAL]\n",
            "\t13 : data:0.662 [NUMERICAL]\n",
            "\t13 : data:0.331 [NUMERICAL]\n",
            "\t13 : data:0.303 [NUMERICAL]\n",
            "\t13 : data:0.191 [NUMERICAL]\n",
            "\t12 : data:0.498 [NUMERICAL]\n",
            "\t12 : data:0.204 [NUMERICAL]\n",
            "\t12 : data:0.122 [NUMERICAL]\n",
            "\t11 : data:0.565 [NUMERICAL]\n",
            "\t11 : data:0.526 [NUMERICAL]\n",
            "\t11 : data:0.443 [NUMERICAL]\n",
            "\t11 : data:0.232 [NUMERICAL]\n",
            "\t11 : data:0.176 [NUMERICAL]\n",
            "\t10 : data:0.707 [NUMERICAL]\n",
            "\t10 : data:0.593 [NUMERICAL]\n",
            "\t10 : data:0.369 [NUMERICAL]\n",
            "\t10 : data:0.341 [NUMERICAL]\n",
            "\t10 : data:0.130 [NUMERICAL]\n",
            "\t9 : data:0.688 [NUMERICAL]\n",
            "\t9 : data:0.103 [NUMERICAL]\n",
            "\t8 : data:0.714 [NUMERICAL]\n",
            "\t8 : data:0.679 [NUMERICAL]\n",
            "\t8 : data:0.609 [NUMERICAL]\n",
            "\t8 : data:0.276 [NUMERICAL]\n",
            "\t8 : data:0.160 [NUMERICAL]\n",
            "\t8 : data:0.131 [NUMERICAL]\n",
            "\t7 : data:0.582 [NUMERICAL]\n",
            "\t5 : data:0.716 [NUMERICAL]\n",
            "\t5 : data:0.68 [NUMERICAL]\n",
            "\t5 : data:0.286 [NUMERICAL]\n",
            "\t4 : data:0.718 [NUMERICAL]\n",
            "\t4 : data:0.715 [NUMERICAL]\n",
            "\t4 : data:0.713 [NUMERICAL]\n",
            "\t4 : data:0.70 [NUMERICAL]\n",
            "\t4 : data:0.690 [NUMERICAL]\n",
            "\t4 : data:0.663 [NUMERICAL]\n",
            "\t4 : data:0.635 [NUMERICAL]\n",
            "\t4 : data:0.555 [NUMERICAL]\n",
            "\t4 : data:0.499 [NUMERICAL]\n",
            "\t4 : data:0.471 [NUMERICAL]\n",
            "\t4 : data:0.231 [NUMERICAL]\n",
            "\t4 : data:0.192 [NUMERICAL]\n",
            "\t4 : data:0.162 [NUMERICAL]\n",
            "\t4 : data:0.161 [NUMERICAL]\n",
            "\t4 : data:0.121 [NUMERICAL]\n",
            "\t4 : data:0.104 [NUMERICAL]\n",
            "\t3 : data:0.95 [NUMERICAL]\n",
            "\t3 : data:0.69 [NUMERICAL]\n",
            "\t3 : data:0.689 [NUMERICAL]\n",
            "\t3 : data:0.536 [NUMERICAL]\n",
            "\t3 : data:0.528 [NUMERICAL]\n",
            "\t3 : data:0.508 [NUMERICAL]\n",
            "\t3 : data:0.259 [NUMERICAL]\n",
            "\t3 : data:0.258 [NUMERICAL]\n",
            "\t2 : data:0.742 [NUMERICAL]\n",
            "\t2 : data:0.741 [NUMERICAL]\n",
            "\t2 : data:0.740 [NUMERICAL]\n",
            "\t2 : data:0.739 [NUMERICAL]\n",
            "\t2 : data:0.73 [NUMERICAL]\n",
            "\t2 : data:0.717 [NUMERICAL]\n",
            "\t2 : data:0.71 [NUMERICAL]\n",
            "\t2 : data:0.650 [NUMERICAL]\n",
            "\t2 : data:0.621 [NUMERICAL]\n",
            "\t2 : data:0.583 [NUMERICAL]\n",
            "\t2 : data:0.564 [NUMERICAL]\n",
            "\t2 : data:0.527 [NUMERICAL]\n",
            "\t2 : data:0.452 [NUMERICAL]\n",
            "\t2 : data:0.444 [NUMERICAL]\n",
            "\t2 : data:0.388 [NUMERICAL]\n",
            "\t2 : data:0.304 [NUMERICAL]\n",
            "\t2 : data:0.230 [NUMERICAL]\n",
            "\t2 : data:0.203 [NUMERICAL]\n",
            "\t2 : data:0.175 [NUMERICAL]\n",
            "\t2 : data:0.148 [NUMERICAL]\n",
            "\t1 : data:0.94 [NUMERICAL]\n",
            "\t1 : data:0.93 [NUMERICAL]\n",
            "\t1 : data:0.743 [NUMERICAL]\n",
            "\t1 : data:0.706 [NUMERICAL]\n",
            "\t1 : data:0.705 [NUMERICAL]\n",
            "\t1 : data:0.691 [NUMERICAL]\n",
            "\t1 : data:0.678 [NUMERICAL]\n",
            "\t1 : data:0.67 [NUMERICAL]\n",
            "\t1 : data:0.637 [NUMERICAL]\n",
            "\t1 : data:0.636 [NUMERICAL]\n",
            "\t1 : data:0.610 [NUMERICAL]\n",
            "\t1 : data:0.592 [NUMERICAL]\n",
            "\t1 : data:0.529 [NUMERICAL]\n",
            "\t1 : data:0.480 [NUMERICAL]\n",
            "\t1 : data:0.473 [NUMERICAL]\n",
            "\t1 : data:0.472 [NUMERICAL]\n",
            "\t1 : data:0.396 [NUMERICAL]\n",
            "\t1 : data:0.313 [NUMERICAL]\n",
            "\t1 : data:0.285 [NUMERICAL]\n",
            "\t1 : data:0.277 [NUMERICAL]\n",
            "\t1 : data:0.249 [NUMERICAL]\n",
            "\t1 : data:0.222 [NUMERICAL]\n",
            "\t1 : data:0.221 [NUMERICAL]\n",
            "\t1 : data:0.147 [NUMERICAL]\n",
            "\t1 : data:0.135 [NUMERICAL]\n",
            "\t1 : data:0.134 [NUMERICAL]\n",
            "\t1 : data:0.133 [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t1166322 : HigherCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t500 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t1500 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t3500 : HigherCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t7500 : HigherCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t31496 : HigherCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.830498 logloss:6.10945\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.90397 logloss:1.33512\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.938795 logloss:0.568085\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:0.950167 logloss:0.393499\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:0.954833 logloss:0.323543\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:0.957533 logloss:0.293047\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:0.9596 logloss:0.273547\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:0.960867 logloss:0.263795\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:0.961533 logloss:0.255504\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:0.962517 logloss:0.250962\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:0.963167 logloss:0.245924\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:0.9634 logloss:0.242079\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:0.964 logloss:0.240756\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:0.96425 logloss:0.238417\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:0.964533 logloss:0.236996\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:0.96485 logloss:0.234643\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:0.964983 logloss:0.232777\n",
            "\ttrees: 171, Out-of-bag evaluation: accuracy:0.964933 logloss:0.231719\n",
            "\ttrees: 181, Out-of-bag evaluation: accuracy:0.964983 logloss:0.231038\n",
            "\ttrees: 191, Out-of-bag evaluation: accuracy:0.965133 logloss:0.230806\n",
            "\ttrees: 201, Out-of-bag evaluation: accuracy:0.965267 logloss:0.229063\n",
            "\ttrees: 211, Out-of-bag evaluation: accuracy:0.965233 logloss:0.228445\n",
            "\ttrees: 221, Out-of-bag evaluation: accuracy:0.965717 logloss:0.22814\n",
            "\ttrees: 231, Out-of-bag evaluation: accuracy:0.96555 logloss:0.227411\n",
            "\ttrees: 241, Out-of-bag evaluation: accuracy:0.965733 logloss:0.227197\n",
            "\ttrees: 251, Out-of-bag evaluation: accuracy:0.9659 logloss:0.227128\n",
            "\ttrees: 261, Out-of-bag evaluation: accuracy:0.966067 logloss:0.227147\n",
            "\ttrees: 271, Out-of-bag evaluation: accuracy:0.966 logloss:0.227069\n",
            "\ttrees: 281, Out-of-bag evaluation: accuracy:0.965883 logloss:0.226611\n",
            "\ttrees: 291, Out-of-bag evaluation: accuracy:0.965917 logloss:0.226496\n",
            "\ttrees: 301, Out-of-bag evaluation: accuracy:0.9659 logloss:0.226489\n",
            "\ttrees: 311, Out-of-bag evaluation: accuracy:0.966133 logloss:0.226479\n",
            "\ttrees: 321, Out-of-bag evaluation: accuracy:0.966217 logloss:0.22645\n",
            "\ttrees: 331, Out-of-bag evaluation: accuracy:0.96625 logloss:0.226421\n",
            "\ttrees: 341, Out-of-bag evaluation: accuracy:0.96605 logloss:0.225929\n",
            "\ttrees: 351, Out-of-bag evaluation: accuracy:0.966233 logloss:0.22578\n",
            "\ttrees: 361, Out-of-bag evaluation: accuracy:0.966367 logloss:0.225249\n",
            "\ttrees: 371, Out-of-bag evaluation: accuracy:0.966533 logloss:0.224674\n",
            "\ttrees: 381, Out-of-bag evaluation: accuracy:0.966567 logloss:0.224576\n",
            "\ttrees: 391, Out-of-bag evaluation: accuracy:0.966783 logloss:0.224497\n",
            "\ttrees: 401, Out-of-bag evaluation: accuracy:0.966667 logloss:0.224493\n",
            "\ttrees: 411, Out-of-bag evaluation: accuracy:0.966767 logloss:0.224461\n",
            "\ttrees: 421, Out-of-bag evaluation: accuracy:0.966583 logloss:0.224394\n",
            "\ttrees: 431, Out-of-bag evaluation: accuracy:0.966717 logloss:0.22435\n",
            "\ttrees: 441, Out-of-bag evaluation: accuracy:0.966717 logloss:0.224336\n",
            "\ttrees: 451, Out-of-bag evaluation: accuracy:0.966717 logloss:0.22425\n",
            "\ttrees: 461, Out-of-bag evaluation: accuracy:0.966817 logloss:0.224198\n",
            "\ttrees: 471, Out-of-bag evaluation: accuracy:0.96685 logloss:0.224122\n",
            "\ttrees: 481, Out-of-bag evaluation: accuracy:0.966833 logloss:0.224085\n",
            "\ttrees: 491, Out-of-bag evaluation: accuracy:0.966817 logloss:0.22406\n",
            "\ttrees: 500, Out-of-bag evaluation: accuracy:0.966867 logloss:0.224047\n",
            "\n",
            "313/313 [==============================] - 3s 5ms/step - loss: 0.0000e+00 - accuracy: 0.9656\n"
          ]
        }
      ]
    }
  ]
}